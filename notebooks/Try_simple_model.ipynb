{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from gensim.models import word2vec\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler# 好处在于可以保存训练集中的参数（均值、方差）\n",
    "from scipy.stats import stats\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "import gc\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../codes/self_defined_function.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing and feature selection\n",
    "take ArtNr '200032' as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/Artikelbewegungen ab 1996.txt', sep=';', encoding = 'ISO-8859-1', header=None)\n",
    "#df = pd.read_excel('../data/Artikelbewegungen.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid table create\n",
    "tmp = create_grid_data_for_an_article('200032', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection, only weekday\n",
    "tmp['weekday'] = tmp.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove weekend\n",
    "tmp = tmp[tmp['weekday'] != 5]\n",
    "tmp = tmp[tmp['weekday'] != 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset_from_timeseries(df, targetname = 'Menge', lookback = 5):\n",
    "    \"\"\"\n",
    "    df should not contain the features, which will not used in the traning of the model\n",
    "    \"\"\"\n",
    "    for i in range(lookback):\n",
    "        df[targetname+'_'+str(i+1)] = df[targetname].shift(i+1)\n",
    "    cols = df.columns.to_list()\n",
    "    cols_x = [i for i in cols if i not in [targetname]]\n",
    "    cols_y = [targetname]\n",
    "    dat_x = df[cols_x].iloc[lookback:, :].values\n",
    "    dat_y = df[cols_y].iloc[lookback:, :].values\n",
    "    return dat_x, dat_y\n",
    "def extract_dataset_from_timeseries_with_diff(df, targetname = 'Menge', lookback = 5):\n",
    "    \"\"\"\n",
    "    df should not contain the features, which will not used in the traning of the model\n",
    "    \"\"\"\n",
    "    for i in range(lookback):\n",
    "        df[targetname+'_'+str(i+1)] = df[targetname].shift(i+1)\n",
    "    if lookback >=5:\n",
    "        df['diff_1'] = df[targetname+'_'+str(1)] - df[targetname+'_'+str(2)]\n",
    "        df['diff_2'] = df[targetname+'_'+str(3)] - df[targetname+'_'+str(4)]\n",
    "        df['diff2_1'] = df['diff_1'] - df['diff_2']\n",
    "    cols = df.columns.to_list()\n",
    "    cols_x = [i for i in cols if i not in [targetname]]\n",
    "    cols_y = [targetname]\n",
    "    dat_x = df[cols_x].iloc[lookback:, :].values\n",
    "    dat_y = df[cols_y].iloc[lookback:, :].values\n",
    "    return dat_x, dat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset for mlp\n",
    "dat_x, dat_y = extract_dataset_from_timeseries_with_diff(tmp, lookback = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dat_x[:2589, :]\n",
    "test_x = dat_x[2589:, :]\n",
    "train_y = dat_y[:2589, :].reshape(-1)\n",
    "test_y = dat_y[2589:, :].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to the local system\n",
    "np.save('../data/rnn_train_x', train_x)\n",
    "np.save('../data/rnn_train_y', train_y)\n",
    "np.save('../data/rnn_test_x', test_x)\n",
    "np.save('../data/rnn_test_y', test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset for lstm\n",
    "dat_x, dat_y = extract_dataset_from_timeseries(tmp[['Menge']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dat_x[:2589, :].reshape(-1, 4, 1)\n",
    "test_x = dat_x[2589:, :].reshape(-1, 4, 1)\n",
    "train_y = dat_y[:2589, :].reshape(-1)\n",
    "test_y = dat_y[2589:, :].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/rnn_train_x', train_x)\n",
    "np.save('../data/rnn_train_y', train_y)\n",
    "np.save('../data/rnn_test_x', test_x)\n",
    "np.save('../data/rnn_test_y', test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test data\n",
    "train_y = train_x[:,1] * 10 + 2 - 3\n",
    "test_y = test_x[:, 1] * 10 + 2 - 3\n",
    "np.save('../data/rnn_train_x', train_x)\n",
    "np.save('../data/rnn_train_y', train_y)\n",
    "np.save('../data/rnn_test_x', test_x)\n",
    "np.save('../data/rnn_test_y', test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2589, 4, 1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with mlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/2589 (0%)]\tLoss: 1034.118408\n",
      "Train Epoch: 0 [300/2589 (12%)]\tLoss: 1287.755859\n",
      "Train Epoch: 0 [600/2589 (23%)]\tLoss: 857.657104\n",
      "Train Epoch: 0 [900/2589 (35%)]\tLoss: 1040.218750\n",
      "Train Epoch: 0 [1200/2589 (46%)]\tLoss: 1278.734009\n",
      "Train Epoch: 0 [1500/2589 (58%)]\tLoss: 1119.141235\n",
      "Train Epoch: 0 [1800/2589 (70%)]\tLoss: 984.965698\n",
      "Train Epoch: 0 [2100/2589 (81%)]\tLoss: 763.185852\n",
      "Train Epoch: 0 [2400/2589 (93%)]\tLoss: 1194.788208\n",
      "====> Epoch: 0 Average train loss: 1124.0521\n",
      "====> Epoch: 0 Average test loss: 1248.1989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2589 (0%)]\tLoss: 1058.995361\n",
      "Train Epoch: 1 [300/2589 (12%)]\tLoss: 1365.283447\n",
      "Train Epoch: 1 [600/2589 (23%)]\tLoss: 915.353271\n",
      "Train Epoch: 1 [900/2589 (35%)]\tLoss: 1068.613159\n",
      "Train Epoch: 1 [1200/2589 (46%)]\tLoss: 827.312439\n",
      "Train Epoch: 1 [1500/2589 (58%)]\tLoss: 1011.582031\n",
      "Train Epoch: 1 [1800/2589 (70%)]\tLoss: 836.534302\n",
      "Train Epoch: 1 [2100/2589 (81%)]\tLoss: 1217.847656\n",
      "Train Epoch: 1 [2400/2589 (93%)]\tLoss: 1245.559692\n",
      "====> Epoch: 1 Average train loss: 940.8314\n",
      "====> Epoch: 1 Average test loss: 984.0328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/2589 (0%)]\tLoss: 974.218140\n",
      "Train Epoch: 2 [300/2589 (12%)]\tLoss: 1053.898926\n",
      "Train Epoch: 2 [600/2589 (23%)]\tLoss: 839.788513\n",
      "Train Epoch: 2 [900/2589 (35%)]\tLoss: 566.921204\n",
      "Train Epoch: 2 [1200/2589 (46%)]\tLoss: 817.167053\n",
      "Train Epoch: 2 [1500/2589 (58%)]\tLoss: 487.572174\n",
      "Train Epoch: 2 [1800/2589 (70%)]\tLoss: 493.112701\n",
      "Train Epoch: 2 [2100/2589 (81%)]\tLoss: 715.618958\n",
      "Train Epoch: 2 [2400/2589 (93%)]\tLoss: 536.647095\n",
      "====> Epoch: 2 Average train loss: 759.3914\n",
      "====> Epoch: 2 Average test loss: 902.6270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [0/2589 (0%)]\tLoss: 816.065369\n",
      "Train Epoch: 3 [300/2589 (12%)]\tLoss: 679.389343\n",
      "Train Epoch: 3 [600/2589 (23%)]\tLoss: 799.853577\n",
      "Train Epoch: 3 [900/2589 (35%)]\tLoss: 826.399475\n",
      "Train Epoch: 3 [1200/2589 (46%)]\tLoss: 587.113586\n",
      "Train Epoch: 3 [1500/2589 (58%)]\tLoss: 506.178406\n",
      "Train Epoch: 3 [1800/2589 (70%)]\tLoss: 610.702087\n",
      "Train Epoch: 3 [2100/2589 (81%)]\tLoss: 615.046997\n",
      "Train Epoch: 3 [2400/2589 (93%)]\tLoss: 550.841248\n",
      "====> Epoch: 3 Average train loss: 689.2419\n",
      "====> Epoch: 3 Average test loss: 888.2711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [0/2589 (0%)]\tLoss: 726.119263\n",
      "Train Epoch: 4 [300/2589 (12%)]\tLoss: 736.628357\n",
      "Train Epoch: 4 [600/2589 (23%)]\tLoss: 632.222595\n",
      "Train Epoch: 4 [900/2589 (35%)]\tLoss: 741.041077\n",
      "Train Epoch: 4 [1200/2589 (46%)]\tLoss: 820.840454\n",
      "Train Epoch: 4 [1500/2589 (58%)]\tLoss: 697.835083\n",
      "Train Epoch: 4 [1800/2589 (70%)]\tLoss: 725.500244\n",
      "Train Epoch: 4 [2100/2589 (81%)]\tLoss: 488.669830\n",
      "Train Epoch: 4 [2400/2589 (93%)]\tLoss: 746.513062\n",
      "====> Epoch: 4 Average train loss: 674.1551\n",
      "====> Epoch: 4 Average test loss: 866.5549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/2589 (0%)]\tLoss: 573.769165\n",
      "Train Epoch: 5 [300/2589 (12%)]\tLoss: 709.228882\n",
      "Train Epoch: 5 [600/2589 (23%)]\tLoss: 556.298157\n",
      "Train Epoch: 5 [900/2589 (35%)]\tLoss: 521.945312\n",
      "Train Epoch: 5 [1200/2589 (46%)]\tLoss: 513.300171\n",
      "Train Epoch: 5 [1500/2589 (58%)]\tLoss: 725.674805\n",
      "Train Epoch: 5 [1800/2589 (70%)]\tLoss: 703.434875\n",
      "Train Epoch: 5 [2100/2589 (81%)]\tLoss: 656.334717\n",
      "Train Epoch: 5 [2400/2589 (93%)]\tLoss: 503.350525\n",
      "====> Epoch: 5 Average train loss: 653.7802\n",
      "====> Epoch: 5 Average test loss: 869.5367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [0/2589 (0%)]\tLoss: 555.971985\n",
      "Train Epoch: 6 [300/2589 (12%)]\tLoss: 682.222595\n",
      "Train Epoch: 6 [600/2589 (23%)]\tLoss: 596.391418\n",
      "Train Epoch: 6 [900/2589 (35%)]\tLoss: 591.607300\n",
      "Train Epoch: 6 [1200/2589 (46%)]\tLoss: 662.716248\n",
      "Train Epoch: 6 [1500/2589 (58%)]\tLoss: 475.148773\n",
      "Train Epoch: 6 [1800/2589 (70%)]\tLoss: 651.677612\n",
      "Train Epoch: 6 [2100/2589 (81%)]\tLoss: 721.373657\n",
      "Train Epoch: 6 [2400/2589 (93%)]\tLoss: 746.892700\n",
      "====> Epoch: 6 Average train loss: 641.6806\n",
      "====> Epoch: 6 Average test loss: 866.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [0/2589 (0%)]\tLoss: 618.348999\n",
      "Train Epoch: 7 [300/2589 (12%)]\tLoss: 712.786804\n",
      "Train Epoch: 7 [600/2589 (23%)]\tLoss: 650.264648\n",
      "Train Epoch: 7 [900/2589 (35%)]\tLoss: 656.344971\n",
      "Train Epoch: 7 [1200/2589 (46%)]\tLoss: 658.390869\n",
      "Train Epoch: 7 [1500/2589 (58%)]\tLoss: 531.723633\n",
      "Train Epoch: 7 [1800/2589 (70%)]\tLoss: 708.957336\n",
      "Train Epoch: 7 [2100/2589 (81%)]\tLoss: 600.540100\n",
      "Train Epoch: 7 [2400/2589 (93%)]\tLoss: 657.737915\n",
      "====> Epoch: 7 Average train loss: 630.3264\n",
      "====> Epoch: 7 Average test loss: 875.1235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [0/2589 (0%)]\tLoss: 452.755554\n",
      "Train Epoch: 8 [300/2589 (12%)]\tLoss: 547.470520\n",
      "Train Epoch: 8 [600/2589 (23%)]\tLoss: 821.385803\n",
      "Train Epoch: 8 [900/2589 (35%)]\tLoss: 549.443909\n",
      "Train Epoch: 8 [1200/2589 (46%)]\tLoss: 594.273865\n",
      "Train Epoch: 8 [1500/2589 (58%)]\tLoss: 629.631592\n",
      "Train Epoch: 8 [1800/2589 (70%)]\tLoss: 645.890442\n",
      "Train Epoch: 8 [2100/2589 (81%)]\tLoss: 561.455933\n",
      "Train Epoch: 8 [2400/2589 (93%)]\tLoss: 595.500793\n",
      "====> Epoch: 8 Average train loss: 623.2726\n",
      "====> Epoch: 8 Average test loss: 881.2080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/2589 (0%)]\tLoss: 595.696045\n",
      "Train Epoch: 9 [300/2589 (12%)]\tLoss: 690.179626\n",
      "Train Epoch: 9 [600/2589 (23%)]\tLoss: 728.523438\n",
      "Train Epoch: 9 [900/2589 (35%)]\tLoss: 476.530487\n",
      "Train Epoch: 9 [1200/2589 (46%)]\tLoss: 682.819763\n",
      "Train Epoch: 9 [1500/2589 (58%)]\tLoss: 452.055756\n",
      "Train Epoch: 9 [1800/2589 (70%)]\tLoss: 590.863953\n",
      "Train Epoch: 9 [2100/2589 (81%)]\tLoss: 548.569519\n",
      "Train Epoch: 9 [2400/2589 (93%)]\tLoss: 724.425415\n",
      "====> Epoch: 9 Average train loss: 608.1130\n",
      "====> Epoch: 9 Average test loss: 880.1544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [0/2589 (0%)]\tLoss: 486.986816\n",
      "Train Epoch: 10 [300/2589 (12%)]\tLoss: 627.999451\n",
      "Train Epoch: 10 [600/2589 (23%)]\tLoss: 593.190979\n",
      "Train Epoch: 10 [900/2589 (35%)]\tLoss: 597.857666\n",
      "Train Epoch: 10 [1200/2589 (46%)]\tLoss: 560.259888\n",
      "Train Epoch: 10 [1500/2589 (58%)]\tLoss: 618.617859\n",
      "Train Epoch: 10 [1800/2589 (70%)]\tLoss: 408.853394\n",
      "Train Epoch: 10 [2100/2589 (81%)]\tLoss: 624.896240\n",
      "Train Epoch: 10 [2400/2589 (93%)]\tLoss: 638.011841\n",
      "====> Epoch: 10 Average train loss: 598.1495\n",
      "====> Epoch: 10 Average test loss: 873.0856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [0/2589 (0%)]\tLoss: 636.713196\n",
      "Train Epoch: 11 [300/2589 (12%)]\tLoss: 454.728790\n",
      "Train Epoch: 11 [600/2589 (23%)]\tLoss: 432.179535\n",
      "Train Epoch: 11 [900/2589 (35%)]\tLoss: 752.641907\n",
      "Train Epoch: 11 [1200/2589 (46%)]\tLoss: 615.634155\n",
      "Train Epoch: 11 [1500/2589 (58%)]\tLoss: 769.405823\n",
      "Train Epoch: 11 [1800/2589 (70%)]\tLoss: 616.921631\n",
      "Train Epoch: 11 [2100/2589 (81%)]\tLoss: 606.082214\n",
      "Train Epoch: 11 [2400/2589 (93%)]\tLoss: 537.269714\n",
      "====> Epoch: 11 Average train loss: 583.6353\n",
      "====> Epoch: 11 Average test loss: 884.1157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [0/2589 (0%)]\tLoss: 531.289490\n",
      "Train Epoch: 12 [300/2589 (12%)]\tLoss: 594.013123\n",
      "Train Epoch: 12 [600/2589 (23%)]\tLoss: 529.759033\n",
      "Train Epoch: 12 [900/2589 (35%)]\tLoss: 438.398346\n",
      "Train Epoch: 12 [1200/2589 (46%)]\tLoss: 368.092499\n",
      "Train Epoch: 12 [1500/2589 (58%)]\tLoss: 485.672150\n",
      "Train Epoch: 12 [1800/2589 (70%)]\tLoss: 604.298096\n",
      "Train Epoch: 12 [2100/2589 (81%)]\tLoss: 628.296814\n",
      "Train Epoch: 12 [2400/2589 (93%)]\tLoss: 413.055176\n",
      "====> Epoch: 12 Average train loss: 576.5279\n",
      "====> Epoch: 12 Average test loss: 874.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [0/2589 (0%)]\tLoss: 456.176849\n",
      "Train Epoch: 13 [300/2589 (12%)]\tLoss: 448.134949\n",
      "Train Epoch: 13 [600/2589 (23%)]\tLoss: 621.687683\n",
      "Train Epoch: 13 [900/2589 (35%)]\tLoss: 584.987671\n",
      "Train Epoch: 13 [1200/2589 (46%)]\tLoss: 647.064819\n",
      "Train Epoch: 13 [1500/2589 (58%)]\tLoss: 517.975708\n",
      "Train Epoch: 13 [1800/2589 (70%)]\tLoss: 621.737915\n",
      "Train Epoch: 13 [2100/2589 (81%)]\tLoss: 490.450195\n",
      "Train Epoch: 13 [2400/2589 (93%)]\tLoss: 665.291382\n",
      "====> Epoch: 13 Average train loss: 569.4730\n",
      "====> Epoch: 13 Average test loss: 881.3408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [0/2589 (0%)]\tLoss: 472.963226\n",
      "Train Epoch: 14 [300/2589 (12%)]\tLoss: 647.286560\n",
      "Train Epoch: 14 [600/2589 (23%)]\tLoss: 670.813538\n",
      "Train Epoch: 14 [900/2589 (35%)]\tLoss: 485.149872\n",
      "Train Epoch: 14 [1200/2589 (46%)]\tLoss: 458.461243\n",
      "Train Epoch: 14 [1500/2589 (58%)]\tLoss: 556.832275\n",
      "Train Epoch: 14 [1800/2589 (70%)]\tLoss: 533.122742\n",
      "Train Epoch: 14 [2100/2589 (81%)]\tLoss: 457.956909\n",
      "Train Epoch: 14 [2400/2589 (93%)]\tLoss: 769.373352\n",
      "====> Epoch: 14 Average train loss: 558.3900\n",
      "====> Epoch: 14 Average test loss: 883.7785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [0/2589 (0%)]\tLoss: 470.398407\n",
      "Train Epoch: 15 [300/2589 (12%)]\tLoss: 497.408539\n",
      "Train Epoch: 15 [600/2589 (23%)]\tLoss: 769.868774\n",
      "Train Epoch: 15 [900/2589 (35%)]\tLoss: 488.938324\n",
      "Train Epoch: 15 [1200/2589 (46%)]\tLoss: 574.893616\n",
      "Train Epoch: 15 [1500/2589 (58%)]\tLoss: 562.018188\n",
      "Train Epoch: 15 [1800/2589 (70%)]\tLoss: 548.969116\n",
      "Train Epoch: 15 [2100/2589 (81%)]\tLoss: 544.554138\n",
      "Train Epoch: 15 [2400/2589 (93%)]\tLoss: 422.059967\n",
      "====> Epoch: 15 Average train loss: 551.7845\n",
      "====> Epoch: 15 Average test loss: 895.6132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [0/2589 (0%)]\tLoss: 533.333679\n",
      "Train Epoch: 16 [300/2589 (12%)]\tLoss: 440.410553\n",
      "Train Epoch: 16 [600/2589 (23%)]\tLoss: 729.725403\n",
      "Train Epoch: 16 [900/2589 (35%)]\tLoss: 477.464966\n",
      "Train Epoch: 16 [1200/2589 (46%)]\tLoss: 648.695068\n",
      "Train Epoch: 16 [1500/2589 (58%)]\tLoss: 556.325012\n",
      "Train Epoch: 16 [1800/2589 (70%)]\tLoss: 396.364136\n",
      "Train Epoch: 16 [2100/2589 (81%)]\tLoss: 537.271484\n",
      "Train Epoch: 16 [2400/2589 (93%)]\tLoss: 668.029419\n",
      "====> Epoch: 16 Average train loss: 544.1252\n",
      "====> Epoch: 16 Average test loss: 894.0781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [0/2589 (0%)]\tLoss: 418.173126\n",
      "Train Epoch: 17 [300/2589 (12%)]\tLoss: 428.842773\n",
      "Train Epoch: 17 [600/2589 (23%)]\tLoss: 583.443298\n",
      "Train Epoch: 17 [900/2589 (35%)]\tLoss: 507.480591\n",
      "Train Epoch: 17 [1200/2589 (46%)]\tLoss: 485.887817\n",
      "Train Epoch: 17 [1500/2589 (58%)]\tLoss: 400.461639\n",
      "Train Epoch: 17 [1800/2589 (70%)]\tLoss: 649.962646\n",
      "Train Epoch: 17 [2100/2589 (81%)]\tLoss: 564.781372\n",
      "Train Epoch: 17 [2400/2589 (93%)]\tLoss: 551.142639\n",
      "====> Epoch: 17 Average train loss: 540.3969\n",
      "====> Epoch: 17 Average test loss: 889.4615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [0/2589 (0%)]\tLoss: 570.609436\n",
      "Train Epoch: 18 [300/2589 (12%)]\tLoss: 583.955933\n",
      "Train Epoch: 18 [600/2589 (23%)]\tLoss: 541.332153\n",
      "Train Epoch: 18 [900/2589 (35%)]\tLoss: 643.010864\n",
      "Train Epoch: 18 [1200/2589 (46%)]\tLoss: 558.167175\n",
      "Train Epoch: 18 [1500/2589 (58%)]\tLoss: 496.657532\n",
      "Train Epoch: 18 [1800/2589 (70%)]\tLoss: 522.277771\n",
      "Train Epoch: 18 [2100/2589 (81%)]\tLoss: 516.689331\n",
      "Train Epoch: 18 [2400/2589 (93%)]\tLoss: 524.578979\n",
      "====> Epoch: 18 Average train loss: 531.3946\n",
      "====> Epoch: 18 Average test loss: 891.0446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [0/2589 (0%)]\tLoss: 666.726196\n",
      "Train Epoch: 19 [300/2589 (12%)]\tLoss: 449.321686\n",
      "Train Epoch: 19 [600/2589 (23%)]\tLoss: 433.826965\n",
      "Train Epoch: 19 [900/2589 (35%)]\tLoss: 371.625031\n",
      "Train Epoch: 19 [1200/2589 (46%)]\tLoss: 611.963135\n",
      "Train Epoch: 19 [1500/2589 (58%)]\tLoss: 494.973907\n",
      "Train Epoch: 19 [1800/2589 (70%)]\tLoss: 483.578156\n",
      "Train Epoch: 19 [2100/2589 (81%)]\tLoss: 606.826843\n",
      "Train Epoch: 19 [2400/2589 (93%)]\tLoss: 616.726196\n",
      "====> Epoch: 19 Average train loss: 522.7849\n",
      "====> Epoch: 19 Average test loss: 897.2014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [0/2589 (0%)]\tLoss: 478.045074\n",
      "Train Epoch: 20 [300/2589 (12%)]\tLoss: 656.875916\n",
      "Train Epoch: 20 [600/2589 (23%)]\tLoss: 574.543945\n",
      "Train Epoch: 20 [900/2589 (35%)]\tLoss: 458.922333\n",
      "Train Epoch: 20 [1200/2589 (46%)]\tLoss: 514.171143\n",
      "Train Epoch: 20 [1500/2589 (58%)]\tLoss: 486.906036\n",
      "Train Epoch: 20 [1800/2589 (70%)]\tLoss: 651.012451\n",
      "Train Epoch: 20 [2100/2589 (81%)]\tLoss: 421.139618\n",
      "Train Epoch: 20 [2400/2589 (93%)]\tLoss: 566.788330\n",
      "====> Epoch: 20 Average train loss: 518.8209\n",
      "====> Epoch: 20 Average test loss: 899.2273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [0/2589 (0%)]\tLoss: 491.888031\n",
      "Train Epoch: 21 [300/2589 (12%)]\tLoss: 514.692810\n",
      "Train Epoch: 21 [600/2589 (23%)]\tLoss: 554.045166\n",
      "Train Epoch: 21 [900/2589 (35%)]\tLoss: 519.960022\n",
      "Train Epoch: 21 [1200/2589 (46%)]\tLoss: 600.433777\n",
      "Train Epoch: 21 [1500/2589 (58%)]\tLoss: 588.287170\n",
      "Train Epoch: 21 [1800/2589 (70%)]\tLoss: 585.802612\n",
      "Train Epoch: 21 [2100/2589 (81%)]\tLoss: 567.372742\n",
      "Train Epoch: 21 [2400/2589 (93%)]\tLoss: 460.017609\n",
      "====> Epoch: 21 Average train loss: 510.5963\n",
      "====> Epoch: 21 Average test loss: 923.9307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [0/2589 (0%)]\tLoss: 740.969543\n",
      "Train Epoch: 22 [300/2589 (12%)]\tLoss: 457.388153\n",
      "Train Epoch: 22 [600/2589 (23%)]\tLoss: 407.566986\n",
      "Train Epoch: 22 [900/2589 (35%)]\tLoss: 510.550262\n",
      "Train Epoch: 22 [1200/2589 (46%)]\tLoss: 658.720337\n",
      "Train Epoch: 22 [1500/2589 (58%)]\tLoss: 524.640991\n",
      "Train Epoch: 22 [1800/2589 (70%)]\tLoss: 456.696289\n",
      "Train Epoch: 22 [2100/2589 (81%)]\tLoss: 518.256042\n",
      "Train Epoch: 22 [2400/2589 (93%)]\tLoss: 394.935120\n",
      "====> Epoch: 22 Average train loss: 508.6902\n",
      "====> Epoch: 22 Average test loss: 894.5046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [0/2589 (0%)]\tLoss: 408.072693\n",
      "Train Epoch: 23 [300/2589 (12%)]\tLoss: 454.774384\n",
      "Train Epoch: 23 [600/2589 (23%)]\tLoss: 392.284637\n",
      "Train Epoch: 23 [900/2589 (35%)]\tLoss: 548.875793\n",
      "Train Epoch: 23 [1200/2589 (46%)]\tLoss: 536.004456\n",
      "Train Epoch: 23 [1500/2589 (58%)]\tLoss: 413.383240\n",
      "Train Epoch: 23 [1800/2589 (70%)]\tLoss: 418.218872\n",
      "Train Epoch: 23 [2100/2589 (81%)]\tLoss: 525.714050\n",
      "Train Epoch: 23 [2400/2589 (93%)]\tLoss: 424.650482\n",
      "====> Epoch: 23 Average train loss: 493.9523\n",
      "====> Epoch: 23 Average test loss: 891.5113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [0/2589 (0%)]\tLoss: 399.268402\n",
      "Train Epoch: 24 [300/2589 (12%)]\tLoss: 496.805878\n",
      "Train Epoch: 24 [600/2589 (23%)]\tLoss: 437.748749\n",
      "Train Epoch: 24 [900/2589 (35%)]\tLoss: 450.244812\n",
      "Train Epoch: 24 [1200/2589 (46%)]\tLoss: 616.871887\n",
      "Train Epoch: 24 [1500/2589 (58%)]\tLoss: 518.959351\n",
      "Train Epoch: 24 [1800/2589 (70%)]\tLoss: 444.304260\n",
      "Train Epoch: 24 [2100/2589 (81%)]\tLoss: 563.659729\n",
      "Train Epoch: 24 [2400/2589 (93%)]\tLoss: 538.801514\n",
      "====> Epoch: 24 Average train loss: 490.5856\n",
      "====> Epoch: 24 Average test loss: 888.0637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [0/2589 (0%)]\tLoss: 352.932526\n",
      "Train Epoch: 25 [300/2589 (12%)]\tLoss: 496.166718\n",
      "Train Epoch: 25 [600/2589 (23%)]\tLoss: 612.908508\n",
      "Train Epoch: 25 [900/2589 (35%)]\tLoss: 428.265228\n",
      "Train Epoch: 25 [1200/2589 (46%)]\tLoss: 492.014191\n",
      "Train Epoch: 25 [1500/2589 (58%)]\tLoss: 563.574768\n",
      "Train Epoch: 25 [1800/2589 (70%)]\tLoss: 576.779175\n",
      "Train Epoch: 25 [2100/2589 (81%)]\tLoss: 605.088196\n",
      "Train Epoch: 25 [2400/2589 (93%)]\tLoss: 419.171722\n",
      "====> Epoch: 25 Average train loss: 486.4406\n",
      "====> Epoch: 25 Average test loss: 909.9299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [0/2589 (0%)]\tLoss: 502.263672\n",
      "Train Epoch: 26 [300/2589 (12%)]\tLoss: 391.968475\n",
      "Train Epoch: 26 [600/2589 (23%)]\tLoss: 366.464905\n",
      "Train Epoch: 26 [900/2589 (35%)]\tLoss: 318.835938\n",
      "Train Epoch: 26 [1200/2589 (46%)]\tLoss: 419.401184\n",
      "Train Epoch: 26 [1500/2589 (58%)]\tLoss: 425.918884\n",
      "Train Epoch: 26 [1800/2589 (70%)]\tLoss: 674.927673\n",
      "Train Epoch: 26 [2100/2589 (81%)]\tLoss: 536.488892\n",
      "Train Epoch: 26 [2400/2589 (93%)]\tLoss: 400.106262\n",
      "====> Epoch: 26 Average train loss: 481.5728\n",
      "====> Epoch: 26 Average test loss: 903.7350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [0/2589 (0%)]\tLoss: 331.028717\n",
      "Train Epoch: 27 [300/2589 (12%)]\tLoss: 412.798004\n",
      "Train Epoch: 27 [600/2589 (23%)]\tLoss: 529.942566\n",
      "Train Epoch: 27 [900/2589 (35%)]\tLoss: 469.547852\n",
      "Train Epoch: 27 [1200/2589 (46%)]\tLoss: 793.806824\n",
      "Train Epoch: 27 [1500/2589 (58%)]\tLoss: 575.235107\n",
      "Train Epoch: 27 [1800/2589 (70%)]\tLoss: 552.406006\n",
      "Train Epoch: 27 [2100/2589 (81%)]\tLoss: 476.967438\n",
      "Train Epoch: 27 [2400/2589 (93%)]\tLoss: 527.779053\n",
      "====> Epoch: 27 Average train loss: 474.3504\n",
      "====> Epoch: 27 Average test loss: 910.5386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [0/2589 (0%)]\tLoss: 437.383942\n",
      "Train Epoch: 28 [300/2589 (12%)]\tLoss: 381.077667\n",
      "Train Epoch: 28 [600/2589 (23%)]\tLoss: 427.767609\n",
      "Train Epoch: 28 [900/2589 (35%)]\tLoss: 502.531921\n",
      "Train Epoch: 28 [1200/2589 (46%)]\tLoss: 315.755554\n",
      "Train Epoch: 28 [1500/2589 (58%)]\tLoss: 559.604431\n",
      "Train Epoch: 28 [1800/2589 (70%)]\tLoss: 632.122742\n",
      "Train Epoch: 28 [2100/2589 (81%)]\tLoss: 339.730927\n",
      "Train Epoch: 28 [2400/2589 (93%)]\tLoss: 381.727539\n",
      "====> Epoch: 28 Average train loss: 474.9620\n",
      "====> Epoch: 28 Average test loss: 914.6547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 [0/2589 (0%)]\tLoss: 447.295197\n",
      "Train Epoch: 29 [300/2589 (12%)]\tLoss: 338.396393\n",
      "Train Epoch: 29 [600/2589 (23%)]\tLoss: 449.292175\n",
      "Train Epoch: 29 [900/2589 (35%)]\tLoss: 445.609711\n",
      "Train Epoch: 29 [1200/2589 (46%)]\tLoss: 724.316589\n",
      "Train Epoch: 29 [1500/2589 (58%)]\tLoss: 475.128723\n",
      "Train Epoch: 29 [1800/2589 (70%)]\tLoss: 537.919067\n",
      "Train Epoch: 29 [2100/2589 (81%)]\tLoss: 472.842133\n",
      "Train Epoch: 29 [2400/2589 (93%)]\tLoss: 431.181488\n",
      "====> Epoch: 29 Average train loss: 462.2716\n",
      "====> Epoch: 29 Average test loss: 923.3673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [0/2589 (0%)]\tLoss: 496.332916\n",
      "Train Epoch: 30 [300/2589 (12%)]\tLoss: 406.037811\n",
      "Train Epoch: 30 [600/2589 (23%)]\tLoss: 341.243713\n",
      "Train Epoch: 30 [900/2589 (35%)]\tLoss: 688.276123\n",
      "Train Epoch: 30 [1200/2589 (46%)]\tLoss: 394.043304\n",
      "Train Epoch: 30 [1500/2589 (58%)]\tLoss: 507.998932\n",
      "Train Epoch: 30 [1800/2589 (70%)]\tLoss: 467.287292\n",
      "Train Epoch: 30 [2100/2589 (81%)]\tLoss: 451.375763\n",
      "Train Epoch: 30 [2400/2589 (93%)]\tLoss: 390.097290\n",
      "====> Epoch: 30 Average train loss: 461.7606\n",
      "====> Epoch: 30 Average test loss: 923.9494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [0/2589 (0%)]\tLoss: 689.903381\n",
      "Train Epoch: 31 [300/2589 (12%)]\tLoss: 447.384247\n",
      "Train Epoch: 31 [600/2589 (23%)]\tLoss: 473.419098\n",
      "Train Epoch: 31 [900/2589 (35%)]\tLoss: 351.656372\n",
      "Train Epoch: 31 [1200/2589 (46%)]\tLoss: 331.674622\n",
      "Train Epoch: 31 [1500/2589 (58%)]\tLoss: 384.621094\n",
      "Train Epoch: 31 [1800/2589 (70%)]\tLoss: 361.161194\n",
      "Train Epoch: 31 [2100/2589 (81%)]\tLoss: 382.837006\n",
      "Train Epoch: 31 [2400/2589 (93%)]\tLoss: 483.629486\n",
      "====> Epoch: 31 Average train loss: 451.5160\n",
      "====> Epoch: 31 Average test loss: 908.0502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [0/2589 (0%)]\tLoss: 580.896729\n",
      "Train Epoch: 32 [300/2589 (12%)]\tLoss: 435.371887\n",
      "Train Epoch: 32 [600/2589 (23%)]\tLoss: 394.320129\n",
      "Train Epoch: 32 [900/2589 (35%)]\tLoss: 515.434631\n",
      "Train Epoch: 32 [1200/2589 (46%)]\tLoss: 482.433502\n",
      "Train Epoch: 32 [1500/2589 (58%)]\tLoss: 490.144989\n",
      "Train Epoch: 32 [1800/2589 (70%)]\tLoss: 434.217865\n",
      "Train Epoch: 32 [2100/2589 (81%)]\tLoss: 397.243164\n",
      "Train Epoch: 32 [2400/2589 (93%)]\tLoss: 437.529388\n",
      "====> Epoch: 32 Average train loss: 454.6642\n",
      "====> Epoch: 32 Average test loss: 919.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [0/2589 (0%)]\tLoss: 396.300812\n",
      "Train Epoch: 33 [300/2589 (12%)]\tLoss: 481.021088\n",
      "Train Epoch: 33 [600/2589 (23%)]\tLoss: 712.870972\n",
      "Train Epoch: 33 [900/2589 (35%)]\tLoss: 509.826477\n",
      "Train Epoch: 33 [1200/2589 (46%)]\tLoss: 502.983704\n",
      "Train Epoch: 33 [1500/2589 (58%)]\tLoss: 510.999908\n",
      "Train Epoch: 33 [1800/2589 (70%)]\tLoss: 481.275543\n",
      "Train Epoch: 33 [2100/2589 (81%)]\tLoss: 578.683167\n",
      "Train Epoch: 33 [2400/2589 (93%)]\tLoss: 376.188660\n",
      "====> Epoch: 33 Average train loss: 455.4979\n",
      "====> Epoch: 33 Average test loss: 939.0751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 [0/2589 (0%)]\tLoss: 630.701172\n",
      "Train Epoch: 34 [300/2589 (12%)]\tLoss: 590.201965\n",
      "Train Epoch: 34 [600/2589 (23%)]\tLoss: 344.553741\n",
      "Train Epoch: 34 [900/2589 (35%)]\tLoss: 420.001953\n",
      "Train Epoch: 34 [1200/2589 (46%)]\tLoss: 438.170837\n",
      "Train Epoch: 34 [1500/2589 (58%)]\tLoss: 394.965485\n",
      "Train Epoch: 34 [1800/2589 (70%)]\tLoss: 510.170868\n",
      "Train Epoch: 34 [2100/2589 (81%)]\tLoss: 447.705200\n",
      "Train Epoch: 34 [2400/2589 (93%)]\tLoss: 385.003326\n",
      "====> Epoch: 34 Average train loss: 455.3193\n",
      "====> Epoch: 34 Average test loss: 917.5809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [0/2589 (0%)]\tLoss: 397.451233\n",
      "Train Epoch: 35 [300/2589 (12%)]\tLoss: 595.028076\n",
      "Train Epoch: 35 [600/2589 (23%)]\tLoss: 295.154205\n",
      "Train Epoch: 35 [900/2589 (35%)]\tLoss: 542.652039\n",
      "Train Epoch: 35 [1200/2589 (46%)]\tLoss: 603.904236\n",
      "Train Epoch: 35 [1500/2589 (58%)]\tLoss: 452.173309\n",
      "Train Epoch: 35 [1800/2589 (70%)]\tLoss: 521.700806\n",
      "Train Epoch: 35 [2100/2589 (81%)]\tLoss: 277.345184\n",
      "Train Epoch: 35 [2400/2589 (93%)]\tLoss: 361.925873\n",
      "====> Epoch: 35 Average train loss: 447.9405\n",
      "====> Epoch: 35 Average test loss: 919.1805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [0/2589 (0%)]\tLoss: 429.272186\n",
      "Train Epoch: 36 [300/2589 (12%)]\tLoss: 478.994080\n",
      "Train Epoch: 36 [600/2589 (23%)]\tLoss: 339.102997\n",
      "Train Epoch: 36 [900/2589 (35%)]\tLoss: 367.451599\n",
      "Train Epoch: 36 [1200/2589 (46%)]\tLoss: 391.656433\n",
      "Train Epoch: 36 [1500/2589 (58%)]\tLoss: 479.534119\n",
      "Train Epoch: 36 [1800/2589 (70%)]\tLoss: 411.192596\n",
      "Train Epoch: 36 [2100/2589 (81%)]\tLoss: 437.292999\n",
      "Train Epoch: 36 [2400/2589 (93%)]\tLoss: 414.356506\n",
      "====> Epoch: 36 Average train loss: 448.5386\n",
      "====> Epoch: 36 Average test loss: 956.6995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [0/2589 (0%)]\tLoss: 381.869354\n",
      "Train Epoch: 37 [300/2589 (12%)]\tLoss: 500.394257\n",
      "Train Epoch: 37 [600/2589 (23%)]\tLoss: 465.971802\n",
      "Train Epoch: 37 [900/2589 (35%)]\tLoss: 404.335175\n",
      "Train Epoch: 37 [1200/2589 (46%)]\tLoss: 525.579224\n",
      "Train Epoch: 37 [1500/2589 (58%)]\tLoss: 258.060638\n",
      "Train Epoch: 37 [1800/2589 (70%)]\tLoss: 605.563416\n",
      "Train Epoch: 37 [2100/2589 (81%)]\tLoss: 444.093781\n",
      "Train Epoch: 37 [2400/2589 (93%)]\tLoss: 474.976166\n",
      "====> Epoch: 37 Average train loss: 432.4633\n",
      "====> Epoch: 37 Average test loss: 932.2764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [0/2589 (0%)]\tLoss: 556.752075\n",
      "Train Epoch: 38 [300/2589 (12%)]\tLoss: 421.933685\n",
      "Train Epoch: 38 [600/2589 (23%)]\tLoss: 543.056763\n",
      "Train Epoch: 38 [900/2589 (35%)]\tLoss: 517.417725\n",
      "Train Epoch: 38 [1200/2589 (46%)]\tLoss: 431.864960\n",
      "Train Epoch: 38 [1500/2589 (58%)]\tLoss: 365.041382\n",
      "Train Epoch: 38 [1800/2589 (70%)]\tLoss: 331.848846\n",
      "Train Epoch: 38 [2100/2589 (81%)]\tLoss: 535.440857\n",
      "Train Epoch: 38 [2400/2589 (93%)]\tLoss: 356.988220\n",
      "====> Epoch: 38 Average train loss: 434.5523\n",
      "====> Epoch: 38 Average test loss: 934.4127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [0/2589 (0%)]\tLoss: 390.810730\n",
      "Train Epoch: 39 [300/2589 (12%)]\tLoss: 431.963287\n",
      "Train Epoch: 39 [600/2589 (23%)]\tLoss: 581.601501\n",
      "Train Epoch: 39 [900/2589 (35%)]\tLoss: 507.851471\n",
      "Train Epoch: 39 [1200/2589 (46%)]\tLoss: 443.084045\n",
      "Train Epoch: 39 [1500/2589 (58%)]\tLoss: 389.443420\n",
      "Train Epoch: 39 [1800/2589 (70%)]\tLoss: 347.964447\n",
      "Train Epoch: 39 [2100/2589 (81%)]\tLoss: 486.851868\n",
      "Train Epoch: 39 [2400/2589 (93%)]\tLoss: 459.067230\n",
      "====> Epoch: 39 Average train loss: 429.9722\n",
      "====> Epoch: 39 Average test loss: 930.3264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [0/2589 (0%)]\tLoss: 378.117371\n",
      "Train Epoch: 40 [300/2589 (12%)]\tLoss: 364.171661\n",
      "Train Epoch: 40 [600/2589 (23%)]\tLoss: 465.545776\n",
      "Train Epoch: 40 [900/2589 (35%)]\tLoss: 482.313293\n",
      "Train Epoch: 40 [1200/2589 (46%)]\tLoss: 334.468231\n",
      "Train Epoch: 40 [1500/2589 (58%)]\tLoss: 399.151367\n",
      "Train Epoch: 40 [1800/2589 (70%)]\tLoss: 381.297272\n",
      "Train Epoch: 40 [2100/2589 (81%)]\tLoss: 437.088470\n",
      "Train Epoch: 40 [2400/2589 (93%)]\tLoss: 323.961823\n",
      "====> Epoch: 40 Average train loss: 427.6449\n",
      "====> Epoch: 40 Average test loss: 939.4470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41 [0/2589 (0%)]\tLoss: 342.215271\n",
      "Train Epoch: 41 [300/2589 (12%)]\tLoss: 330.022949\n",
      "Train Epoch: 41 [600/2589 (23%)]\tLoss: 272.620239\n",
      "Train Epoch: 41 [900/2589 (35%)]\tLoss: 597.907104\n",
      "Train Epoch: 41 [1200/2589 (46%)]\tLoss: 364.971161\n",
      "Train Epoch: 41 [1500/2589 (58%)]\tLoss: 406.633881\n",
      "Train Epoch: 41 [1800/2589 (70%)]\tLoss: 474.479370\n",
      "Train Epoch: 41 [2100/2589 (81%)]\tLoss: 470.766388\n",
      "Train Epoch: 41 [2400/2589 (93%)]\tLoss: 386.157288\n",
      "====> Epoch: 41 Average train loss: 433.5561\n",
      "====> Epoch: 41 Average test loss: 923.5214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [0/2589 (0%)]\tLoss: 429.766632\n",
      "Train Epoch: 42 [300/2589 (12%)]\tLoss: 337.348145\n",
      "Train Epoch: 42 [600/2589 (23%)]\tLoss: 352.853699\n",
      "Train Epoch: 42 [900/2589 (35%)]\tLoss: 347.124847\n",
      "Train Epoch: 42 [1200/2589 (46%)]\tLoss: 388.192322\n",
      "Train Epoch: 42 [1500/2589 (58%)]\tLoss: 313.467346\n",
      "Train Epoch: 42 [1800/2589 (70%)]\tLoss: 561.742981\n",
      "Train Epoch: 42 [2100/2589 (81%)]\tLoss: 509.624542\n",
      "Train Epoch: 42 [2400/2589 (93%)]\tLoss: 453.902710\n",
      "====> Epoch: 42 Average train loss: 419.3669\n",
      "====> Epoch: 42 Average test loss: 950.0268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [0/2589 (0%)]\tLoss: 454.395782\n",
      "Train Epoch: 43 [300/2589 (12%)]\tLoss: 405.255798\n",
      "Train Epoch: 43 [600/2589 (23%)]\tLoss: 443.124481\n",
      "Train Epoch: 43 [900/2589 (35%)]\tLoss: 316.200562\n",
      "Train Epoch: 43 [1200/2589 (46%)]\tLoss: 418.155426\n",
      "Train Epoch: 43 [1500/2589 (58%)]\tLoss: 465.228210\n",
      "Train Epoch: 43 [1800/2589 (70%)]\tLoss: 492.096741\n",
      "Train Epoch: 43 [2100/2589 (81%)]\tLoss: 531.669800\n",
      "Train Epoch: 43 [2400/2589 (93%)]\tLoss: 431.767517\n",
      "====> Epoch: 43 Average train loss: 422.6905\n",
      "====> Epoch: 43 Average test loss: 960.6830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 [0/2589 (0%)]\tLoss: 429.146484\n",
      "Train Epoch: 44 [300/2589 (12%)]\tLoss: 573.921265\n",
      "Train Epoch: 44 [600/2589 (23%)]\tLoss: 559.931091\n",
      "Train Epoch: 44 [900/2589 (35%)]\tLoss: 466.347473\n",
      "Train Epoch: 44 [1200/2589 (46%)]\tLoss: 399.746002\n",
      "Train Epoch: 44 [1500/2589 (58%)]\tLoss: 559.840149\n",
      "Train Epoch: 44 [1800/2589 (70%)]\tLoss: 265.004578\n",
      "Train Epoch: 44 [2100/2589 (81%)]\tLoss: 468.669861\n",
      "Train Epoch: 44 [2400/2589 (93%)]\tLoss: 229.796860\n",
      "====> Epoch: 44 Average train loss: 408.0473\n",
      "====> Epoch: 44 Average test loss: 952.4708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [0/2589 (0%)]\tLoss: 353.657227\n",
      "Train Epoch: 45 [300/2589 (12%)]\tLoss: 460.925262\n",
      "Train Epoch: 45 [600/2589 (23%)]\tLoss: 216.351883\n",
      "Train Epoch: 45 [900/2589 (35%)]\tLoss: 365.435944\n",
      "Train Epoch: 45 [1200/2589 (46%)]\tLoss: 310.739258\n",
      "Train Epoch: 45 [1500/2589 (58%)]\tLoss: 431.949738\n",
      "Train Epoch: 45 [1800/2589 (70%)]\tLoss: 369.746887\n",
      "Train Epoch: 45 [2100/2589 (81%)]\tLoss: 278.248596\n",
      "Train Epoch: 45 [2400/2589 (93%)]\tLoss: 390.212982\n",
      "====> Epoch: 45 Average train loss: 417.9800\n",
      "====> Epoch: 45 Average test loss: 921.5839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 46 [0/2589 (0%)]\tLoss: 305.372375\n",
      "Train Epoch: 46 [300/2589 (12%)]\tLoss: 577.855591\n",
      "Train Epoch: 46 [600/2589 (23%)]\tLoss: 459.664551\n",
      "Train Epoch: 46 [900/2589 (35%)]\tLoss: 397.988831\n",
      "Train Epoch: 46 [1200/2589 (46%)]\tLoss: 339.214508\n",
      "Train Epoch: 46 [1500/2589 (58%)]\tLoss: 313.438202\n",
      "Train Epoch: 46 [1800/2589 (70%)]\tLoss: 307.890594\n",
      "Train Epoch: 46 [2100/2589 (81%)]\tLoss: 465.095520\n",
      "Train Epoch: 46 [2400/2589 (93%)]\tLoss: 423.852844\n",
      "====> Epoch: 46 Average train loss: 417.3113\n",
      "====> Epoch: 46 Average test loss: 940.3619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [0/2589 (0%)]\tLoss: 340.624298\n",
      "Train Epoch: 47 [300/2589 (12%)]\tLoss: 312.520721\n",
      "Train Epoch: 47 [600/2589 (23%)]\tLoss: 360.882812\n",
      "Train Epoch: 47 [900/2589 (35%)]\tLoss: 378.416870\n",
      "Train Epoch: 47 [1200/2589 (46%)]\tLoss: 363.983398\n",
      "Train Epoch: 47 [1500/2589 (58%)]\tLoss: 554.953491\n",
      "Train Epoch: 47 [1800/2589 (70%)]\tLoss: 442.536102\n",
      "Train Epoch: 47 [2100/2589 (81%)]\tLoss: 328.149292\n",
      "Train Epoch: 47 [2400/2589 (93%)]\tLoss: 390.757782\n",
      "====> Epoch: 47 Average train loss: 419.7925\n",
      "====> Epoch: 47 Average test loss: 933.3900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [0/2589 (0%)]\tLoss: 367.322632\n",
      "Train Epoch: 48 [300/2589 (12%)]\tLoss: 334.337372\n",
      "Train Epoch: 48 [600/2589 (23%)]\tLoss: 506.184143\n",
      "Train Epoch: 48 [900/2589 (35%)]\tLoss: 569.965515\n",
      "Train Epoch: 48 [1200/2589 (46%)]\tLoss: 344.939850\n",
      "Train Epoch: 48 [1500/2589 (58%)]\tLoss: 532.592529\n",
      "Train Epoch: 48 [1800/2589 (70%)]\tLoss: 486.933502\n",
      "Train Epoch: 48 [2100/2589 (81%)]\tLoss: 358.071747\n",
      "Train Epoch: 48 [2400/2589 (93%)]\tLoss: 354.833679\n",
      "====> Epoch: 48 Average train loss: 407.7558\n",
      "====> Epoch: 48 Average test loss: 947.2791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 49 [0/2589 (0%)]\tLoss: 751.601746\n",
      "Train Epoch: 49 [300/2589 (12%)]\tLoss: 425.024628\n",
      "Train Epoch: 49 [600/2589 (23%)]\tLoss: 544.692017\n",
      "Train Epoch: 49 [900/2589 (35%)]\tLoss: 377.508820\n",
      "Train Epoch: 49 [1200/2589 (46%)]\tLoss: 381.597839\n",
      "Train Epoch: 49 [1500/2589 (58%)]\tLoss: 439.909760\n",
      "Train Epoch: 49 [1800/2589 (70%)]\tLoss: 385.063782\n",
      "Train Epoch: 49 [2100/2589 (81%)]\tLoss: 483.281921\n",
      "Train Epoch: 49 [2400/2589 (93%)]\tLoss: 691.889099\n",
      "====> Epoch: 49 Average train loss: 414.2922\n",
      "====> Epoch: 49 Average test loss: 933.7014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 50 [0/2589 (0%)]\tLoss: 331.261078\n",
      "Train Epoch: 50 [300/2589 (12%)]\tLoss: 445.278595\n",
      "Train Epoch: 50 [600/2589 (23%)]\tLoss: 363.711639\n",
      "Train Epoch: 50 [900/2589 (35%)]\tLoss: 414.095490\n",
      "Train Epoch: 50 [1200/2589 (46%)]\tLoss: 603.718811\n",
      "Train Epoch: 50 [1500/2589 (58%)]\tLoss: 428.832611\n",
      "Train Epoch: 50 [1800/2589 (70%)]\tLoss: 349.428680\n",
      "Train Epoch: 50 [2100/2589 (81%)]\tLoss: 527.004028\n",
      "Train Epoch: 50 [2400/2589 (93%)]\tLoss: 430.179962\n",
      "====> Epoch: 50 Average train loss: 405.6186\n",
      "====> Epoch: 50 Average test loss: 929.3186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 51 [0/2589 (0%)]\tLoss: 332.023834\n",
      "Train Epoch: 51 [300/2589 (12%)]\tLoss: 258.500458\n",
      "Train Epoch: 51 [600/2589 (23%)]\tLoss: 291.159210\n",
      "Train Epoch: 51 [900/2589 (35%)]\tLoss: 491.650116\n",
      "Train Epoch: 51 [1200/2589 (46%)]\tLoss: 302.266815\n",
      "Train Epoch: 51 [1500/2589 (58%)]\tLoss: 365.906677\n",
      "Train Epoch: 51 [1800/2589 (70%)]\tLoss: 408.450714\n",
      "Train Epoch: 51 [2100/2589 (81%)]\tLoss: 538.495361\n",
      "Train Epoch: 51 [2400/2589 (93%)]\tLoss: 407.116974\n",
      "====> Epoch: 51 Average train loss: 402.8474\n",
      "====> Epoch: 51 Average test loss: 927.4473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 52 [0/2589 (0%)]\tLoss: 334.485077\n",
      "Train Epoch: 52 [300/2589 (12%)]\tLoss: 375.301605\n",
      "Train Epoch: 52 [600/2589 (23%)]\tLoss: 420.879822\n",
      "Train Epoch: 52 [900/2589 (35%)]\tLoss: 414.528320\n",
      "Train Epoch: 52 [1200/2589 (46%)]\tLoss: 342.303162\n",
      "Train Epoch: 52 [1500/2589 (58%)]\tLoss: 310.304718\n",
      "Train Epoch: 52 [1800/2589 (70%)]\tLoss: 377.818390\n",
      "Train Epoch: 52 [2100/2589 (81%)]\tLoss: 502.615814\n",
      "Train Epoch: 52 [2400/2589 (93%)]\tLoss: 481.570862\n",
      "====> Epoch: 52 Average train loss: 400.0707\n",
      "====> Epoch: 52 Average test loss: 932.2186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [0/2589 (0%)]\tLoss: 347.422241\n",
      "Train Epoch: 53 [300/2589 (12%)]\tLoss: 319.692810\n",
      "Train Epoch: 53 [600/2589 (23%)]\tLoss: 381.886871\n",
      "Train Epoch: 53 [900/2589 (35%)]\tLoss: 473.079193\n",
      "Train Epoch: 53 [1200/2589 (46%)]\tLoss: 367.219238\n",
      "Train Epoch: 53 [1500/2589 (58%)]\tLoss: 360.682922\n",
      "Train Epoch: 53 [1800/2589 (70%)]\tLoss: 375.509064\n",
      "Train Epoch: 53 [2100/2589 (81%)]\tLoss: 372.823456\n",
      "Train Epoch: 53 [2400/2589 (93%)]\tLoss: 426.322235\n",
      "====> Epoch: 53 Average train loss: 397.9776\n",
      "====> Epoch: 53 Average test loss: 938.6765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 54 [0/2589 (0%)]\tLoss: 282.873474\n",
      "Train Epoch: 54 [300/2589 (12%)]\tLoss: 503.159271\n",
      "Train Epoch: 54 [600/2589 (23%)]\tLoss: 379.193970\n",
      "Train Epoch: 54 [900/2589 (35%)]\tLoss: 486.985352\n",
      "Train Epoch: 54 [1200/2589 (46%)]\tLoss: 511.618622\n",
      "Train Epoch: 54 [1500/2589 (58%)]\tLoss: 399.985474\n",
      "Train Epoch: 54 [1800/2589 (70%)]\tLoss: 405.920044\n",
      "Train Epoch: 54 [2100/2589 (81%)]\tLoss: 436.593048\n",
      "Train Epoch: 54 [2400/2589 (93%)]\tLoss: 482.485931\n",
      "====> Epoch: 54 Average train loss: 395.8831\n",
      "====> Epoch: 54 Average test loss: 934.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 55 [0/2589 (0%)]\tLoss: 331.170074\n",
      "Train Epoch: 55 [300/2589 (12%)]\tLoss: 432.828644\n",
      "Train Epoch: 55 [600/2589 (23%)]\tLoss: 372.601196\n",
      "Train Epoch: 55 [900/2589 (35%)]\tLoss: 378.969910\n",
      "Train Epoch: 55 [1200/2589 (46%)]\tLoss: 534.354675\n",
      "Train Epoch: 55 [1500/2589 (58%)]\tLoss: 309.259155\n",
      "Train Epoch: 55 [1800/2589 (70%)]\tLoss: 327.566864\n",
      "Train Epoch: 55 [2100/2589 (81%)]\tLoss: 285.030457\n",
      "Train Epoch: 55 [2400/2589 (93%)]\tLoss: 481.356934\n",
      "====> Epoch: 55 Average train loss: 397.8540\n",
      "====> Epoch: 55 Average test loss: 952.6467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [0/2589 (0%)]\tLoss: 364.100647\n",
      "Train Epoch: 56 [300/2589 (12%)]\tLoss: 367.606567\n",
      "Train Epoch: 56 [600/2589 (23%)]\tLoss: 394.067566\n",
      "Train Epoch: 56 [900/2589 (35%)]\tLoss: 407.238281\n",
      "Train Epoch: 56 [1200/2589 (46%)]\tLoss: 441.078766\n",
      "Train Epoch: 56 [1500/2589 (58%)]\tLoss: 315.025757\n",
      "Train Epoch: 56 [1800/2589 (70%)]\tLoss: 339.470276\n",
      "Train Epoch: 56 [2100/2589 (81%)]\tLoss: 405.202423\n",
      "Train Epoch: 56 [2400/2589 (93%)]\tLoss: 325.666595\n",
      "====> Epoch: 56 Average train loss: 389.6751\n",
      "====> Epoch: 56 Average test loss: 940.4711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 57 [0/2589 (0%)]\tLoss: 335.335663\n",
      "Train Epoch: 57 [300/2589 (12%)]\tLoss: 520.671997\n",
      "Train Epoch: 57 [600/2589 (23%)]\tLoss: 354.409393\n",
      "Train Epoch: 57 [900/2589 (35%)]\tLoss: 366.939056\n",
      "Train Epoch: 57 [1200/2589 (46%)]\tLoss: 412.378052\n",
      "Train Epoch: 57 [1500/2589 (58%)]\tLoss: 360.361450\n",
      "Train Epoch: 57 [1800/2589 (70%)]\tLoss: 368.610626\n",
      "Train Epoch: 57 [2100/2589 (81%)]\tLoss: 373.191467\n",
      "Train Epoch: 57 [2400/2589 (93%)]\tLoss: 461.323669\n",
      "====> Epoch: 57 Average train loss: 386.5832\n",
      "====> Epoch: 57 Average test loss: 944.3632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 58 [0/2589 (0%)]\tLoss: 308.455841\n",
      "Train Epoch: 58 [300/2589 (12%)]\tLoss: 315.799408\n",
      "Train Epoch: 58 [600/2589 (23%)]\tLoss: 409.783203\n",
      "Train Epoch: 58 [900/2589 (35%)]\tLoss: 463.645325\n",
      "Train Epoch: 58 [1200/2589 (46%)]\tLoss: 424.681915\n",
      "Train Epoch: 58 [1500/2589 (58%)]\tLoss: 318.608887\n",
      "Train Epoch: 58 [1800/2589 (70%)]\tLoss: 332.137878\n",
      "Train Epoch: 58 [2100/2589 (81%)]\tLoss: 373.983582\n",
      "Train Epoch: 58 [2400/2589 (93%)]\tLoss: 422.734070\n",
      "====> Epoch: 58 Average train loss: 378.1669\n",
      "====> Epoch: 58 Average test loss: 931.5571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 59 [0/2589 (0%)]\tLoss: 253.799667\n",
      "Train Epoch: 59 [300/2589 (12%)]\tLoss: 421.564789\n",
      "Train Epoch: 59 [600/2589 (23%)]\tLoss: 320.409302\n",
      "Train Epoch: 59 [900/2589 (35%)]\tLoss: 278.421967\n",
      "Train Epoch: 59 [1200/2589 (46%)]\tLoss: 471.866516\n",
      "Train Epoch: 59 [1500/2589 (58%)]\tLoss: 442.690948\n",
      "Train Epoch: 59 [1800/2589 (70%)]\tLoss: 191.873474\n",
      "Train Epoch: 59 [2100/2589 (81%)]\tLoss: 243.693878\n",
      "Train Epoch: 59 [2400/2589 (93%)]\tLoss: 306.223633\n",
      "====> Epoch: 59 Average train loss: 378.0986\n",
      "====> Epoch: 59 Average test loss: 937.4637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60 [0/2589 (0%)]\tLoss: 351.471588\n",
      "Train Epoch: 60 [300/2589 (12%)]\tLoss: 319.410217\n",
      "Train Epoch: 60 [600/2589 (23%)]\tLoss: 336.231262\n",
      "Train Epoch: 60 [900/2589 (35%)]\tLoss: 563.595520\n",
      "Train Epoch: 60 [1200/2589 (46%)]\tLoss: 448.542999\n",
      "Train Epoch: 60 [1500/2589 (58%)]\tLoss: 390.853455\n",
      "Train Epoch: 60 [1800/2589 (70%)]\tLoss: 441.638672\n",
      "Train Epoch: 60 [2100/2589 (81%)]\tLoss: 434.234375\n",
      "Train Epoch: 60 [2400/2589 (93%)]\tLoss: 611.146729\n",
      "====> Epoch: 60 Average train loss: 380.5029\n",
      "====> Epoch: 60 Average test loss: 946.6053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 61 [0/2589 (0%)]\tLoss: 330.639099\n",
      "Train Epoch: 61 [300/2589 (12%)]\tLoss: 346.179199\n",
      "Train Epoch: 61 [600/2589 (23%)]\tLoss: 412.868774\n",
      "Train Epoch: 61 [900/2589 (35%)]\tLoss: 426.595428\n",
      "Train Epoch: 61 [1200/2589 (46%)]\tLoss: 420.752106\n",
      "Train Epoch: 61 [1500/2589 (58%)]\tLoss: 294.793579\n",
      "Train Epoch: 61 [1800/2589 (70%)]\tLoss: 341.187683\n",
      "Train Epoch: 61 [2100/2589 (81%)]\tLoss: 365.967804\n",
      "Train Epoch: 61 [2400/2589 (93%)]\tLoss: 339.238770\n",
      "====> Epoch: 61 Average train loss: 383.1741\n",
      "====> Epoch: 61 Average test loss: 931.3373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 62 [0/2589 (0%)]\tLoss: 404.834137\n",
      "Train Epoch: 62 [300/2589 (12%)]\tLoss: 276.299225\n",
      "Train Epoch: 62 [600/2589 (23%)]\tLoss: 316.171539\n",
      "Train Epoch: 62 [900/2589 (35%)]\tLoss: 414.005310\n",
      "Train Epoch: 62 [1200/2589 (46%)]\tLoss: 355.992065\n",
      "Train Epoch: 62 [1500/2589 (58%)]\tLoss: 301.906830\n",
      "Train Epoch: 62 [1800/2589 (70%)]\tLoss: 447.850311\n",
      "Train Epoch: 62 [2100/2589 (81%)]\tLoss: 408.031403\n",
      "Train Epoch: 62 [2400/2589 (93%)]\tLoss: 438.114624\n",
      "====> Epoch: 62 Average train loss: 385.4059\n",
      "====> Epoch: 62 Average test loss: 947.1248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 63 [0/2589 (0%)]\tLoss: 404.774139\n",
      "Train Epoch: 63 [300/2589 (12%)]\tLoss: 381.236267\n",
      "Train Epoch: 63 [600/2589 (23%)]\tLoss: 385.135376\n",
      "Train Epoch: 63 [900/2589 (35%)]\tLoss: 375.292877\n",
      "Train Epoch: 63 [1200/2589 (46%)]\tLoss: 495.991791\n",
      "Train Epoch: 63 [1500/2589 (58%)]\tLoss: 492.534637\n",
      "Train Epoch: 63 [1800/2589 (70%)]\tLoss: 321.796722\n",
      "Train Epoch: 63 [2100/2589 (81%)]\tLoss: 348.396912\n",
      "Train Epoch: 63 [2400/2589 (93%)]\tLoss: 346.324890\n",
      "====> Epoch: 63 Average train loss: 371.5776\n",
      "====> Epoch: 63 Average test loss: 954.6412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 64 [0/2589 (0%)]\tLoss: 299.181335\n",
      "Train Epoch: 64 [300/2589 (12%)]\tLoss: 299.221100\n",
      "Train Epoch: 64 [600/2589 (23%)]\tLoss: 329.250275\n",
      "Train Epoch: 64 [900/2589 (35%)]\tLoss: 363.957367\n",
      "Train Epoch: 64 [1200/2589 (46%)]\tLoss: 402.318817\n",
      "Train Epoch: 64 [1500/2589 (58%)]\tLoss: 343.501038\n",
      "Train Epoch: 64 [1800/2589 (70%)]\tLoss: 519.020630\n",
      "Train Epoch: 64 [2100/2589 (81%)]\tLoss: 484.892426\n",
      "Train Epoch: 64 [2400/2589 (93%)]\tLoss: 353.956757\n",
      "====> Epoch: 64 Average train loss: 379.4034\n",
      "====> Epoch: 64 Average test loss: 944.0536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 65 [0/2589 (0%)]\tLoss: 382.848022\n",
      "Train Epoch: 65 [300/2589 (12%)]\tLoss: 352.157623\n",
      "Train Epoch: 65 [600/2589 (23%)]\tLoss: 308.156250\n",
      "Train Epoch: 65 [900/2589 (35%)]\tLoss: 243.945099\n",
      "Train Epoch: 65 [1200/2589 (46%)]\tLoss: 294.443207\n",
      "Train Epoch: 65 [1500/2589 (58%)]\tLoss: 382.883911\n",
      "Train Epoch: 65 [1800/2589 (70%)]\tLoss: 257.612885\n",
      "Train Epoch: 65 [2100/2589 (81%)]\tLoss: 452.560059\n",
      "Train Epoch: 65 [2400/2589 (93%)]\tLoss: 335.281891\n",
      "====> Epoch: 65 Average train loss: 376.9571\n",
      "====> Epoch: 65 Average test loss: 932.6029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 66 [0/2589 (0%)]\tLoss: 457.260345\n",
      "Train Epoch: 66 [300/2589 (12%)]\tLoss: 328.321960\n",
      "Train Epoch: 66 [600/2589 (23%)]\tLoss: 333.416443\n",
      "Train Epoch: 66 [900/2589 (35%)]\tLoss: 352.787445\n",
      "Train Epoch: 66 [1200/2589 (46%)]\tLoss: 418.780304\n",
      "Train Epoch: 66 [1500/2589 (58%)]\tLoss: 357.428558\n",
      "Train Epoch: 66 [1800/2589 (70%)]\tLoss: 305.443970\n",
      "Train Epoch: 66 [2100/2589 (81%)]\tLoss: 379.632111\n",
      "Train Epoch: 66 [2400/2589 (93%)]\tLoss: 349.447784\n",
      "====> Epoch: 66 Average train loss: 380.8258\n",
      "====> Epoch: 66 Average test loss: 972.6159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 67 [0/2589 (0%)]\tLoss: 440.206360\n",
      "Train Epoch: 67 [300/2589 (12%)]\tLoss: 315.776001\n",
      "Train Epoch: 67 [600/2589 (23%)]\tLoss: 412.694153\n",
      "Train Epoch: 67 [900/2589 (35%)]\tLoss: 358.109283\n",
      "Train Epoch: 67 [1200/2589 (46%)]\tLoss: 428.843353\n",
      "Train Epoch: 67 [1500/2589 (58%)]\tLoss: 386.210266\n",
      "Train Epoch: 67 [1800/2589 (70%)]\tLoss: 286.219543\n",
      "Train Epoch: 67 [2100/2589 (81%)]\tLoss: 246.962387\n",
      "Train Epoch: 67 [2400/2589 (93%)]\tLoss: 353.001862\n",
      "====> Epoch: 67 Average train loss: 370.8002\n",
      "====> Epoch: 67 Average test loss: 943.1704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 68 [0/2589 (0%)]\tLoss: 447.586395\n",
      "Train Epoch: 68 [300/2589 (12%)]\tLoss: 326.389679\n",
      "Train Epoch: 68 [600/2589 (23%)]\tLoss: 355.779663\n",
      "Train Epoch: 68 [900/2589 (35%)]\tLoss: 310.422974\n",
      "Train Epoch: 68 [1200/2589 (46%)]\tLoss: 324.364960\n",
      "Train Epoch: 68 [1500/2589 (58%)]\tLoss: 320.248169\n",
      "Train Epoch: 68 [1800/2589 (70%)]\tLoss: 345.482269\n",
      "Train Epoch: 68 [2100/2589 (81%)]\tLoss: 277.572296\n",
      "Train Epoch: 68 [2400/2589 (93%)]\tLoss: 397.440582\n",
      "====> Epoch: 68 Average train loss: 366.6071\n",
      "====> Epoch: 68 Average test loss: 968.0443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 69 [0/2589 (0%)]\tLoss: 541.029053\n",
      "Train Epoch: 69 [300/2589 (12%)]\tLoss: 341.365326\n",
      "Train Epoch: 69 [600/2589 (23%)]\tLoss: 228.609833\n",
      "Train Epoch: 69 [900/2589 (35%)]\tLoss: 369.956757\n",
      "Train Epoch: 69 [1200/2589 (46%)]\tLoss: 383.342926\n",
      "Train Epoch: 69 [1500/2589 (58%)]\tLoss: 350.021545\n",
      "Train Epoch: 69 [1800/2589 (70%)]\tLoss: 419.085327\n",
      "Train Epoch: 69 [2100/2589 (81%)]\tLoss: 370.730682\n",
      "Train Epoch: 69 [2400/2589 (93%)]\tLoss: 275.933167\n",
      "====> Epoch: 69 Average train loss: 367.8340\n",
      "====> Epoch: 69 Average test loss: 986.7255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 70 [0/2589 (0%)]\tLoss: 409.811646\n",
      "Train Epoch: 70 [300/2589 (12%)]\tLoss: 339.033386\n",
      "Train Epoch: 70 [600/2589 (23%)]\tLoss: 307.887360\n",
      "Train Epoch: 70 [900/2589 (35%)]\tLoss: 305.522003\n",
      "Train Epoch: 70 [1200/2589 (46%)]\tLoss: 293.595642\n",
      "Train Epoch: 70 [1500/2589 (58%)]\tLoss: 393.065918\n",
      "Train Epoch: 70 [1800/2589 (70%)]\tLoss: 374.522919\n",
      "Train Epoch: 70 [2100/2589 (81%)]\tLoss: 341.221680\n",
      "Train Epoch: 70 [2400/2589 (93%)]\tLoss: 403.088928\n",
      "====> Epoch: 70 Average train loss: 358.8125\n",
      "====> Epoch: 70 Average test loss: 980.2476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 71 [0/2589 (0%)]\tLoss: 375.746216\n",
      "Train Epoch: 71 [300/2589 (12%)]\tLoss: 266.725861\n",
      "Train Epoch: 71 [600/2589 (23%)]\tLoss: 298.532684\n",
      "Train Epoch: 71 [900/2589 (35%)]\tLoss: 275.714966\n",
      "Train Epoch: 71 [1200/2589 (46%)]\tLoss: 431.133148\n",
      "Train Epoch: 71 [1500/2589 (58%)]\tLoss: 282.981750\n",
      "Train Epoch: 71 [1800/2589 (70%)]\tLoss: 306.288666\n",
      "Train Epoch: 71 [2100/2589 (81%)]\tLoss: 276.776978\n",
      "Train Epoch: 71 [2400/2589 (93%)]\tLoss: 342.010223\n",
      "====> Epoch: 71 Average train loss: 360.6806\n",
      "====> Epoch: 71 Average test loss: 935.3177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [0/2589 (0%)]\tLoss: 300.057037\n",
      "Train Epoch: 72 [300/2589 (12%)]\tLoss: 412.033875\n",
      "Train Epoch: 72 [600/2589 (23%)]\tLoss: 368.216125\n",
      "Train Epoch: 72 [900/2589 (35%)]\tLoss: 549.629272\n",
      "Train Epoch: 72 [1200/2589 (46%)]\tLoss: 262.190430\n",
      "Train Epoch: 72 [1500/2589 (58%)]\tLoss: 302.926361\n",
      "Train Epoch: 72 [1800/2589 (70%)]\tLoss: 285.910736\n",
      "Train Epoch: 72 [2100/2589 (81%)]\tLoss: 318.641754\n",
      "Train Epoch: 72 [2400/2589 (93%)]\tLoss: 390.668579\n",
      "====> Epoch: 72 Average train loss: 352.9947\n",
      "====> Epoch: 72 Average test loss: 958.4211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [0/2589 (0%)]\tLoss: 405.750854\n",
      "Train Epoch: 73 [300/2589 (12%)]\tLoss: 370.559021\n",
      "Train Epoch: 73 [600/2589 (23%)]\tLoss: 328.243439\n",
      "Train Epoch: 73 [900/2589 (35%)]\tLoss: 295.563660\n",
      "Train Epoch: 73 [1200/2589 (46%)]\tLoss: 340.001892\n",
      "Train Epoch: 73 [1500/2589 (58%)]\tLoss: 403.528412\n",
      "Train Epoch: 73 [1800/2589 (70%)]\tLoss: 431.423248\n",
      "Train Epoch: 73 [2100/2589 (81%)]\tLoss: 464.269226\n",
      "Train Epoch: 73 [2400/2589 (93%)]\tLoss: 447.408020\n",
      "====> Epoch: 73 Average train loss: 358.3520\n",
      "====> Epoch: 73 Average test loss: 947.1361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 74 [0/2589 (0%)]\tLoss: 387.756714\n",
      "Train Epoch: 74 [300/2589 (12%)]\tLoss: 480.018616\n",
      "Train Epoch: 74 [600/2589 (23%)]\tLoss: 362.033844\n",
      "Train Epoch: 74 [900/2589 (35%)]\tLoss: 390.848755\n",
      "Train Epoch: 74 [1200/2589 (46%)]\tLoss: 412.233704\n",
      "Train Epoch: 74 [1500/2589 (58%)]\tLoss: 413.491302\n",
      "Train Epoch: 74 [1800/2589 (70%)]\tLoss: 439.350952\n",
      "Train Epoch: 74 [2100/2589 (81%)]\tLoss: 478.650665\n",
      "Train Epoch: 74 [2400/2589 (93%)]\tLoss: 440.214233\n",
      "====> Epoch: 74 Average train loss: 358.4761\n",
      "====> Epoch: 74 Average test loss: 935.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 75 [0/2589 (0%)]\tLoss: 294.107758\n",
      "Train Epoch: 75 [300/2589 (12%)]\tLoss: 356.330414\n",
      "Train Epoch: 75 [600/2589 (23%)]\tLoss: 305.438171\n",
      "Train Epoch: 75 [900/2589 (35%)]\tLoss: 368.428345\n",
      "Train Epoch: 75 [1200/2589 (46%)]\tLoss: 390.918732\n",
      "Train Epoch: 75 [1500/2589 (58%)]\tLoss: 320.985992\n",
      "Train Epoch: 75 [1800/2589 (70%)]\tLoss: 261.164856\n",
      "Train Epoch: 75 [2100/2589 (81%)]\tLoss: 389.507477\n",
      "Train Epoch: 75 [2400/2589 (93%)]\tLoss: 227.315033\n",
      "====> Epoch: 75 Average train loss: 361.0345\n",
      "====> Epoch: 75 Average test loss: 952.7463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 76 [0/2589 (0%)]\tLoss: 257.324249\n",
      "Train Epoch: 76 [300/2589 (12%)]\tLoss: 450.911560\n",
      "Train Epoch: 76 [600/2589 (23%)]\tLoss: 433.782715\n",
      "Train Epoch: 76 [900/2589 (35%)]\tLoss: 335.773438\n",
      "Train Epoch: 76 [1200/2589 (46%)]\tLoss: 329.296997\n",
      "Train Epoch: 76 [1500/2589 (58%)]\tLoss: 266.727661\n",
      "Train Epoch: 76 [1800/2589 (70%)]\tLoss: 408.976501\n",
      "Train Epoch: 76 [2100/2589 (81%)]\tLoss: 429.525208\n",
      "Train Epoch: 76 [2400/2589 (93%)]\tLoss: 295.237732\n",
      "====> Epoch: 76 Average train loss: 363.3425\n",
      "====> Epoch: 76 Average test loss: 960.7448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 77 [0/2589 (0%)]\tLoss: 430.064453\n",
      "Train Epoch: 77 [300/2589 (12%)]\tLoss: 458.611816\n",
      "Train Epoch: 77 [600/2589 (23%)]\tLoss: 322.329498\n",
      "Train Epoch: 77 [900/2589 (35%)]\tLoss: 413.234894\n",
      "Train Epoch: 77 [1200/2589 (46%)]\tLoss: 389.392517\n",
      "Train Epoch: 77 [1500/2589 (58%)]\tLoss: 238.908493\n",
      "Train Epoch: 77 [1800/2589 (70%)]\tLoss: 278.094269\n",
      "Train Epoch: 77 [2100/2589 (81%)]\tLoss: 286.462219\n",
      "Train Epoch: 77 [2400/2589 (93%)]\tLoss: 394.942993\n",
      "====> Epoch: 77 Average train loss: 358.6756\n",
      "====> Epoch: 77 Average test loss: 934.2775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 78 [0/2589 (0%)]\tLoss: 437.785461\n",
      "Train Epoch: 78 [300/2589 (12%)]\tLoss: 330.567169\n",
      "Train Epoch: 78 [600/2589 (23%)]\tLoss: 403.896759\n",
      "Train Epoch: 78 [900/2589 (35%)]\tLoss: 308.719086\n",
      "Train Epoch: 78 [1200/2589 (46%)]\tLoss: 408.335754\n",
      "Train Epoch: 78 [1500/2589 (58%)]\tLoss: 387.688660\n",
      "Train Epoch: 78 [1800/2589 (70%)]\tLoss: 465.290161\n",
      "Train Epoch: 78 [2100/2589 (81%)]\tLoss: 317.912476\n",
      "Train Epoch: 78 [2400/2589 (93%)]\tLoss: 300.429291\n",
      "====> Epoch: 78 Average train loss: 357.4406\n",
      "====> Epoch: 78 Average test loss: 949.5006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 79 [0/2589 (0%)]\tLoss: 394.163910\n",
      "Train Epoch: 79 [300/2589 (12%)]\tLoss: 241.225296\n",
      "Train Epoch: 79 [600/2589 (23%)]\tLoss: 283.330078\n",
      "Train Epoch: 79 [900/2589 (35%)]\tLoss: 398.082397\n",
      "Train Epoch: 79 [1200/2589 (46%)]\tLoss: 326.946991\n",
      "Train Epoch: 79 [1500/2589 (58%)]\tLoss: 418.987030\n",
      "Train Epoch: 79 [1800/2589 (70%)]\tLoss: 227.674377\n",
      "Train Epoch: 79 [2100/2589 (81%)]\tLoss: 303.294098\n",
      "Train Epoch: 79 [2400/2589 (93%)]\tLoss: 300.294586\n",
      "====> Epoch: 79 Average train loss: 347.3038\n",
      "====> Epoch: 79 Average test loss: 940.0397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 80 [0/2589 (0%)]\tLoss: 471.675385\n",
      "Train Epoch: 80 [300/2589 (12%)]\tLoss: 326.934265\n",
      "Train Epoch: 80 [600/2589 (23%)]\tLoss: 233.919357\n",
      "Train Epoch: 80 [900/2589 (35%)]\tLoss: 369.890625\n",
      "Train Epoch: 80 [1200/2589 (46%)]\tLoss: 292.379395\n",
      "Train Epoch: 80 [1500/2589 (58%)]\tLoss: 310.795380\n",
      "Train Epoch: 80 [1800/2589 (70%)]\tLoss: 277.603088\n",
      "Train Epoch: 80 [2100/2589 (81%)]\tLoss: 314.207031\n",
      "Train Epoch: 80 [2400/2589 (93%)]\tLoss: 436.382294\n",
      "====> Epoch: 80 Average train loss: 361.5138\n",
      "====> Epoch: 80 Average test loss: 979.0884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 81 [0/2589 (0%)]\tLoss: 269.029327\n",
      "Train Epoch: 81 [300/2589 (12%)]\tLoss: 256.295227\n",
      "Train Epoch: 81 [600/2589 (23%)]\tLoss: 408.722748\n",
      "Train Epoch: 81 [900/2589 (35%)]\tLoss: 448.662445\n",
      "Train Epoch: 81 [1200/2589 (46%)]\tLoss: 251.996643\n",
      "Train Epoch: 81 [1500/2589 (58%)]\tLoss: 340.028778\n",
      "Train Epoch: 81 [1800/2589 (70%)]\tLoss: 532.258484\n",
      "Train Epoch: 81 [2100/2589 (81%)]\tLoss: 414.528931\n",
      "Train Epoch: 81 [2400/2589 (93%)]\tLoss: 240.443420\n",
      "====> Epoch: 81 Average train loss: 346.4799\n",
      "====> Epoch: 81 Average test loss: 954.8261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 82 [0/2589 (0%)]\tLoss: 283.176361\n",
      "Train Epoch: 82 [300/2589 (12%)]\tLoss: 363.401550\n",
      "Train Epoch: 82 [600/2589 (23%)]\tLoss: 339.144135\n",
      "Train Epoch: 82 [900/2589 (35%)]\tLoss: 261.483978\n",
      "Train Epoch: 82 [1200/2589 (46%)]\tLoss: 381.751404\n",
      "Train Epoch: 82 [1500/2589 (58%)]\tLoss: 342.806366\n",
      "Train Epoch: 82 [1800/2589 (70%)]\tLoss: 295.425751\n",
      "Train Epoch: 82 [2100/2589 (81%)]\tLoss: 363.227844\n",
      "Train Epoch: 82 [2400/2589 (93%)]\tLoss: 257.589630\n",
      "====> Epoch: 82 Average train loss: 348.2157\n",
      "====> Epoch: 82 Average test loss: 964.2443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 83 [0/2589 (0%)]\tLoss: 351.148529\n",
      "Train Epoch: 83 [300/2589 (12%)]\tLoss: 366.234985\n",
      "Train Epoch: 83 [600/2589 (23%)]\tLoss: 287.775757\n",
      "Train Epoch: 83 [900/2589 (35%)]\tLoss: 349.365326\n",
      "Train Epoch: 83 [1200/2589 (46%)]\tLoss: 419.030823\n",
      "Train Epoch: 83 [1500/2589 (58%)]\tLoss: 371.236633\n",
      "Train Epoch: 83 [1800/2589 (70%)]\tLoss: 255.483459\n",
      "Train Epoch: 83 [2100/2589 (81%)]\tLoss: 440.393707\n",
      "Train Epoch: 83 [2400/2589 (93%)]\tLoss: 439.175476\n",
      "====> Epoch: 83 Average train loss: 350.6359\n",
      "====> Epoch: 83 Average test loss: 955.9120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 84 [0/2589 (0%)]\tLoss: 308.359436\n",
      "Train Epoch: 84 [300/2589 (12%)]\tLoss: 252.608749\n",
      "Train Epoch: 84 [600/2589 (23%)]\tLoss: 305.568939\n",
      "Train Epoch: 84 [900/2589 (35%)]\tLoss: 280.081512\n",
      "Train Epoch: 84 [1200/2589 (46%)]\tLoss: 365.243835\n",
      "Train Epoch: 84 [1500/2589 (58%)]\tLoss: 456.293274\n",
      "Train Epoch: 84 [1800/2589 (70%)]\tLoss: 252.010483\n",
      "Train Epoch: 84 [2100/2589 (81%)]\tLoss: 379.540100\n",
      "Train Epoch: 84 [2400/2589 (93%)]\tLoss: 288.497162\n",
      "====> Epoch: 84 Average train loss: 346.0239\n",
      "====> Epoch: 84 Average test loss: 976.0338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 85 [0/2589 (0%)]\tLoss: 259.294952\n",
      "Train Epoch: 85 [300/2589 (12%)]\tLoss: 329.366241\n",
      "Train Epoch: 85 [600/2589 (23%)]\tLoss: 229.135605\n",
      "Train Epoch: 85 [900/2589 (35%)]\tLoss: 312.243927\n",
      "Train Epoch: 85 [1200/2589 (46%)]\tLoss: 353.631226\n",
      "Train Epoch: 85 [1500/2589 (58%)]\tLoss: 298.068665\n",
      "Train Epoch: 85 [1800/2589 (70%)]\tLoss: 298.757172\n",
      "Train Epoch: 85 [2100/2589 (81%)]\tLoss: 344.420471\n",
      "Train Epoch: 85 [2400/2589 (93%)]\tLoss: 274.154266\n",
      "====> Epoch: 85 Average train loss: 343.3639\n",
      "====> Epoch: 85 Average test loss: 973.3776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 86 [0/2589 (0%)]\tLoss: 351.937164\n",
      "Train Epoch: 86 [300/2589 (12%)]\tLoss: 213.381149\n",
      "Train Epoch: 86 [600/2589 (23%)]\tLoss: 360.105865\n",
      "Train Epoch: 86 [900/2589 (35%)]\tLoss: 355.804138\n",
      "Train Epoch: 86 [1200/2589 (46%)]\tLoss: 450.591522\n",
      "Train Epoch: 86 [1500/2589 (58%)]\tLoss: 497.863892\n",
      "Train Epoch: 86 [1800/2589 (70%)]\tLoss: 513.873352\n",
      "Train Epoch: 86 [2100/2589 (81%)]\tLoss: 355.827454\n",
      "Train Epoch: 86 [2400/2589 (93%)]\tLoss: 332.820435\n",
      "====> Epoch: 86 Average train loss: 344.2160\n",
      "====> Epoch: 86 Average test loss: 974.9186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 87 [0/2589 (0%)]\tLoss: 318.416107\n",
      "Train Epoch: 87 [300/2589 (12%)]\tLoss: 293.608063\n",
      "Train Epoch: 87 [600/2589 (23%)]\tLoss: 419.319946\n",
      "Train Epoch: 87 [900/2589 (35%)]\tLoss: 316.409973\n",
      "Train Epoch: 87 [1200/2589 (46%)]\tLoss: 370.842896\n",
      "Train Epoch: 87 [1500/2589 (58%)]\tLoss: 200.580215\n",
      "Train Epoch: 87 [1800/2589 (70%)]\tLoss: 307.102051\n",
      "Train Epoch: 87 [2100/2589 (81%)]\tLoss: 352.352570\n",
      "Train Epoch: 87 [2400/2589 (93%)]\tLoss: 337.784271\n",
      "====> Epoch: 87 Average train loss: 341.8547\n",
      "====> Epoch: 87 Average test loss: 956.3986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 88 [0/2589 (0%)]\tLoss: 348.561310\n",
      "Train Epoch: 88 [300/2589 (12%)]\tLoss: 390.233978\n",
      "Train Epoch: 88 [600/2589 (23%)]\tLoss: 300.088013\n",
      "Train Epoch: 88 [900/2589 (35%)]\tLoss: 430.847046\n",
      "Train Epoch: 88 [1200/2589 (46%)]\tLoss: 348.843719\n",
      "Train Epoch: 88 [1500/2589 (58%)]\tLoss: 317.634277\n",
      "Train Epoch: 88 [1800/2589 (70%)]\tLoss: 417.847260\n",
      "Train Epoch: 88 [2100/2589 (81%)]\tLoss: 202.448441\n",
      "Train Epoch: 88 [2400/2589 (93%)]\tLoss: 322.536407\n",
      "====> Epoch: 88 Average train loss: 343.0482\n",
      "====> Epoch: 88 Average test loss: 959.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 89 [0/2589 (0%)]\tLoss: 298.095245\n",
      "Train Epoch: 89 [300/2589 (12%)]\tLoss: 223.979599\n",
      "Train Epoch: 89 [600/2589 (23%)]\tLoss: 339.420380\n",
      "Train Epoch: 89 [900/2589 (35%)]\tLoss: 322.971680\n",
      "Train Epoch: 89 [1200/2589 (46%)]\tLoss: 613.030457\n",
      "Train Epoch: 89 [1500/2589 (58%)]\tLoss: 464.721466\n",
      "Train Epoch: 89 [1800/2589 (70%)]\tLoss: 405.562561\n",
      "Train Epoch: 89 [2100/2589 (81%)]\tLoss: 242.089462\n",
      "Train Epoch: 89 [2400/2589 (93%)]\tLoss: 244.121979\n",
      "====> Epoch: 89 Average train loss: 341.7867\n",
      "====> Epoch: 89 Average test loss: 958.7591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 90 [0/2589 (0%)]\tLoss: 216.632645\n",
      "Train Epoch: 90 [300/2589 (12%)]\tLoss: 232.249649\n",
      "Train Epoch: 90 [600/2589 (23%)]\tLoss: 313.684235\n",
      "Train Epoch: 90 [900/2589 (35%)]\tLoss: 412.557831\n",
      "Train Epoch: 90 [1200/2589 (46%)]\tLoss: 309.756134\n",
      "Train Epoch: 90 [1500/2589 (58%)]\tLoss: 391.421234\n",
      "Train Epoch: 90 [1800/2589 (70%)]\tLoss: 231.250275\n",
      "Train Epoch: 90 [2100/2589 (81%)]\tLoss: 306.996216\n",
      "Train Epoch: 90 [2400/2589 (93%)]\tLoss: 323.676788\n",
      "====> Epoch: 90 Average train loss: 339.3578\n",
      "====> Epoch: 90 Average test loss: 993.0330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 91 [0/2589 (0%)]\tLoss: 319.230377\n",
      "Train Epoch: 91 [300/2589 (12%)]\tLoss: 383.257019\n",
      "Train Epoch: 91 [600/2589 (23%)]\tLoss: 289.664124\n",
      "Train Epoch: 91 [900/2589 (35%)]\tLoss: 331.891602\n",
      "Train Epoch: 91 [1200/2589 (46%)]\tLoss: 400.702850\n",
      "Train Epoch: 91 [1500/2589 (58%)]\tLoss: 411.198029\n",
      "Train Epoch: 91 [1800/2589 (70%)]\tLoss: 393.947754\n",
      "Train Epoch: 91 [2100/2589 (81%)]\tLoss: 422.920197\n",
      "Train Epoch: 91 [2400/2589 (93%)]\tLoss: 335.657166\n",
      "====> Epoch: 91 Average train loss: 338.4229\n",
      "====> Epoch: 91 Average test loss: 969.6166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 92 [0/2589 (0%)]\tLoss: 277.503784\n",
      "Train Epoch: 92 [300/2589 (12%)]\tLoss: 245.821625\n",
      "Train Epoch: 92 [600/2589 (23%)]\tLoss: 357.177887\n",
      "Train Epoch: 92 [900/2589 (35%)]\tLoss: 337.430298\n",
      "Train Epoch: 92 [1200/2589 (46%)]\tLoss: 334.425720\n",
      "Train Epoch: 92 [1500/2589 (58%)]\tLoss: 435.879486\n",
      "Train Epoch: 92 [1800/2589 (70%)]\tLoss: 351.593872\n",
      "Train Epoch: 92 [2100/2589 (81%)]\tLoss: 427.033295\n",
      "Train Epoch: 92 [2400/2589 (93%)]\tLoss: 407.475433\n",
      "====> Epoch: 92 Average train loss: 347.8771\n",
      "====> Epoch: 92 Average test loss: 938.7603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 93 [0/2589 (0%)]\tLoss: 203.302155\n",
      "Train Epoch: 93 [300/2589 (12%)]\tLoss: 384.976898\n",
      "Train Epoch: 93 [600/2589 (23%)]\tLoss: 265.714417\n",
      "Train Epoch: 93 [900/2589 (35%)]\tLoss: 264.150940\n",
      "Train Epoch: 93 [1200/2589 (46%)]\tLoss: 517.801575\n",
      "Train Epoch: 93 [1500/2589 (58%)]\tLoss: 277.442078\n",
      "Train Epoch: 93 [1800/2589 (70%)]\tLoss: 358.852936\n",
      "Train Epoch: 93 [2100/2589 (81%)]\tLoss: 316.801239\n",
      "Train Epoch: 93 [2400/2589 (93%)]\tLoss: 386.137756\n",
      "====> Epoch: 93 Average train loss: 339.4553\n",
      "====> Epoch: 93 Average test loss: 963.2021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 94 [0/2589 (0%)]\tLoss: 502.712433\n",
      "Train Epoch: 94 [300/2589 (12%)]\tLoss: 451.669769\n",
      "Train Epoch: 94 [600/2589 (23%)]\tLoss: 417.321259\n",
      "Train Epoch: 94 [900/2589 (35%)]\tLoss: 248.673615\n",
      "Train Epoch: 94 [1200/2589 (46%)]\tLoss: 270.685394\n",
      "Train Epoch: 94 [1500/2589 (58%)]\tLoss: 387.628235\n",
      "Train Epoch: 94 [1800/2589 (70%)]\tLoss: 265.832947\n",
      "Train Epoch: 94 [2100/2589 (81%)]\tLoss: 447.515076\n",
      "Train Epoch: 94 [2400/2589 (93%)]\tLoss: 365.823364\n",
      "====> Epoch: 94 Average train loss: 341.1661\n",
      "====> Epoch: 94 Average test loss: 972.1973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 95 [0/2589 (0%)]\tLoss: 350.875092\n",
      "Train Epoch: 95 [300/2589 (12%)]\tLoss: 364.792847\n",
      "Train Epoch: 95 [600/2589 (23%)]\tLoss: 394.244507\n",
      "Train Epoch: 95 [900/2589 (35%)]\tLoss: 252.724991\n",
      "Train Epoch: 95 [1200/2589 (46%)]\tLoss: 275.572754\n",
      "Train Epoch: 95 [1500/2589 (58%)]\tLoss: 359.697083\n",
      "Train Epoch: 95 [1800/2589 (70%)]\tLoss: 343.412262\n",
      "Train Epoch: 95 [2100/2589 (81%)]\tLoss: 276.612122\n",
      "Train Epoch: 95 [2400/2589 (93%)]\tLoss: 330.155884\n",
      "====> Epoch: 95 Average train loss: 328.5024\n",
      "====> Epoch: 95 Average test loss: 949.0389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 96 [0/2589 (0%)]\tLoss: 352.553070\n",
      "Train Epoch: 96 [300/2589 (12%)]\tLoss: 272.498962\n",
      "Train Epoch: 96 [600/2589 (23%)]\tLoss: 336.368256\n",
      "Train Epoch: 96 [900/2589 (35%)]\tLoss: 326.245697\n",
      "Train Epoch: 96 [1200/2589 (46%)]\tLoss: 323.819214\n",
      "Train Epoch: 96 [1500/2589 (58%)]\tLoss: 274.751434\n",
      "Train Epoch: 96 [1800/2589 (70%)]\tLoss: 380.857758\n",
      "Train Epoch: 96 [2100/2589 (81%)]\tLoss: 470.478882\n",
      "Train Epoch: 96 [2400/2589 (93%)]\tLoss: 287.950562\n",
      "====> Epoch: 96 Average train loss: 332.4037\n",
      "====> Epoch: 96 Average test loss: 977.4015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 97 [0/2589 (0%)]\tLoss: 251.073303\n",
      "Train Epoch: 97 [300/2589 (12%)]\tLoss: 348.823059\n",
      "Train Epoch: 97 [600/2589 (23%)]\tLoss: 375.643829\n",
      "Train Epoch: 97 [900/2589 (35%)]\tLoss: 317.860474\n",
      "Train Epoch: 97 [1200/2589 (46%)]\tLoss: 312.276672\n",
      "Train Epoch: 97 [1500/2589 (58%)]\tLoss: 286.287170\n",
      "Train Epoch: 97 [1800/2589 (70%)]\tLoss: 263.274475\n",
      "Train Epoch: 97 [2100/2589 (81%)]\tLoss: 307.288574\n",
      "Train Epoch: 97 [2400/2589 (93%)]\tLoss: 239.611191\n",
      "====> Epoch: 97 Average train loss: 340.5896\n",
      "====> Epoch: 97 Average test loss: 974.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 98 [0/2589 (0%)]\tLoss: 350.837738\n",
      "Train Epoch: 98 [300/2589 (12%)]\tLoss: 477.356659\n",
      "Train Epoch: 98 [600/2589 (23%)]\tLoss: 567.165649\n",
      "Train Epoch: 98 [900/2589 (35%)]\tLoss: 306.927643\n",
      "Train Epoch: 98 [1200/2589 (46%)]\tLoss: 459.943970\n",
      "Train Epoch: 98 [1500/2589 (58%)]\tLoss: 289.097137\n",
      "Train Epoch: 98 [1800/2589 (70%)]\tLoss: 313.999542\n",
      "Train Epoch: 98 [2100/2589 (81%)]\tLoss: 409.659149\n",
      "Train Epoch: 98 [2400/2589 (93%)]\tLoss: 287.987488\n",
      "====> Epoch: 98 Average train loss: 345.6075\n",
      "====> Epoch: 98 Average test loss: 938.5838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 99 [0/2589 (0%)]\tLoss: 288.890900\n",
      "Train Epoch: 99 [300/2589 (12%)]\tLoss: 363.316864\n",
      "Train Epoch: 99 [600/2589 (23%)]\tLoss: 343.580139\n",
      "Train Epoch: 99 [900/2589 (35%)]\tLoss: 301.471954\n",
      "Train Epoch: 99 [1200/2589 (46%)]\tLoss: 277.727814\n",
      "Train Epoch: 99 [1500/2589 (58%)]\tLoss: 324.176697\n",
      "Train Epoch: 99 [1800/2589 (70%)]\tLoss: 382.231476\n",
      "Train Epoch: 99 [2100/2589 (81%)]\tLoss: 368.551605\n",
      "Train Epoch: 99 [2400/2589 (93%)]\tLoss: 233.863052\n",
      "====> Epoch: 99 Average train loss: 351.5699\n",
      "====> Epoch: 99 Average test loss: 952.3362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/2589 (0%)]\tLoss: 306.996796\n",
      "Train Epoch: 100 [300/2589 (12%)]\tLoss: 257.034241\n",
      "Train Epoch: 100 [600/2589 (23%)]\tLoss: 325.716339\n",
      "Train Epoch: 100 [900/2589 (35%)]\tLoss: 362.103424\n",
      "Train Epoch: 100 [1200/2589 (46%)]\tLoss: 447.285370\n",
      "Train Epoch: 100 [1500/2589 (58%)]\tLoss: 416.342621\n",
      "Train Epoch: 100 [1800/2589 (70%)]\tLoss: 253.028458\n",
      "Train Epoch: 100 [2100/2589 (81%)]\tLoss: 334.235901\n",
      "Train Epoch: 100 [2400/2589 (93%)]\tLoss: 297.031525\n",
      "====> Epoch: 100 Average train loss: 338.4789\n",
      "====> Epoch: 100 Average test loss: 927.6988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 101 [0/2589 (0%)]\tLoss: 284.198456\n",
      "Train Epoch: 101 [300/2589 (12%)]\tLoss: 395.399597\n",
      "Train Epoch: 101 [600/2589 (23%)]\tLoss: 309.725403\n",
      "Train Epoch: 101 [900/2589 (35%)]\tLoss: 417.389038\n",
      "Train Epoch: 101 [1200/2589 (46%)]\tLoss: 299.280457\n",
      "Train Epoch: 101 [1500/2589 (58%)]\tLoss: 316.676697\n",
      "Train Epoch: 101 [1800/2589 (70%)]\tLoss: 284.095978\n",
      "Train Epoch: 101 [2100/2589 (81%)]\tLoss: 297.459351\n",
      "Train Epoch: 101 [2400/2589 (93%)]\tLoss: 391.176178\n",
      "====> Epoch: 101 Average train loss: 322.4482\n",
      "====> Epoch: 101 Average test loss: 932.8209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 102 [0/2589 (0%)]\tLoss: 327.457214\n",
      "Train Epoch: 102 [300/2589 (12%)]\tLoss: 284.071106\n",
      "Train Epoch: 102 [600/2589 (23%)]\tLoss: 305.860626\n",
      "Train Epoch: 102 [900/2589 (35%)]\tLoss: 463.685211\n",
      "Train Epoch: 102 [1200/2589 (46%)]\tLoss: 524.869568\n",
      "Train Epoch: 102 [1500/2589 (58%)]\tLoss: 235.557312\n",
      "Train Epoch: 102 [1800/2589 (70%)]\tLoss: 245.196228\n",
      "Train Epoch: 102 [2100/2589 (81%)]\tLoss: 341.427917\n",
      "Train Epoch: 102 [2400/2589 (93%)]\tLoss: 370.680847\n",
      "====> Epoch: 102 Average train loss: 332.1342\n",
      "====> Epoch: 102 Average test loss: 930.3229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 103 [0/2589 (0%)]\tLoss: 287.848969\n",
      "Train Epoch: 103 [300/2589 (12%)]\tLoss: 334.568481\n",
      "Train Epoch: 103 [600/2589 (23%)]\tLoss: 327.785767\n",
      "Train Epoch: 103 [900/2589 (35%)]\tLoss: 273.671417\n",
      "Train Epoch: 103 [1200/2589 (46%)]\tLoss: 250.770508\n",
      "Train Epoch: 103 [1500/2589 (58%)]\tLoss: 362.921082\n",
      "Train Epoch: 103 [1800/2589 (70%)]\tLoss: 309.932526\n",
      "Train Epoch: 103 [2100/2589 (81%)]\tLoss: 282.447205\n",
      "Train Epoch: 103 [2400/2589 (93%)]\tLoss: 259.774017\n",
      "====> Epoch: 103 Average train loss: 324.7520\n",
      "====> Epoch: 103 Average test loss: 982.3641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 104 [0/2589 (0%)]\tLoss: 387.161682\n",
      "Train Epoch: 104 [300/2589 (12%)]\tLoss: 336.715881\n",
      "Train Epoch: 104 [600/2589 (23%)]\tLoss: 360.399139\n",
      "Train Epoch: 104 [900/2589 (35%)]\tLoss: 447.540680\n",
      "Train Epoch: 104 [1200/2589 (46%)]\tLoss: 341.497955\n",
      "Train Epoch: 104 [1500/2589 (58%)]\tLoss: 427.376740\n",
      "Train Epoch: 104 [1800/2589 (70%)]\tLoss: 268.785614\n",
      "Train Epoch: 104 [2100/2589 (81%)]\tLoss: 382.364441\n",
      "Train Epoch: 104 [2400/2589 (93%)]\tLoss: 386.465881\n",
      "====> Epoch: 104 Average train loss: 333.2766\n",
      "====> Epoch: 104 Average test loss: 953.7135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 105 [0/2589 (0%)]\tLoss: 270.092224\n",
      "Train Epoch: 105 [300/2589 (12%)]\tLoss: 305.460938\n",
      "Train Epoch: 105 [600/2589 (23%)]\tLoss: 353.750977\n",
      "Train Epoch: 105 [900/2589 (35%)]\tLoss: 281.756714\n",
      "Train Epoch: 105 [1200/2589 (46%)]\tLoss: 307.747437\n",
      "Train Epoch: 105 [1500/2589 (58%)]\tLoss: 274.484833\n",
      "Train Epoch: 105 [1800/2589 (70%)]\tLoss: 537.868469\n",
      "Train Epoch: 105 [2100/2589 (81%)]\tLoss: 381.689178\n",
      "Train Epoch: 105 [2400/2589 (93%)]\tLoss: 280.623413\n",
      "====> Epoch: 105 Average train loss: 326.5977\n",
      "====> Epoch: 105 Average test loss: 936.0273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 106 [0/2589 (0%)]\tLoss: 423.344543\n",
      "Train Epoch: 106 [300/2589 (12%)]\tLoss: 261.251740\n",
      "Train Epoch: 106 [600/2589 (23%)]\tLoss: 257.442078\n",
      "Train Epoch: 106 [900/2589 (35%)]\tLoss: 342.316010\n",
      "Train Epoch: 106 [1200/2589 (46%)]\tLoss: 319.360016\n",
      "Train Epoch: 106 [1500/2589 (58%)]\tLoss: 281.915436\n",
      "Train Epoch: 106 [1800/2589 (70%)]\tLoss: 348.875854\n",
      "Train Epoch: 106 [2100/2589 (81%)]\tLoss: 318.358063\n",
      "Train Epoch: 106 [2400/2589 (93%)]\tLoss: 440.222534\n",
      "====> Epoch: 106 Average train loss: 316.2711\n",
      "====> Epoch: 106 Average test loss: 957.2432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 107 [0/2589 (0%)]\tLoss: 217.402649\n",
      "Train Epoch: 107 [300/2589 (12%)]\tLoss: 319.551971\n",
      "Train Epoch: 107 [600/2589 (23%)]\tLoss: 366.684265\n",
      "Train Epoch: 107 [900/2589 (35%)]\tLoss: 321.874786\n",
      "Train Epoch: 107 [1200/2589 (46%)]\tLoss: 294.181000\n",
      "Train Epoch: 107 [1500/2589 (58%)]\tLoss: 281.948853\n",
      "Train Epoch: 107 [1800/2589 (70%)]\tLoss: 273.302277\n",
      "Train Epoch: 107 [2100/2589 (81%)]\tLoss: 278.272156\n",
      "Train Epoch: 107 [2400/2589 (93%)]\tLoss: 240.628616\n",
      "====> Epoch: 107 Average train loss: 323.8973\n",
      "====> Epoch: 107 Average test loss: 970.4144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 108 [0/2589 (0%)]\tLoss: 479.482727\n",
      "Train Epoch: 108 [300/2589 (12%)]\tLoss: 674.266602\n",
      "Train Epoch: 108 [600/2589 (23%)]\tLoss: 388.174164\n",
      "Train Epoch: 108 [900/2589 (35%)]\tLoss: 306.769226\n",
      "Train Epoch: 108 [1200/2589 (46%)]\tLoss: 542.086548\n",
      "Train Epoch: 108 [1500/2589 (58%)]\tLoss: 327.756348\n",
      "Train Epoch: 108 [1800/2589 (70%)]\tLoss: 403.982849\n",
      "Train Epoch: 108 [2100/2589 (81%)]\tLoss: 335.222229\n",
      "Train Epoch: 108 [2400/2589 (93%)]\tLoss: 437.792419\n",
      "====> Epoch: 108 Average train loss: 342.1807\n",
      "====> Epoch: 108 Average test loss: 948.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [0/2589 (0%)]\tLoss: 362.037933\n",
      "Train Epoch: 109 [300/2589 (12%)]\tLoss: 294.728668\n",
      "Train Epoch: 109 [600/2589 (23%)]\tLoss: 344.154724\n",
      "Train Epoch: 109 [900/2589 (35%)]\tLoss: 383.555878\n",
      "Train Epoch: 109 [1200/2589 (46%)]\tLoss: 310.419128\n",
      "Train Epoch: 109 [1500/2589 (58%)]\tLoss: 335.156250\n",
      "Train Epoch: 109 [1800/2589 (70%)]\tLoss: 247.145279\n",
      "Train Epoch: 109 [2100/2589 (81%)]\tLoss: 276.122467\n",
      "Train Epoch: 109 [2400/2589 (93%)]\tLoss: 377.765930\n",
      "====> Epoch: 109 Average train loss: 325.0555\n",
      "====> Epoch: 109 Average test loss: 972.3555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 110 [0/2589 (0%)]\tLoss: 307.829437\n",
      "Train Epoch: 110 [300/2589 (12%)]\tLoss: 341.949097\n",
      "Train Epoch: 110 [600/2589 (23%)]\tLoss: 298.095917\n",
      "Train Epoch: 110 [900/2589 (35%)]\tLoss: 391.015350\n",
      "Train Epoch: 110 [1200/2589 (46%)]\tLoss: 322.035034\n",
      "Train Epoch: 110 [1500/2589 (58%)]\tLoss: 249.613449\n",
      "Train Epoch: 110 [1800/2589 (70%)]\tLoss: 351.620270\n",
      "Train Epoch: 110 [2100/2589 (81%)]\tLoss: 268.743103\n",
      "Train Epoch: 110 [2400/2589 (93%)]\tLoss: 211.049667\n",
      "====> Epoch: 110 Average train loss: 333.3139\n",
      "====> Epoch: 110 Average test loss: 948.4443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 111 [0/2589 (0%)]\tLoss: 346.575195\n",
      "Train Epoch: 111 [300/2589 (12%)]\tLoss: 280.534393\n",
      "Train Epoch: 111 [600/2589 (23%)]\tLoss: 309.985291\n",
      "Train Epoch: 111 [900/2589 (35%)]\tLoss: 345.204163\n",
      "Train Epoch: 111 [1200/2589 (46%)]\tLoss: 534.181030\n",
      "Train Epoch: 111 [1500/2589 (58%)]\tLoss: 193.390640\n",
      "Train Epoch: 111 [1800/2589 (70%)]\tLoss: 319.429413\n",
      "Train Epoch: 111 [2100/2589 (81%)]\tLoss: 364.625214\n",
      "Train Epoch: 111 [2400/2589 (93%)]\tLoss: 463.148499\n",
      "====> Epoch: 111 Average train loss: 327.3484\n",
      "====> Epoch: 111 Average test loss: 957.2665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 112 [0/2589 (0%)]\tLoss: 265.149048\n",
      "Train Epoch: 112 [300/2589 (12%)]\tLoss: 322.616333\n",
      "Train Epoch: 112 [600/2589 (23%)]\tLoss: 310.669586\n",
      "Train Epoch: 112 [900/2589 (35%)]\tLoss: 355.477539\n",
      "Train Epoch: 112 [1200/2589 (46%)]\tLoss: 341.401855\n",
      "Train Epoch: 112 [1500/2589 (58%)]\tLoss: 308.231506\n",
      "Train Epoch: 112 [1800/2589 (70%)]\tLoss: 444.053253\n",
      "Train Epoch: 112 [2100/2589 (81%)]\tLoss: 347.479675\n",
      "Train Epoch: 112 [2400/2589 (93%)]\tLoss: 381.369934\n",
      "====> Epoch: 112 Average train loss: 331.4291\n",
      "====> Epoch: 112 Average test loss: 973.0709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 113 [0/2589 (0%)]\tLoss: 230.539566\n",
      "Train Epoch: 113 [300/2589 (12%)]\tLoss: 339.979492\n",
      "Train Epoch: 113 [600/2589 (23%)]\tLoss: 486.110352\n",
      "Train Epoch: 113 [900/2589 (35%)]\tLoss: 375.069672\n",
      "Train Epoch: 113 [1200/2589 (46%)]\tLoss: 380.081390\n",
      "Train Epoch: 113 [1500/2589 (58%)]\tLoss: 326.928894\n",
      "Train Epoch: 113 [1800/2589 (70%)]\tLoss: 333.129059\n",
      "Train Epoch: 113 [2100/2589 (81%)]\tLoss: 357.788208\n",
      "Train Epoch: 113 [2400/2589 (93%)]\tLoss: 370.791595\n",
      "====> Epoch: 113 Average train loss: 325.5642\n",
      "====> Epoch: 113 Average test loss: 945.1518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 114 [0/2589 (0%)]\tLoss: 418.684082\n",
      "Train Epoch: 114 [300/2589 (12%)]\tLoss: 363.369843\n",
      "Train Epoch: 114 [600/2589 (23%)]\tLoss: 220.680115\n",
      "Train Epoch: 114 [900/2589 (35%)]\tLoss: 334.163513\n",
      "Train Epoch: 114 [1200/2589 (46%)]\tLoss: 295.565491\n",
      "Train Epoch: 114 [1500/2589 (58%)]\tLoss: 319.016815\n",
      "Train Epoch: 114 [1800/2589 (70%)]\tLoss: 384.581970\n",
      "Train Epoch: 114 [2100/2589 (81%)]\tLoss: 419.461487\n",
      "Train Epoch: 114 [2400/2589 (93%)]\tLoss: 236.305771\n",
      "====> Epoch: 114 Average train loss: 320.4059\n",
      "====> Epoch: 114 Average test loss: 957.2931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 115 [0/2589 (0%)]\tLoss: 254.035416\n",
      "Train Epoch: 115 [300/2589 (12%)]\tLoss: 408.733795\n",
      "Train Epoch: 115 [600/2589 (23%)]\tLoss: 325.773560\n",
      "Train Epoch: 115 [900/2589 (35%)]\tLoss: 254.128754\n",
      "Train Epoch: 115 [1200/2589 (46%)]\tLoss: 274.533783\n",
      "Train Epoch: 115 [1500/2589 (58%)]\tLoss: 350.935822\n",
      "Train Epoch: 115 [1800/2589 (70%)]\tLoss: 338.962708\n",
      "Train Epoch: 115 [2100/2589 (81%)]\tLoss: 410.496307\n",
      "Train Epoch: 115 [2400/2589 (93%)]\tLoss: 274.926361\n",
      "====> Epoch: 115 Average train loss: 319.3234\n",
      "====> Epoch: 115 Average test loss: 950.5748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 116 [0/2589 (0%)]\tLoss: 358.844574\n",
      "Train Epoch: 116 [300/2589 (12%)]\tLoss: 281.693237\n",
      "Train Epoch: 116 [600/2589 (23%)]\tLoss: 232.752930\n",
      "Train Epoch: 116 [900/2589 (35%)]\tLoss: 233.906509\n",
      "Train Epoch: 116 [1200/2589 (46%)]\tLoss: 252.371277\n",
      "Train Epoch: 116 [1500/2589 (58%)]\tLoss: 343.556427\n",
      "Train Epoch: 116 [1800/2589 (70%)]\tLoss: 409.300873\n",
      "Train Epoch: 116 [2100/2589 (81%)]\tLoss: 200.139343\n",
      "Train Epoch: 116 [2400/2589 (93%)]\tLoss: 295.544342\n",
      "====> Epoch: 116 Average train loss: 310.0840\n",
      "====> Epoch: 116 Average test loss: 953.3301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 117 [0/2589 (0%)]\tLoss: 274.911346\n",
      "Train Epoch: 117 [300/2589 (12%)]\tLoss: 378.954651\n",
      "Train Epoch: 117 [600/2589 (23%)]\tLoss: 323.113373\n",
      "Train Epoch: 117 [900/2589 (35%)]\tLoss: 273.119995\n",
      "Train Epoch: 117 [1200/2589 (46%)]\tLoss: 452.788727\n",
      "Train Epoch: 117 [1500/2589 (58%)]\tLoss: 464.269836\n",
      "Train Epoch: 117 [1800/2589 (70%)]\tLoss: 362.328583\n",
      "Train Epoch: 117 [2100/2589 (81%)]\tLoss: 395.031036\n",
      "Train Epoch: 117 [2400/2589 (93%)]\tLoss: 270.439209\n",
      "====> Epoch: 117 Average train loss: 317.6530\n",
      "====> Epoch: 117 Average test loss: 968.8362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 118 [0/2589 (0%)]\tLoss: 275.115692\n",
      "Train Epoch: 118 [300/2589 (12%)]\tLoss: 470.854004\n",
      "Train Epoch: 118 [600/2589 (23%)]\tLoss: 370.022919\n",
      "Train Epoch: 118 [900/2589 (35%)]\tLoss: 209.907059\n",
      "Train Epoch: 118 [1200/2589 (46%)]\tLoss: 360.684448\n",
      "Train Epoch: 118 [1500/2589 (58%)]\tLoss: 292.781311\n",
      "Train Epoch: 118 [1800/2589 (70%)]\tLoss: 296.725220\n",
      "Train Epoch: 118 [2100/2589 (81%)]\tLoss: 261.879913\n",
      "Train Epoch: 118 [2400/2589 (93%)]\tLoss: 491.999725\n",
      "====> Epoch: 118 Average train loss: 328.2742\n",
      "====> Epoch: 118 Average test loss: 993.9598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 119 [0/2589 (0%)]\tLoss: 277.230011\n",
      "Train Epoch: 119 [300/2589 (12%)]\tLoss: 327.882141\n",
      "Train Epoch: 119 [600/2589 (23%)]\tLoss: 333.341431\n",
      "Train Epoch: 119 [900/2589 (35%)]\tLoss: 263.153198\n",
      "Train Epoch: 119 [1200/2589 (46%)]\tLoss: 276.427948\n",
      "Train Epoch: 119 [1500/2589 (58%)]\tLoss: 433.608124\n",
      "Train Epoch: 119 [1800/2589 (70%)]\tLoss: 368.590820\n",
      "Train Epoch: 119 [2100/2589 (81%)]\tLoss: 388.086853\n",
      "Train Epoch: 119 [2400/2589 (93%)]\tLoss: 259.769562\n",
      "====> Epoch: 119 Average train loss: 315.0166\n",
      "====> Epoch: 119 Average test loss: 965.6818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 120 [0/2589 (0%)]\tLoss: 211.426468\n",
      "Train Epoch: 120 [300/2589 (12%)]\tLoss: 305.654663\n",
      "Train Epoch: 120 [600/2589 (23%)]\tLoss: 250.940369\n",
      "Train Epoch: 120 [900/2589 (35%)]\tLoss: 451.689392\n",
      "Train Epoch: 120 [1200/2589 (46%)]\tLoss: 242.782913\n",
      "Train Epoch: 120 [1500/2589 (58%)]\tLoss: 298.718231\n",
      "Train Epoch: 120 [1800/2589 (70%)]\tLoss: 273.576660\n",
      "Train Epoch: 120 [2100/2589 (81%)]\tLoss: 201.347839\n",
      "Train Epoch: 120 [2400/2589 (93%)]\tLoss: 423.157349\n",
      "====> Epoch: 120 Average train loss: 318.4530\n",
      "====> Epoch: 120 Average test loss: 960.5876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 121 [0/2589 (0%)]\tLoss: 294.018921\n",
      "Train Epoch: 121 [300/2589 (12%)]\tLoss: 380.040192\n",
      "Train Epoch: 121 [600/2589 (23%)]\tLoss: 209.352814\n",
      "Train Epoch: 121 [900/2589 (35%)]\tLoss: 316.435272\n",
      "Train Epoch: 121 [1200/2589 (46%)]\tLoss: 426.473267\n",
      "Train Epoch: 121 [1500/2589 (58%)]\tLoss: 348.350647\n",
      "Train Epoch: 121 [1800/2589 (70%)]\tLoss: 253.267899\n",
      "Train Epoch: 121 [2100/2589 (81%)]\tLoss: 301.884125\n",
      "Train Epoch: 121 [2400/2589 (93%)]\tLoss: 333.714478\n",
      "====> Epoch: 121 Average train loss: 329.4672\n",
      "====> Epoch: 121 Average test loss: 937.3013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122 [0/2589 (0%)]\tLoss: 420.795471\n",
      "Train Epoch: 122 [300/2589 (12%)]\tLoss: 340.436615\n",
      "Train Epoch: 122 [600/2589 (23%)]\tLoss: 338.977051\n",
      "Train Epoch: 122 [900/2589 (35%)]\tLoss: 277.934662\n",
      "Train Epoch: 122 [1200/2589 (46%)]\tLoss: 384.315247\n",
      "Train Epoch: 122 [1500/2589 (58%)]\tLoss: 262.138947\n",
      "Train Epoch: 122 [1800/2589 (70%)]\tLoss: 335.404297\n",
      "Train Epoch: 122 [2100/2589 (81%)]\tLoss: 266.464294\n",
      "Train Epoch: 122 [2400/2589 (93%)]\tLoss: 432.670959\n",
      "====> Epoch: 122 Average train loss: 315.2819\n",
      "====> Epoch: 122 Average test loss: 931.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 123 [0/2589 (0%)]\tLoss: 372.996155\n",
      "Train Epoch: 123 [300/2589 (12%)]\tLoss: 338.237885\n",
      "Train Epoch: 123 [600/2589 (23%)]\tLoss: 367.406647\n",
      "Train Epoch: 123 [900/2589 (35%)]\tLoss: 270.926178\n",
      "Train Epoch: 123 [1200/2589 (46%)]\tLoss: 333.136902\n",
      "Train Epoch: 123 [1500/2589 (58%)]\tLoss: 273.141296\n",
      "Train Epoch: 123 [1800/2589 (70%)]\tLoss: 234.938934\n",
      "Train Epoch: 123 [2100/2589 (81%)]\tLoss: 268.999176\n",
      "Train Epoch: 123 [2400/2589 (93%)]\tLoss: 362.773315\n",
      "====> Epoch: 123 Average train loss: 327.1321\n",
      "====> Epoch: 123 Average test loss: 926.5654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 124 [0/2589 (0%)]\tLoss: 337.051270\n",
      "Train Epoch: 124 [300/2589 (12%)]\tLoss: 467.547058\n",
      "Train Epoch: 124 [600/2589 (23%)]\tLoss: 268.867859\n",
      "Train Epoch: 124 [900/2589 (35%)]\tLoss: 631.831909\n",
      "Train Epoch: 124 [1200/2589 (46%)]\tLoss: 232.204681\n",
      "Train Epoch: 124 [1500/2589 (58%)]\tLoss: 313.799316\n",
      "Train Epoch: 124 [1800/2589 (70%)]\tLoss: 260.320953\n",
      "Train Epoch: 124 [2100/2589 (81%)]\tLoss: 296.923279\n",
      "Train Epoch: 124 [2400/2589 (93%)]\tLoss: 326.161346\n",
      "====> Epoch: 124 Average train loss: 315.9258\n",
      "====> Epoch: 124 Average test loss: 955.8672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 125 [0/2589 (0%)]\tLoss: 314.675140\n",
      "Train Epoch: 125 [300/2589 (12%)]\tLoss: 328.462250\n",
      "Train Epoch: 125 [600/2589 (23%)]\tLoss: 344.673767\n",
      "Train Epoch: 125 [900/2589 (35%)]\tLoss: 244.846863\n",
      "Train Epoch: 125 [1200/2589 (46%)]\tLoss: 271.647522\n",
      "Train Epoch: 125 [1500/2589 (58%)]\tLoss: 350.088715\n",
      "Train Epoch: 125 [1800/2589 (70%)]\tLoss: 397.168762\n",
      "Train Epoch: 125 [2100/2589 (81%)]\tLoss: 526.555786\n",
      "Train Epoch: 125 [2400/2589 (93%)]\tLoss: 416.541290\n",
      "====> Epoch: 125 Average train loss: 313.4901\n",
      "====> Epoch: 125 Average test loss: 944.0171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 126 [0/2589 (0%)]\tLoss: 330.412231\n",
      "Train Epoch: 126 [300/2589 (12%)]\tLoss: 331.621796\n",
      "Train Epoch: 126 [600/2589 (23%)]\tLoss: 398.770020\n",
      "Train Epoch: 126 [900/2589 (35%)]\tLoss: 463.246063\n",
      "Train Epoch: 126 [1200/2589 (46%)]\tLoss: 266.653412\n",
      "Train Epoch: 126 [1500/2589 (58%)]\tLoss: 213.212753\n",
      "Train Epoch: 126 [1800/2589 (70%)]\tLoss: 486.203400\n",
      "Train Epoch: 126 [2100/2589 (81%)]\tLoss: 440.144257\n",
      "Train Epoch: 126 [2400/2589 (93%)]\tLoss: 329.622040\n",
      "====> Epoch: 126 Average train loss: 325.7055\n",
      "====> Epoch: 126 Average test loss: 954.0568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 127 [0/2589 (0%)]\tLoss: 202.486496\n",
      "Train Epoch: 127 [300/2589 (12%)]\tLoss: 336.389374\n",
      "Train Epoch: 127 [600/2589 (23%)]\tLoss: 247.066727\n",
      "Train Epoch: 127 [900/2589 (35%)]\tLoss: 269.646881\n",
      "Train Epoch: 127 [1200/2589 (46%)]\tLoss: 248.453598\n",
      "Train Epoch: 127 [1500/2589 (58%)]\tLoss: 328.038177\n",
      "Train Epoch: 127 [1800/2589 (70%)]\tLoss: 233.079880\n",
      "Train Epoch: 127 [2100/2589 (81%)]\tLoss: 247.666245\n",
      "Train Epoch: 127 [2400/2589 (93%)]\tLoss: 307.417480\n",
      "====> Epoch: 127 Average train loss: 306.0570\n",
      "====> Epoch: 127 Average test loss: 948.4123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 128 [0/2589 (0%)]\tLoss: 289.502563\n",
      "Train Epoch: 128 [300/2589 (12%)]\tLoss: 308.612030\n",
      "Train Epoch: 128 [600/2589 (23%)]\tLoss: 248.739639\n",
      "Train Epoch: 128 [900/2589 (35%)]\tLoss: 266.332550\n",
      "Train Epoch: 128 [1200/2589 (46%)]\tLoss: 296.203339\n",
      "Train Epoch: 128 [1500/2589 (58%)]\tLoss: 271.800079\n",
      "Train Epoch: 128 [1800/2589 (70%)]\tLoss: 247.055557\n",
      "Train Epoch: 128 [2100/2589 (81%)]\tLoss: 292.246185\n",
      "Train Epoch: 128 [2400/2589 (93%)]\tLoss: 269.559906\n",
      "====> Epoch: 128 Average train loss: 320.0558\n",
      "====> Epoch: 128 Average test loss: 971.1561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 129 [0/2589 (0%)]\tLoss: 295.994568\n",
      "Train Epoch: 129 [300/2589 (12%)]\tLoss: 313.300018\n",
      "Train Epoch: 129 [600/2589 (23%)]\tLoss: 290.229218\n",
      "Train Epoch: 129 [900/2589 (35%)]\tLoss: 298.600250\n",
      "Train Epoch: 129 [1200/2589 (46%)]\tLoss: 229.892029\n",
      "Train Epoch: 129 [1500/2589 (58%)]\tLoss: 325.440399\n",
      "Train Epoch: 129 [1800/2589 (70%)]\tLoss: 286.110931\n",
      "Train Epoch: 129 [2100/2589 (81%)]\tLoss: 390.291718\n",
      "Train Epoch: 129 [2400/2589 (93%)]\tLoss: 355.289215\n",
      "====> Epoch: 129 Average train loss: 313.4424\n",
      "====> Epoch: 129 Average test loss: 984.1972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 130 [0/2589 (0%)]\tLoss: 222.580627\n",
      "Train Epoch: 130 [300/2589 (12%)]\tLoss: 309.437836\n",
      "Train Epoch: 130 [600/2589 (23%)]\tLoss: 480.298309\n",
      "Train Epoch: 130 [900/2589 (35%)]\tLoss: 336.623474\n",
      "Train Epoch: 130 [1200/2589 (46%)]\tLoss: 274.734100\n",
      "Train Epoch: 130 [1500/2589 (58%)]\tLoss: 250.780273\n",
      "Train Epoch: 130 [1800/2589 (70%)]\tLoss: 204.784119\n",
      "Train Epoch: 130 [2100/2589 (81%)]\tLoss: 280.692688\n",
      "Train Epoch: 130 [2400/2589 (93%)]\tLoss: 358.290039\n",
      "====> Epoch: 130 Average train loss: 313.2222\n",
      "====> Epoch: 130 Average test loss: 993.5314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 131 [0/2589 (0%)]\tLoss: 321.592651\n",
      "Train Epoch: 131 [300/2589 (12%)]\tLoss: 514.077271\n",
      "Train Epoch: 131 [600/2589 (23%)]\tLoss: 379.867889\n",
      "Train Epoch: 131 [900/2589 (35%)]\tLoss: 459.211060\n",
      "Train Epoch: 131 [1200/2589 (46%)]\tLoss: 334.849640\n",
      "Train Epoch: 131 [1500/2589 (58%)]\tLoss: 321.745911\n",
      "Train Epoch: 131 [1800/2589 (70%)]\tLoss: 311.701752\n",
      "Train Epoch: 131 [2100/2589 (81%)]\tLoss: 439.709381\n",
      "Train Epoch: 131 [2400/2589 (93%)]\tLoss: 322.426208\n",
      "====> Epoch: 131 Average train loss: 324.6414\n",
      "====> Epoch: 131 Average test loss: 942.9069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 132 [0/2589 (0%)]\tLoss: 197.794937\n",
      "Train Epoch: 132 [300/2589 (12%)]\tLoss: 338.439575\n",
      "Train Epoch: 132 [600/2589 (23%)]\tLoss: 357.918762\n",
      "Train Epoch: 132 [900/2589 (35%)]\tLoss: 337.782043\n",
      "Train Epoch: 132 [1200/2589 (46%)]\tLoss: 262.815887\n",
      "Train Epoch: 132 [1500/2589 (58%)]\tLoss: 504.547699\n",
      "Train Epoch: 132 [1800/2589 (70%)]\tLoss: 196.290237\n",
      "Train Epoch: 132 [2100/2589 (81%)]\tLoss: 300.682190\n",
      "Train Epoch: 132 [2400/2589 (93%)]\tLoss: 233.460907\n",
      "====> Epoch: 132 Average train loss: 312.3437\n",
      "====> Epoch: 132 Average test loss: 971.6245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 133 [0/2589 (0%)]\tLoss: 249.273880\n",
      "Train Epoch: 133 [300/2589 (12%)]\tLoss: 311.829926\n",
      "Train Epoch: 133 [600/2589 (23%)]\tLoss: 203.310974\n",
      "Train Epoch: 133 [900/2589 (35%)]\tLoss: 350.508972\n",
      "Train Epoch: 133 [1200/2589 (46%)]\tLoss: 404.878571\n",
      "Train Epoch: 133 [1500/2589 (58%)]\tLoss: 404.421722\n",
      "Train Epoch: 133 [1800/2589 (70%)]\tLoss: 310.201447\n",
      "Train Epoch: 133 [2100/2589 (81%)]\tLoss: 439.143372\n",
      "Train Epoch: 133 [2400/2589 (93%)]\tLoss: 258.512848\n",
      "====> Epoch: 133 Average train loss: 311.5475\n",
      "====> Epoch: 133 Average test loss: 969.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 134 [0/2589 (0%)]\tLoss: 286.804962\n",
      "Train Epoch: 134 [300/2589 (12%)]\tLoss: 290.020874\n",
      "Train Epoch: 134 [600/2589 (23%)]\tLoss: 245.704483\n",
      "Train Epoch: 134 [900/2589 (35%)]\tLoss: 286.765594\n",
      "Train Epoch: 134 [1200/2589 (46%)]\tLoss: 818.232239\n",
      "Train Epoch: 134 [1500/2589 (58%)]\tLoss: 306.940063\n",
      "Train Epoch: 134 [1800/2589 (70%)]\tLoss: 267.695526\n",
      "Train Epoch: 134 [2100/2589 (81%)]\tLoss: 295.148285\n",
      "Train Epoch: 134 [2400/2589 (93%)]\tLoss: 346.458191\n",
      "====> Epoch: 134 Average train loss: 311.1465\n",
      "====> Epoch: 134 Average test loss: 955.8380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 135 [0/2589 (0%)]\tLoss: 328.725311\n",
      "Train Epoch: 135 [300/2589 (12%)]\tLoss: 342.318420\n",
      "Train Epoch: 135 [600/2589 (23%)]\tLoss: 344.277344\n",
      "Train Epoch: 135 [900/2589 (35%)]\tLoss: 455.991791\n",
      "Train Epoch: 135 [1200/2589 (46%)]\tLoss: 208.741882\n",
      "Train Epoch: 135 [1500/2589 (58%)]\tLoss: 359.086578\n",
      "Train Epoch: 135 [1800/2589 (70%)]\tLoss: 311.688843\n",
      "Train Epoch: 135 [2100/2589 (81%)]\tLoss: 367.605957\n",
      "Train Epoch: 135 [2400/2589 (93%)]\tLoss: 309.779907\n",
      "====> Epoch: 135 Average train loss: 309.2940\n",
      "====> Epoch: 135 Average test loss: 971.8181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 136 [0/2589 (0%)]\tLoss: 290.945618\n",
      "Train Epoch: 136 [300/2589 (12%)]\tLoss: 383.686432\n",
      "Train Epoch: 136 [600/2589 (23%)]\tLoss: 213.676422\n",
      "Train Epoch: 136 [900/2589 (35%)]\tLoss: 406.917084\n",
      "Train Epoch: 136 [1200/2589 (46%)]\tLoss: 319.430695\n",
      "Train Epoch: 136 [1500/2589 (58%)]\tLoss: 256.567413\n",
      "Train Epoch: 136 [1800/2589 (70%)]\tLoss: 430.261230\n",
      "Train Epoch: 136 [2100/2589 (81%)]\tLoss: 282.606934\n",
      "Train Epoch: 136 [2400/2589 (93%)]\tLoss: 265.817200\n",
      "====> Epoch: 136 Average train loss: 316.0909\n",
      "====> Epoch: 136 Average test loss: 983.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 137 [0/2589 (0%)]\tLoss: 315.518921\n",
      "Train Epoch: 137 [300/2589 (12%)]\tLoss: 314.015991\n",
      "Train Epoch: 137 [600/2589 (23%)]\tLoss: 129.954269\n",
      "Train Epoch: 137 [900/2589 (35%)]\tLoss: 289.260406\n",
      "Train Epoch: 137 [1200/2589 (46%)]\tLoss: 291.824585\n",
      "Train Epoch: 137 [1500/2589 (58%)]\tLoss: 257.920624\n",
      "Train Epoch: 137 [1800/2589 (70%)]\tLoss: 418.875305\n",
      "Train Epoch: 137 [2100/2589 (81%)]\tLoss: 303.104156\n",
      "Train Epoch: 137 [2400/2589 (93%)]\tLoss: 216.478546\n",
      "====> Epoch: 137 Average train loss: 312.6290\n",
      "====> Epoch: 137 Average test loss: 975.2307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 138 [0/2589 (0%)]\tLoss: 453.495056\n",
      "Train Epoch: 138 [300/2589 (12%)]\tLoss: 330.280945\n",
      "Train Epoch: 138 [600/2589 (23%)]\tLoss: 309.340759\n",
      "Train Epoch: 138 [900/2589 (35%)]\tLoss: 383.137878\n",
      "Train Epoch: 138 [1200/2589 (46%)]\tLoss: 233.455719\n",
      "Train Epoch: 138 [1500/2589 (58%)]\tLoss: 272.744202\n",
      "Train Epoch: 138 [1800/2589 (70%)]\tLoss: 290.120422\n",
      "Train Epoch: 138 [2100/2589 (81%)]\tLoss: 385.336456\n",
      "Train Epoch: 138 [2400/2589 (93%)]\tLoss: 283.547394\n",
      "====> Epoch: 138 Average train loss: 313.5687\n",
      "====> Epoch: 138 Average test loss: 968.0496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 139 [0/2589 (0%)]\tLoss: 224.716125\n",
      "Train Epoch: 139 [300/2589 (12%)]\tLoss: 225.273087\n",
      "Train Epoch: 139 [600/2589 (23%)]\tLoss: 352.198547\n",
      "Train Epoch: 139 [900/2589 (35%)]\tLoss: 341.931580\n",
      "Train Epoch: 139 [1200/2589 (46%)]\tLoss: 472.659668\n",
      "Train Epoch: 139 [1500/2589 (58%)]\tLoss: 351.275360\n",
      "Train Epoch: 139 [1800/2589 (70%)]\tLoss: 244.463379\n",
      "Train Epoch: 139 [2100/2589 (81%)]\tLoss: 382.883209\n",
      "Train Epoch: 139 [2400/2589 (93%)]\tLoss: 312.773590\n",
      "====> Epoch: 139 Average train loss: 313.7963\n",
      "====> Epoch: 139 Average test loss: 959.0716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 140 [0/2589 (0%)]\tLoss: 223.500748\n",
      "Train Epoch: 140 [300/2589 (12%)]\tLoss: 220.398895\n",
      "Train Epoch: 140 [600/2589 (23%)]\tLoss: 353.569305\n",
      "Train Epoch: 140 [900/2589 (35%)]\tLoss: 266.569641\n",
      "Train Epoch: 140 [1200/2589 (46%)]\tLoss: 314.986938\n",
      "Train Epoch: 140 [1500/2589 (58%)]\tLoss: 337.475403\n",
      "Train Epoch: 140 [1800/2589 (70%)]\tLoss: 441.925568\n",
      "Train Epoch: 140 [2100/2589 (81%)]\tLoss: 344.531433\n",
      "Train Epoch: 140 [2400/2589 (93%)]\tLoss: 223.394623\n",
      "====> Epoch: 140 Average train loss: 305.9673\n",
      "====> Epoch: 140 Average test loss: 991.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 141 [0/2589 (0%)]\tLoss: 217.787399\n",
      "Train Epoch: 141 [300/2589 (12%)]\tLoss: 334.605255\n",
      "Train Epoch: 141 [600/2589 (23%)]\tLoss: 342.235046\n",
      "Train Epoch: 141 [900/2589 (35%)]\tLoss: 286.877106\n",
      "Train Epoch: 141 [1200/2589 (46%)]\tLoss: 337.890015\n",
      "Train Epoch: 141 [1500/2589 (58%)]\tLoss: 290.961639\n",
      "Train Epoch: 141 [1800/2589 (70%)]\tLoss: 287.369751\n",
      "Train Epoch: 141 [2100/2589 (81%)]\tLoss: 285.484497\n",
      "Train Epoch: 141 [2400/2589 (93%)]\tLoss: 298.667999\n",
      "====> Epoch: 141 Average train loss: 311.9897\n",
      "====> Epoch: 141 Average test loss: 953.1882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 142 [0/2589 (0%)]\tLoss: 364.673401\n",
      "Train Epoch: 142 [300/2589 (12%)]\tLoss: 269.200653\n",
      "Train Epoch: 142 [600/2589 (23%)]\tLoss: 275.325958\n",
      "Train Epoch: 142 [900/2589 (35%)]\tLoss: 209.485352\n",
      "Train Epoch: 142 [1200/2589 (46%)]\tLoss: 222.510895\n",
      "Train Epoch: 142 [1500/2589 (58%)]\tLoss: 450.797211\n",
      "Train Epoch: 142 [1800/2589 (70%)]\tLoss: 315.379242\n",
      "Train Epoch: 142 [2100/2589 (81%)]\tLoss: 186.909851\n",
      "Train Epoch: 142 [2400/2589 (93%)]\tLoss: 259.984283\n",
      "====> Epoch: 142 Average train loss: 305.9269\n",
      "====> Epoch: 142 Average test loss: 936.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 143 [0/2589 (0%)]\tLoss: 297.876495\n",
      "Train Epoch: 143 [300/2589 (12%)]\tLoss: 409.329895\n",
      "Train Epoch: 143 [600/2589 (23%)]\tLoss: 297.125488\n",
      "Train Epoch: 143 [900/2589 (35%)]\tLoss: 308.332855\n",
      "Train Epoch: 143 [1200/2589 (46%)]\tLoss: 207.399414\n",
      "Train Epoch: 143 [1500/2589 (58%)]\tLoss: 294.115143\n",
      "Train Epoch: 143 [1800/2589 (70%)]\tLoss: 222.805832\n",
      "Train Epoch: 143 [2100/2589 (81%)]\tLoss: 271.512909\n",
      "Train Epoch: 143 [2400/2589 (93%)]\tLoss: 258.902222\n",
      "====> Epoch: 143 Average train loss: 310.3594\n",
      "====> Epoch: 143 Average test loss: 964.3604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 144 [0/2589 (0%)]\tLoss: 245.138321\n",
      "Train Epoch: 144 [300/2589 (12%)]\tLoss: 244.932343\n",
      "Train Epoch: 144 [600/2589 (23%)]\tLoss: 235.254257\n",
      "Train Epoch: 144 [900/2589 (35%)]\tLoss: 226.243881\n",
      "Train Epoch: 144 [1200/2589 (46%)]\tLoss: 235.296890\n",
      "Train Epoch: 144 [1500/2589 (58%)]\tLoss: 217.262695\n",
      "Train Epoch: 144 [1800/2589 (70%)]\tLoss: 250.368057\n",
      "Train Epoch: 144 [2100/2589 (81%)]\tLoss: 262.887360\n",
      "Train Epoch: 144 [2400/2589 (93%)]\tLoss: 237.708557\n",
      "====> Epoch: 144 Average train loss: 292.1918\n",
      "====> Epoch: 144 Average test loss: 956.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [0/2589 (0%)]\tLoss: 270.685242\n",
      "Train Epoch: 145 [300/2589 (12%)]\tLoss: 212.095673\n",
      "Train Epoch: 145 [600/2589 (23%)]\tLoss: 330.753265\n",
      "Train Epoch: 145 [900/2589 (35%)]\tLoss: 215.091263\n",
      "Train Epoch: 145 [1200/2589 (46%)]\tLoss: 256.369659\n",
      "Train Epoch: 145 [1500/2589 (58%)]\tLoss: 278.589020\n",
      "Train Epoch: 145 [1800/2589 (70%)]\tLoss: 245.780533\n",
      "Train Epoch: 145 [2100/2589 (81%)]\tLoss: 247.369461\n",
      "Train Epoch: 145 [2400/2589 (93%)]\tLoss: 306.102722\n",
      "====> Epoch: 145 Average train loss: 299.6701\n",
      "====> Epoch: 145 Average test loss: 948.5739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 146 [0/2589 (0%)]\tLoss: 232.947601\n",
      "Train Epoch: 146 [300/2589 (12%)]\tLoss: 235.759125\n",
      "Train Epoch: 146 [600/2589 (23%)]\tLoss: 284.850464\n",
      "Train Epoch: 146 [900/2589 (35%)]\tLoss: 330.405304\n",
      "Train Epoch: 146 [1200/2589 (46%)]\tLoss: 314.084961\n",
      "Train Epoch: 146 [1500/2589 (58%)]\tLoss: 254.677322\n",
      "Train Epoch: 146 [1800/2589 (70%)]\tLoss: 273.338928\n",
      "Train Epoch: 146 [2100/2589 (81%)]\tLoss: 271.421234\n",
      "Train Epoch: 146 [2400/2589 (93%)]\tLoss: 379.495636\n",
      "====> Epoch: 146 Average train loss: 305.2812\n",
      "====> Epoch: 146 Average test loss: 961.7281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 147 [0/2589 (0%)]\tLoss: 243.139328\n",
      "Train Epoch: 147 [300/2589 (12%)]\tLoss: 362.387878\n",
      "Train Epoch: 147 [600/2589 (23%)]\tLoss: 194.701202\n",
      "Train Epoch: 147 [900/2589 (35%)]\tLoss: 238.942825\n",
      "Train Epoch: 147 [1200/2589 (46%)]\tLoss: 322.669128\n",
      "Train Epoch: 147 [1500/2589 (58%)]\tLoss: 378.173065\n",
      "Train Epoch: 147 [1800/2589 (70%)]\tLoss: 229.736328\n",
      "Train Epoch: 147 [2100/2589 (81%)]\tLoss: 275.925476\n",
      "Train Epoch: 147 [2400/2589 (93%)]\tLoss: 244.863480\n",
      "====> Epoch: 147 Average train loss: 303.7032\n",
      "====> Epoch: 147 Average test loss: 924.4402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 148 [0/2589 (0%)]\tLoss: 335.464752\n",
      "Train Epoch: 148 [300/2589 (12%)]\tLoss: 426.043335\n",
      "Train Epoch: 148 [600/2589 (23%)]\tLoss: 276.056641\n",
      "Train Epoch: 148 [900/2589 (35%)]\tLoss: 316.109314\n",
      "Train Epoch: 148 [1200/2589 (46%)]\tLoss: 321.574890\n",
      "Train Epoch: 148 [1500/2589 (58%)]\tLoss: 298.313751\n",
      "Train Epoch: 148 [1800/2589 (70%)]\tLoss: 319.862427\n",
      "Train Epoch: 148 [2100/2589 (81%)]\tLoss: 263.808624\n",
      "Train Epoch: 148 [2400/2589 (93%)]\tLoss: 194.997574\n",
      "====> Epoch: 148 Average train loss: 312.4003\n",
      "====> Epoch: 148 Average test loss: 952.2524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 149 [0/2589 (0%)]\tLoss: 310.251038\n",
      "Train Epoch: 149 [300/2589 (12%)]\tLoss: 205.879883\n",
      "Train Epoch: 149 [600/2589 (23%)]\tLoss: 437.121155\n",
      "Train Epoch: 149 [900/2589 (35%)]\tLoss: 287.393585\n",
      "Train Epoch: 149 [1200/2589 (46%)]\tLoss: 259.480316\n",
      "Train Epoch: 149 [1500/2589 (58%)]\tLoss: 320.989441\n",
      "Train Epoch: 149 [1800/2589 (70%)]\tLoss: 359.608978\n",
      "Train Epoch: 149 [2100/2589 (81%)]\tLoss: 289.219055\n",
      "Train Epoch: 149 [2400/2589 (93%)]\tLoss: 337.409088\n",
      "====> Epoch: 149 Average train loss: 302.6485\n",
      "====> Epoch: 149 Average test loss: 963.7783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 150 [0/2589 (0%)]\tLoss: 285.356628\n",
      "Train Epoch: 150 [300/2589 (12%)]\tLoss: 301.464844\n",
      "Train Epoch: 150 [600/2589 (23%)]\tLoss: 220.501511\n",
      "Train Epoch: 150 [900/2589 (35%)]\tLoss: 209.304520\n",
      "Train Epoch: 150 [1200/2589 (46%)]\tLoss: 204.247421\n",
      "Train Epoch: 150 [1500/2589 (58%)]\tLoss: 279.236450\n",
      "Train Epoch: 150 [1800/2589 (70%)]\tLoss: 258.951447\n",
      "Train Epoch: 150 [2100/2589 (81%)]\tLoss: 448.575409\n",
      "Train Epoch: 150 [2400/2589 (93%)]\tLoss: 267.544189\n",
      "====> Epoch: 150 Average train loss: 311.7900\n",
      "====> Epoch: 150 Average test loss: 989.9393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 151 [0/2589 (0%)]\tLoss: 397.033142\n",
      "Train Epoch: 151 [300/2589 (12%)]\tLoss: 207.043396\n",
      "Train Epoch: 151 [600/2589 (23%)]\tLoss: 264.599762\n",
      "Train Epoch: 151 [900/2589 (35%)]\tLoss: 247.464188\n",
      "Train Epoch: 151 [1200/2589 (46%)]\tLoss: 279.868988\n",
      "Train Epoch: 151 [1500/2589 (58%)]\tLoss: 288.671692\n",
      "Train Epoch: 151 [1800/2589 (70%)]\tLoss: 424.844574\n",
      "Train Epoch: 151 [2100/2589 (81%)]\tLoss: 255.450027\n",
      "Train Epoch: 151 [2400/2589 (93%)]\tLoss: 230.865982\n",
      "====> Epoch: 151 Average train loss: 299.5473\n",
      "====> Epoch: 151 Average test loss: 969.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 152 [0/2589 (0%)]\tLoss: 418.346527\n",
      "Train Epoch: 152 [300/2589 (12%)]\tLoss: 256.558441\n",
      "Train Epoch: 152 [600/2589 (23%)]\tLoss: 308.157990\n",
      "Train Epoch: 152 [900/2589 (35%)]\tLoss: 278.913971\n",
      "Train Epoch: 152 [1200/2589 (46%)]\tLoss: 206.951324\n",
      "Train Epoch: 152 [1500/2589 (58%)]\tLoss: 252.959320\n",
      "Train Epoch: 152 [1800/2589 (70%)]\tLoss: 247.847610\n",
      "Train Epoch: 152 [2100/2589 (81%)]\tLoss: 238.614578\n",
      "Train Epoch: 152 [2400/2589 (93%)]\tLoss: 288.407990\n",
      "====> Epoch: 152 Average train loss: 298.3241\n",
      "====> Epoch: 152 Average test loss: 929.3180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 153 [0/2589 (0%)]\tLoss: 357.020905\n",
      "Train Epoch: 153 [300/2589 (12%)]\tLoss: 399.472321\n",
      "Train Epoch: 153 [600/2589 (23%)]\tLoss: 279.838165\n",
      "Train Epoch: 153 [900/2589 (35%)]\tLoss: 308.192688\n",
      "Train Epoch: 153 [1200/2589 (46%)]\tLoss: 295.701691\n",
      "Train Epoch: 153 [1500/2589 (58%)]\tLoss: 176.830658\n",
      "Train Epoch: 153 [1800/2589 (70%)]\tLoss: 276.712067\n",
      "Train Epoch: 153 [2100/2589 (81%)]\tLoss: 280.409210\n",
      "Train Epoch: 153 [2400/2589 (93%)]\tLoss: 238.246399\n",
      "====> Epoch: 153 Average train loss: 310.6136\n",
      "====> Epoch: 153 Average test loss: 970.9718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 154 [0/2589 (0%)]\tLoss: 207.384445\n",
      "Train Epoch: 154 [300/2589 (12%)]\tLoss: 295.619171\n",
      "Train Epoch: 154 [600/2589 (23%)]\tLoss: 315.231964\n",
      "Train Epoch: 154 [900/2589 (35%)]\tLoss: 194.877533\n",
      "Train Epoch: 154 [1200/2589 (46%)]\tLoss: 341.976257\n",
      "Train Epoch: 154 [1500/2589 (58%)]\tLoss: 181.592834\n",
      "Train Epoch: 154 [1800/2589 (70%)]\tLoss: 330.004395\n",
      "Train Epoch: 154 [2100/2589 (81%)]\tLoss: 279.087341\n",
      "Train Epoch: 154 [2400/2589 (93%)]\tLoss: 296.160034\n",
      "====> Epoch: 154 Average train loss: 302.5952\n",
      "====> Epoch: 154 Average test loss: 951.7415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 155 [0/2589 (0%)]\tLoss: 335.246643\n",
      "Train Epoch: 155 [300/2589 (12%)]\tLoss: 229.002686\n",
      "Train Epoch: 155 [600/2589 (23%)]\tLoss: 321.855408\n",
      "Train Epoch: 155 [900/2589 (35%)]\tLoss: 229.488434\n",
      "Train Epoch: 155 [1200/2589 (46%)]\tLoss: 384.315399\n",
      "Train Epoch: 155 [1500/2589 (58%)]\tLoss: 273.796844\n",
      "Train Epoch: 155 [1800/2589 (70%)]\tLoss: 305.399017\n",
      "Train Epoch: 155 [2100/2589 (81%)]\tLoss: 493.403168\n",
      "Train Epoch: 155 [2400/2589 (93%)]\tLoss: 214.844025\n",
      "====> Epoch: 155 Average train loss: 292.2742\n",
      "====> Epoch: 155 Average test loss: 951.7609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 156 [0/2589 (0%)]\tLoss: 275.880890\n",
      "Train Epoch: 156 [300/2589 (12%)]\tLoss: 232.735413\n",
      "Train Epoch: 156 [600/2589 (23%)]\tLoss: 221.105179\n",
      "Train Epoch: 156 [900/2589 (35%)]\tLoss: 357.489227\n",
      "Train Epoch: 156 [1200/2589 (46%)]\tLoss: 271.012177\n",
      "Train Epoch: 156 [1500/2589 (58%)]\tLoss: 283.120300\n",
      "Train Epoch: 156 [1800/2589 (70%)]\tLoss: 196.137070\n",
      "Train Epoch: 156 [2100/2589 (81%)]\tLoss: 428.669952\n",
      "Train Epoch: 156 [2400/2589 (93%)]\tLoss: 285.690033\n",
      "====> Epoch: 156 Average train loss: 295.4678\n",
      "====> Epoch: 156 Average test loss: 951.7236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 157 [0/2589 (0%)]\tLoss: 282.150513\n",
      "Train Epoch: 157 [300/2589 (12%)]\tLoss: 293.671173\n",
      "Train Epoch: 157 [600/2589 (23%)]\tLoss: 281.567352\n",
      "Train Epoch: 157 [900/2589 (35%)]\tLoss: 290.888489\n",
      "Train Epoch: 157 [1200/2589 (46%)]\tLoss: 337.245270\n",
      "Train Epoch: 157 [1500/2589 (58%)]\tLoss: 368.882690\n",
      "Train Epoch: 157 [1800/2589 (70%)]\tLoss: 272.685516\n",
      "Train Epoch: 157 [2100/2589 (81%)]\tLoss: 289.633972\n",
      "Train Epoch: 157 [2400/2589 (93%)]\tLoss: 299.800446\n",
      "====> Epoch: 157 Average train loss: 300.9035\n",
      "====> Epoch: 157 Average test loss: 950.2237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 158 [0/2589 (0%)]\tLoss: 358.262665\n",
      "Train Epoch: 158 [300/2589 (12%)]\tLoss: 382.216278\n",
      "Train Epoch: 158 [600/2589 (23%)]\tLoss: 275.324371\n",
      "Train Epoch: 158 [900/2589 (35%)]\tLoss: 275.855347\n",
      "Train Epoch: 158 [1200/2589 (46%)]\tLoss: 265.290100\n",
      "Train Epoch: 158 [1500/2589 (58%)]\tLoss: 578.969604\n",
      "Train Epoch: 158 [1800/2589 (70%)]\tLoss: 285.195862\n",
      "Train Epoch: 158 [2100/2589 (81%)]\tLoss: 260.452209\n",
      "Train Epoch: 158 [2400/2589 (93%)]\tLoss: 277.745728\n",
      "====> Epoch: 158 Average train loss: 290.5256\n",
      "====> Epoch: 158 Average test loss: 959.2640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 159 [0/2589 (0%)]\tLoss: 383.973785\n",
      "Train Epoch: 159 [300/2589 (12%)]\tLoss: 296.439789\n",
      "Train Epoch: 159 [600/2589 (23%)]\tLoss: 334.683441\n",
      "Train Epoch: 159 [900/2589 (35%)]\tLoss: 245.395279\n",
      "Train Epoch: 159 [1200/2589 (46%)]\tLoss: 318.957123\n",
      "Train Epoch: 159 [1500/2589 (58%)]\tLoss: 268.839569\n",
      "Train Epoch: 159 [1800/2589 (70%)]\tLoss: 241.539841\n",
      "Train Epoch: 159 [2100/2589 (81%)]\tLoss: 262.088165\n",
      "Train Epoch: 159 [2400/2589 (93%)]\tLoss: 277.266876\n",
      "====> Epoch: 159 Average train loss: 306.8628\n",
      "====> Epoch: 159 Average test loss: 970.4388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 160 [0/2589 (0%)]\tLoss: 309.410248\n",
      "Train Epoch: 160 [300/2589 (12%)]\tLoss: 258.290619\n",
      "Train Epoch: 160 [600/2589 (23%)]\tLoss: 381.720276\n",
      "Train Epoch: 160 [900/2589 (35%)]\tLoss: 257.866089\n",
      "Train Epoch: 160 [1200/2589 (46%)]\tLoss: 289.440063\n",
      "Train Epoch: 160 [1500/2589 (58%)]\tLoss: 320.660675\n",
      "Train Epoch: 160 [1800/2589 (70%)]\tLoss: 295.834045\n",
      "Train Epoch: 160 [2100/2589 (81%)]\tLoss: 325.035370\n",
      "Train Epoch: 160 [2400/2589 (93%)]\tLoss: 248.468903\n",
      "====> Epoch: 160 Average train loss: 310.9529\n",
      "====> Epoch: 160 Average test loss: 967.4301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 161 [0/2589 (0%)]\tLoss: 309.919861\n",
      "Train Epoch: 161 [300/2589 (12%)]\tLoss: 217.783493\n",
      "Train Epoch: 161 [600/2589 (23%)]\tLoss: 297.190247\n",
      "Train Epoch: 161 [900/2589 (35%)]\tLoss: 278.590057\n",
      "Train Epoch: 161 [1200/2589 (46%)]\tLoss: 256.893280\n",
      "Train Epoch: 161 [1500/2589 (58%)]\tLoss: 375.790680\n",
      "Train Epoch: 161 [1800/2589 (70%)]\tLoss: 233.016129\n",
      "Train Epoch: 161 [2100/2589 (81%)]\tLoss: 417.187775\n",
      "Train Epoch: 161 [2400/2589 (93%)]\tLoss: 322.257202\n",
      "====> Epoch: 161 Average train loss: 306.3364\n",
      "====> Epoch: 161 Average test loss: 974.9544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 162 [0/2589 (0%)]\tLoss: 343.942932\n",
      "Train Epoch: 162 [300/2589 (12%)]\tLoss: 405.095032\n",
      "Train Epoch: 162 [600/2589 (23%)]\tLoss: 321.842133\n",
      "Train Epoch: 162 [900/2589 (35%)]\tLoss: 260.144989\n",
      "Train Epoch: 162 [1200/2589 (46%)]\tLoss: 314.947723\n",
      "Train Epoch: 162 [1500/2589 (58%)]\tLoss: 379.996155\n",
      "Train Epoch: 162 [1800/2589 (70%)]\tLoss: 257.722687\n",
      "Train Epoch: 162 [2100/2589 (81%)]\tLoss: 451.740570\n",
      "Train Epoch: 162 [2400/2589 (93%)]\tLoss: 329.483490\n",
      "====> Epoch: 162 Average train loss: 297.7580\n",
      "====> Epoch: 162 Average test loss: 936.2174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 163 [0/2589 (0%)]\tLoss: 134.764587\n",
      "Train Epoch: 163 [300/2589 (12%)]\tLoss: 233.853043\n",
      "Train Epoch: 163 [600/2589 (23%)]\tLoss: 251.040176\n",
      "Train Epoch: 163 [900/2589 (35%)]\tLoss: 261.267426\n",
      "Train Epoch: 163 [1200/2589 (46%)]\tLoss: 339.227142\n",
      "Train Epoch: 163 [1500/2589 (58%)]\tLoss: 327.669922\n",
      "Train Epoch: 163 [1800/2589 (70%)]\tLoss: 240.273895\n",
      "Train Epoch: 163 [2100/2589 (81%)]\tLoss: 495.556854\n",
      "Train Epoch: 163 [2400/2589 (93%)]\tLoss: 311.825287\n",
      "====> Epoch: 163 Average train loss: 294.3129\n",
      "====> Epoch: 163 Average test loss: 958.3674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 164 [0/2589 (0%)]\tLoss: 348.195862\n",
      "Train Epoch: 164 [300/2589 (12%)]\tLoss: 293.778870\n",
      "Train Epoch: 164 [600/2589 (23%)]\tLoss: 215.245956\n",
      "Train Epoch: 164 [900/2589 (35%)]\tLoss: 257.500610\n",
      "Train Epoch: 164 [1200/2589 (46%)]\tLoss: 266.446625\n",
      "Train Epoch: 164 [1500/2589 (58%)]\tLoss: 271.837097\n",
      "Train Epoch: 164 [1800/2589 (70%)]\tLoss: 461.363342\n",
      "Train Epoch: 164 [2100/2589 (81%)]\tLoss: 402.411774\n",
      "Train Epoch: 164 [2400/2589 (93%)]\tLoss: 237.647888\n",
      "====> Epoch: 164 Average train loss: 282.3434\n",
      "====> Epoch: 164 Average test loss: 966.5026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 165 [0/2589 (0%)]\tLoss: 319.030853\n",
      "Train Epoch: 165 [300/2589 (12%)]\tLoss: 304.489044\n",
      "Train Epoch: 165 [600/2589 (23%)]\tLoss: 191.620422\n",
      "Train Epoch: 165 [900/2589 (35%)]\tLoss: 294.940765\n",
      "Train Epoch: 165 [1200/2589 (46%)]\tLoss: 258.564026\n",
      "Train Epoch: 165 [1500/2589 (58%)]\tLoss: 212.815491\n",
      "Train Epoch: 165 [1800/2589 (70%)]\tLoss: 462.671082\n",
      "Train Epoch: 165 [2100/2589 (81%)]\tLoss: 254.284637\n",
      "Train Epoch: 165 [2400/2589 (93%)]\tLoss: 372.254028\n",
      "====> Epoch: 165 Average train loss: 292.7350\n",
      "====> Epoch: 165 Average test loss: 958.5152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 166 [0/2589 (0%)]\tLoss: 365.095642\n",
      "Train Epoch: 166 [300/2589 (12%)]\tLoss: 336.775208\n",
      "Train Epoch: 166 [600/2589 (23%)]\tLoss: 392.900604\n",
      "Train Epoch: 166 [900/2589 (35%)]\tLoss: 395.888184\n",
      "Train Epoch: 166 [1200/2589 (46%)]\tLoss: 240.161087\n",
      "Train Epoch: 166 [1500/2589 (58%)]\tLoss: 513.519409\n",
      "Train Epoch: 166 [1800/2589 (70%)]\tLoss: 388.164032\n",
      "Train Epoch: 166 [2100/2589 (81%)]\tLoss: 257.369904\n",
      "Train Epoch: 166 [2400/2589 (93%)]\tLoss: 252.560150\n",
      "====> Epoch: 166 Average train loss: 301.5169\n",
      "====> Epoch: 166 Average test loss: 955.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 167 [0/2589 (0%)]\tLoss: 247.659393\n",
      "Train Epoch: 167 [300/2589 (12%)]\tLoss: 244.166046\n",
      "Train Epoch: 167 [600/2589 (23%)]\tLoss: 314.283295\n",
      "Train Epoch: 167 [900/2589 (35%)]\tLoss: 255.221619\n",
      "Train Epoch: 167 [1200/2589 (46%)]\tLoss: 277.149536\n",
      "Train Epoch: 167 [1500/2589 (58%)]\tLoss: 318.424011\n",
      "Train Epoch: 167 [1800/2589 (70%)]\tLoss: 252.186981\n",
      "Train Epoch: 167 [2100/2589 (81%)]\tLoss: 334.661804\n",
      "Train Epoch: 167 [2400/2589 (93%)]\tLoss: 325.009491\n",
      "====> Epoch: 167 Average train loss: 295.1907\n",
      "====> Epoch: 167 Average test loss: 978.9627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 168 [0/2589 (0%)]\tLoss: 314.689880\n",
      "Train Epoch: 168 [300/2589 (12%)]\tLoss: 329.968384\n",
      "Train Epoch: 168 [600/2589 (23%)]\tLoss: 242.553650\n",
      "Train Epoch: 168 [900/2589 (35%)]\tLoss: 219.970917\n",
      "Train Epoch: 168 [1200/2589 (46%)]\tLoss: 272.497772\n",
      "Train Epoch: 168 [1500/2589 (58%)]\tLoss: 282.971283\n",
      "Train Epoch: 168 [1800/2589 (70%)]\tLoss: 457.247864\n",
      "Train Epoch: 168 [2100/2589 (81%)]\tLoss: 265.731598\n",
      "Train Epoch: 168 [2400/2589 (93%)]\tLoss: 326.755859\n",
      "====> Epoch: 168 Average train loss: 302.0107\n",
      "====> Epoch: 168 Average test loss: 948.6024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 169 [0/2589 (0%)]\tLoss: 269.419861\n",
      "Train Epoch: 169 [300/2589 (12%)]\tLoss: 244.048096\n",
      "Train Epoch: 169 [600/2589 (23%)]\tLoss: 317.940582\n",
      "Train Epoch: 169 [900/2589 (35%)]\tLoss: 320.985840\n",
      "Train Epoch: 169 [1200/2589 (46%)]\tLoss: 347.778320\n",
      "Train Epoch: 169 [1500/2589 (58%)]\tLoss: 311.087799\n",
      "Train Epoch: 169 [1800/2589 (70%)]\tLoss: 243.460892\n",
      "Train Epoch: 169 [2100/2589 (81%)]\tLoss: 336.765137\n",
      "Train Epoch: 169 [2400/2589 (93%)]\tLoss: 325.428131\n",
      "====> Epoch: 169 Average train loss: 304.6606\n",
      "====> Epoch: 169 Average test loss: 939.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 170 [0/2589 (0%)]\tLoss: 325.619690\n",
      "Train Epoch: 170 [300/2589 (12%)]\tLoss: 211.792236\n",
      "Train Epoch: 170 [600/2589 (23%)]\tLoss: 452.898254\n",
      "Train Epoch: 170 [900/2589 (35%)]\tLoss: 264.985565\n",
      "Train Epoch: 170 [1200/2589 (46%)]\tLoss: 237.214218\n",
      "Train Epoch: 170 [1500/2589 (58%)]\tLoss: 269.697662\n",
      "Train Epoch: 170 [1800/2589 (70%)]\tLoss: 307.927765\n",
      "Train Epoch: 170 [2100/2589 (81%)]\tLoss: 228.472626\n",
      "Train Epoch: 170 [2400/2589 (93%)]\tLoss: 265.799011\n",
      "====> Epoch: 170 Average train loss: 308.3304\n",
      "====> Epoch: 170 Average test loss: 959.4663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 171 [0/2589 (0%)]\tLoss: 220.775330\n",
      "Train Epoch: 171 [300/2589 (12%)]\tLoss: 232.988693\n",
      "Train Epoch: 171 [600/2589 (23%)]\tLoss: 201.387314\n",
      "Train Epoch: 171 [900/2589 (35%)]\tLoss: 271.189636\n",
      "Train Epoch: 171 [1200/2589 (46%)]\tLoss: 314.333405\n",
      "Train Epoch: 171 [1500/2589 (58%)]\tLoss: 358.003418\n",
      "Train Epoch: 171 [1800/2589 (70%)]\tLoss: 262.123444\n",
      "Train Epoch: 171 [2100/2589 (81%)]\tLoss: 316.020325\n",
      "Train Epoch: 171 [2400/2589 (93%)]\tLoss: 295.362183\n",
      "====> Epoch: 171 Average train loss: 293.8205\n",
      "====> Epoch: 171 Average test loss: 959.4623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 172 [0/2589 (0%)]\tLoss: 288.364532\n",
      "Train Epoch: 172 [300/2589 (12%)]\tLoss: 270.746399\n",
      "Train Epoch: 172 [600/2589 (23%)]\tLoss: 391.751770\n",
      "Train Epoch: 172 [900/2589 (35%)]\tLoss: 292.225098\n",
      "Train Epoch: 172 [1200/2589 (46%)]\tLoss: 301.217682\n",
      "Train Epoch: 172 [1500/2589 (58%)]\tLoss: 180.437515\n",
      "Train Epoch: 172 [1800/2589 (70%)]\tLoss: 393.338348\n",
      "Train Epoch: 172 [2100/2589 (81%)]\tLoss: 251.828186\n",
      "Train Epoch: 172 [2400/2589 (93%)]\tLoss: 370.687469\n",
      "====> Epoch: 172 Average train loss: 299.9631\n",
      "====> Epoch: 172 Average test loss: 953.5529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 173 [0/2589 (0%)]\tLoss: 175.631287\n",
      "Train Epoch: 173 [300/2589 (12%)]\tLoss: 251.988678\n",
      "Train Epoch: 173 [600/2589 (23%)]\tLoss: 427.515533\n",
      "Train Epoch: 173 [900/2589 (35%)]\tLoss: 237.190750\n",
      "Train Epoch: 173 [1200/2589 (46%)]\tLoss: 257.512878\n",
      "Train Epoch: 173 [1500/2589 (58%)]\tLoss: 256.191742\n",
      "Train Epoch: 173 [1800/2589 (70%)]\tLoss: 258.508698\n",
      "Train Epoch: 173 [2100/2589 (81%)]\tLoss: 337.834534\n",
      "Train Epoch: 173 [2400/2589 (93%)]\tLoss: 373.818665\n",
      "====> Epoch: 173 Average train loss: 288.6295\n",
      "====> Epoch: 173 Average test loss: 965.6863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 174 [0/2589 (0%)]\tLoss: 223.649185\n",
      "Train Epoch: 174 [300/2589 (12%)]\tLoss: 230.262619\n",
      "Train Epoch: 174 [600/2589 (23%)]\tLoss: 278.710114\n",
      "Train Epoch: 174 [900/2589 (35%)]\tLoss: 385.686554\n",
      "Train Epoch: 174 [1200/2589 (46%)]\tLoss: 287.055756\n",
      "Train Epoch: 174 [1500/2589 (58%)]\tLoss: 270.301483\n",
      "Train Epoch: 174 [1800/2589 (70%)]\tLoss: 387.674896\n",
      "Train Epoch: 174 [2100/2589 (81%)]\tLoss: 216.230515\n",
      "Train Epoch: 174 [2400/2589 (93%)]\tLoss: 286.897095\n",
      "====> Epoch: 174 Average train loss: 297.1048\n",
      "====> Epoch: 174 Average test loss: 952.3953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 175 [0/2589 (0%)]\tLoss: 221.549103\n",
      "Train Epoch: 175 [300/2589 (12%)]\tLoss: 324.668488\n",
      "Train Epoch: 175 [600/2589 (23%)]\tLoss: 319.036804\n",
      "Train Epoch: 175 [900/2589 (35%)]\tLoss: 326.302063\n",
      "Train Epoch: 175 [1200/2589 (46%)]\tLoss: 280.993561\n",
      "Train Epoch: 175 [1500/2589 (58%)]\tLoss: 304.316467\n",
      "Train Epoch: 175 [1800/2589 (70%)]\tLoss: 320.737823\n",
      "Train Epoch: 175 [2100/2589 (81%)]\tLoss: 376.915039\n",
      "Train Epoch: 175 [2400/2589 (93%)]\tLoss: 299.245819\n",
      "====> Epoch: 175 Average train loss: 287.7318\n",
      "====> Epoch: 175 Average test loss: 958.2136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 176 [0/2589 (0%)]\tLoss: 257.054871\n",
      "Train Epoch: 176 [300/2589 (12%)]\tLoss: 315.235504\n",
      "Train Epoch: 176 [600/2589 (23%)]\tLoss: 372.723450\n",
      "Train Epoch: 176 [900/2589 (35%)]\tLoss: 301.150330\n",
      "Train Epoch: 176 [1200/2589 (46%)]\tLoss: 321.754944\n",
      "Train Epoch: 176 [1500/2589 (58%)]\tLoss: 253.559631\n",
      "Train Epoch: 176 [1800/2589 (70%)]\tLoss: 251.776993\n",
      "Train Epoch: 176 [2100/2589 (81%)]\tLoss: 350.374390\n",
      "Train Epoch: 176 [2400/2589 (93%)]\tLoss: 330.561005\n",
      "====> Epoch: 176 Average train loss: 296.0452\n",
      "====> Epoch: 176 Average test loss: 950.5170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 177 [0/2589 (0%)]\tLoss: 404.291992\n",
      "Train Epoch: 177 [300/2589 (12%)]\tLoss: 323.939392\n",
      "Train Epoch: 177 [600/2589 (23%)]\tLoss: 359.639526\n",
      "Train Epoch: 177 [900/2589 (35%)]\tLoss: 325.754364\n",
      "Train Epoch: 177 [1200/2589 (46%)]\tLoss: 308.824829\n",
      "Train Epoch: 177 [1500/2589 (58%)]\tLoss: 315.424408\n",
      "Train Epoch: 177 [1800/2589 (70%)]\tLoss: 271.928040\n",
      "Train Epoch: 177 [2100/2589 (81%)]\tLoss: 204.168854\n",
      "Train Epoch: 177 [2400/2589 (93%)]\tLoss: 266.629120\n",
      "====> Epoch: 177 Average train loss: 295.0491\n",
      "====> Epoch: 177 Average test loss: 949.3898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 178 [0/2589 (0%)]\tLoss: 248.279861\n",
      "Train Epoch: 178 [300/2589 (12%)]\tLoss: 310.898773\n",
      "Train Epoch: 178 [600/2589 (23%)]\tLoss: 218.645264\n",
      "Train Epoch: 178 [900/2589 (35%)]\tLoss: 268.441315\n",
      "Train Epoch: 178 [1200/2589 (46%)]\tLoss: 187.240921\n",
      "Train Epoch: 178 [1500/2589 (58%)]\tLoss: 445.751465\n",
      "Train Epoch: 178 [1800/2589 (70%)]\tLoss: 191.813309\n",
      "Train Epoch: 178 [2100/2589 (81%)]\tLoss: 259.184937\n",
      "Train Epoch: 178 [2400/2589 (93%)]\tLoss: 293.532196\n",
      "====> Epoch: 178 Average train loss: 295.3596\n",
      "====> Epoch: 178 Average test loss: 948.5417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 179 [0/2589 (0%)]\tLoss: 248.499557\n",
      "Train Epoch: 179 [300/2589 (12%)]\tLoss: 274.178314\n",
      "Train Epoch: 179 [600/2589 (23%)]\tLoss: 254.926315\n",
      "Train Epoch: 179 [900/2589 (35%)]\tLoss: 220.520172\n",
      "Train Epoch: 179 [1200/2589 (46%)]\tLoss: 323.223022\n",
      "Train Epoch: 179 [1500/2589 (58%)]\tLoss: 304.780212\n",
      "Train Epoch: 179 [1800/2589 (70%)]\tLoss: 324.372833\n",
      "Train Epoch: 179 [2100/2589 (81%)]\tLoss: 393.728180\n",
      "Train Epoch: 179 [2400/2589 (93%)]\tLoss: 438.264191\n",
      "====> Epoch: 179 Average train loss: 290.2683\n",
      "====> Epoch: 179 Average test loss: 931.3939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 180 [0/2589 (0%)]\tLoss: 196.207611\n",
      "Train Epoch: 180 [300/2589 (12%)]\tLoss: 265.519623\n",
      "Train Epoch: 180 [600/2589 (23%)]\tLoss: 313.003998\n",
      "Train Epoch: 180 [900/2589 (35%)]\tLoss: 287.828705\n",
      "Train Epoch: 180 [1200/2589 (46%)]\tLoss: 341.311462\n",
      "Train Epoch: 180 [1500/2589 (58%)]\tLoss: 250.035477\n",
      "Train Epoch: 180 [1800/2589 (70%)]\tLoss: 302.186462\n",
      "Train Epoch: 180 [2100/2589 (81%)]\tLoss: 260.247772\n",
      "Train Epoch: 180 [2400/2589 (93%)]\tLoss: 267.152405\n",
      "====> Epoch: 180 Average train loss: 289.1649\n",
      "====> Epoch: 180 Average test loss: 948.9381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181 [0/2589 (0%)]\tLoss: 322.895325\n",
      "Train Epoch: 181 [300/2589 (12%)]\tLoss: 215.409424\n",
      "Train Epoch: 181 [600/2589 (23%)]\tLoss: 285.749481\n",
      "Train Epoch: 181 [900/2589 (35%)]\tLoss: 247.562012\n",
      "Train Epoch: 181 [1200/2589 (46%)]\tLoss: 304.269043\n",
      "Train Epoch: 181 [1500/2589 (58%)]\tLoss: 210.803513\n",
      "Train Epoch: 181 [1800/2589 (70%)]\tLoss: 266.005524\n",
      "Train Epoch: 181 [2100/2589 (81%)]\tLoss: 246.729507\n",
      "Train Epoch: 181 [2400/2589 (93%)]\tLoss: 286.144562\n",
      "====> Epoch: 181 Average train loss: 278.7682\n",
      "====> Epoch: 181 Average test loss: 955.0710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 182 [0/2589 (0%)]\tLoss: 221.016190\n",
      "Train Epoch: 182 [300/2589 (12%)]\tLoss: 239.893524\n",
      "Train Epoch: 182 [600/2589 (23%)]\tLoss: 295.571686\n",
      "Train Epoch: 182 [900/2589 (35%)]\tLoss: 231.212585\n",
      "Train Epoch: 182 [1200/2589 (46%)]\tLoss: 166.389542\n",
      "Train Epoch: 182 [1500/2589 (58%)]\tLoss: 227.149658\n",
      "Train Epoch: 182 [1800/2589 (70%)]\tLoss: 259.360474\n",
      "Train Epoch: 182 [2100/2589 (81%)]\tLoss: 299.336395\n",
      "Train Epoch: 182 [2400/2589 (93%)]\tLoss: 354.368439\n",
      "====> Epoch: 182 Average train loss: 298.3679\n",
      "====> Epoch: 182 Average test loss: 967.7408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 183 [0/2589 (0%)]\tLoss: 228.090134\n",
      "Train Epoch: 183 [300/2589 (12%)]\tLoss: 242.619614\n",
      "Train Epoch: 183 [600/2589 (23%)]\tLoss: 301.167450\n",
      "Train Epoch: 183 [900/2589 (35%)]\tLoss: 238.881378\n",
      "Train Epoch: 183 [1200/2589 (46%)]\tLoss: 470.008514\n",
      "Train Epoch: 183 [1500/2589 (58%)]\tLoss: 342.030853\n",
      "Train Epoch: 183 [1800/2589 (70%)]\tLoss: 179.459824\n",
      "Train Epoch: 183 [2100/2589 (81%)]\tLoss: 399.124847\n",
      "Train Epoch: 183 [2400/2589 (93%)]\tLoss: 260.671295\n",
      "====> Epoch: 183 Average train loss: 293.7868\n",
      "====> Epoch: 183 Average test loss: 940.5209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 184 [0/2589 (0%)]\tLoss: 227.744827\n",
      "Train Epoch: 184 [300/2589 (12%)]\tLoss: 313.766296\n",
      "Train Epoch: 184 [600/2589 (23%)]\tLoss: 318.499878\n",
      "Train Epoch: 184 [900/2589 (35%)]\tLoss: 340.801605\n",
      "Train Epoch: 184 [1200/2589 (46%)]\tLoss: 374.733826\n",
      "Train Epoch: 184 [1500/2589 (58%)]\tLoss: 288.294434\n",
      "Train Epoch: 184 [1800/2589 (70%)]\tLoss: 338.170258\n",
      "Train Epoch: 184 [2100/2589 (81%)]\tLoss: 260.611145\n",
      "Train Epoch: 184 [2400/2589 (93%)]\tLoss: 295.410706\n",
      "====> Epoch: 184 Average train loss: 287.4435\n",
      "====> Epoch: 184 Average test loss: 959.6196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 185 [0/2589 (0%)]\tLoss: 241.610336\n",
      "Train Epoch: 185 [300/2589 (12%)]\tLoss: 313.572235\n",
      "Train Epoch: 185 [600/2589 (23%)]\tLoss: 316.286957\n",
      "Train Epoch: 185 [900/2589 (35%)]\tLoss: 269.143158\n",
      "Train Epoch: 185 [1200/2589 (46%)]\tLoss: 201.189926\n",
      "Train Epoch: 185 [1500/2589 (58%)]\tLoss: 238.089096\n",
      "Train Epoch: 185 [1800/2589 (70%)]\tLoss: 248.863174\n",
      "Train Epoch: 185 [2100/2589 (81%)]\tLoss: 475.568390\n",
      "Train Epoch: 185 [2400/2589 (93%)]\tLoss: 371.936340\n",
      "====> Epoch: 185 Average train loss: 289.3261\n",
      "====> Epoch: 185 Average test loss: 937.6472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 186 [0/2589 (0%)]\tLoss: 315.810852\n",
      "Train Epoch: 186 [300/2589 (12%)]\tLoss: 236.739929\n",
      "Train Epoch: 186 [600/2589 (23%)]\tLoss: 259.917633\n",
      "Train Epoch: 186 [900/2589 (35%)]\tLoss: 271.525238\n",
      "Train Epoch: 186 [1200/2589 (46%)]\tLoss: 286.948883\n",
      "Train Epoch: 186 [1500/2589 (58%)]\tLoss: 347.303009\n",
      "Train Epoch: 186 [1800/2589 (70%)]\tLoss: 333.766174\n",
      "Train Epoch: 186 [2100/2589 (81%)]\tLoss: 288.783356\n",
      "Train Epoch: 186 [2400/2589 (93%)]\tLoss: 233.111725\n",
      "====> Epoch: 186 Average train loss: 291.3074\n",
      "====> Epoch: 186 Average test loss: 976.1365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 187 [0/2589 (0%)]\tLoss: 264.264069\n",
      "Train Epoch: 187 [300/2589 (12%)]\tLoss: 240.024597\n",
      "Train Epoch: 187 [600/2589 (23%)]\tLoss: 252.842865\n",
      "Train Epoch: 187 [900/2589 (35%)]\tLoss: 301.756226\n",
      "Train Epoch: 187 [1200/2589 (46%)]\tLoss: 275.153809\n",
      "Train Epoch: 187 [1500/2589 (58%)]\tLoss: 253.156647\n",
      "Train Epoch: 187 [1800/2589 (70%)]\tLoss: 346.027039\n",
      "Train Epoch: 187 [2100/2589 (81%)]\tLoss: 261.297089\n",
      "Train Epoch: 187 [2400/2589 (93%)]\tLoss: 294.910950\n",
      "====> Epoch: 187 Average train loss: 281.7763\n",
      "====> Epoch: 187 Average test loss: 954.8184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 188 [0/2589 (0%)]\tLoss: 194.428391\n",
      "Train Epoch: 188 [300/2589 (12%)]\tLoss: 244.827911\n",
      "Train Epoch: 188 [600/2589 (23%)]\tLoss: 295.702026\n",
      "Train Epoch: 188 [900/2589 (35%)]\tLoss: 295.274231\n",
      "Train Epoch: 188 [1200/2589 (46%)]\tLoss: 274.119415\n",
      "Train Epoch: 188 [1500/2589 (58%)]\tLoss: 298.597870\n",
      "Train Epoch: 188 [1800/2589 (70%)]\tLoss: 240.046417\n",
      "Train Epoch: 188 [2100/2589 (81%)]\tLoss: 352.797333\n",
      "Train Epoch: 188 [2400/2589 (93%)]\tLoss: 352.588806\n",
      "====> Epoch: 188 Average train loss: 291.9143\n",
      "====> Epoch: 188 Average test loss: 950.1817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 189 [0/2589 (0%)]\tLoss: 213.303650\n",
      "Train Epoch: 189 [300/2589 (12%)]\tLoss: 256.962830\n",
      "Train Epoch: 189 [600/2589 (23%)]\tLoss: 263.301941\n",
      "Train Epoch: 189 [900/2589 (35%)]\tLoss: 283.014709\n",
      "Train Epoch: 189 [1200/2589 (46%)]\tLoss: 228.742844\n",
      "Train Epoch: 189 [1500/2589 (58%)]\tLoss: 385.896942\n",
      "Train Epoch: 189 [1800/2589 (70%)]\tLoss: 212.246613\n",
      "Train Epoch: 189 [2100/2589 (81%)]\tLoss: 316.306458\n",
      "Train Epoch: 189 [2400/2589 (93%)]\tLoss: 220.260712\n",
      "====> Epoch: 189 Average train loss: 289.9069\n",
      "====> Epoch: 189 Average test loss: 926.9161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 190 [0/2589 (0%)]\tLoss: 288.215607\n",
      "Train Epoch: 190 [300/2589 (12%)]\tLoss: 364.063965\n",
      "Train Epoch: 190 [600/2589 (23%)]\tLoss: 288.874115\n",
      "Train Epoch: 190 [900/2589 (35%)]\tLoss: 314.707703\n",
      "Train Epoch: 190 [1200/2589 (46%)]\tLoss: 354.455383\n",
      "Train Epoch: 190 [1500/2589 (58%)]\tLoss: 175.325851\n",
      "Train Epoch: 190 [1800/2589 (70%)]\tLoss: 281.789734\n",
      "Train Epoch: 190 [2100/2589 (81%)]\tLoss: 303.661316\n",
      "Train Epoch: 190 [2400/2589 (93%)]\tLoss: 257.351593\n",
      "====> Epoch: 190 Average train loss: 294.9245\n",
      "====> Epoch: 190 Average test loss: 958.0129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 191 [0/2589 (0%)]\tLoss: 314.360443\n",
      "Train Epoch: 191 [300/2589 (12%)]\tLoss: 221.615982\n",
      "Train Epoch: 191 [600/2589 (23%)]\tLoss: 588.824646\n",
      "Train Epoch: 191 [900/2589 (35%)]\tLoss: 289.614594\n",
      "Train Epoch: 191 [1200/2589 (46%)]\tLoss: 253.706039\n",
      "Train Epoch: 191 [1500/2589 (58%)]\tLoss: 303.913086\n",
      "Train Epoch: 191 [1800/2589 (70%)]\tLoss: 242.582626\n",
      "Train Epoch: 191 [2100/2589 (81%)]\tLoss: 386.713745\n",
      "Train Epoch: 191 [2400/2589 (93%)]\tLoss: 297.345703\n",
      "====> Epoch: 191 Average train loss: 285.8623\n",
      "====> Epoch: 191 Average test loss: 938.1819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 192 [0/2589 (0%)]\tLoss: 199.406540\n",
      "Train Epoch: 192 [300/2589 (12%)]\tLoss: 280.438843\n",
      "Train Epoch: 192 [600/2589 (23%)]\tLoss: 211.465302\n",
      "Train Epoch: 192 [900/2589 (35%)]\tLoss: 209.100693\n",
      "Train Epoch: 192 [1200/2589 (46%)]\tLoss: 272.988922\n",
      "Train Epoch: 192 [1500/2589 (58%)]\tLoss: 415.046478\n",
      "Train Epoch: 192 [1800/2589 (70%)]\tLoss: 350.085358\n",
      "Train Epoch: 192 [2100/2589 (81%)]\tLoss: 264.449097\n",
      "Train Epoch: 192 [2400/2589 (93%)]\tLoss: 201.135284\n",
      "====> Epoch: 192 Average train loss: 287.0969\n",
      "====> Epoch: 192 Average test loss: 986.2358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 193 [0/2589 (0%)]\tLoss: 212.320053\n",
      "Train Epoch: 193 [300/2589 (12%)]\tLoss: 373.498901\n",
      "Train Epoch: 193 [600/2589 (23%)]\tLoss: 261.984467\n",
      "Train Epoch: 193 [900/2589 (35%)]\tLoss: 312.239075\n",
      "Train Epoch: 193 [1200/2589 (46%)]\tLoss: 235.676529\n",
      "Train Epoch: 193 [1500/2589 (58%)]\tLoss: 325.241028\n",
      "Train Epoch: 193 [1800/2589 (70%)]\tLoss: 350.665161\n",
      "Train Epoch: 193 [2100/2589 (81%)]\tLoss: 305.423859\n",
      "Train Epoch: 193 [2400/2589 (93%)]\tLoss: 340.454132\n",
      "====> Epoch: 193 Average train loss: 293.5056\n",
      "====> Epoch: 193 Average test loss: 947.2255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 194 [0/2589 (0%)]\tLoss: 277.539246\n",
      "Train Epoch: 194 [300/2589 (12%)]\tLoss: 241.523926\n",
      "Train Epoch: 194 [600/2589 (23%)]\tLoss: 258.112030\n",
      "Train Epoch: 194 [900/2589 (35%)]\tLoss: 287.875183\n",
      "Train Epoch: 194 [1200/2589 (46%)]\tLoss: 211.298050\n",
      "Train Epoch: 194 [1500/2589 (58%)]\tLoss: 296.029327\n",
      "Train Epoch: 194 [1800/2589 (70%)]\tLoss: 227.023453\n",
      "Train Epoch: 194 [2100/2589 (81%)]\tLoss: 225.928772\n",
      "Train Epoch: 194 [2400/2589 (93%)]\tLoss: 241.137726\n",
      "====> Epoch: 194 Average train loss: 278.7362\n",
      "====> Epoch: 194 Average test loss: 954.2830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 195 [0/2589 (0%)]\tLoss: 273.734253\n",
      "Train Epoch: 195 [300/2589 (12%)]\tLoss: 296.269592\n",
      "Train Epoch: 195 [600/2589 (23%)]\tLoss: 246.888275\n",
      "Train Epoch: 195 [900/2589 (35%)]\tLoss: 432.073547\n",
      "Train Epoch: 195 [1200/2589 (46%)]\tLoss: 207.211884\n",
      "Train Epoch: 195 [1500/2589 (58%)]\tLoss: 286.653961\n",
      "Train Epoch: 195 [1800/2589 (70%)]\tLoss: 221.157578\n",
      "Train Epoch: 195 [2100/2589 (81%)]\tLoss: 245.665253\n",
      "Train Epoch: 195 [2400/2589 (93%)]\tLoss: 265.530853\n",
      "====> Epoch: 195 Average train loss: 291.1597\n",
      "====> Epoch: 195 Average test loss: 965.3250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 196 [0/2589 (0%)]\tLoss: 217.946930\n",
      "Train Epoch: 196 [300/2589 (12%)]\tLoss: 326.390900\n",
      "Train Epoch: 196 [600/2589 (23%)]\tLoss: 219.510422\n",
      "Train Epoch: 196 [900/2589 (35%)]\tLoss: 417.509003\n",
      "Train Epoch: 196 [1200/2589 (46%)]\tLoss: 320.565796\n",
      "Train Epoch: 196 [1500/2589 (58%)]\tLoss: 260.507538\n",
      "Train Epoch: 196 [1800/2589 (70%)]\tLoss: 343.948853\n",
      "Train Epoch: 196 [2100/2589 (81%)]\tLoss: 355.298035\n",
      "Train Epoch: 196 [2400/2589 (93%)]\tLoss: 392.000214\n",
      "====> Epoch: 196 Average train loss: 286.5055\n",
      "====> Epoch: 196 Average test loss: 954.8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 197 [0/2589 (0%)]\tLoss: 267.191437\n",
      "Train Epoch: 197 [300/2589 (12%)]\tLoss: 312.838684\n",
      "Train Epoch: 197 [600/2589 (23%)]\tLoss: 343.446808\n",
      "Train Epoch: 197 [900/2589 (35%)]\tLoss: 309.458649\n",
      "Train Epoch: 197 [1200/2589 (46%)]\tLoss: 301.882294\n",
      "Train Epoch: 197 [1500/2589 (58%)]\tLoss: 195.716476\n",
      "Train Epoch: 197 [1800/2589 (70%)]\tLoss: 154.876144\n",
      "Train Epoch: 197 [2100/2589 (81%)]\tLoss: 270.969635\n",
      "Train Epoch: 197 [2400/2589 (93%)]\tLoss: 261.238983\n",
      "====> Epoch: 197 Average train loss: 288.3584\n",
      "====> Epoch: 197 Average test loss: 948.9534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 198 [0/2589 (0%)]\tLoss: 263.187469\n",
      "Train Epoch: 198 [300/2589 (12%)]\tLoss: 267.415802\n",
      "Train Epoch: 198 [600/2589 (23%)]\tLoss: 383.326569\n",
      "Train Epoch: 198 [900/2589 (35%)]\tLoss: 238.026520\n",
      "Train Epoch: 198 [1200/2589 (46%)]\tLoss: 264.297302\n",
      "Train Epoch: 198 [1500/2589 (58%)]\tLoss: 259.852539\n",
      "Train Epoch: 198 [1800/2589 (70%)]\tLoss: 286.223053\n",
      "Train Epoch: 198 [2100/2589 (81%)]\tLoss: 226.921158\n",
      "Train Epoch: 198 [2400/2589 (93%)]\tLoss: 340.064362\n",
      "====> Epoch: 198 Average train loss: 279.1180\n",
      "====> Epoch: 198 Average test loss: 973.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 199 [0/2589 (0%)]\tLoss: 248.664246\n",
      "Train Epoch: 199 [300/2589 (12%)]\tLoss: 285.570129\n",
      "Train Epoch: 199 [600/2589 (23%)]\tLoss: 237.786484\n",
      "Train Epoch: 199 [900/2589 (35%)]\tLoss: 283.206909\n",
      "Train Epoch: 199 [1200/2589 (46%)]\tLoss: 226.645859\n",
      "Train Epoch: 199 [1500/2589 (58%)]\tLoss: 289.032562\n",
      "Train Epoch: 199 [1800/2589 (70%)]\tLoss: 239.986618\n",
      "Train Epoch: 199 [2100/2589 (81%)]\tLoss: 265.882935\n",
      "Train Epoch: 199 [2400/2589 (93%)]\tLoss: 274.600739\n",
      "====> Epoch: 199 Average train loss: 281.2591\n",
      "====> Epoch: 199 Average test loss: 952.5858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 200 [0/2589 (0%)]\tLoss: 216.661377\n",
      "Train Epoch: 200 [300/2589 (12%)]\tLoss: 419.977264\n",
      "Train Epoch: 200 [600/2589 (23%)]\tLoss: 205.633133\n",
      "Train Epoch: 200 [900/2589 (35%)]\tLoss: 254.591034\n",
      "Train Epoch: 200 [1200/2589 (46%)]\tLoss: 220.217133\n",
      "Train Epoch: 200 [1500/2589 (58%)]\tLoss: 306.606995\n",
      "Train Epoch: 200 [1800/2589 (70%)]\tLoss: 284.388947\n",
      "Train Epoch: 200 [2100/2589 (81%)]\tLoss: 325.449219\n",
      "Train Epoch: 200 [2400/2589 (93%)]\tLoss: 217.714005\n",
      "====> Epoch: 200 Average train loss: 277.3325\n",
      "====> Epoch: 200 Average test loss: 962.5599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 201 [0/2589 (0%)]\tLoss: 307.321350\n",
      "Train Epoch: 201 [300/2589 (12%)]\tLoss: 390.546478\n",
      "Train Epoch: 201 [600/2589 (23%)]\tLoss: 271.325470\n",
      "Train Epoch: 201 [900/2589 (35%)]\tLoss: 210.923660\n",
      "Train Epoch: 201 [1200/2589 (46%)]\tLoss: 205.743484\n",
      "Train Epoch: 201 [1500/2589 (58%)]\tLoss: 282.767181\n",
      "Train Epoch: 201 [1800/2589 (70%)]\tLoss: 315.500214\n",
      "Train Epoch: 201 [2100/2589 (81%)]\tLoss: 253.393509\n",
      "Train Epoch: 201 [2400/2589 (93%)]\tLoss: 437.091949\n",
      "====> Epoch: 201 Average train loss: 288.7359\n",
      "====> Epoch: 201 Average test loss: 949.5732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 202 [0/2589 (0%)]\tLoss: 223.859406\n",
      "Train Epoch: 202 [300/2589 (12%)]\tLoss: 335.843414\n",
      "Train Epoch: 202 [600/2589 (23%)]\tLoss: 497.150482\n",
      "Train Epoch: 202 [900/2589 (35%)]\tLoss: 289.146881\n",
      "Train Epoch: 202 [1200/2589 (46%)]\tLoss: 270.964508\n",
      "Train Epoch: 202 [1500/2589 (58%)]\tLoss: 298.309509\n",
      "Train Epoch: 202 [1800/2589 (70%)]\tLoss: 182.120544\n",
      "Train Epoch: 202 [2100/2589 (81%)]\tLoss: 279.383240\n",
      "Train Epoch: 202 [2400/2589 (93%)]\tLoss: 334.069031\n",
      "====> Epoch: 202 Average train loss: 282.6682\n",
      "====> Epoch: 202 Average test loss: 951.7338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 203 [0/2589 (0%)]\tLoss: 298.644836\n",
      "Train Epoch: 203 [300/2589 (12%)]\tLoss: 463.187469\n",
      "Train Epoch: 203 [600/2589 (23%)]\tLoss: 229.218521\n",
      "Train Epoch: 203 [900/2589 (35%)]\tLoss: 263.946167\n",
      "Train Epoch: 203 [1200/2589 (46%)]\tLoss: 196.263107\n",
      "Train Epoch: 203 [1500/2589 (58%)]\tLoss: 356.706451\n",
      "Train Epoch: 203 [1800/2589 (70%)]\tLoss: 285.504395\n",
      "Train Epoch: 203 [2100/2589 (81%)]\tLoss: 277.682648\n",
      "Train Epoch: 203 [2400/2589 (93%)]\tLoss: 428.458679\n",
      "====> Epoch: 203 Average train loss: 296.2076\n",
      "====> Epoch: 203 Average test loss: 948.2977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 204 [0/2589 (0%)]\tLoss: 256.924408\n",
      "Train Epoch: 204 [300/2589 (12%)]\tLoss: 240.428848\n",
      "Train Epoch: 204 [600/2589 (23%)]\tLoss: 358.177826\n",
      "Train Epoch: 204 [900/2589 (35%)]\tLoss: 332.831085\n",
      "Train Epoch: 204 [1200/2589 (46%)]\tLoss: 305.989471\n",
      "Train Epoch: 204 [1500/2589 (58%)]\tLoss: 239.443634\n",
      "Train Epoch: 204 [1800/2589 (70%)]\tLoss: 255.039627\n",
      "Train Epoch: 204 [2100/2589 (81%)]\tLoss: 281.160767\n",
      "Train Epoch: 204 [2400/2589 (93%)]\tLoss: 268.224152\n",
      "====> Epoch: 204 Average train loss: 282.1770\n",
      "====> Epoch: 204 Average test loss: 932.2148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 205 [0/2589 (0%)]\tLoss: 324.393066\n",
      "Train Epoch: 205 [300/2589 (12%)]\tLoss: 483.037567\n",
      "Train Epoch: 205 [600/2589 (23%)]\tLoss: 273.792694\n",
      "Train Epoch: 205 [900/2589 (35%)]\tLoss: 400.688446\n",
      "Train Epoch: 205 [1200/2589 (46%)]\tLoss: 369.727112\n",
      "Train Epoch: 205 [1500/2589 (58%)]\tLoss: 335.174683\n",
      "Train Epoch: 205 [1800/2589 (70%)]\tLoss: 223.213104\n",
      "Train Epoch: 205 [2100/2589 (81%)]\tLoss: 253.428055\n",
      "Train Epoch: 205 [2400/2589 (93%)]\tLoss: 300.696350\n",
      "====> Epoch: 205 Average train loss: 297.6444\n",
      "====> Epoch: 205 Average test loss: 943.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 206 [0/2589 (0%)]\tLoss: 296.737823\n",
      "Train Epoch: 206 [300/2589 (12%)]\tLoss: 302.354004\n",
      "Train Epoch: 206 [600/2589 (23%)]\tLoss: 340.116333\n",
      "Train Epoch: 206 [900/2589 (35%)]\tLoss: 440.200806\n",
      "Train Epoch: 206 [1200/2589 (46%)]\tLoss: 200.729294\n",
      "Train Epoch: 206 [1500/2589 (58%)]\tLoss: 242.328156\n",
      "Train Epoch: 206 [1800/2589 (70%)]\tLoss: 231.562790\n",
      "Train Epoch: 206 [2100/2589 (81%)]\tLoss: 191.847427\n",
      "Train Epoch: 206 [2400/2589 (93%)]\tLoss: 329.063080\n",
      "====> Epoch: 206 Average train loss: 274.8850\n",
      "====> Epoch: 206 Average test loss: 951.4783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 207 [0/2589 (0%)]\tLoss: 183.600540\n",
      "Train Epoch: 207 [300/2589 (12%)]\tLoss: 324.014954\n",
      "Train Epoch: 207 [600/2589 (23%)]\tLoss: 301.119904\n",
      "Train Epoch: 207 [900/2589 (35%)]\tLoss: 221.520859\n",
      "Train Epoch: 207 [1200/2589 (46%)]\tLoss: 449.490051\n",
      "Train Epoch: 207 [1500/2589 (58%)]\tLoss: 292.544525\n",
      "Train Epoch: 207 [1800/2589 (70%)]\tLoss: 312.101135\n",
      "Train Epoch: 207 [2100/2589 (81%)]\tLoss: 224.242249\n",
      "Train Epoch: 207 [2400/2589 (93%)]\tLoss: 214.830795\n",
      "====> Epoch: 207 Average train loss: 284.7482\n",
      "====> Epoch: 207 Average test loss: 957.3763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 208 [0/2589 (0%)]\tLoss: 210.936951\n",
      "Train Epoch: 208 [300/2589 (12%)]\tLoss: 218.645676\n",
      "Train Epoch: 208 [600/2589 (23%)]\tLoss: 223.422668\n",
      "Train Epoch: 208 [900/2589 (35%)]\tLoss: 265.359741\n",
      "Train Epoch: 208 [1200/2589 (46%)]\tLoss: 262.385040\n",
      "Train Epoch: 208 [1500/2589 (58%)]\tLoss: 529.537231\n",
      "Train Epoch: 208 [1800/2589 (70%)]\tLoss: 359.194397\n",
      "Train Epoch: 208 [2100/2589 (81%)]\tLoss: 381.391602\n",
      "Train Epoch: 208 [2400/2589 (93%)]\tLoss: 326.292908\n",
      "====> Epoch: 208 Average train loss: 279.4568\n",
      "====> Epoch: 208 Average test loss: 945.2461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 209 [0/2589 (0%)]\tLoss: 284.292267\n",
      "Train Epoch: 209 [300/2589 (12%)]\tLoss: 229.370804\n",
      "Train Epoch: 209 [600/2589 (23%)]\tLoss: 296.640503\n",
      "Train Epoch: 209 [900/2589 (35%)]\tLoss: 204.448456\n",
      "Train Epoch: 209 [1200/2589 (46%)]\tLoss: 283.330627\n",
      "Train Epoch: 209 [1500/2589 (58%)]\tLoss: 324.016479\n",
      "Train Epoch: 209 [1800/2589 (70%)]\tLoss: 392.491882\n",
      "Train Epoch: 209 [2100/2589 (81%)]\tLoss: 394.374664\n",
      "Train Epoch: 209 [2400/2589 (93%)]\tLoss: 329.722504\n",
      "====> Epoch: 209 Average train loss: 299.6629\n",
      "====> Epoch: 209 Average test loss: 979.5190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 210 [0/2589 (0%)]\tLoss: 186.950714\n",
      "Train Epoch: 210 [300/2589 (12%)]\tLoss: 222.946869\n",
      "Train Epoch: 210 [600/2589 (23%)]\tLoss: 174.124161\n",
      "Train Epoch: 210 [900/2589 (35%)]\tLoss: 246.285553\n",
      "Train Epoch: 210 [1200/2589 (46%)]\tLoss: 277.934174\n",
      "Train Epoch: 210 [1500/2589 (58%)]\tLoss: 280.586487\n",
      "Train Epoch: 210 [1800/2589 (70%)]\tLoss: 256.037750\n",
      "Train Epoch: 210 [2100/2589 (81%)]\tLoss: 305.881073\n",
      "Train Epoch: 210 [2400/2589 (93%)]\tLoss: 206.863617\n",
      "====> Epoch: 210 Average train loss: 279.2535\n",
      "====> Epoch: 210 Average test loss: 954.4168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 211 [0/2589 (0%)]\tLoss: 216.761246\n",
      "Train Epoch: 211 [300/2589 (12%)]\tLoss: 429.292114\n",
      "Train Epoch: 211 [600/2589 (23%)]\tLoss: 254.404007\n",
      "Train Epoch: 211 [900/2589 (35%)]\tLoss: 343.986450\n",
      "Train Epoch: 211 [1200/2589 (46%)]\tLoss: 426.852356\n",
      "Train Epoch: 211 [1500/2589 (58%)]\tLoss: 343.061829\n",
      "Train Epoch: 211 [1800/2589 (70%)]\tLoss: 294.336304\n",
      "Train Epoch: 211 [2100/2589 (81%)]\tLoss: 258.040100\n",
      "Train Epoch: 211 [2400/2589 (93%)]\tLoss: 338.251587\n",
      "====> Epoch: 211 Average train loss: 286.8362\n",
      "====> Epoch: 211 Average test loss: 957.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 212 [0/2589 (0%)]\tLoss: 160.205612\n",
      "Train Epoch: 212 [300/2589 (12%)]\tLoss: 297.654297\n",
      "Train Epoch: 212 [600/2589 (23%)]\tLoss: 305.619812\n",
      "Train Epoch: 212 [900/2589 (35%)]\tLoss: 255.084946\n",
      "Train Epoch: 212 [1200/2589 (46%)]\tLoss: 308.597992\n",
      "Train Epoch: 212 [1500/2589 (58%)]\tLoss: 266.415924\n",
      "Train Epoch: 212 [1800/2589 (70%)]\tLoss: 264.323334\n",
      "Train Epoch: 212 [2100/2589 (81%)]\tLoss: 237.931671\n",
      "Train Epoch: 212 [2400/2589 (93%)]\tLoss: 434.719940\n",
      "====> Epoch: 212 Average train loss: 282.1609\n",
      "====> Epoch: 212 Average test loss: 956.1771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 213 [0/2589 (0%)]\tLoss: 198.539612\n",
      "Train Epoch: 213 [300/2589 (12%)]\tLoss: 263.908569\n",
      "Train Epoch: 213 [600/2589 (23%)]\tLoss: 540.262817\n",
      "Train Epoch: 213 [900/2589 (35%)]\tLoss: 189.849609\n",
      "Train Epoch: 213 [1200/2589 (46%)]\tLoss: 235.437042\n",
      "Train Epoch: 213 [1500/2589 (58%)]\tLoss: 249.696152\n",
      "Train Epoch: 213 [1800/2589 (70%)]\tLoss: 195.595184\n",
      "Train Epoch: 213 [2100/2589 (81%)]\tLoss: 308.688324\n",
      "Train Epoch: 213 [2400/2589 (93%)]\tLoss: 211.753693\n",
      "====> Epoch: 213 Average train loss: 283.0846\n",
      "====> Epoch: 213 Average test loss: 956.3666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 214 [0/2589 (0%)]\tLoss: 293.632355\n",
      "Train Epoch: 214 [300/2589 (12%)]\tLoss: 297.430145\n",
      "Train Epoch: 214 [600/2589 (23%)]\tLoss: 289.466583\n",
      "Train Epoch: 214 [900/2589 (35%)]\tLoss: 236.519562\n",
      "Train Epoch: 214 [1200/2589 (46%)]\tLoss: 220.228195\n",
      "Train Epoch: 214 [1500/2589 (58%)]\tLoss: 295.376404\n",
      "Train Epoch: 214 [1800/2589 (70%)]\tLoss: 276.003754\n",
      "Train Epoch: 214 [2100/2589 (81%)]\tLoss: 264.498230\n",
      "Train Epoch: 214 [2400/2589 (93%)]\tLoss: 314.633636\n",
      "====> Epoch: 214 Average train loss: 283.1988\n",
      "====> Epoch: 214 Average test loss: 953.8370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 215 [0/2589 (0%)]\tLoss: 239.253174\n",
      "Train Epoch: 215 [300/2589 (12%)]\tLoss: 218.015137\n",
      "Train Epoch: 215 [600/2589 (23%)]\tLoss: 275.291412\n",
      "Train Epoch: 215 [900/2589 (35%)]\tLoss: 455.240540\n",
      "Train Epoch: 215 [1200/2589 (46%)]\tLoss: 249.612335\n",
      "Train Epoch: 215 [1500/2589 (58%)]\tLoss: 221.739349\n",
      "Train Epoch: 215 [1800/2589 (70%)]\tLoss: 508.838531\n",
      "Train Epoch: 215 [2100/2589 (81%)]\tLoss: 203.336044\n",
      "Train Epoch: 215 [2400/2589 (93%)]\tLoss: 287.497986\n",
      "====> Epoch: 215 Average train loss: 283.4595\n",
      "====> Epoch: 215 Average test loss: 947.8553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 216 [0/2589 (0%)]\tLoss: 274.758331\n",
      "Train Epoch: 216 [300/2589 (12%)]\tLoss: 392.616608\n",
      "Train Epoch: 216 [600/2589 (23%)]\tLoss: 304.699707\n",
      "Train Epoch: 216 [900/2589 (35%)]\tLoss: 332.632324\n",
      "Train Epoch: 216 [1200/2589 (46%)]\tLoss: 270.986847\n",
      "Train Epoch: 216 [1500/2589 (58%)]\tLoss: 236.456146\n",
      "Train Epoch: 216 [1800/2589 (70%)]\tLoss: 288.603790\n",
      "Train Epoch: 216 [2100/2589 (81%)]\tLoss: 247.198425\n",
      "Train Epoch: 216 [2400/2589 (93%)]\tLoss: 225.283630\n",
      "====> Epoch: 216 Average train loss: 281.8930\n",
      "====> Epoch: 216 Average test loss: 948.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 217 [0/2589 (0%)]\tLoss: 245.383133\n",
      "Train Epoch: 217 [300/2589 (12%)]\tLoss: 231.574997\n",
      "Train Epoch: 217 [600/2589 (23%)]\tLoss: 271.894958\n",
      "Train Epoch: 217 [900/2589 (35%)]\tLoss: 170.459442\n",
      "Train Epoch: 217 [1200/2589 (46%)]\tLoss: 332.139008\n",
      "Train Epoch: 217 [1500/2589 (58%)]\tLoss: 298.537170\n",
      "Train Epoch: 217 [1800/2589 (70%)]\tLoss: 351.155823\n",
      "Train Epoch: 217 [2100/2589 (81%)]\tLoss: 225.831833\n",
      "Train Epoch: 217 [2400/2589 (93%)]\tLoss: 284.908722\n",
      "====> Epoch: 217 Average train loss: 277.1074\n",
      "====> Epoch: 217 Average test loss: 945.3123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 218 [0/2589 (0%)]\tLoss: 305.289734\n",
      "Train Epoch: 218 [300/2589 (12%)]\tLoss: 231.113571\n",
      "Train Epoch: 218 [600/2589 (23%)]\tLoss: 287.257843\n",
      "Train Epoch: 218 [900/2589 (35%)]\tLoss: 263.404236\n",
      "Train Epoch: 218 [1200/2589 (46%)]\tLoss: 188.949524\n",
      "Train Epoch: 218 [1500/2589 (58%)]\tLoss: 288.198639\n",
      "Train Epoch: 218 [1800/2589 (70%)]\tLoss: 392.477844\n",
      "Train Epoch: 218 [2100/2589 (81%)]\tLoss: 258.383453\n",
      "Train Epoch: 218 [2400/2589 (93%)]\tLoss: 281.386353\n",
      "====> Epoch: 218 Average train loss: 286.6068\n",
      "====> Epoch: 218 Average test loss: 956.5764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 219 [0/2589 (0%)]\tLoss: 283.227142\n",
      "Train Epoch: 219 [300/2589 (12%)]\tLoss: 268.967438\n",
      "Train Epoch: 219 [600/2589 (23%)]\tLoss: 396.702301\n",
      "Train Epoch: 219 [900/2589 (35%)]\tLoss: 247.216049\n",
      "Train Epoch: 219 [1200/2589 (46%)]\tLoss: 309.634796\n",
      "Train Epoch: 219 [1500/2589 (58%)]\tLoss: 296.617615\n",
      "Train Epoch: 219 [1800/2589 (70%)]\tLoss: 400.675507\n",
      "Train Epoch: 219 [2100/2589 (81%)]\tLoss: 307.259857\n",
      "Train Epoch: 219 [2400/2589 (93%)]\tLoss: 326.203766\n",
      "====> Epoch: 219 Average train loss: 287.3362\n",
      "====> Epoch: 219 Average test loss: 962.5220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 220 [0/2589 (0%)]\tLoss: 343.225708\n",
      "Train Epoch: 220 [300/2589 (12%)]\tLoss: 244.499695\n",
      "Train Epoch: 220 [600/2589 (23%)]\tLoss: 217.065659\n",
      "Train Epoch: 220 [900/2589 (35%)]\tLoss: 207.666733\n",
      "Train Epoch: 220 [1200/2589 (46%)]\tLoss: 244.840591\n",
      "Train Epoch: 220 [1500/2589 (58%)]\tLoss: 244.145248\n",
      "Train Epoch: 220 [1800/2589 (70%)]\tLoss: 422.342255\n",
      "Train Epoch: 220 [2100/2589 (81%)]\tLoss: 321.033661\n",
      "Train Epoch: 220 [2400/2589 (93%)]\tLoss: 304.181946\n",
      "====> Epoch: 220 Average train loss: 280.0851\n",
      "====> Epoch: 220 Average test loss: 949.6780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 221 [0/2589 (0%)]\tLoss: 289.393097\n",
      "Train Epoch: 221 [300/2589 (12%)]\tLoss: 247.461655\n",
      "Train Epoch: 221 [600/2589 (23%)]\tLoss: 424.055359\n",
      "Train Epoch: 221 [900/2589 (35%)]\tLoss: 373.200378\n",
      "Train Epoch: 221 [1200/2589 (46%)]\tLoss: 363.068665\n",
      "Train Epoch: 221 [1500/2589 (58%)]\tLoss: 270.187958\n",
      "Train Epoch: 221 [1800/2589 (70%)]\tLoss: 250.645691\n",
      "Train Epoch: 221 [2100/2589 (81%)]\tLoss: 172.599152\n",
      "Train Epoch: 221 [2400/2589 (93%)]\tLoss: 198.926651\n",
      "====> Epoch: 221 Average train loss: 279.4026\n",
      "====> Epoch: 221 Average test loss: 956.1382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 222 [0/2589 (0%)]\tLoss: 259.320343\n",
      "Train Epoch: 222 [300/2589 (12%)]\tLoss: 223.008362\n",
      "Train Epoch: 222 [600/2589 (23%)]\tLoss: 269.755310\n",
      "Train Epoch: 222 [900/2589 (35%)]\tLoss: 249.556702\n",
      "Train Epoch: 222 [1200/2589 (46%)]\tLoss: 452.386017\n",
      "Train Epoch: 222 [1500/2589 (58%)]\tLoss: 183.552307\n",
      "Train Epoch: 222 [1800/2589 (70%)]\tLoss: 233.842667\n",
      "Train Epoch: 222 [2100/2589 (81%)]\tLoss: 219.636780\n",
      "Train Epoch: 222 [2400/2589 (93%)]\tLoss: 272.274750\n",
      "====> Epoch: 222 Average train loss: 287.9443\n",
      "====> Epoch: 222 Average test loss: 954.2374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 223 [0/2589 (0%)]\tLoss: 272.537781\n",
      "Train Epoch: 223 [300/2589 (12%)]\tLoss: 477.986694\n",
      "Train Epoch: 223 [600/2589 (23%)]\tLoss: 481.293274\n",
      "Train Epoch: 223 [900/2589 (35%)]\tLoss: 253.361191\n",
      "Train Epoch: 223 [1200/2589 (46%)]\tLoss: 269.403717\n",
      "Train Epoch: 223 [1500/2589 (58%)]\tLoss: 194.791016\n",
      "Train Epoch: 223 [1800/2589 (70%)]\tLoss: 351.722015\n",
      "Train Epoch: 223 [2100/2589 (81%)]\tLoss: 304.056213\n",
      "Train Epoch: 223 [2400/2589 (93%)]\tLoss: 346.625183\n",
      "====> Epoch: 223 Average train loss: 281.1707\n",
      "====> Epoch: 223 Average test loss: 945.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 224 [0/2589 (0%)]\tLoss: 313.963745\n",
      "Train Epoch: 224 [300/2589 (12%)]\tLoss: 297.251282\n",
      "Train Epoch: 224 [600/2589 (23%)]\tLoss: 214.310150\n",
      "Train Epoch: 224 [900/2589 (35%)]\tLoss: 282.153931\n",
      "Train Epoch: 224 [1200/2589 (46%)]\tLoss: 306.076172\n",
      "Train Epoch: 224 [1500/2589 (58%)]\tLoss: 335.961456\n",
      "Train Epoch: 224 [1800/2589 (70%)]\tLoss: 401.844208\n",
      "Train Epoch: 224 [2100/2589 (81%)]\tLoss: 232.771973\n",
      "Train Epoch: 224 [2400/2589 (93%)]\tLoss: 201.550293\n",
      "====> Epoch: 224 Average train loss: 292.4003\n",
      "====> Epoch: 224 Average test loss: 951.0888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 225 [0/2589 (0%)]\tLoss: 345.399353\n",
      "Train Epoch: 225 [300/2589 (12%)]\tLoss: 277.696808\n",
      "Train Epoch: 225 [600/2589 (23%)]\tLoss: 297.932922\n",
      "Train Epoch: 225 [900/2589 (35%)]\tLoss: 249.411133\n",
      "Train Epoch: 225 [1200/2589 (46%)]\tLoss: 476.194794\n",
      "Train Epoch: 225 [1500/2589 (58%)]\tLoss: 250.375046\n",
      "Train Epoch: 225 [1800/2589 (70%)]\tLoss: 304.798248\n",
      "Train Epoch: 225 [2100/2589 (81%)]\tLoss: 326.430115\n",
      "Train Epoch: 225 [2400/2589 (93%)]\tLoss: 267.497772\n",
      "====> Epoch: 225 Average train loss: 270.9002\n",
      "====> Epoch: 225 Average test loss: 969.2720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 226 [0/2589 (0%)]\tLoss: 343.073029\n",
      "Train Epoch: 226 [300/2589 (12%)]\tLoss: 214.530319\n",
      "Train Epoch: 226 [600/2589 (23%)]\tLoss: 253.145508\n",
      "Train Epoch: 226 [900/2589 (35%)]\tLoss: 231.414871\n",
      "Train Epoch: 226 [1200/2589 (46%)]\tLoss: 302.285339\n",
      "Train Epoch: 226 [1500/2589 (58%)]\tLoss: 294.691895\n",
      "Train Epoch: 226 [1800/2589 (70%)]\tLoss: 263.723358\n",
      "Train Epoch: 226 [2100/2589 (81%)]\tLoss: 310.627563\n",
      "Train Epoch: 226 [2400/2589 (93%)]\tLoss: 196.403641\n",
      "====> Epoch: 226 Average train loss: 268.6879\n",
      "====> Epoch: 226 Average test loss: 946.6650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 227 [0/2589 (0%)]\tLoss: 222.184799\n",
      "Train Epoch: 227 [300/2589 (12%)]\tLoss: 292.221863\n",
      "Train Epoch: 227 [600/2589 (23%)]\tLoss: 223.072220\n",
      "Train Epoch: 227 [900/2589 (35%)]\tLoss: 163.516953\n",
      "Train Epoch: 227 [1200/2589 (46%)]\tLoss: 232.472595\n",
      "Train Epoch: 227 [1500/2589 (58%)]\tLoss: 206.133469\n",
      "Train Epoch: 227 [1800/2589 (70%)]\tLoss: 360.670197\n",
      "Train Epoch: 227 [2100/2589 (81%)]\tLoss: 376.121124\n",
      "Train Epoch: 227 [2400/2589 (93%)]\tLoss: 205.975571\n",
      "====> Epoch: 227 Average train loss: 276.1469\n",
      "====> Epoch: 227 Average test loss: 942.1839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 228 [0/2589 (0%)]\tLoss: 207.672943\n",
      "Train Epoch: 228 [300/2589 (12%)]\tLoss: 179.651855\n",
      "Train Epoch: 228 [600/2589 (23%)]\tLoss: 286.435944\n",
      "Train Epoch: 228 [900/2589 (35%)]\tLoss: 209.605423\n",
      "Train Epoch: 228 [1200/2589 (46%)]\tLoss: 251.417664\n",
      "Train Epoch: 228 [1500/2589 (58%)]\tLoss: 329.778381\n",
      "Train Epoch: 228 [1800/2589 (70%)]\tLoss: 252.511169\n",
      "Train Epoch: 228 [2100/2589 (81%)]\tLoss: 271.801697\n",
      "Train Epoch: 228 [2400/2589 (93%)]\tLoss: 262.741272\n",
      "====> Epoch: 228 Average train loss: 273.4603\n",
      "====> Epoch: 228 Average test loss: 962.2717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 229 [0/2589 (0%)]\tLoss: 313.156616\n",
      "Train Epoch: 229 [300/2589 (12%)]\tLoss: 354.573181\n",
      "Train Epoch: 229 [600/2589 (23%)]\tLoss: 304.896149\n",
      "Train Epoch: 229 [900/2589 (35%)]\tLoss: 442.923065\n",
      "Train Epoch: 229 [1200/2589 (46%)]\tLoss: 232.553238\n",
      "Train Epoch: 229 [1500/2589 (58%)]\tLoss: 257.235565\n",
      "Train Epoch: 229 [1800/2589 (70%)]\tLoss: 188.701218\n",
      "Train Epoch: 229 [2100/2589 (81%)]\tLoss: 601.872681\n",
      "Train Epoch: 229 [2400/2589 (93%)]\tLoss: 204.800049\n",
      "====> Epoch: 229 Average train loss: 284.5630\n",
      "====> Epoch: 229 Average test loss: 922.2335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 230 [0/2589 (0%)]\tLoss: 314.272736\n",
      "Train Epoch: 230 [300/2589 (12%)]\tLoss: 317.578125\n",
      "Train Epoch: 230 [600/2589 (23%)]\tLoss: 277.318176\n",
      "Train Epoch: 230 [900/2589 (35%)]\tLoss: 359.205170\n",
      "Train Epoch: 230 [1200/2589 (46%)]\tLoss: 207.867645\n",
      "Train Epoch: 230 [1500/2589 (58%)]\tLoss: 235.635361\n",
      "Train Epoch: 230 [1800/2589 (70%)]\tLoss: 456.347260\n",
      "Train Epoch: 230 [2100/2589 (81%)]\tLoss: 304.551331\n",
      "Train Epoch: 230 [2400/2589 (93%)]\tLoss: 206.871353\n",
      "====> Epoch: 230 Average train loss: 279.6606\n",
      "====> Epoch: 230 Average test loss: 950.5285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 231 [0/2589 (0%)]\tLoss: 390.966278\n",
      "Train Epoch: 231 [300/2589 (12%)]\tLoss: 257.987488\n",
      "Train Epoch: 231 [600/2589 (23%)]\tLoss: 233.907745\n",
      "Train Epoch: 231 [900/2589 (35%)]\tLoss: 271.628845\n",
      "Train Epoch: 231 [1200/2589 (46%)]\tLoss: 220.813080\n",
      "Train Epoch: 231 [1500/2589 (58%)]\tLoss: 269.749664\n",
      "Train Epoch: 231 [1800/2589 (70%)]\tLoss: 324.232117\n",
      "Train Epoch: 231 [2100/2589 (81%)]\tLoss: 289.554321\n",
      "Train Epoch: 231 [2400/2589 (93%)]\tLoss: 222.684525\n",
      "====> Epoch: 231 Average train loss: 272.3907\n",
      "====> Epoch: 231 Average test loss: 948.0928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 232 [0/2589 (0%)]\tLoss: 296.771790\n",
      "Train Epoch: 232 [300/2589 (12%)]\tLoss: 268.623535\n",
      "Train Epoch: 232 [600/2589 (23%)]\tLoss: 233.851532\n",
      "Train Epoch: 232 [900/2589 (35%)]\tLoss: 356.793640\n",
      "Train Epoch: 232 [1200/2589 (46%)]\tLoss: 228.451752\n",
      "Train Epoch: 232 [1500/2589 (58%)]\tLoss: 201.392563\n",
      "Train Epoch: 232 [1800/2589 (70%)]\tLoss: 352.923401\n",
      "Train Epoch: 232 [2100/2589 (81%)]\tLoss: 247.349503\n",
      "Train Epoch: 232 [2400/2589 (93%)]\tLoss: 361.276855\n",
      "====> Epoch: 232 Average train loss: 283.8976\n",
      "====> Epoch: 232 Average test loss: 955.4910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 233 [0/2589 (0%)]\tLoss: 231.418701\n",
      "Train Epoch: 233 [300/2589 (12%)]\tLoss: 292.579620\n",
      "Train Epoch: 233 [600/2589 (23%)]\tLoss: 241.834320\n",
      "Train Epoch: 233 [900/2589 (35%)]\tLoss: 317.499207\n",
      "Train Epoch: 233 [1200/2589 (46%)]\tLoss: 193.593079\n",
      "Train Epoch: 233 [1500/2589 (58%)]\tLoss: 200.418213\n",
      "Train Epoch: 233 [1800/2589 (70%)]\tLoss: 234.099960\n",
      "Train Epoch: 233 [2100/2589 (81%)]\tLoss: 206.989151\n",
      "Train Epoch: 233 [2400/2589 (93%)]\tLoss: 248.065338\n",
      "====> Epoch: 233 Average train loss: 274.3226\n",
      "====> Epoch: 233 Average test loss: 957.3167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 234 [0/2589 (0%)]\tLoss: 269.667053\n",
      "Train Epoch: 234 [300/2589 (12%)]\tLoss: 296.972961\n",
      "Train Epoch: 234 [600/2589 (23%)]\tLoss: 211.868423\n",
      "Train Epoch: 234 [900/2589 (35%)]\tLoss: 198.359421\n",
      "Train Epoch: 234 [1200/2589 (46%)]\tLoss: 339.845306\n",
      "Train Epoch: 234 [1500/2589 (58%)]\tLoss: 192.990723\n",
      "Train Epoch: 234 [1800/2589 (70%)]\tLoss: 378.123505\n",
      "Train Epoch: 234 [2100/2589 (81%)]\tLoss: 254.320633\n",
      "Train Epoch: 234 [2400/2589 (93%)]\tLoss: 189.637207\n",
      "====> Epoch: 234 Average train loss: 275.8051\n",
      "====> Epoch: 234 Average test loss: 934.0971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 235 [0/2589 (0%)]\tLoss: 351.156891\n",
      "Train Epoch: 235 [300/2589 (12%)]\tLoss: 369.788208\n",
      "Train Epoch: 235 [600/2589 (23%)]\tLoss: 413.689819\n",
      "Train Epoch: 235 [900/2589 (35%)]\tLoss: 218.296463\n",
      "Train Epoch: 235 [1200/2589 (46%)]\tLoss: 265.856659\n",
      "Train Epoch: 235 [1500/2589 (58%)]\tLoss: 262.143280\n",
      "Train Epoch: 235 [1800/2589 (70%)]\tLoss: 266.458893\n",
      "Train Epoch: 235 [2100/2589 (81%)]\tLoss: 320.809906\n",
      "Train Epoch: 235 [2400/2589 (93%)]\tLoss: 268.404266\n",
      "====> Epoch: 235 Average train loss: 275.4742\n",
      "====> Epoch: 235 Average test loss: 962.5831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 236 [0/2589 (0%)]\tLoss: 253.091537\n",
      "Train Epoch: 236 [300/2589 (12%)]\tLoss: 230.771255\n",
      "Train Epoch: 236 [600/2589 (23%)]\tLoss: 271.991882\n",
      "Train Epoch: 236 [900/2589 (35%)]\tLoss: 227.133453\n",
      "Train Epoch: 236 [1200/2589 (46%)]\tLoss: 292.374817\n",
      "Train Epoch: 236 [1500/2589 (58%)]\tLoss: 272.215118\n",
      "Train Epoch: 236 [1800/2589 (70%)]\tLoss: 213.426590\n",
      "Train Epoch: 236 [2100/2589 (81%)]\tLoss: 296.054779\n",
      "Train Epoch: 236 [2400/2589 (93%)]\tLoss: 268.747101\n",
      "====> Epoch: 236 Average train loss: 285.0843\n",
      "====> Epoch: 236 Average test loss: 960.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 237 [0/2589 (0%)]\tLoss: 226.667953\n",
      "Train Epoch: 237 [300/2589 (12%)]\tLoss: 315.978577\n",
      "Train Epoch: 237 [600/2589 (23%)]\tLoss: 280.950378\n",
      "Train Epoch: 237 [900/2589 (35%)]\tLoss: 250.053543\n",
      "Train Epoch: 237 [1200/2589 (46%)]\tLoss: 278.936310\n",
      "Train Epoch: 237 [1500/2589 (58%)]\tLoss: 219.629532\n",
      "Train Epoch: 237 [1800/2589 (70%)]\tLoss: 247.803284\n",
      "Train Epoch: 237 [2100/2589 (81%)]\tLoss: 216.006729\n",
      "Train Epoch: 237 [2400/2589 (93%)]\tLoss: 364.562378\n",
      "====> Epoch: 237 Average train loss: 275.9194\n",
      "====> Epoch: 237 Average test loss: 947.3671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 238 [0/2589 (0%)]\tLoss: 234.966064\n",
      "Train Epoch: 238 [300/2589 (12%)]\tLoss: 410.792847\n",
      "Train Epoch: 238 [600/2589 (23%)]\tLoss: 259.159058\n",
      "Train Epoch: 238 [900/2589 (35%)]\tLoss: 352.810150\n",
      "Train Epoch: 238 [1200/2589 (46%)]\tLoss: 255.981659\n",
      "Train Epoch: 238 [1500/2589 (58%)]\tLoss: 324.898865\n",
      "Train Epoch: 238 [1800/2589 (70%)]\tLoss: 271.036377\n",
      "Train Epoch: 238 [2100/2589 (81%)]\tLoss: 470.694916\n",
      "Train Epoch: 238 [2400/2589 (93%)]\tLoss: 204.386520\n",
      "====> Epoch: 238 Average train loss: 281.3177\n",
      "====> Epoch: 238 Average test loss: 954.1545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 239 [0/2589 (0%)]\tLoss: 248.223862\n",
      "Train Epoch: 239 [300/2589 (12%)]\tLoss: 212.955505\n",
      "Train Epoch: 239 [600/2589 (23%)]\tLoss: 232.902512\n",
      "Train Epoch: 239 [900/2589 (35%)]\tLoss: 306.982483\n",
      "Train Epoch: 239 [1200/2589 (46%)]\tLoss: 227.159988\n",
      "Train Epoch: 239 [1500/2589 (58%)]\tLoss: 304.007904\n",
      "Train Epoch: 239 [1800/2589 (70%)]\tLoss: 241.894333\n",
      "Train Epoch: 239 [2100/2589 (81%)]\tLoss: 235.788818\n",
      "Train Epoch: 239 [2400/2589 (93%)]\tLoss: 234.420898\n",
      "====> Epoch: 239 Average train loss: 269.5574\n",
      "====> Epoch: 239 Average test loss: 960.9354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 240 [0/2589 (0%)]\tLoss: 261.486969\n",
      "Train Epoch: 240 [300/2589 (12%)]\tLoss: 326.352356\n",
      "Train Epoch: 240 [600/2589 (23%)]\tLoss: 282.717438\n",
      "Train Epoch: 240 [900/2589 (35%)]\tLoss: 241.570831\n",
      "Train Epoch: 240 [1200/2589 (46%)]\tLoss: 311.911407\n",
      "Train Epoch: 240 [1500/2589 (58%)]\tLoss: 210.713562\n",
      "Train Epoch: 240 [1800/2589 (70%)]\tLoss: 329.786682\n",
      "Train Epoch: 240 [2100/2589 (81%)]\tLoss: 303.511017\n",
      "Train Epoch: 240 [2400/2589 (93%)]\tLoss: 218.383377\n",
      "====> Epoch: 240 Average train loss: 290.3645\n",
      "====> Epoch: 240 Average test loss: 947.8688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 241 [0/2589 (0%)]\tLoss: 243.786758\n",
      "Train Epoch: 241 [300/2589 (12%)]\tLoss: 391.396362\n",
      "Train Epoch: 241 [600/2589 (23%)]\tLoss: 229.149155\n",
      "Train Epoch: 241 [900/2589 (35%)]\tLoss: 274.827606\n",
      "Train Epoch: 241 [1200/2589 (46%)]\tLoss: 261.744049\n",
      "Train Epoch: 241 [1500/2589 (58%)]\tLoss: 248.177078\n",
      "Train Epoch: 241 [1800/2589 (70%)]\tLoss: 174.155228\n",
      "Train Epoch: 241 [2100/2589 (81%)]\tLoss: 290.863373\n",
      "Train Epoch: 241 [2400/2589 (93%)]\tLoss: 372.261200\n",
      "====> Epoch: 241 Average train loss: 276.9535\n",
      "====> Epoch: 241 Average test loss: 941.8356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 242 [0/2589 (0%)]\tLoss: 192.784698\n",
      "Train Epoch: 242 [300/2589 (12%)]\tLoss: 319.874908\n",
      "Train Epoch: 242 [600/2589 (23%)]\tLoss: 254.952118\n",
      "Train Epoch: 242 [900/2589 (35%)]\tLoss: 180.572083\n",
      "Train Epoch: 242 [1200/2589 (46%)]\tLoss: 266.700134\n",
      "Train Epoch: 242 [1500/2589 (58%)]\tLoss: 274.033844\n",
      "Train Epoch: 242 [1800/2589 (70%)]\tLoss: 290.254181\n",
      "Train Epoch: 242 [2100/2589 (81%)]\tLoss: 310.711884\n",
      "Train Epoch: 242 [2400/2589 (93%)]\tLoss: 294.057526\n",
      "====> Epoch: 242 Average train loss: 279.5696\n",
      "====> Epoch: 242 Average test loss: 977.7775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 243 [0/2589 (0%)]\tLoss: 384.729126\n",
      "Train Epoch: 243 [300/2589 (12%)]\tLoss: 236.989807\n",
      "Train Epoch: 243 [600/2589 (23%)]\tLoss: 220.399384\n",
      "Train Epoch: 243 [900/2589 (35%)]\tLoss: 299.989929\n",
      "Train Epoch: 243 [1200/2589 (46%)]\tLoss: 250.561295\n",
      "Train Epoch: 243 [1500/2589 (58%)]\tLoss: 185.276855\n",
      "Train Epoch: 243 [1800/2589 (70%)]\tLoss: 365.589050\n",
      "Train Epoch: 243 [2100/2589 (81%)]\tLoss: 290.205353\n",
      "Train Epoch: 243 [2400/2589 (93%)]\tLoss: 211.690948\n",
      "====> Epoch: 243 Average train loss: 267.7878\n",
      "====> Epoch: 243 Average test loss: 946.0546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 244 [0/2589 (0%)]\tLoss: 285.638580\n",
      "Train Epoch: 244 [300/2589 (12%)]\tLoss: 261.636322\n",
      "Train Epoch: 244 [600/2589 (23%)]\tLoss: 354.306549\n",
      "Train Epoch: 244 [900/2589 (35%)]\tLoss: 399.682343\n",
      "Train Epoch: 244 [1200/2589 (46%)]\tLoss: 225.472610\n",
      "Train Epoch: 244 [1500/2589 (58%)]\tLoss: 232.842712\n",
      "Train Epoch: 244 [1800/2589 (70%)]\tLoss: 369.786774\n",
      "Train Epoch: 244 [2100/2589 (81%)]\tLoss: 191.762848\n",
      "Train Epoch: 244 [2400/2589 (93%)]\tLoss: 268.335754\n",
      "====> Epoch: 244 Average train loss: 274.0046\n",
      "====> Epoch: 244 Average test loss: 958.0830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 245 [0/2589 (0%)]\tLoss: 227.632278\n",
      "Train Epoch: 245 [300/2589 (12%)]\tLoss: 305.408661\n",
      "Train Epoch: 245 [600/2589 (23%)]\tLoss: 299.388031\n",
      "Train Epoch: 245 [900/2589 (35%)]\tLoss: 286.164490\n",
      "Train Epoch: 245 [1200/2589 (46%)]\tLoss: 316.730316\n",
      "Train Epoch: 245 [1500/2589 (58%)]\tLoss: 298.381683\n",
      "Train Epoch: 245 [1800/2589 (70%)]\tLoss: 343.534393\n",
      "Train Epoch: 245 [2100/2589 (81%)]\tLoss: 230.266312\n",
      "Train Epoch: 245 [2400/2589 (93%)]\tLoss: 258.646851\n",
      "====> Epoch: 245 Average train loss: 283.5545\n",
      "====> Epoch: 245 Average test loss: 943.3004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 246 [0/2589 (0%)]\tLoss: 244.877670\n",
      "Train Epoch: 246 [300/2589 (12%)]\tLoss: 173.432785\n",
      "Train Epoch: 246 [600/2589 (23%)]\tLoss: 283.697906\n",
      "Train Epoch: 246 [900/2589 (35%)]\tLoss: 266.721802\n",
      "Train Epoch: 246 [1200/2589 (46%)]\tLoss: 178.765930\n",
      "Train Epoch: 246 [1500/2589 (58%)]\tLoss: 342.696594\n",
      "Train Epoch: 246 [1800/2589 (70%)]\tLoss: 306.295929\n",
      "Train Epoch: 246 [2100/2589 (81%)]\tLoss: 309.595154\n",
      "Train Epoch: 246 [2400/2589 (93%)]\tLoss: 269.461609\n",
      "====> Epoch: 246 Average train loss: 280.0639\n",
      "====> Epoch: 246 Average test loss: 944.8895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 247 [0/2589 (0%)]\tLoss: 314.016785\n",
      "Train Epoch: 247 [300/2589 (12%)]\tLoss: 283.889832\n",
      "Train Epoch: 247 [600/2589 (23%)]\tLoss: 356.641754\n",
      "Train Epoch: 247 [900/2589 (35%)]\tLoss: 283.610962\n",
      "Train Epoch: 247 [1200/2589 (46%)]\tLoss: 327.927246\n",
      "Train Epoch: 247 [1500/2589 (58%)]\tLoss: 301.497467\n",
      "Train Epoch: 247 [1800/2589 (70%)]\tLoss: 225.167725\n",
      "Train Epoch: 247 [2100/2589 (81%)]\tLoss: 344.901245\n",
      "Train Epoch: 247 [2400/2589 (93%)]\tLoss: 267.353668\n",
      "====> Epoch: 247 Average train loss: 292.3107\n",
      "====> Epoch: 247 Average test loss: 966.2883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 248 [0/2589 (0%)]\tLoss: 173.856308\n",
      "Train Epoch: 248 [300/2589 (12%)]\tLoss: 270.450134\n",
      "Train Epoch: 248 [600/2589 (23%)]\tLoss: 199.073532\n",
      "Train Epoch: 248 [900/2589 (35%)]\tLoss: 428.994537\n",
      "Train Epoch: 248 [1200/2589 (46%)]\tLoss: 243.233948\n",
      "Train Epoch: 248 [1500/2589 (58%)]\tLoss: 358.570221\n",
      "Train Epoch: 248 [1800/2589 (70%)]\tLoss: 341.657562\n",
      "Train Epoch: 248 [2100/2589 (81%)]\tLoss: 376.844696\n",
      "Train Epoch: 248 [2400/2589 (93%)]\tLoss: 229.277145\n",
      "====> Epoch: 248 Average train loss: 275.6439\n",
      "====> Epoch: 248 Average test loss: 944.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 249 [0/2589 (0%)]\tLoss: 186.157166\n",
      "Train Epoch: 249 [300/2589 (12%)]\tLoss: 273.106628\n",
      "Train Epoch: 249 [600/2589 (23%)]\tLoss: 310.173431\n",
      "Train Epoch: 249 [900/2589 (35%)]\tLoss: 233.407974\n",
      "Train Epoch: 249 [1200/2589 (46%)]\tLoss: 236.987213\n",
      "Train Epoch: 249 [1500/2589 (58%)]\tLoss: 205.670929\n",
      "Train Epoch: 249 [1800/2589 (70%)]\tLoss: 279.590179\n",
      "Train Epoch: 249 [2100/2589 (81%)]\tLoss: 265.577179\n",
      "Train Epoch: 249 [2400/2589 (93%)]\tLoss: 281.272675\n",
      "====> Epoch: 249 Average train loss: 263.5925\n",
      "====> Epoch: 249 Average test loss: 961.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 250 [0/2589 (0%)]\tLoss: 238.320709\n",
      "Train Epoch: 250 [300/2589 (12%)]\tLoss: 314.670349\n",
      "Train Epoch: 250 [600/2589 (23%)]\tLoss: 373.237335\n",
      "Train Epoch: 250 [900/2589 (35%)]\tLoss: 236.819244\n",
      "Train Epoch: 250 [1200/2589 (46%)]\tLoss: 217.748276\n",
      "Train Epoch: 250 [1500/2589 (58%)]\tLoss: 240.062851\n",
      "Train Epoch: 250 [1800/2589 (70%)]\tLoss: 212.326721\n",
      "Train Epoch: 250 [2100/2589 (81%)]\tLoss: 242.912399\n",
      "Train Epoch: 250 [2400/2589 (93%)]\tLoss: 266.415222\n",
      "====> Epoch: 250 Average train loss: 274.6921\n",
      "====> Epoch: 250 Average test loss: 959.4420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 251 [0/2589 (0%)]\tLoss: 281.462402\n",
      "Train Epoch: 251 [300/2589 (12%)]\tLoss: 255.428558\n",
      "Train Epoch: 251 [600/2589 (23%)]\tLoss: 253.293289\n",
      "Train Epoch: 251 [900/2589 (35%)]\tLoss: 253.331894\n",
      "Train Epoch: 251 [1200/2589 (46%)]\tLoss: 350.979065\n",
      "Train Epoch: 251 [1500/2589 (58%)]\tLoss: 318.348846\n",
      "Train Epoch: 251 [1800/2589 (70%)]\tLoss: 327.448639\n",
      "Train Epoch: 251 [2100/2589 (81%)]\tLoss: 302.097046\n",
      "Train Epoch: 251 [2400/2589 (93%)]\tLoss: 212.993683\n",
      "====> Epoch: 251 Average train loss: 279.0173\n",
      "====> Epoch: 251 Average test loss: 946.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 252 [0/2589 (0%)]\tLoss: 239.854691\n",
      "Train Epoch: 252 [300/2589 (12%)]\tLoss: 245.657822\n",
      "Train Epoch: 252 [600/2589 (23%)]\tLoss: 281.193207\n",
      "Train Epoch: 252 [900/2589 (35%)]\tLoss: 210.645508\n",
      "Train Epoch: 252 [1200/2589 (46%)]\tLoss: 225.609360\n",
      "Train Epoch: 252 [1500/2589 (58%)]\tLoss: 305.252106\n",
      "Train Epoch: 252 [1800/2589 (70%)]\tLoss: 261.986938\n",
      "Train Epoch: 252 [2100/2589 (81%)]\tLoss: 250.108749\n",
      "Train Epoch: 252 [2400/2589 (93%)]\tLoss: 252.216797\n",
      "====> Epoch: 252 Average train loss: 276.1983\n",
      "====> Epoch: 252 Average test loss: 972.4064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 253 [0/2589 (0%)]\tLoss: 396.072418\n",
      "Train Epoch: 253 [300/2589 (12%)]\tLoss: 268.795990\n",
      "Train Epoch: 253 [600/2589 (23%)]\tLoss: 296.498810\n",
      "Train Epoch: 253 [900/2589 (35%)]\tLoss: 246.017670\n",
      "Train Epoch: 253 [1200/2589 (46%)]\tLoss: 219.523193\n",
      "Train Epoch: 253 [1500/2589 (58%)]\tLoss: 226.350479\n",
      "Train Epoch: 253 [1800/2589 (70%)]\tLoss: 303.448853\n",
      "Train Epoch: 253 [2100/2589 (81%)]\tLoss: 269.577728\n",
      "Train Epoch: 253 [2400/2589 (93%)]\tLoss: 213.028519\n",
      "====> Epoch: 253 Average train loss: 279.1970\n",
      "====> Epoch: 253 Average test loss: 947.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 254 [0/2589 (0%)]\tLoss: 199.908035\n",
      "Train Epoch: 254 [300/2589 (12%)]\tLoss: 190.295578\n",
      "Train Epoch: 254 [600/2589 (23%)]\tLoss: 272.638306\n",
      "Train Epoch: 254 [900/2589 (35%)]\tLoss: 214.834045\n",
      "Train Epoch: 254 [1200/2589 (46%)]\tLoss: 257.477203\n",
      "Train Epoch: 254 [1500/2589 (58%)]\tLoss: 344.937500\n",
      "Train Epoch: 254 [1800/2589 (70%)]\tLoss: 218.668167\n",
      "Train Epoch: 254 [2100/2589 (81%)]\tLoss: 305.913788\n",
      "Train Epoch: 254 [2400/2589 (93%)]\tLoss: 359.127228\n",
      "====> Epoch: 254 Average train loss: 276.8047\n",
      "====> Epoch: 254 Average test loss: 959.2897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 255 [0/2589 (0%)]\tLoss: 255.049637\n",
      "Train Epoch: 255 [300/2589 (12%)]\tLoss: 249.855774\n",
      "Train Epoch: 255 [600/2589 (23%)]\tLoss: 240.394211\n",
      "Train Epoch: 255 [900/2589 (35%)]\tLoss: 250.684708\n",
      "Train Epoch: 255 [1200/2589 (46%)]\tLoss: 274.520905\n",
      "Train Epoch: 255 [1500/2589 (58%)]\tLoss: 210.618484\n",
      "Train Epoch: 255 [1800/2589 (70%)]\tLoss: 256.417786\n",
      "Train Epoch: 255 [2100/2589 (81%)]\tLoss: 225.361084\n",
      "Train Epoch: 255 [2400/2589 (93%)]\tLoss: 344.901550\n",
      "====> Epoch: 255 Average train loss: 284.1618\n",
      "====> Epoch: 255 Average test loss: 945.7911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 256 [0/2589 (0%)]\tLoss: 305.814972\n",
      "Train Epoch: 256 [300/2589 (12%)]\tLoss: 303.992065\n",
      "Train Epoch: 256 [600/2589 (23%)]\tLoss: 392.121887\n",
      "Train Epoch: 256 [900/2589 (35%)]\tLoss: 279.020477\n",
      "Train Epoch: 256 [1200/2589 (46%)]\tLoss: 367.906189\n",
      "Train Epoch: 256 [1500/2589 (58%)]\tLoss: 225.788315\n",
      "Train Epoch: 256 [1800/2589 (70%)]\tLoss: 282.729156\n",
      "Train Epoch: 256 [2100/2589 (81%)]\tLoss: 233.947021\n",
      "Train Epoch: 256 [2400/2589 (93%)]\tLoss: 290.790863\n",
      "====> Epoch: 256 Average train loss: 276.9905\n",
      "====> Epoch: 256 Average test loss: 934.4705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 257 [0/2589 (0%)]\tLoss: 193.351593\n",
      "Train Epoch: 257 [300/2589 (12%)]\tLoss: 285.542450\n",
      "Train Epoch: 257 [600/2589 (23%)]\tLoss: 290.338745\n",
      "Train Epoch: 257 [900/2589 (35%)]\tLoss: 390.250336\n",
      "Train Epoch: 257 [1200/2589 (46%)]\tLoss: 173.181458\n",
      "Train Epoch: 257 [1500/2589 (58%)]\tLoss: 265.527924\n",
      "Train Epoch: 257 [1800/2589 (70%)]\tLoss: 322.074432\n",
      "Train Epoch: 257 [2100/2589 (81%)]\tLoss: 210.987991\n",
      "Train Epoch: 257 [2400/2589 (93%)]\tLoss: 217.086655\n",
      "====> Epoch: 257 Average train loss: 276.1016\n",
      "====> Epoch: 257 Average test loss: 953.3167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 258 [0/2589 (0%)]\tLoss: 221.113998\n",
      "Train Epoch: 258 [300/2589 (12%)]\tLoss: 196.654404\n",
      "Train Epoch: 258 [600/2589 (23%)]\tLoss: 293.048035\n",
      "Train Epoch: 258 [900/2589 (35%)]\tLoss: 422.587799\n",
      "Train Epoch: 258 [1200/2589 (46%)]\tLoss: 214.712265\n",
      "Train Epoch: 258 [1500/2589 (58%)]\tLoss: 179.079391\n",
      "Train Epoch: 258 [1800/2589 (70%)]\tLoss: 282.849396\n",
      "Train Epoch: 258 [2100/2589 (81%)]\tLoss: 148.004593\n",
      "Train Epoch: 258 [2400/2589 (93%)]\tLoss: 270.050446\n",
      "====> Epoch: 258 Average train loss: 273.0126\n",
      "====> Epoch: 258 Average test loss: 936.5139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 259 [0/2589 (0%)]\tLoss: 194.514359\n",
      "Train Epoch: 259 [300/2589 (12%)]\tLoss: 279.791199\n",
      "Train Epoch: 259 [600/2589 (23%)]\tLoss: 453.923492\n",
      "Train Epoch: 259 [900/2589 (35%)]\tLoss: 207.104401\n",
      "Train Epoch: 259 [1200/2589 (46%)]\tLoss: 273.661102\n",
      "Train Epoch: 259 [1500/2589 (58%)]\tLoss: 273.543091\n",
      "Train Epoch: 259 [1800/2589 (70%)]\tLoss: 263.601440\n",
      "Train Epoch: 259 [2100/2589 (81%)]\tLoss: 224.055496\n",
      "Train Epoch: 259 [2400/2589 (93%)]\tLoss: 266.703583\n",
      "====> Epoch: 259 Average train loss: 275.8659\n",
      "====> Epoch: 259 Average test loss: 939.3304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 260 [0/2589 (0%)]\tLoss: 267.906830\n",
      "Train Epoch: 260 [300/2589 (12%)]\tLoss: 248.184128\n",
      "Train Epoch: 260 [600/2589 (23%)]\tLoss: 229.149994\n",
      "Train Epoch: 260 [900/2589 (35%)]\tLoss: 342.944946\n",
      "Train Epoch: 260 [1200/2589 (46%)]\tLoss: 164.709000\n",
      "Train Epoch: 260 [1500/2589 (58%)]\tLoss: 341.889984\n",
      "Train Epoch: 260 [1800/2589 (70%)]\tLoss: 345.715912\n",
      "Train Epoch: 260 [2100/2589 (81%)]\tLoss: 220.480896\n",
      "Train Epoch: 260 [2400/2589 (93%)]\tLoss: 193.073990\n",
      "====> Epoch: 260 Average train loss: 278.6407\n",
      "====> Epoch: 260 Average test loss: 949.0807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 261 [0/2589 (0%)]\tLoss: 196.590042\n",
      "Train Epoch: 261 [300/2589 (12%)]\tLoss: 253.776306\n",
      "Train Epoch: 261 [600/2589 (23%)]\tLoss: 246.759064\n",
      "Train Epoch: 261 [900/2589 (35%)]\tLoss: 281.522278\n",
      "Train Epoch: 261 [1200/2589 (46%)]\tLoss: 281.251007\n",
      "Train Epoch: 261 [1500/2589 (58%)]\tLoss: 294.228973\n",
      "Train Epoch: 261 [1800/2589 (70%)]\tLoss: 225.154816\n",
      "Train Epoch: 261 [2100/2589 (81%)]\tLoss: 260.086121\n",
      "Train Epoch: 261 [2400/2589 (93%)]\tLoss: 310.340332\n",
      "====> Epoch: 261 Average train loss: 279.0631\n",
      "====> Epoch: 261 Average test loss: 940.3941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 262 [0/2589 (0%)]\tLoss: 265.212677\n",
      "Train Epoch: 262 [300/2589 (12%)]\tLoss: 329.279846\n",
      "Train Epoch: 262 [600/2589 (23%)]\tLoss: 311.620819\n",
      "Train Epoch: 262 [900/2589 (35%)]\tLoss: 259.169769\n",
      "Train Epoch: 262 [1200/2589 (46%)]\tLoss: 235.704788\n",
      "Train Epoch: 262 [1500/2589 (58%)]\tLoss: 220.691986\n",
      "Train Epoch: 262 [1800/2589 (70%)]\tLoss: 226.128937\n",
      "Train Epoch: 262 [2100/2589 (81%)]\tLoss: 217.888901\n",
      "Train Epoch: 262 [2400/2589 (93%)]\tLoss: 219.922363\n",
      "====> Epoch: 262 Average train loss: 271.8615\n",
      "====> Epoch: 262 Average test loss: 943.3442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 263 [0/2589 (0%)]\tLoss: 213.918457\n",
      "Train Epoch: 263 [300/2589 (12%)]\tLoss: 252.304428\n",
      "Train Epoch: 263 [600/2589 (23%)]\tLoss: 439.140961\n",
      "Train Epoch: 263 [900/2589 (35%)]\tLoss: 248.521774\n",
      "Train Epoch: 263 [1200/2589 (46%)]\tLoss: 275.103790\n",
      "Train Epoch: 263 [1500/2589 (58%)]\tLoss: 253.342941\n",
      "Train Epoch: 263 [1800/2589 (70%)]\tLoss: 232.912567\n",
      "Train Epoch: 263 [2100/2589 (81%)]\tLoss: 294.615204\n",
      "Train Epoch: 263 [2400/2589 (93%)]\tLoss: 333.456146\n",
      "====> Epoch: 263 Average train loss: 277.0902\n",
      "====> Epoch: 263 Average test loss: 945.3698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 264 [0/2589 (0%)]\tLoss: 253.892380\n",
      "Train Epoch: 264 [300/2589 (12%)]\tLoss: 249.084396\n",
      "Train Epoch: 264 [600/2589 (23%)]\tLoss: 248.325043\n",
      "Train Epoch: 264 [900/2589 (35%)]\tLoss: 254.963089\n",
      "Train Epoch: 264 [1200/2589 (46%)]\tLoss: 281.197662\n",
      "Train Epoch: 264 [1500/2589 (58%)]\tLoss: 237.945312\n",
      "Train Epoch: 264 [1800/2589 (70%)]\tLoss: 296.176880\n",
      "Train Epoch: 264 [2100/2589 (81%)]\tLoss: 211.528839\n",
      "Train Epoch: 264 [2400/2589 (93%)]\tLoss: 427.557281\n",
      "====> Epoch: 264 Average train loss: 277.3555\n",
      "====> Epoch: 264 Average test loss: 938.7479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 265 [0/2589 (0%)]\tLoss: 230.727066\n",
      "Train Epoch: 265 [300/2589 (12%)]\tLoss: 262.493713\n",
      "Train Epoch: 265 [600/2589 (23%)]\tLoss: 265.690826\n",
      "Train Epoch: 265 [900/2589 (35%)]\tLoss: 405.642853\n",
      "Train Epoch: 265 [1200/2589 (46%)]\tLoss: 267.761932\n",
      "Train Epoch: 265 [1500/2589 (58%)]\tLoss: 227.250702\n",
      "Train Epoch: 265 [1800/2589 (70%)]\tLoss: 259.898376\n",
      "Train Epoch: 265 [2100/2589 (81%)]\tLoss: 271.767792\n",
      "Train Epoch: 265 [2400/2589 (93%)]\tLoss: 288.187042\n",
      "====> Epoch: 265 Average train loss: 272.3608\n",
      "====> Epoch: 265 Average test loss: 944.4515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 266 [0/2589 (0%)]\tLoss: 392.891876\n",
      "Train Epoch: 266 [300/2589 (12%)]\tLoss: 250.925690\n",
      "Train Epoch: 266 [600/2589 (23%)]\tLoss: 289.921844\n",
      "Train Epoch: 266 [900/2589 (35%)]\tLoss: 290.474030\n",
      "Train Epoch: 266 [1200/2589 (46%)]\tLoss: 254.162216\n",
      "Train Epoch: 266 [1500/2589 (58%)]\tLoss: 168.060196\n",
      "Train Epoch: 266 [1800/2589 (70%)]\tLoss: 309.611603\n",
      "Train Epoch: 266 [2100/2589 (81%)]\tLoss: 287.745880\n",
      "Train Epoch: 266 [2400/2589 (93%)]\tLoss: 341.609497\n",
      "====> Epoch: 266 Average train loss: 275.1378\n",
      "====> Epoch: 266 Average test loss: 937.4523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 267 [0/2589 (0%)]\tLoss: 271.814087\n",
      "Train Epoch: 267 [300/2589 (12%)]\tLoss: 194.071960\n",
      "Train Epoch: 267 [600/2589 (23%)]\tLoss: 310.397339\n",
      "Train Epoch: 267 [900/2589 (35%)]\tLoss: 248.762970\n",
      "Train Epoch: 267 [1200/2589 (46%)]\tLoss: 254.755630\n",
      "Train Epoch: 267 [1500/2589 (58%)]\tLoss: 257.294006\n",
      "Train Epoch: 267 [1800/2589 (70%)]\tLoss: 296.206329\n",
      "Train Epoch: 267 [2100/2589 (81%)]\tLoss: 200.776215\n",
      "Train Epoch: 267 [2400/2589 (93%)]\tLoss: 253.087723\n",
      "====> Epoch: 267 Average train loss: 268.9020\n",
      "====> Epoch: 267 Average test loss: 951.6843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 268 [0/2589 (0%)]\tLoss: 263.174225\n",
      "Train Epoch: 268 [300/2589 (12%)]\tLoss: 373.252747\n",
      "Train Epoch: 268 [600/2589 (23%)]\tLoss: 292.067444\n",
      "Train Epoch: 268 [900/2589 (35%)]\tLoss: 330.426544\n",
      "Train Epoch: 268 [1200/2589 (46%)]\tLoss: 198.814209\n",
      "Train Epoch: 268 [1500/2589 (58%)]\tLoss: 374.425903\n",
      "Train Epoch: 268 [1800/2589 (70%)]\tLoss: 316.880280\n",
      "Train Epoch: 268 [2100/2589 (81%)]\tLoss: 229.163925\n",
      "Train Epoch: 268 [2400/2589 (93%)]\tLoss: 241.266068\n",
      "====> Epoch: 268 Average train loss: 281.6068\n",
      "====> Epoch: 268 Average test loss: 978.8264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 269 [0/2589 (0%)]\tLoss: 199.653168\n",
      "Train Epoch: 269 [300/2589 (12%)]\tLoss: 294.541351\n",
      "Train Epoch: 269 [600/2589 (23%)]\tLoss: 228.881790\n",
      "Train Epoch: 269 [900/2589 (35%)]\tLoss: 236.845474\n",
      "Train Epoch: 269 [1200/2589 (46%)]\tLoss: 284.355591\n",
      "Train Epoch: 269 [1500/2589 (58%)]\tLoss: 328.513733\n",
      "Train Epoch: 269 [1800/2589 (70%)]\tLoss: 272.084564\n",
      "Train Epoch: 269 [2100/2589 (81%)]\tLoss: 216.940369\n",
      "Train Epoch: 269 [2400/2589 (93%)]\tLoss: 238.608536\n",
      "====> Epoch: 269 Average train loss: 266.7095\n",
      "====> Epoch: 269 Average test loss: 954.1975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 270 [0/2589 (0%)]\tLoss: 232.265656\n",
      "Train Epoch: 270 [300/2589 (12%)]\tLoss: 263.035522\n",
      "Train Epoch: 270 [600/2589 (23%)]\tLoss: 287.779755\n",
      "Train Epoch: 270 [900/2589 (35%)]\tLoss: 248.352097\n",
      "Train Epoch: 270 [1200/2589 (46%)]\tLoss: 284.951569\n",
      "Train Epoch: 270 [1500/2589 (58%)]\tLoss: 366.225952\n",
      "Train Epoch: 270 [1800/2589 (70%)]\tLoss: 273.943207\n",
      "Train Epoch: 270 [2100/2589 (81%)]\tLoss: 251.546112\n",
      "Train Epoch: 270 [2400/2589 (93%)]\tLoss: 214.809982\n",
      "====> Epoch: 270 Average train loss: 266.8466\n",
      "====> Epoch: 270 Average test loss: 958.6299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 271 [0/2589 (0%)]\tLoss: 223.991455\n",
      "Train Epoch: 271 [300/2589 (12%)]\tLoss: 326.955444\n",
      "Train Epoch: 271 [600/2589 (23%)]\tLoss: 390.963501\n",
      "Train Epoch: 271 [900/2589 (35%)]\tLoss: 236.811462\n",
      "Train Epoch: 271 [1200/2589 (46%)]\tLoss: 204.048965\n",
      "Train Epoch: 271 [1500/2589 (58%)]\tLoss: 406.402374\n",
      "Train Epoch: 271 [1800/2589 (70%)]\tLoss: 297.333435\n",
      "Train Epoch: 271 [2100/2589 (81%)]\tLoss: 454.340912\n",
      "Train Epoch: 271 [2400/2589 (93%)]\tLoss: 306.724548\n",
      "====> Epoch: 271 Average train loss: 266.7924\n",
      "====> Epoch: 271 Average test loss: 990.0432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 272 [0/2589 (0%)]\tLoss: 344.608673\n",
      "Train Epoch: 272 [300/2589 (12%)]\tLoss: 193.109238\n",
      "Train Epoch: 272 [600/2589 (23%)]\tLoss: 276.674194\n",
      "Train Epoch: 272 [900/2589 (35%)]\tLoss: 238.649216\n",
      "Train Epoch: 272 [1200/2589 (46%)]\tLoss: 309.089020\n",
      "Train Epoch: 272 [1500/2589 (58%)]\tLoss: 273.653473\n",
      "Train Epoch: 272 [1800/2589 (70%)]\tLoss: 360.818665\n",
      "Train Epoch: 272 [2100/2589 (81%)]\tLoss: 262.507843\n",
      "Train Epoch: 272 [2400/2589 (93%)]\tLoss: 240.582733\n",
      "====> Epoch: 272 Average train loss: 273.5929\n",
      "====> Epoch: 272 Average test loss: 937.4767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 273 [0/2589 (0%)]\tLoss: 207.519119\n",
      "Train Epoch: 273 [300/2589 (12%)]\tLoss: 307.880341\n",
      "Train Epoch: 273 [600/2589 (23%)]\tLoss: 285.456543\n",
      "Train Epoch: 273 [900/2589 (35%)]\tLoss: 388.116180\n",
      "Train Epoch: 273 [1200/2589 (46%)]\tLoss: 357.454926\n",
      "Train Epoch: 273 [1500/2589 (58%)]\tLoss: 208.345932\n",
      "Train Epoch: 273 [1800/2589 (70%)]\tLoss: 191.424423\n",
      "Train Epoch: 273 [2100/2589 (81%)]\tLoss: 336.652069\n",
      "Train Epoch: 273 [2400/2589 (93%)]\tLoss: 257.519318\n",
      "====> Epoch: 273 Average train loss: 276.3306\n",
      "====> Epoch: 273 Average test loss: 955.8962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 274 [0/2589 (0%)]\tLoss: 383.386353\n",
      "Train Epoch: 274 [300/2589 (12%)]\tLoss: 293.554321\n",
      "Train Epoch: 274 [600/2589 (23%)]\tLoss: 253.648575\n",
      "Train Epoch: 274 [900/2589 (35%)]\tLoss: 182.344513\n",
      "Train Epoch: 274 [1200/2589 (46%)]\tLoss: 301.977142\n",
      "Train Epoch: 274 [1500/2589 (58%)]\tLoss: 333.615997\n",
      "Train Epoch: 274 [1800/2589 (70%)]\tLoss: 264.892303\n",
      "Train Epoch: 274 [2100/2589 (81%)]\tLoss: 204.179092\n",
      "Train Epoch: 274 [2400/2589 (93%)]\tLoss: 409.985626\n",
      "====> Epoch: 274 Average train loss: 275.3371\n",
      "====> Epoch: 274 Average test loss: 969.7827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 275 [0/2589 (0%)]\tLoss: 232.349457\n",
      "Train Epoch: 275 [300/2589 (12%)]\tLoss: 243.711319\n",
      "Train Epoch: 275 [600/2589 (23%)]\tLoss: 188.855927\n",
      "Train Epoch: 275 [900/2589 (35%)]\tLoss: 275.856262\n",
      "Train Epoch: 275 [1200/2589 (46%)]\tLoss: 337.476776\n",
      "Train Epoch: 275 [1500/2589 (58%)]\tLoss: 333.635742\n",
      "Train Epoch: 275 [1800/2589 (70%)]\tLoss: 346.042267\n",
      "Train Epoch: 275 [2100/2589 (81%)]\tLoss: 217.934967\n",
      "Train Epoch: 275 [2400/2589 (93%)]\tLoss: 292.948364\n",
      "====> Epoch: 275 Average train loss: 274.4039\n",
      "====> Epoch: 275 Average test loss: 932.4879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 276 [0/2589 (0%)]\tLoss: 230.071365\n",
      "Train Epoch: 276 [300/2589 (12%)]\tLoss: 273.552582\n",
      "Train Epoch: 276 [600/2589 (23%)]\tLoss: 415.897736\n",
      "Train Epoch: 276 [900/2589 (35%)]\tLoss: 300.402283\n",
      "Train Epoch: 276 [1200/2589 (46%)]\tLoss: 324.390564\n",
      "Train Epoch: 276 [1500/2589 (58%)]\tLoss: 404.751953\n",
      "Train Epoch: 276 [1800/2589 (70%)]\tLoss: 382.732422\n",
      "Train Epoch: 276 [2100/2589 (81%)]\tLoss: 283.831757\n",
      "Train Epoch: 276 [2400/2589 (93%)]\tLoss: 218.667969\n",
      "====> Epoch: 276 Average train loss: 274.8249\n",
      "====> Epoch: 276 Average test loss: 951.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 277 [0/2589 (0%)]\tLoss: 308.197723\n",
      "Train Epoch: 277 [300/2589 (12%)]\tLoss: 293.219208\n",
      "Train Epoch: 277 [600/2589 (23%)]\tLoss: 386.042938\n",
      "Train Epoch: 277 [900/2589 (35%)]\tLoss: 242.179703\n",
      "Train Epoch: 277 [1200/2589 (46%)]\tLoss: 247.730331\n",
      "Train Epoch: 277 [1500/2589 (58%)]\tLoss: 239.912048\n",
      "Train Epoch: 277 [1800/2589 (70%)]\tLoss: 251.247314\n",
      "Train Epoch: 277 [2100/2589 (81%)]\tLoss: 249.890198\n",
      "Train Epoch: 277 [2400/2589 (93%)]\tLoss: 228.798187\n",
      "====> Epoch: 277 Average train loss: 260.3414\n",
      "====> Epoch: 277 Average test loss: 969.0207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 278 [0/2589 (0%)]\tLoss: 317.735779\n",
      "Train Epoch: 278 [300/2589 (12%)]\tLoss: 241.480133\n",
      "Train Epoch: 278 [600/2589 (23%)]\tLoss: 182.408920\n",
      "Train Epoch: 278 [900/2589 (35%)]\tLoss: 301.003052\n",
      "Train Epoch: 278 [1200/2589 (46%)]\tLoss: 225.673767\n",
      "Train Epoch: 278 [1500/2589 (58%)]\tLoss: 284.613647\n",
      "Train Epoch: 278 [1800/2589 (70%)]\tLoss: 219.798340\n",
      "Train Epoch: 278 [2100/2589 (81%)]\tLoss: 267.502228\n",
      "Train Epoch: 278 [2400/2589 (93%)]\tLoss: 285.606232\n",
      "====> Epoch: 278 Average train loss: 267.7797\n",
      "====> Epoch: 278 Average test loss: 957.6791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 279 [0/2589 (0%)]\tLoss: 388.783112\n",
      "Train Epoch: 279 [300/2589 (12%)]\tLoss: 297.135223\n",
      "Train Epoch: 279 [600/2589 (23%)]\tLoss: 269.723236\n",
      "Train Epoch: 279 [900/2589 (35%)]\tLoss: 272.151489\n",
      "Train Epoch: 279 [1200/2589 (46%)]\tLoss: 250.724854\n",
      "Train Epoch: 279 [1500/2589 (58%)]\tLoss: 308.124939\n",
      "Train Epoch: 279 [1800/2589 (70%)]\tLoss: 291.094330\n",
      "Train Epoch: 279 [2100/2589 (81%)]\tLoss: 259.635529\n",
      "Train Epoch: 279 [2400/2589 (93%)]\tLoss: 230.680557\n",
      "====> Epoch: 279 Average train loss: 266.3253\n",
      "====> Epoch: 279 Average test loss: 921.5095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 280 [0/2589 (0%)]\tLoss: 226.886993\n",
      "Train Epoch: 280 [300/2589 (12%)]\tLoss: 233.493103\n",
      "Train Epoch: 280 [600/2589 (23%)]\tLoss: 214.172394\n",
      "Train Epoch: 280 [900/2589 (35%)]\tLoss: 210.156555\n",
      "Train Epoch: 280 [1200/2589 (46%)]\tLoss: 266.521057\n",
      "Train Epoch: 280 [1500/2589 (58%)]\tLoss: 361.916718\n",
      "Train Epoch: 280 [1800/2589 (70%)]\tLoss: 235.173019\n",
      "Train Epoch: 280 [2100/2589 (81%)]\tLoss: 263.011169\n",
      "Train Epoch: 280 [2400/2589 (93%)]\tLoss: 427.570801\n",
      "====> Epoch: 280 Average train loss: 270.0631\n",
      "====> Epoch: 280 Average test loss: 947.5970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 281 [0/2589 (0%)]\tLoss: 312.869751\n",
      "Train Epoch: 281 [300/2589 (12%)]\tLoss: 292.169464\n",
      "Train Epoch: 281 [600/2589 (23%)]\tLoss: 277.035431\n",
      "Train Epoch: 281 [900/2589 (35%)]\tLoss: 190.032486\n",
      "Train Epoch: 281 [1200/2589 (46%)]\tLoss: 348.942444\n",
      "Train Epoch: 281 [1500/2589 (58%)]\tLoss: 268.300812\n",
      "Train Epoch: 281 [1800/2589 (70%)]\tLoss: 224.423904\n",
      "Train Epoch: 281 [2100/2589 (81%)]\tLoss: 272.228577\n",
      "Train Epoch: 281 [2400/2589 (93%)]\tLoss: 275.911041\n",
      "====> Epoch: 281 Average train loss: 259.9094\n",
      "====> Epoch: 281 Average test loss: 952.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 282 [0/2589 (0%)]\tLoss: 227.653748\n",
      "Train Epoch: 282 [300/2589 (12%)]\tLoss: 174.429993\n",
      "Train Epoch: 282 [600/2589 (23%)]\tLoss: 309.443054\n",
      "Train Epoch: 282 [900/2589 (35%)]\tLoss: 230.360886\n",
      "Train Epoch: 282 [1200/2589 (46%)]\tLoss: 285.493317\n",
      "Train Epoch: 282 [1500/2589 (58%)]\tLoss: 362.813751\n",
      "Train Epoch: 282 [1800/2589 (70%)]\tLoss: 313.660156\n",
      "Train Epoch: 282 [2100/2589 (81%)]\tLoss: 189.960266\n",
      "Train Epoch: 282 [2400/2589 (93%)]\tLoss: 336.736969\n",
      "====> Epoch: 282 Average train loss: 270.5743\n",
      "====> Epoch: 282 Average test loss: 993.0489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 283 [0/2589 (0%)]\tLoss: 278.029572\n",
      "Train Epoch: 283 [300/2589 (12%)]\tLoss: 288.821564\n",
      "Train Epoch: 283 [600/2589 (23%)]\tLoss: 187.928452\n",
      "Train Epoch: 283 [900/2589 (35%)]\tLoss: 286.776215\n",
      "Train Epoch: 283 [1200/2589 (46%)]\tLoss: 369.210449\n",
      "Train Epoch: 283 [1500/2589 (58%)]\tLoss: 232.098389\n",
      "Train Epoch: 283 [1800/2589 (70%)]\tLoss: 281.265503\n",
      "Train Epoch: 283 [2100/2589 (81%)]\tLoss: 434.214966\n",
      "Train Epoch: 283 [2400/2589 (93%)]\tLoss: 308.559601\n",
      "====> Epoch: 283 Average train loss: 271.7831\n",
      "====> Epoch: 283 Average test loss: 943.5726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 284 [0/2589 (0%)]\tLoss: 175.616348\n",
      "Train Epoch: 284 [300/2589 (12%)]\tLoss: 225.746475\n",
      "Train Epoch: 284 [600/2589 (23%)]\tLoss: 384.497223\n",
      "Train Epoch: 284 [900/2589 (35%)]\tLoss: 210.274963\n",
      "Train Epoch: 284 [1200/2589 (46%)]\tLoss: 211.888840\n",
      "Train Epoch: 284 [1500/2589 (58%)]\tLoss: 201.098633\n",
      "Train Epoch: 284 [1800/2589 (70%)]\tLoss: 316.686249\n",
      "Train Epoch: 284 [2100/2589 (81%)]\tLoss: 187.104385\n",
      "Train Epoch: 284 [2400/2589 (93%)]\tLoss: 231.340988\n",
      "====> Epoch: 284 Average train loss: 264.6139\n",
      "====> Epoch: 284 Average test loss: 953.7394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 285 [0/2589 (0%)]\tLoss: 268.435913\n",
      "Train Epoch: 285 [300/2589 (12%)]\tLoss: 301.913544\n",
      "Train Epoch: 285 [600/2589 (23%)]\tLoss: 222.065414\n",
      "Train Epoch: 285 [900/2589 (35%)]\tLoss: 367.511383\n",
      "Train Epoch: 285 [1200/2589 (46%)]\tLoss: 283.076782\n",
      "Train Epoch: 285 [1500/2589 (58%)]\tLoss: 210.900360\n",
      "Train Epoch: 285 [1800/2589 (70%)]\tLoss: 236.502716\n",
      "Train Epoch: 285 [2100/2589 (81%)]\tLoss: 235.459564\n",
      "Train Epoch: 285 [2400/2589 (93%)]\tLoss: 299.403625\n",
      "====> Epoch: 285 Average train loss: 277.4544\n",
      "====> Epoch: 285 Average test loss: 928.6539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 286 [0/2589 (0%)]\tLoss: 260.143982\n",
      "Train Epoch: 286 [300/2589 (12%)]\tLoss: 218.712341\n",
      "Train Epoch: 286 [600/2589 (23%)]\tLoss: 265.277252\n",
      "Train Epoch: 286 [900/2589 (35%)]\tLoss: 217.329132\n",
      "Train Epoch: 286 [1200/2589 (46%)]\tLoss: 244.210693\n",
      "Train Epoch: 286 [1500/2589 (58%)]\tLoss: 225.082840\n",
      "Train Epoch: 286 [1800/2589 (70%)]\tLoss: 350.084259\n",
      "Train Epoch: 286 [2100/2589 (81%)]\tLoss: 241.578049\n",
      "Train Epoch: 286 [2400/2589 (93%)]\tLoss: 433.837799\n",
      "====> Epoch: 286 Average train loss: 270.0543\n",
      "====> Epoch: 286 Average test loss: 931.7021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 287 [0/2589 (0%)]\tLoss: 251.712662\n",
      "Train Epoch: 287 [300/2589 (12%)]\tLoss: 235.356018\n",
      "Train Epoch: 287 [600/2589 (23%)]\tLoss: 247.597610\n",
      "Train Epoch: 287 [900/2589 (35%)]\tLoss: 179.994598\n",
      "Train Epoch: 287 [1200/2589 (46%)]\tLoss: 176.812195\n",
      "Train Epoch: 287 [1500/2589 (58%)]\tLoss: 275.361145\n",
      "Train Epoch: 287 [1800/2589 (70%)]\tLoss: 198.713074\n",
      "Train Epoch: 287 [2100/2589 (81%)]\tLoss: 277.794739\n",
      "Train Epoch: 287 [2400/2589 (93%)]\tLoss: 339.207520\n",
      "====> Epoch: 287 Average train loss: 263.2057\n",
      "====> Epoch: 287 Average test loss: 946.0688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 288 [0/2589 (0%)]\tLoss: 441.250549\n",
      "Train Epoch: 288 [300/2589 (12%)]\tLoss: 318.855164\n",
      "Train Epoch: 288 [600/2589 (23%)]\tLoss: 234.560120\n",
      "Train Epoch: 288 [900/2589 (35%)]\tLoss: 288.727112\n",
      "Train Epoch: 288 [1200/2589 (46%)]\tLoss: 249.545700\n",
      "Train Epoch: 288 [1500/2589 (58%)]\tLoss: 366.298920\n",
      "Train Epoch: 288 [1800/2589 (70%)]\tLoss: 237.724579\n",
      "Train Epoch: 288 [2100/2589 (81%)]\tLoss: 304.012390\n",
      "Train Epoch: 288 [2400/2589 (93%)]\tLoss: 276.296692\n",
      "====> Epoch: 288 Average train loss: 269.5708\n",
      "====> Epoch: 288 Average test loss: 965.2894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 289 [0/2589 (0%)]\tLoss: 232.491669\n",
      "Train Epoch: 289 [300/2589 (12%)]\tLoss: 252.325302\n",
      "Train Epoch: 289 [600/2589 (23%)]\tLoss: 157.922913\n",
      "Train Epoch: 289 [900/2589 (35%)]\tLoss: 242.935257\n",
      "Train Epoch: 289 [1200/2589 (46%)]\tLoss: 187.334869\n",
      "Train Epoch: 289 [1500/2589 (58%)]\tLoss: 252.668610\n",
      "Train Epoch: 289 [1800/2589 (70%)]\tLoss: 223.685516\n",
      "Train Epoch: 289 [2100/2589 (81%)]\tLoss: 373.044647\n",
      "Train Epoch: 289 [2400/2589 (93%)]\tLoss: 291.825989\n",
      "====> Epoch: 289 Average train loss: 262.7905\n",
      "====> Epoch: 289 Average test loss: 948.3494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 290 [0/2589 (0%)]\tLoss: 294.165039\n",
      "Train Epoch: 290 [300/2589 (12%)]\tLoss: 234.105255\n",
      "Train Epoch: 290 [600/2589 (23%)]\tLoss: 250.731918\n",
      "Train Epoch: 290 [900/2589 (35%)]\tLoss: 229.852371\n",
      "Train Epoch: 290 [1200/2589 (46%)]\tLoss: 484.742615\n",
      "Train Epoch: 290 [1500/2589 (58%)]\tLoss: 232.190567\n",
      "Train Epoch: 290 [1800/2589 (70%)]\tLoss: 216.098892\n",
      "Train Epoch: 290 [2100/2589 (81%)]\tLoss: 291.156738\n",
      "Train Epoch: 290 [2400/2589 (93%)]\tLoss: 312.106873\n",
      "====> Epoch: 290 Average train loss: 265.4538\n",
      "====> Epoch: 290 Average test loss: 936.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 291 [0/2589 (0%)]\tLoss: 276.662079\n",
      "Train Epoch: 291 [300/2589 (12%)]\tLoss: 464.832947\n",
      "Train Epoch: 291 [600/2589 (23%)]\tLoss: 283.939392\n",
      "Train Epoch: 291 [900/2589 (35%)]\tLoss: 304.090698\n",
      "Train Epoch: 291 [1200/2589 (46%)]\tLoss: 318.949677\n",
      "Train Epoch: 291 [1500/2589 (58%)]\tLoss: 228.107025\n",
      "Train Epoch: 291 [1800/2589 (70%)]\tLoss: 240.134445\n",
      "Train Epoch: 291 [2100/2589 (81%)]\tLoss: 322.487122\n",
      "Train Epoch: 291 [2400/2589 (93%)]\tLoss: 278.802704\n",
      "====> Epoch: 291 Average train loss: 273.2462\n",
      "====> Epoch: 291 Average test loss: 956.8455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 292 [0/2589 (0%)]\tLoss: 238.805923\n",
      "Train Epoch: 292 [300/2589 (12%)]\tLoss: 263.349304\n",
      "Train Epoch: 292 [600/2589 (23%)]\tLoss: 252.448883\n",
      "Train Epoch: 292 [900/2589 (35%)]\tLoss: 191.507370\n",
      "Train Epoch: 292 [1200/2589 (46%)]\tLoss: 405.488159\n",
      "Train Epoch: 292 [1500/2589 (58%)]\tLoss: 243.716461\n",
      "Train Epoch: 292 [1800/2589 (70%)]\tLoss: 267.137726\n",
      "Train Epoch: 292 [2100/2589 (81%)]\tLoss: 208.406158\n",
      "Train Epoch: 292 [2400/2589 (93%)]\tLoss: 255.443817\n",
      "====> Epoch: 292 Average train loss: 261.7479\n",
      "====> Epoch: 292 Average test loss: 935.1797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 293 [0/2589 (0%)]\tLoss: 175.280090\n",
      "Train Epoch: 293 [300/2589 (12%)]\tLoss: 312.418274\n",
      "Train Epoch: 293 [600/2589 (23%)]\tLoss: 252.632645\n",
      "Train Epoch: 293 [900/2589 (35%)]\tLoss: 224.448105\n",
      "Train Epoch: 293 [1200/2589 (46%)]\tLoss: 272.844269\n",
      "Train Epoch: 293 [1500/2589 (58%)]\tLoss: 143.715027\n",
      "Train Epoch: 293 [1800/2589 (70%)]\tLoss: 212.146347\n",
      "Train Epoch: 293 [2100/2589 (81%)]\tLoss: 210.382782\n",
      "Train Epoch: 293 [2400/2589 (93%)]\tLoss: 286.486389\n",
      "====> Epoch: 293 Average train loss: 268.3186\n",
      "====> Epoch: 293 Average test loss: 945.0760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 294 [0/2589 (0%)]\tLoss: 202.488007\n",
      "Train Epoch: 294 [300/2589 (12%)]\tLoss: 297.489197\n",
      "Train Epoch: 294 [600/2589 (23%)]\tLoss: 215.661423\n",
      "Train Epoch: 294 [900/2589 (35%)]\tLoss: 247.322769\n",
      "Train Epoch: 294 [1200/2589 (46%)]\tLoss: 182.565933\n",
      "Train Epoch: 294 [1500/2589 (58%)]\tLoss: 244.889343\n",
      "Train Epoch: 294 [1800/2589 (70%)]\tLoss: 225.302490\n",
      "Train Epoch: 294 [2100/2589 (81%)]\tLoss: 278.745422\n",
      "Train Epoch: 294 [2400/2589 (93%)]\tLoss: 502.258331\n",
      "====> Epoch: 294 Average train loss: 277.9409\n",
      "====> Epoch: 294 Average test loss: 967.3154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 295 [0/2589 (0%)]\tLoss: 300.055115\n",
      "Train Epoch: 295 [300/2589 (12%)]\tLoss: 178.621735\n",
      "Train Epoch: 295 [600/2589 (23%)]\tLoss: 238.390335\n",
      "Train Epoch: 295 [900/2589 (35%)]\tLoss: 394.548859\n",
      "Train Epoch: 295 [1200/2589 (46%)]\tLoss: 270.325806\n",
      "Train Epoch: 295 [1500/2589 (58%)]\tLoss: 316.548767\n",
      "Train Epoch: 295 [1800/2589 (70%)]\tLoss: 442.004547\n",
      "Train Epoch: 295 [2100/2589 (81%)]\tLoss: 266.387848\n",
      "Train Epoch: 295 [2400/2589 (93%)]\tLoss: 238.829910\n",
      "====> Epoch: 295 Average train loss: 281.1856\n",
      "====> Epoch: 295 Average test loss: 945.3422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 296 [0/2589 (0%)]\tLoss: 163.242172\n",
      "Train Epoch: 296 [300/2589 (12%)]\tLoss: 448.872009\n",
      "Train Epoch: 296 [600/2589 (23%)]\tLoss: 260.761932\n",
      "Train Epoch: 296 [900/2589 (35%)]\tLoss: 220.661240\n",
      "Train Epoch: 296 [1200/2589 (46%)]\tLoss: 271.416565\n",
      "Train Epoch: 296 [1500/2589 (58%)]\tLoss: 334.821014\n",
      "Train Epoch: 296 [1800/2589 (70%)]\tLoss: 317.891296\n",
      "Train Epoch: 296 [2100/2589 (81%)]\tLoss: 207.614258\n",
      "Train Epoch: 296 [2400/2589 (93%)]\tLoss: 265.008850\n",
      "====> Epoch: 296 Average train loss: 267.5939\n",
      "====> Epoch: 296 Average test loss: 946.3652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 297 [0/2589 (0%)]\tLoss: 221.086380\n",
      "Train Epoch: 297 [300/2589 (12%)]\tLoss: 235.858994\n",
      "Train Epoch: 297 [600/2589 (23%)]\tLoss: 191.649429\n",
      "Train Epoch: 297 [900/2589 (35%)]\tLoss: 261.424713\n",
      "Train Epoch: 297 [1200/2589 (46%)]\tLoss: 327.839966\n",
      "Train Epoch: 297 [1500/2589 (58%)]\tLoss: 360.156891\n",
      "Train Epoch: 297 [1800/2589 (70%)]\tLoss: 408.746124\n",
      "Train Epoch: 297 [2100/2589 (81%)]\tLoss: 353.776794\n",
      "Train Epoch: 297 [2400/2589 (93%)]\tLoss: 244.410782\n",
      "====> Epoch: 297 Average train loss: 271.2309\n",
      "====> Epoch: 297 Average test loss: 944.8759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 298 [0/2589 (0%)]\tLoss: 279.171173\n",
      "Train Epoch: 298 [300/2589 (12%)]\tLoss: 313.528442\n",
      "Train Epoch: 298 [600/2589 (23%)]\tLoss: 223.231003\n",
      "Train Epoch: 298 [900/2589 (35%)]\tLoss: 305.428680\n",
      "Train Epoch: 298 [1200/2589 (46%)]\tLoss: 193.754776\n",
      "Train Epoch: 298 [1500/2589 (58%)]\tLoss: 251.414795\n",
      "Train Epoch: 298 [1800/2589 (70%)]\tLoss: 284.200378\n",
      "Train Epoch: 298 [2100/2589 (81%)]\tLoss: 291.696136\n",
      "Train Epoch: 298 [2400/2589 (93%)]\tLoss: 221.979568\n",
      "====> Epoch: 298 Average train loss: 272.0146\n",
      "====> Epoch: 298 Average test loss: 967.4447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 299 [0/2589 (0%)]\tLoss: 321.608856\n",
      "Train Epoch: 299 [300/2589 (12%)]\tLoss: 242.658859\n",
      "Train Epoch: 299 [600/2589 (23%)]\tLoss: 265.754425\n",
      "Train Epoch: 299 [900/2589 (35%)]\tLoss: 246.378601\n",
      "Train Epoch: 299 [1200/2589 (46%)]\tLoss: 293.714874\n",
      "Train Epoch: 299 [1500/2589 (58%)]\tLoss: 248.692780\n",
      "Train Epoch: 299 [1800/2589 (70%)]\tLoss: 432.947601\n",
      "Train Epoch: 299 [2100/2589 (81%)]\tLoss: 162.436234\n",
      "Train Epoch: 299 [2400/2589 (93%)]\tLoss: 245.364563\n",
      "====> Epoch: 299 Average train loss: 264.0948\n",
      "====> Epoch: 299 Average test loss: 953.7415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 300 [0/2589 (0%)]\tLoss: 254.570450\n",
      "Train Epoch: 300 [300/2589 (12%)]\tLoss: 387.399933\n",
      "Train Epoch: 300 [600/2589 (23%)]\tLoss: 358.679688\n",
      "Train Epoch: 300 [900/2589 (35%)]\tLoss: 225.940094\n",
      "Train Epoch: 300 [1200/2589 (46%)]\tLoss: 307.719696\n",
      "Train Epoch: 300 [1500/2589 (58%)]\tLoss: 397.856720\n",
      "Train Epoch: 300 [1800/2589 (70%)]\tLoss: 235.107376\n",
      "Train Epoch: 300 [2100/2589 (81%)]\tLoss: 254.176895\n",
      "Train Epoch: 300 [2400/2589 (93%)]\tLoss: 247.827942\n",
      "====> Epoch: 300 Average train loss: 261.3290\n",
      "====> Epoch: 300 Average test loss: 952.8093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 301 [0/2589 (0%)]\tLoss: 285.596619\n",
      "Train Epoch: 301 [300/2589 (12%)]\tLoss: 326.823364\n",
      "Train Epoch: 301 [600/2589 (23%)]\tLoss: 290.023438\n",
      "Train Epoch: 301 [900/2589 (35%)]\tLoss: 228.560928\n",
      "Train Epoch: 301 [1200/2589 (46%)]\tLoss: 298.259247\n",
      "Train Epoch: 301 [1500/2589 (58%)]\tLoss: 304.756714\n",
      "Train Epoch: 301 [1800/2589 (70%)]\tLoss: 233.602036\n",
      "Train Epoch: 301 [2100/2589 (81%)]\tLoss: 224.332993\n",
      "Train Epoch: 301 [2400/2589 (93%)]\tLoss: 220.329620\n",
      "====> Epoch: 301 Average train loss: 268.8899\n",
      "====> Epoch: 301 Average test loss: 939.1192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 302 [0/2589 (0%)]\tLoss: 334.599670\n",
      "Train Epoch: 302 [300/2589 (12%)]\tLoss: 299.239136\n",
      "Train Epoch: 302 [600/2589 (23%)]\tLoss: 207.500763\n",
      "Train Epoch: 302 [900/2589 (35%)]\tLoss: 235.170471\n",
      "Train Epoch: 302 [1200/2589 (46%)]\tLoss: 211.617615\n",
      "Train Epoch: 302 [1500/2589 (58%)]\tLoss: 290.511108\n",
      "Train Epoch: 302 [1800/2589 (70%)]\tLoss: 176.950653\n",
      "Train Epoch: 302 [2100/2589 (81%)]\tLoss: 270.049225\n",
      "Train Epoch: 302 [2400/2589 (93%)]\tLoss: 245.604996\n",
      "====> Epoch: 302 Average train loss: 262.5023\n",
      "====> Epoch: 302 Average test loss: 941.4927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 303 [0/2589 (0%)]\tLoss: 313.083771\n",
      "Train Epoch: 303 [300/2589 (12%)]\tLoss: 339.163513\n",
      "Train Epoch: 303 [600/2589 (23%)]\tLoss: 212.660873\n",
      "Train Epoch: 303 [900/2589 (35%)]\tLoss: 265.415466\n",
      "Train Epoch: 303 [1200/2589 (46%)]\tLoss: 349.063599\n",
      "Train Epoch: 303 [1500/2589 (58%)]\tLoss: 234.779984\n",
      "Train Epoch: 303 [1800/2589 (70%)]\tLoss: 369.389740\n",
      "Train Epoch: 303 [2100/2589 (81%)]\tLoss: 503.574921\n",
      "Train Epoch: 303 [2400/2589 (93%)]\tLoss: 245.232010\n",
      "====> Epoch: 303 Average train loss: 277.1310\n",
      "====> Epoch: 303 Average test loss: 949.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 304 [0/2589 (0%)]\tLoss: 206.443802\n",
      "Train Epoch: 304 [300/2589 (12%)]\tLoss: 296.411407\n",
      "Train Epoch: 304 [600/2589 (23%)]\tLoss: 372.045990\n",
      "Train Epoch: 304 [900/2589 (35%)]\tLoss: 245.587097\n",
      "Train Epoch: 304 [1200/2589 (46%)]\tLoss: 223.990936\n",
      "Train Epoch: 304 [1500/2589 (58%)]\tLoss: 254.534683\n",
      "Train Epoch: 304 [1800/2589 (70%)]\tLoss: 320.184052\n",
      "Train Epoch: 304 [2100/2589 (81%)]\tLoss: 213.316010\n",
      "Train Epoch: 304 [2400/2589 (93%)]\tLoss: 227.072922\n",
      "====> Epoch: 304 Average train loss: 266.9339\n",
      "====> Epoch: 304 Average test loss: 954.1442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 305 [0/2589 (0%)]\tLoss: 281.785767\n",
      "Train Epoch: 305 [300/2589 (12%)]\tLoss: 185.008530\n",
      "Train Epoch: 305 [600/2589 (23%)]\tLoss: 285.504700\n",
      "Train Epoch: 305 [900/2589 (35%)]\tLoss: 379.101349\n",
      "Train Epoch: 305 [1200/2589 (46%)]\tLoss: 191.445602\n",
      "Train Epoch: 305 [1500/2589 (58%)]\tLoss: 213.872238\n",
      "Train Epoch: 305 [1800/2589 (70%)]\tLoss: 175.254456\n",
      "Train Epoch: 305 [2100/2589 (81%)]\tLoss: 286.404846\n",
      "Train Epoch: 305 [2400/2589 (93%)]\tLoss: 301.976440\n",
      "====> Epoch: 305 Average train loss: 271.0514\n",
      "====> Epoch: 305 Average test loss: 955.8581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 306 [0/2589 (0%)]\tLoss: 217.915298\n",
      "Train Epoch: 306 [300/2589 (12%)]\tLoss: 194.961884\n",
      "Train Epoch: 306 [600/2589 (23%)]\tLoss: 295.069946\n",
      "Train Epoch: 306 [900/2589 (35%)]\tLoss: 246.467194\n",
      "Train Epoch: 306 [1200/2589 (46%)]\tLoss: 375.412262\n",
      "Train Epoch: 306 [1500/2589 (58%)]\tLoss: 209.328140\n",
      "Train Epoch: 306 [1800/2589 (70%)]\tLoss: 239.269318\n",
      "Train Epoch: 306 [2100/2589 (81%)]\tLoss: 287.133575\n",
      "Train Epoch: 306 [2400/2589 (93%)]\tLoss: 182.525131\n",
      "====> Epoch: 306 Average train loss: 262.4417\n",
      "====> Epoch: 306 Average test loss: 940.1801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 307 [0/2589 (0%)]\tLoss: 302.141571\n",
      "Train Epoch: 307 [300/2589 (12%)]\tLoss: 272.216522\n",
      "Train Epoch: 307 [600/2589 (23%)]\tLoss: 570.036560\n",
      "Train Epoch: 307 [900/2589 (35%)]\tLoss: 203.044907\n",
      "Train Epoch: 307 [1200/2589 (46%)]\tLoss: 330.150116\n",
      "Train Epoch: 307 [1500/2589 (58%)]\tLoss: 269.382904\n",
      "Train Epoch: 307 [1800/2589 (70%)]\tLoss: 311.288269\n",
      "Train Epoch: 307 [2100/2589 (81%)]\tLoss: 349.813843\n",
      "Train Epoch: 307 [2400/2589 (93%)]\tLoss: 245.892532\n",
      "====> Epoch: 307 Average train loss: 259.9726\n",
      "====> Epoch: 307 Average test loss: 951.3405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 308 [0/2589 (0%)]\tLoss: 405.060211\n",
      "Train Epoch: 308 [300/2589 (12%)]\tLoss: 345.814240\n",
      "Train Epoch: 308 [600/2589 (23%)]\tLoss: 325.103577\n",
      "Train Epoch: 308 [900/2589 (35%)]\tLoss: 211.580292\n",
      "Train Epoch: 308 [1200/2589 (46%)]\tLoss: 337.570435\n",
      "Train Epoch: 308 [1500/2589 (58%)]\tLoss: 386.139557\n",
      "Train Epoch: 308 [1800/2589 (70%)]\tLoss: 243.427261\n",
      "Train Epoch: 308 [2100/2589 (81%)]\tLoss: 205.161957\n",
      "Train Epoch: 308 [2400/2589 (93%)]\tLoss: 262.043671\n",
      "====> Epoch: 308 Average train loss: 266.1367\n",
      "====> Epoch: 308 Average test loss: 944.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 309 [0/2589 (0%)]\tLoss: 276.542511\n",
      "Train Epoch: 309 [300/2589 (12%)]\tLoss: 343.339722\n",
      "Train Epoch: 309 [600/2589 (23%)]\tLoss: 250.493439\n",
      "Train Epoch: 309 [900/2589 (35%)]\tLoss: 239.723389\n",
      "Train Epoch: 309 [1200/2589 (46%)]\tLoss: 253.964310\n",
      "Train Epoch: 309 [1500/2589 (58%)]\tLoss: 283.303589\n",
      "Train Epoch: 309 [1800/2589 (70%)]\tLoss: 210.053406\n",
      "Train Epoch: 309 [2100/2589 (81%)]\tLoss: 275.619415\n",
      "Train Epoch: 309 [2400/2589 (93%)]\tLoss: 245.724762\n",
      "====> Epoch: 309 Average train loss: 273.5811\n",
      "====> Epoch: 309 Average test loss: 952.0250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 310 [0/2589 (0%)]\tLoss: 215.022659\n",
      "Train Epoch: 310 [300/2589 (12%)]\tLoss: 327.990204\n",
      "Train Epoch: 310 [600/2589 (23%)]\tLoss: 253.480774\n",
      "Train Epoch: 310 [900/2589 (35%)]\tLoss: 260.084686\n",
      "Train Epoch: 310 [1200/2589 (46%)]\tLoss: 385.250793\n",
      "Train Epoch: 310 [1500/2589 (58%)]\tLoss: 288.428131\n",
      "Train Epoch: 310 [1800/2589 (70%)]\tLoss: 245.776581\n",
      "Train Epoch: 310 [2100/2589 (81%)]\tLoss: 194.939972\n",
      "Train Epoch: 310 [2400/2589 (93%)]\tLoss: 232.811951\n",
      "====> Epoch: 310 Average train loss: 256.9783\n",
      "====> Epoch: 310 Average test loss: 940.8093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 311 [0/2589 (0%)]\tLoss: 264.214935\n",
      "Train Epoch: 311 [300/2589 (12%)]\tLoss: 225.590561\n",
      "Train Epoch: 311 [600/2589 (23%)]\tLoss: 247.509354\n",
      "Train Epoch: 311 [900/2589 (35%)]\tLoss: 237.869141\n",
      "Train Epoch: 311 [1200/2589 (46%)]\tLoss: 265.593933\n",
      "Train Epoch: 311 [1500/2589 (58%)]\tLoss: 208.475525\n",
      "Train Epoch: 311 [1800/2589 (70%)]\tLoss: 345.942108\n",
      "Train Epoch: 311 [2100/2589 (81%)]\tLoss: 261.473083\n",
      "Train Epoch: 311 [2400/2589 (93%)]\tLoss: 171.706818\n",
      "====> Epoch: 311 Average train loss: 255.6692\n",
      "====> Epoch: 311 Average test loss: 972.2814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 312 [0/2589 (0%)]\tLoss: 300.790192\n",
      "Train Epoch: 312 [300/2589 (12%)]\tLoss: 325.384949\n",
      "Train Epoch: 312 [600/2589 (23%)]\tLoss: 315.487823\n",
      "Train Epoch: 312 [900/2589 (35%)]\tLoss: 219.858994\n",
      "Train Epoch: 312 [1200/2589 (46%)]\tLoss: 333.735443\n",
      "Train Epoch: 312 [1500/2589 (58%)]\tLoss: 270.851746\n",
      "Train Epoch: 312 [1800/2589 (70%)]\tLoss: 240.236008\n",
      "Train Epoch: 312 [2100/2589 (81%)]\tLoss: 392.169312\n",
      "Train Epoch: 312 [2400/2589 (93%)]\tLoss: 402.894623\n",
      "====> Epoch: 312 Average train loss: 269.1949\n",
      "====> Epoch: 312 Average test loss: 928.4889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 313 [0/2589 (0%)]\tLoss: 309.900024\n",
      "Train Epoch: 313 [300/2589 (12%)]\tLoss: 322.041351\n",
      "Train Epoch: 313 [600/2589 (23%)]\tLoss: 306.042694\n",
      "Train Epoch: 313 [900/2589 (35%)]\tLoss: 310.017303\n",
      "Train Epoch: 313 [1200/2589 (46%)]\tLoss: 215.568588\n",
      "Train Epoch: 313 [1500/2589 (58%)]\tLoss: 255.421356\n",
      "Train Epoch: 313 [1800/2589 (70%)]\tLoss: 206.935150\n",
      "Train Epoch: 313 [2100/2589 (81%)]\tLoss: 294.337769\n",
      "Train Epoch: 313 [2400/2589 (93%)]\tLoss: 213.381210\n",
      "====> Epoch: 313 Average train loss: 257.1447\n",
      "====> Epoch: 313 Average test loss: 938.5498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 314 [0/2589 (0%)]\tLoss: 211.883377\n",
      "Train Epoch: 314 [300/2589 (12%)]\tLoss: 191.652969\n",
      "Train Epoch: 314 [600/2589 (23%)]\tLoss: 271.885559\n",
      "Train Epoch: 314 [900/2589 (35%)]\tLoss: 146.561722\n",
      "Train Epoch: 314 [1200/2589 (46%)]\tLoss: 275.492706\n",
      "Train Epoch: 314 [1500/2589 (58%)]\tLoss: 236.598221\n",
      "Train Epoch: 314 [1800/2589 (70%)]\tLoss: 267.797485\n",
      "Train Epoch: 314 [2100/2589 (81%)]\tLoss: 221.463196\n",
      "Train Epoch: 314 [2400/2589 (93%)]\tLoss: 249.374695\n",
      "====> Epoch: 314 Average train loss: 265.3014\n",
      "====> Epoch: 314 Average test loss: 942.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 315 [0/2589 (0%)]\tLoss: 366.413605\n",
      "Train Epoch: 315 [300/2589 (12%)]\tLoss: 289.983398\n",
      "Train Epoch: 315 [600/2589 (23%)]\tLoss: 277.613678\n",
      "Train Epoch: 315 [900/2589 (35%)]\tLoss: 300.278137\n",
      "Train Epoch: 315 [1200/2589 (46%)]\tLoss: 208.690979\n",
      "Train Epoch: 315 [1500/2589 (58%)]\tLoss: 234.969681\n",
      "Train Epoch: 315 [1800/2589 (70%)]\tLoss: 245.473404\n",
      "Train Epoch: 315 [2100/2589 (81%)]\tLoss: 274.098267\n",
      "Train Epoch: 315 [2400/2589 (93%)]\tLoss: 384.600555\n",
      "====> Epoch: 315 Average train loss: 269.3150\n",
      "====> Epoch: 315 Average test loss: 933.4404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 316 [0/2589 (0%)]\tLoss: 278.325256\n",
      "Train Epoch: 316 [300/2589 (12%)]\tLoss: 294.433868\n",
      "Train Epoch: 316 [600/2589 (23%)]\tLoss: 187.725128\n",
      "Train Epoch: 316 [900/2589 (35%)]\tLoss: 149.157333\n",
      "Train Epoch: 316 [1200/2589 (46%)]\tLoss: 185.686386\n",
      "Train Epoch: 316 [1500/2589 (58%)]\tLoss: 305.711975\n",
      "Train Epoch: 316 [1800/2589 (70%)]\tLoss: 212.769470\n",
      "Train Epoch: 316 [2100/2589 (81%)]\tLoss: 189.913330\n",
      "Train Epoch: 316 [2400/2589 (93%)]\tLoss: 223.433350\n",
      "====> Epoch: 316 Average train loss: 257.7905\n",
      "====> Epoch: 316 Average test loss: 932.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 317 [0/2589 (0%)]\tLoss: 213.623367\n",
      "Train Epoch: 317 [300/2589 (12%)]\tLoss: 247.876633\n",
      "Train Epoch: 317 [600/2589 (23%)]\tLoss: 191.012848\n",
      "Train Epoch: 317 [900/2589 (35%)]\tLoss: 211.932693\n",
      "Train Epoch: 317 [1200/2589 (46%)]\tLoss: 407.792694\n",
      "Train Epoch: 317 [1500/2589 (58%)]\tLoss: 293.362610\n",
      "Train Epoch: 317 [1800/2589 (70%)]\tLoss: 256.184326\n",
      "Train Epoch: 317 [2100/2589 (81%)]\tLoss: 363.324280\n",
      "Train Epoch: 317 [2400/2589 (93%)]\tLoss: 203.063461\n",
      "====> Epoch: 317 Average train loss: 261.5942\n",
      "====> Epoch: 317 Average test loss: 943.2633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 318 [0/2589 (0%)]\tLoss: 188.919983\n",
      "Train Epoch: 318 [300/2589 (12%)]\tLoss: 252.595566\n",
      "Train Epoch: 318 [600/2589 (23%)]\tLoss: 284.345978\n",
      "Train Epoch: 318 [900/2589 (35%)]\tLoss: 222.784164\n",
      "Train Epoch: 318 [1200/2589 (46%)]\tLoss: 262.367279\n",
      "Train Epoch: 318 [1500/2589 (58%)]\tLoss: 388.046600\n",
      "Train Epoch: 318 [1800/2589 (70%)]\tLoss: 259.700470\n",
      "Train Epoch: 318 [2100/2589 (81%)]\tLoss: 256.785065\n",
      "Train Epoch: 318 [2400/2589 (93%)]\tLoss: 270.049286\n",
      "====> Epoch: 318 Average train loss: 261.8507\n",
      "====> Epoch: 318 Average test loss: 937.0328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 319 [0/2589 (0%)]\tLoss: 256.292206\n",
      "Train Epoch: 319 [300/2589 (12%)]\tLoss: 320.854675\n",
      "Train Epoch: 319 [600/2589 (23%)]\tLoss: 196.075134\n",
      "Train Epoch: 319 [900/2589 (35%)]\tLoss: 149.049362\n",
      "Train Epoch: 319 [1200/2589 (46%)]\tLoss: 214.594818\n",
      "Train Epoch: 319 [1500/2589 (58%)]\tLoss: 209.720352\n",
      "Train Epoch: 319 [1800/2589 (70%)]\tLoss: 335.349304\n",
      "Train Epoch: 319 [2100/2589 (81%)]\tLoss: 255.839798\n",
      "Train Epoch: 319 [2400/2589 (93%)]\tLoss: 282.031525\n",
      "====> Epoch: 319 Average train loss: 254.5281\n",
      "====> Epoch: 319 Average test loss: 942.2435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 320 [0/2589 (0%)]\tLoss: 249.759384\n",
      "Train Epoch: 320 [300/2589 (12%)]\tLoss: 334.446930\n",
      "Train Epoch: 320 [600/2589 (23%)]\tLoss: 280.289093\n",
      "Train Epoch: 320 [900/2589 (35%)]\tLoss: 378.700500\n",
      "Train Epoch: 320 [1200/2589 (46%)]\tLoss: 213.094147\n",
      "Train Epoch: 320 [1500/2589 (58%)]\tLoss: 198.872101\n",
      "Train Epoch: 320 [1800/2589 (70%)]\tLoss: 232.195587\n",
      "Train Epoch: 320 [2100/2589 (81%)]\tLoss: 196.086212\n",
      "Train Epoch: 320 [2400/2589 (93%)]\tLoss: 264.788727\n",
      "====> Epoch: 320 Average train loss: 262.8053\n",
      "====> Epoch: 320 Average test loss: 948.6943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 321 [0/2589 (0%)]\tLoss: 206.391739\n",
      "Train Epoch: 321 [300/2589 (12%)]\tLoss: 193.859116\n",
      "Train Epoch: 321 [600/2589 (23%)]\tLoss: 217.167282\n",
      "Train Epoch: 321 [900/2589 (35%)]\tLoss: 252.286423\n",
      "Train Epoch: 321 [1200/2589 (46%)]\tLoss: 187.486328\n",
      "Train Epoch: 321 [1500/2589 (58%)]\tLoss: 285.463501\n",
      "Train Epoch: 321 [1800/2589 (70%)]\tLoss: 155.048691\n",
      "Train Epoch: 321 [2100/2589 (81%)]\tLoss: 178.458435\n",
      "Train Epoch: 321 [2400/2589 (93%)]\tLoss: 228.589218\n",
      "====> Epoch: 321 Average train loss: 255.9441\n",
      "====> Epoch: 321 Average test loss: 923.1171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 322 [0/2589 (0%)]\tLoss: 227.417130\n",
      "Train Epoch: 322 [300/2589 (12%)]\tLoss: 276.923706\n",
      "Train Epoch: 322 [600/2589 (23%)]\tLoss: 302.982513\n",
      "Train Epoch: 322 [900/2589 (35%)]\tLoss: 241.930161\n",
      "Train Epoch: 322 [1200/2589 (46%)]\tLoss: 254.856644\n",
      "Train Epoch: 322 [1500/2589 (58%)]\tLoss: 294.172699\n",
      "Train Epoch: 322 [1800/2589 (70%)]\tLoss: 319.065308\n",
      "Train Epoch: 322 [2100/2589 (81%)]\tLoss: 243.042587\n",
      "Train Epoch: 322 [2400/2589 (93%)]\tLoss: 448.457123\n",
      "====> Epoch: 322 Average train loss: 261.3504\n",
      "====> Epoch: 322 Average test loss: 937.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 323 [0/2589 (0%)]\tLoss: 331.837982\n",
      "Train Epoch: 323 [300/2589 (12%)]\tLoss: 212.365509\n",
      "Train Epoch: 323 [600/2589 (23%)]\tLoss: 247.627945\n",
      "Train Epoch: 323 [900/2589 (35%)]\tLoss: 316.536285\n",
      "Train Epoch: 323 [1200/2589 (46%)]\tLoss: 243.717529\n",
      "Train Epoch: 323 [1500/2589 (58%)]\tLoss: 279.751831\n",
      "Train Epoch: 323 [1800/2589 (70%)]\tLoss: 199.817947\n",
      "Train Epoch: 323 [2100/2589 (81%)]\tLoss: 225.339325\n",
      "Train Epoch: 323 [2400/2589 (93%)]\tLoss: 249.307861\n",
      "====> Epoch: 323 Average train loss: 261.7910\n",
      "====> Epoch: 323 Average test loss: 946.7642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 324 [0/2589 (0%)]\tLoss: 319.745636\n",
      "Train Epoch: 324 [300/2589 (12%)]\tLoss: 324.001343\n",
      "Train Epoch: 324 [600/2589 (23%)]\tLoss: 251.675735\n",
      "Train Epoch: 324 [900/2589 (35%)]\tLoss: 237.450104\n",
      "Train Epoch: 324 [1200/2589 (46%)]\tLoss: 282.022888\n",
      "Train Epoch: 324 [1500/2589 (58%)]\tLoss: 251.175049\n",
      "Train Epoch: 324 [1800/2589 (70%)]\tLoss: 191.932755\n",
      "Train Epoch: 324 [2100/2589 (81%)]\tLoss: 209.974380\n",
      "Train Epoch: 324 [2400/2589 (93%)]\tLoss: 241.224594\n",
      "====> Epoch: 324 Average train loss: 263.3947\n",
      "====> Epoch: 324 Average test loss: 947.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 325 [0/2589 (0%)]\tLoss: 254.186661\n",
      "Train Epoch: 325 [300/2589 (12%)]\tLoss: 247.728577\n",
      "Train Epoch: 325 [600/2589 (23%)]\tLoss: 298.922943\n",
      "Train Epoch: 325 [900/2589 (35%)]\tLoss: 297.784271\n",
      "Train Epoch: 325 [1200/2589 (46%)]\tLoss: 330.712036\n",
      "Train Epoch: 325 [1500/2589 (58%)]\tLoss: 266.662079\n",
      "Train Epoch: 325 [1800/2589 (70%)]\tLoss: 219.917038\n",
      "Train Epoch: 325 [2100/2589 (81%)]\tLoss: 220.430176\n",
      "Train Epoch: 325 [2400/2589 (93%)]\tLoss: 240.987900\n",
      "====> Epoch: 325 Average train loss: 249.5544\n",
      "====> Epoch: 325 Average test loss: 937.4764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 326 [0/2589 (0%)]\tLoss: 154.421661\n",
      "Train Epoch: 326 [300/2589 (12%)]\tLoss: 194.097382\n",
      "Train Epoch: 326 [600/2589 (23%)]\tLoss: 241.958252\n",
      "Train Epoch: 326 [900/2589 (35%)]\tLoss: 237.946045\n",
      "Train Epoch: 326 [1200/2589 (46%)]\tLoss: 238.596054\n",
      "Train Epoch: 326 [1500/2589 (58%)]\tLoss: 228.912277\n",
      "Train Epoch: 326 [1800/2589 (70%)]\tLoss: 227.911880\n",
      "Train Epoch: 326 [2100/2589 (81%)]\tLoss: 317.116211\n",
      "Train Epoch: 326 [2400/2589 (93%)]\tLoss: 191.842865\n",
      "====> Epoch: 326 Average train loss: 262.2332\n",
      "====> Epoch: 326 Average test loss: 934.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 327 [0/2589 (0%)]\tLoss: 203.300018\n",
      "Train Epoch: 327 [300/2589 (12%)]\tLoss: 187.428329\n",
      "Train Epoch: 327 [600/2589 (23%)]\tLoss: 211.769577\n",
      "Train Epoch: 327 [900/2589 (35%)]\tLoss: 356.637421\n",
      "Train Epoch: 327 [1200/2589 (46%)]\tLoss: 247.556213\n",
      "Train Epoch: 327 [1500/2589 (58%)]\tLoss: 221.484482\n",
      "Train Epoch: 327 [1800/2589 (70%)]\tLoss: 239.007828\n",
      "Train Epoch: 327 [2100/2589 (81%)]\tLoss: 228.591766\n",
      "Train Epoch: 327 [2400/2589 (93%)]\tLoss: 195.424088\n",
      "====> Epoch: 327 Average train loss: 262.3908\n",
      "====> Epoch: 327 Average test loss: 948.2976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 328 [0/2589 (0%)]\tLoss: 194.336288\n",
      "Train Epoch: 328 [300/2589 (12%)]\tLoss: 269.564117\n",
      "Train Epoch: 328 [600/2589 (23%)]\tLoss: 265.316803\n",
      "Train Epoch: 328 [900/2589 (35%)]\tLoss: 202.301407\n",
      "Train Epoch: 328 [1200/2589 (46%)]\tLoss: 319.885651\n",
      "Train Epoch: 328 [1500/2589 (58%)]\tLoss: 253.430313\n",
      "Train Epoch: 328 [1800/2589 (70%)]\tLoss: 331.694000\n",
      "Train Epoch: 328 [2100/2589 (81%)]\tLoss: 190.687485\n",
      "Train Epoch: 328 [2400/2589 (93%)]\tLoss: 246.171844\n",
      "====> Epoch: 328 Average train loss: 260.5096\n",
      "====> Epoch: 328 Average test loss: 947.8442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 329 [0/2589 (0%)]\tLoss: 219.048996\n",
      "Train Epoch: 329 [300/2589 (12%)]\tLoss: 256.500397\n",
      "Train Epoch: 329 [600/2589 (23%)]\tLoss: 268.427521\n",
      "Train Epoch: 329 [900/2589 (35%)]\tLoss: 240.103317\n",
      "Train Epoch: 329 [1200/2589 (46%)]\tLoss: 380.186249\n",
      "Train Epoch: 329 [1500/2589 (58%)]\tLoss: 268.972351\n",
      "Train Epoch: 329 [1800/2589 (70%)]\tLoss: 343.101868\n",
      "Train Epoch: 329 [2100/2589 (81%)]\tLoss: 322.888733\n",
      "Train Epoch: 329 [2400/2589 (93%)]\tLoss: 233.965118\n",
      "====> Epoch: 329 Average train loss: 260.6546\n",
      "====> Epoch: 329 Average test loss: 941.6453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 330 [0/2589 (0%)]\tLoss: 221.512390\n",
      "Train Epoch: 330 [300/2589 (12%)]\tLoss: 307.727173\n",
      "Train Epoch: 330 [600/2589 (23%)]\tLoss: 399.201019\n",
      "Train Epoch: 330 [900/2589 (35%)]\tLoss: 259.270050\n",
      "Train Epoch: 330 [1200/2589 (46%)]\tLoss: 235.750870\n",
      "Train Epoch: 330 [1500/2589 (58%)]\tLoss: 268.917328\n",
      "Train Epoch: 330 [1800/2589 (70%)]\tLoss: 226.509628\n",
      "Train Epoch: 330 [2100/2589 (81%)]\tLoss: 260.031616\n",
      "Train Epoch: 330 [2400/2589 (93%)]\tLoss: 239.600815\n",
      "====> Epoch: 330 Average train loss: 260.5555\n",
      "====> Epoch: 330 Average test loss: 944.3398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 331 [0/2589 (0%)]\tLoss: 194.327362\n",
      "Train Epoch: 331 [300/2589 (12%)]\tLoss: 279.281219\n",
      "Train Epoch: 331 [600/2589 (23%)]\tLoss: 191.025101\n",
      "Train Epoch: 331 [900/2589 (35%)]\tLoss: 243.510193\n",
      "Train Epoch: 331 [1200/2589 (46%)]\tLoss: 255.548935\n",
      "Train Epoch: 331 [1500/2589 (58%)]\tLoss: 206.667511\n",
      "Train Epoch: 331 [1800/2589 (70%)]\tLoss: 261.585419\n",
      "Train Epoch: 331 [2100/2589 (81%)]\tLoss: 377.758820\n",
      "Train Epoch: 331 [2400/2589 (93%)]\tLoss: 211.424942\n",
      "====> Epoch: 331 Average train loss: 253.5587\n",
      "====> Epoch: 331 Average test loss: 941.9277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 332 [0/2589 (0%)]\tLoss: 232.969940\n",
      "Train Epoch: 332 [300/2589 (12%)]\tLoss: 275.731720\n",
      "Train Epoch: 332 [600/2589 (23%)]\tLoss: 273.025482\n",
      "Train Epoch: 332 [900/2589 (35%)]\tLoss: 331.748901\n",
      "Train Epoch: 332 [1200/2589 (46%)]\tLoss: 212.212097\n",
      "Train Epoch: 332 [1500/2589 (58%)]\tLoss: 212.710281\n",
      "Train Epoch: 332 [1800/2589 (70%)]\tLoss: 329.525024\n",
      "Train Epoch: 332 [2100/2589 (81%)]\tLoss: 314.621704\n",
      "Train Epoch: 332 [2400/2589 (93%)]\tLoss: 308.892395\n",
      "====> Epoch: 332 Average train loss: 259.3448\n",
      "====> Epoch: 332 Average test loss: 959.4010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 333 [0/2589 (0%)]\tLoss: 158.493103\n",
      "Train Epoch: 333 [300/2589 (12%)]\tLoss: 239.355408\n",
      "Train Epoch: 333 [600/2589 (23%)]\tLoss: 261.838837\n",
      "Train Epoch: 333 [900/2589 (35%)]\tLoss: 264.772400\n",
      "Train Epoch: 333 [1200/2589 (46%)]\tLoss: 282.568481\n",
      "Train Epoch: 333 [1500/2589 (58%)]\tLoss: 336.680847\n",
      "Train Epoch: 333 [1800/2589 (70%)]\tLoss: 312.723450\n",
      "Train Epoch: 333 [2100/2589 (81%)]\tLoss: 171.291809\n",
      "Train Epoch: 333 [2400/2589 (93%)]\tLoss: 228.838699\n",
      "====> Epoch: 333 Average train loss: 261.0243\n",
      "====> Epoch: 333 Average test loss: 936.1480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 334 [0/2589 (0%)]\tLoss: 281.165314\n",
      "Train Epoch: 334 [300/2589 (12%)]\tLoss: 280.030304\n",
      "Train Epoch: 334 [600/2589 (23%)]\tLoss: 272.883759\n",
      "Train Epoch: 334 [900/2589 (35%)]\tLoss: 380.536835\n",
      "Train Epoch: 334 [1200/2589 (46%)]\tLoss: 204.745895\n",
      "Train Epoch: 334 [1500/2589 (58%)]\tLoss: 206.739807\n",
      "Train Epoch: 334 [1800/2589 (70%)]\tLoss: 269.300873\n",
      "Train Epoch: 334 [2100/2589 (81%)]\tLoss: 249.684845\n",
      "Train Epoch: 334 [2400/2589 (93%)]\tLoss: 320.290802\n",
      "====> Epoch: 334 Average train loss: 254.6252\n",
      "====> Epoch: 334 Average test loss: 964.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 335 [0/2589 (0%)]\tLoss: 542.213684\n",
      "Train Epoch: 335 [300/2589 (12%)]\tLoss: 190.083527\n",
      "Train Epoch: 335 [600/2589 (23%)]\tLoss: 247.859467\n",
      "Train Epoch: 335 [900/2589 (35%)]\tLoss: 319.929169\n",
      "Train Epoch: 335 [1200/2589 (46%)]\tLoss: 262.764038\n",
      "Train Epoch: 335 [1500/2589 (58%)]\tLoss: 224.432892\n",
      "Train Epoch: 335 [1800/2589 (70%)]\tLoss: 219.614639\n",
      "Train Epoch: 335 [2100/2589 (81%)]\tLoss: 293.658356\n",
      "Train Epoch: 335 [2400/2589 (93%)]\tLoss: 292.570831\n",
      "====> Epoch: 335 Average train loss: 261.0443\n",
      "====> Epoch: 335 Average test loss: 933.9248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 336 [0/2589 (0%)]\tLoss: 238.313232\n",
      "Train Epoch: 336 [300/2589 (12%)]\tLoss: 229.237625\n",
      "Train Epoch: 336 [600/2589 (23%)]\tLoss: 189.995605\n",
      "Train Epoch: 336 [900/2589 (35%)]\tLoss: 293.837372\n",
      "Train Epoch: 336 [1200/2589 (46%)]\tLoss: 315.745270\n",
      "Train Epoch: 336 [1500/2589 (58%)]\tLoss: 351.162994\n",
      "Train Epoch: 336 [1800/2589 (70%)]\tLoss: 215.289062\n",
      "Train Epoch: 336 [2100/2589 (81%)]\tLoss: 227.843582\n",
      "Train Epoch: 336 [2400/2589 (93%)]\tLoss: 272.994080\n",
      "====> Epoch: 336 Average train loss: 260.5739\n",
      "====> Epoch: 336 Average test loss: 926.1443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 337 [0/2589 (0%)]\tLoss: 196.490036\n",
      "Train Epoch: 337 [300/2589 (12%)]\tLoss: 208.404953\n",
      "Train Epoch: 337 [600/2589 (23%)]\tLoss: 436.386047\n",
      "Train Epoch: 337 [900/2589 (35%)]\tLoss: 205.040390\n",
      "Train Epoch: 337 [1200/2589 (46%)]\tLoss: 181.353622\n",
      "Train Epoch: 337 [1500/2589 (58%)]\tLoss: 297.162720\n",
      "Train Epoch: 337 [1800/2589 (70%)]\tLoss: 253.178513\n",
      "Train Epoch: 337 [2100/2589 (81%)]\tLoss: 361.626892\n",
      "Train Epoch: 337 [2400/2589 (93%)]\tLoss: 296.249298\n",
      "====> Epoch: 337 Average train loss: 255.9836\n",
      "====> Epoch: 337 Average test loss: 924.0224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 338 [0/2589 (0%)]\tLoss: 217.979080\n",
      "Train Epoch: 338 [300/2589 (12%)]\tLoss: 165.697464\n",
      "Train Epoch: 338 [600/2589 (23%)]\tLoss: 248.452621\n",
      "Train Epoch: 338 [900/2589 (35%)]\tLoss: 265.978973\n",
      "Train Epoch: 338 [1200/2589 (46%)]\tLoss: 286.140350\n",
      "Train Epoch: 338 [1500/2589 (58%)]\tLoss: 410.066010\n",
      "Train Epoch: 338 [1800/2589 (70%)]\tLoss: 220.144623\n",
      "Train Epoch: 338 [2100/2589 (81%)]\tLoss: 186.472427\n",
      "Train Epoch: 338 [2400/2589 (93%)]\tLoss: 307.013794\n",
      "====> Epoch: 338 Average train loss: 264.8444\n",
      "====> Epoch: 338 Average test loss: 937.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 339 [0/2589 (0%)]\tLoss: 239.486893\n",
      "Train Epoch: 339 [300/2589 (12%)]\tLoss: 238.584091\n",
      "Train Epoch: 339 [600/2589 (23%)]\tLoss: 224.577881\n",
      "Train Epoch: 339 [900/2589 (35%)]\tLoss: 247.824768\n",
      "Train Epoch: 339 [1200/2589 (46%)]\tLoss: 297.226074\n",
      "Train Epoch: 339 [1500/2589 (58%)]\tLoss: 219.648453\n",
      "Train Epoch: 339 [1800/2589 (70%)]\tLoss: 282.070374\n",
      "Train Epoch: 339 [2100/2589 (81%)]\tLoss: 275.051056\n",
      "Train Epoch: 339 [2400/2589 (93%)]\tLoss: 192.436066\n",
      "====> Epoch: 339 Average train loss: 270.0186\n",
      "====> Epoch: 339 Average test loss: 947.1173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 340 [0/2589 (0%)]\tLoss: 219.171158\n",
      "Train Epoch: 340 [300/2589 (12%)]\tLoss: 219.824402\n",
      "Train Epoch: 340 [600/2589 (23%)]\tLoss: 212.919983\n",
      "Train Epoch: 340 [900/2589 (35%)]\tLoss: 269.672882\n",
      "Train Epoch: 340 [1200/2589 (46%)]\tLoss: 164.546875\n",
      "Train Epoch: 340 [1500/2589 (58%)]\tLoss: 200.981506\n",
      "Train Epoch: 340 [1800/2589 (70%)]\tLoss: 235.301102\n",
      "Train Epoch: 340 [2100/2589 (81%)]\tLoss: 229.832565\n",
      "Train Epoch: 340 [2400/2589 (93%)]\tLoss: 232.154602\n",
      "====> Epoch: 340 Average train loss: 264.1271\n",
      "====> Epoch: 340 Average test loss: 958.1835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 341 [0/2589 (0%)]\tLoss: 284.308502\n",
      "Train Epoch: 341 [300/2589 (12%)]\tLoss: 302.076965\n",
      "Train Epoch: 341 [600/2589 (23%)]\tLoss: 211.670670\n",
      "Train Epoch: 341 [900/2589 (35%)]\tLoss: 283.500946\n",
      "Train Epoch: 341 [1200/2589 (46%)]\tLoss: 174.247940\n",
      "Train Epoch: 341 [1500/2589 (58%)]\tLoss: 157.118637\n",
      "Train Epoch: 341 [1800/2589 (70%)]\tLoss: 307.682587\n",
      "Train Epoch: 341 [2100/2589 (81%)]\tLoss: 471.154938\n",
      "Train Epoch: 341 [2400/2589 (93%)]\tLoss: 317.807465\n",
      "====> Epoch: 341 Average train loss: 256.6861\n",
      "====> Epoch: 341 Average test loss: 968.2186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 342 [0/2589 (0%)]\tLoss: 217.435516\n",
      "Train Epoch: 342 [300/2589 (12%)]\tLoss: 227.214539\n",
      "Train Epoch: 342 [600/2589 (23%)]\tLoss: 232.239304\n",
      "Train Epoch: 342 [900/2589 (35%)]\tLoss: 257.612732\n",
      "Train Epoch: 342 [1200/2589 (46%)]\tLoss: 287.973267\n",
      "Train Epoch: 342 [1500/2589 (58%)]\tLoss: 236.184219\n",
      "Train Epoch: 342 [1800/2589 (70%)]\tLoss: 291.267059\n",
      "Train Epoch: 342 [2100/2589 (81%)]\tLoss: 239.982681\n",
      "Train Epoch: 342 [2400/2589 (93%)]\tLoss: 367.624481\n",
      "====> Epoch: 342 Average train loss: 266.5034\n",
      "====> Epoch: 342 Average test loss: 954.0414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 343 [0/2589 (0%)]\tLoss: 254.297562\n",
      "Train Epoch: 343 [300/2589 (12%)]\tLoss: 310.573181\n",
      "Train Epoch: 343 [600/2589 (23%)]\tLoss: 353.531189\n",
      "Train Epoch: 343 [900/2589 (35%)]\tLoss: 291.460663\n",
      "Train Epoch: 343 [1200/2589 (46%)]\tLoss: 215.676422\n",
      "Train Epoch: 343 [1500/2589 (58%)]\tLoss: 200.021225\n",
      "Train Epoch: 343 [1800/2589 (70%)]\tLoss: 213.613922\n",
      "Train Epoch: 343 [2100/2589 (81%)]\tLoss: 210.637848\n",
      "Train Epoch: 343 [2400/2589 (93%)]\tLoss: 382.737732\n",
      "====> Epoch: 343 Average train loss: 254.3696\n",
      "====> Epoch: 343 Average test loss: 941.5994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 344 [0/2589 (0%)]\tLoss: 164.724472\n",
      "Train Epoch: 344 [300/2589 (12%)]\tLoss: 218.619919\n",
      "Train Epoch: 344 [600/2589 (23%)]\tLoss: 235.191086\n",
      "Train Epoch: 344 [900/2589 (35%)]\tLoss: 331.703766\n",
      "Train Epoch: 344 [1200/2589 (46%)]\tLoss: 208.077911\n",
      "Train Epoch: 344 [1500/2589 (58%)]\tLoss: 298.188263\n",
      "Train Epoch: 344 [1800/2589 (70%)]\tLoss: 231.894608\n",
      "Train Epoch: 344 [2100/2589 (81%)]\tLoss: 287.616730\n",
      "Train Epoch: 344 [2400/2589 (93%)]\tLoss: 236.122101\n",
      "====> Epoch: 344 Average train loss: 252.8084\n",
      "====> Epoch: 344 Average test loss: 950.0778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 345 [0/2589 (0%)]\tLoss: 221.539062\n",
      "Train Epoch: 345 [300/2589 (12%)]\tLoss: 220.861084\n",
      "Train Epoch: 345 [600/2589 (23%)]\tLoss: 337.196228\n",
      "Train Epoch: 345 [900/2589 (35%)]\tLoss: 402.056976\n",
      "Train Epoch: 345 [1200/2589 (46%)]\tLoss: 346.921600\n",
      "Train Epoch: 345 [1500/2589 (58%)]\tLoss: 285.850189\n",
      "Train Epoch: 345 [1800/2589 (70%)]\tLoss: 278.080688\n",
      "Train Epoch: 345 [2100/2589 (81%)]\tLoss: 265.565521\n",
      "Train Epoch: 345 [2400/2589 (93%)]\tLoss: 331.408173\n",
      "====> Epoch: 345 Average train loss: 264.8466\n",
      "====> Epoch: 345 Average test loss: 942.0285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 346 [0/2589 (0%)]\tLoss: 217.689407\n",
      "Train Epoch: 346 [300/2589 (12%)]\tLoss: 390.591156\n",
      "Train Epoch: 346 [600/2589 (23%)]\tLoss: 189.776550\n",
      "Train Epoch: 346 [900/2589 (35%)]\tLoss: 247.170975\n",
      "Train Epoch: 346 [1200/2589 (46%)]\tLoss: 237.202698\n",
      "Train Epoch: 346 [1500/2589 (58%)]\tLoss: 176.104874\n",
      "Train Epoch: 346 [1800/2589 (70%)]\tLoss: 338.708069\n",
      "Train Epoch: 346 [2100/2589 (81%)]\tLoss: 182.086029\n",
      "Train Epoch: 346 [2400/2589 (93%)]\tLoss: 247.310638\n",
      "====> Epoch: 346 Average train loss: 263.2365\n",
      "====> Epoch: 346 Average test loss: 945.1237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 347 [0/2589 (0%)]\tLoss: 336.916687\n",
      "Train Epoch: 347 [300/2589 (12%)]\tLoss: 266.183075\n",
      "Train Epoch: 347 [600/2589 (23%)]\tLoss: 169.468170\n",
      "Train Epoch: 347 [900/2589 (35%)]\tLoss: 157.081009\n",
      "Train Epoch: 347 [1200/2589 (46%)]\tLoss: 293.678864\n",
      "Train Epoch: 347 [1500/2589 (58%)]\tLoss: 275.645660\n",
      "Train Epoch: 347 [1800/2589 (70%)]\tLoss: 233.985138\n",
      "Train Epoch: 347 [2100/2589 (81%)]\tLoss: 209.237106\n",
      "Train Epoch: 347 [2400/2589 (93%)]\tLoss: 259.789734\n",
      "====> Epoch: 347 Average train loss: 250.7006\n",
      "====> Epoch: 347 Average test loss: 950.7366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 348 [0/2589 (0%)]\tLoss: 354.613922\n",
      "Train Epoch: 348 [300/2589 (12%)]\tLoss: 248.439651\n",
      "Train Epoch: 348 [600/2589 (23%)]\tLoss: 291.602509\n",
      "Train Epoch: 348 [900/2589 (35%)]\tLoss: 266.362854\n",
      "Train Epoch: 348 [1200/2589 (46%)]\tLoss: 381.486542\n",
      "Train Epoch: 348 [1500/2589 (58%)]\tLoss: 453.669312\n",
      "Train Epoch: 348 [1800/2589 (70%)]\tLoss: 263.515900\n",
      "Train Epoch: 348 [2100/2589 (81%)]\tLoss: 204.817474\n",
      "Train Epoch: 348 [2400/2589 (93%)]\tLoss: 268.438141\n",
      "====> Epoch: 348 Average train loss: 271.3756\n",
      "====> Epoch: 348 Average test loss: 961.0988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 349 [0/2589 (0%)]\tLoss: 185.650864\n",
      "Train Epoch: 349 [300/2589 (12%)]\tLoss: 253.677704\n",
      "Train Epoch: 349 [600/2589 (23%)]\tLoss: 169.140915\n",
      "Train Epoch: 349 [900/2589 (35%)]\tLoss: 382.147003\n",
      "Train Epoch: 349 [1200/2589 (46%)]\tLoss: 210.829758\n",
      "Train Epoch: 349 [1500/2589 (58%)]\tLoss: 290.132904\n",
      "Train Epoch: 349 [1800/2589 (70%)]\tLoss: 204.488251\n",
      "Train Epoch: 349 [2100/2589 (81%)]\tLoss: 254.082672\n",
      "Train Epoch: 349 [2400/2589 (93%)]\tLoss: 277.758209\n",
      "====> Epoch: 349 Average train loss: 262.4128\n",
      "====> Epoch: 349 Average test loss: 956.6597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 350 [0/2589 (0%)]\tLoss: 209.453812\n",
      "Train Epoch: 350 [300/2589 (12%)]\tLoss: 236.718307\n",
      "Train Epoch: 350 [600/2589 (23%)]\tLoss: 215.739685\n",
      "Train Epoch: 350 [900/2589 (35%)]\tLoss: 311.067261\n",
      "Train Epoch: 350 [1200/2589 (46%)]\tLoss: 200.161575\n",
      "Train Epoch: 350 [1500/2589 (58%)]\tLoss: 207.904648\n",
      "Train Epoch: 350 [1800/2589 (70%)]\tLoss: 197.783554\n",
      "Train Epoch: 350 [2100/2589 (81%)]\tLoss: 313.650787\n",
      "Train Epoch: 350 [2400/2589 (93%)]\tLoss: 266.496674\n",
      "====> Epoch: 350 Average train loss: 259.3699\n",
      "====> Epoch: 350 Average test loss: 927.8883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 351 [0/2589 (0%)]\tLoss: 362.379974\n",
      "Train Epoch: 351 [300/2589 (12%)]\tLoss: 141.281006\n",
      "Train Epoch: 351 [600/2589 (23%)]\tLoss: 258.543121\n",
      "Train Epoch: 351 [900/2589 (35%)]\tLoss: 152.748322\n",
      "Train Epoch: 351 [1200/2589 (46%)]\tLoss: 170.642166\n",
      "Train Epoch: 351 [1500/2589 (58%)]\tLoss: 264.287628\n",
      "Train Epoch: 351 [1800/2589 (70%)]\tLoss: 187.588348\n",
      "Train Epoch: 351 [2100/2589 (81%)]\tLoss: 293.484070\n",
      "Train Epoch: 351 [2400/2589 (93%)]\tLoss: 392.996002\n",
      "====> Epoch: 351 Average train loss: 256.2318\n",
      "====> Epoch: 351 Average test loss: 944.4013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 352 [0/2589 (0%)]\tLoss: 166.007904\n",
      "Train Epoch: 352 [300/2589 (12%)]\tLoss: 159.886719\n",
      "Train Epoch: 352 [600/2589 (23%)]\tLoss: 221.948730\n",
      "Train Epoch: 352 [900/2589 (35%)]\tLoss: 404.871704\n",
      "Train Epoch: 352 [1200/2589 (46%)]\tLoss: 330.837769\n",
      "Train Epoch: 352 [1500/2589 (58%)]\tLoss: 254.361160\n",
      "Train Epoch: 352 [1800/2589 (70%)]\tLoss: 286.453339\n",
      "Train Epoch: 352 [2100/2589 (81%)]\tLoss: 217.613983\n",
      "Train Epoch: 352 [2400/2589 (93%)]\tLoss: 242.596100\n",
      "====> Epoch: 352 Average train loss: 265.4568\n",
      "====> Epoch: 352 Average test loss: 974.4774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 353 [0/2589 (0%)]\tLoss: 164.435608\n",
      "Train Epoch: 353 [300/2589 (12%)]\tLoss: 268.442444\n",
      "Train Epoch: 353 [600/2589 (23%)]\tLoss: 200.898972\n",
      "Train Epoch: 353 [900/2589 (35%)]\tLoss: 213.494339\n",
      "Train Epoch: 353 [1200/2589 (46%)]\tLoss: 222.602615\n",
      "Train Epoch: 353 [1500/2589 (58%)]\tLoss: 208.999557\n",
      "Train Epoch: 353 [1800/2589 (70%)]\tLoss: 239.697540\n",
      "Train Epoch: 353 [2100/2589 (81%)]\tLoss: 281.537994\n",
      "Train Epoch: 353 [2400/2589 (93%)]\tLoss: 242.520248\n",
      "====> Epoch: 353 Average train loss: 253.6762\n",
      "====> Epoch: 353 Average test loss: 959.7214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 354 [0/2589 (0%)]\tLoss: 313.387817\n",
      "Train Epoch: 354 [300/2589 (12%)]\tLoss: 252.489273\n",
      "Train Epoch: 354 [600/2589 (23%)]\tLoss: 183.216599\n",
      "Train Epoch: 354 [900/2589 (35%)]\tLoss: 195.393555\n",
      "Train Epoch: 354 [1200/2589 (46%)]\tLoss: 355.404144\n",
      "Train Epoch: 354 [1500/2589 (58%)]\tLoss: 203.293060\n",
      "Train Epoch: 354 [1800/2589 (70%)]\tLoss: 270.208496\n",
      "Train Epoch: 354 [2100/2589 (81%)]\tLoss: 320.701599\n",
      "Train Epoch: 354 [2400/2589 (93%)]\tLoss: 207.684219\n",
      "====> Epoch: 354 Average train loss: 260.1967\n",
      "====> Epoch: 354 Average test loss: 946.2910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 355 [0/2589 (0%)]\tLoss: 253.620224\n",
      "Train Epoch: 355 [300/2589 (12%)]\tLoss: 140.446457\n",
      "Train Epoch: 355 [600/2589 (23%)]\tLoss: 240.810226\n",
      "Train Epoch: 355 [900/2589 (35%)]\tLoss: 314.010315\n",
      "Train Epoch: 355 [1200/2589 (46%)]\tLoss: 186.514755\n",
      "Train Epoch: 355 [1500/2589 (58%)]\tLoss: 206.369553\n",
      "Train Epoch: 355 [1800/2589 (70%)]\tLoss: 212.525909\n",
      "Train Epoch: 355 [2100/2589 (81%)]\tLoss: 232.797012\n",
      "Train Epoch: 355 [2400/2589 (93%)]\tLoss: 358.665863\n",
      "====> Epoch: 355 Average train loss: 265.4736\n",
      "====> Epoch: 355 Average test loss: 937.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 356 [0/2589 (0%)]\tLoss: 218.950760\n",
      "Train Epoch: 356 [300/2589 (12%)]\tLoss: 243.163239\n",
      "Train Epoch: 356 [600/2589 (23%)]\tLoss: 238.161667\n",
      "Train Epoch: 356 [900/2589 (35%)]\tLoss: 213.324905\n",
      "Train Epoch: 356 [1200/2589 (46%)]\tLoss: 221.304001\n",
      "Train Epoch: 356 [1500/2589 (58%)]\tLoss: 334.078430\n",
      "Train Epoch: 356 [1800/2589 (70%)]\tLoss: 231.939743\n",
      "Train Epoch: 356 [2100/2589 (81%)]\tLoss: 290.886505\n",
      "Train Epoch: 356 [2400/2589 (93%)]\tLoss: 225.325333\n",
      "====> Epoch: 356 Average train loss: 253.4973\n",
      "====> Epoch: 356 Average test loss: 936.0545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 357 [0/2589 (0%)]\tLoss: 221.936005\n",
      "Train Epoch: 357 [300/2589 (12%)]\tLoss: 261.805878\n",
      "Train Epoch: 357 [600/2589 (23%)]\tLoss: 196.028992\n",
      "Train Epoch: 357 [900/2589 (35%)]\tLoss: 287.870575\n",
      "Train Epoch: 357 [1200/2589 (46%)]\tLoss: 233.643845\n",
      "Train Epoch: 357 [1500/2589 (58%)]\tLoss: 284.528168\n",
      "Train Epoch: 357 [1800/2589 (70%)]\tLoss: 288.671356\n",
      "Train Epoch: 357 [2100/2589 (81%)]\tLoss: 237.687653\n",
      "Train Epoch: 357 [2400/2589 (93%)]\tLoss: 252.206924\n",
      "====> Epoch: 357 Average train loss: 243.2253\n",
      "====> Epoch: 357 Average test loss: 948.6334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 358 [0/2589 (0%)]\tLoss: 402.940735\n",
      "Train Epoch: 358 [300/2589 (12%)]\tLoss: 235.459930\n",
      "Train Epoch: 358 [600/2589 (23%)]\tLoss: 286.989899\n",
      "Train Epoch: 358 [900/2589 (35%)]\tLoss: 202.368683\n",
      "Train Epoch: 358 [1200/2589 (46%)]\tLoss: 320.007050\n",
      "Train Epoch: 358 [1500/2589 (58%)]\tLoss: 329.867310\n",
      "Train Epoch: 358 [1800/2589 (70%)]\tLoss: 307.400696\n",
      "Train Epoch: 358 [2100/2589 (81%)]\tLoss: 306.086609\n",
      "Train Epoch: 358 [2400/2589 (93%)]\tLoss: 189.233200\n",
      "====> Epoch: 358 Average train loss: 263.6834\n",
      "====> Epoch: 358 Average test loss: 929.8859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 359 [0/2589 (0%)]\tLoss: 248.234116\n",
      "Train Epoch: 359 [300/2589 (12%)]\tLoss: 171.006577\n",
      "Train Epoch: 359 [600/2589 (23%)]\tLoss: 174.849091\n",
      "Train Epoch: 359 [900/2589 (35%)]\tLoss: 185.528870\n",
      "Train Epoch: 359 [1200/2589 (46%)]\tLoss: 198.673050\n",
      "Train Epoch: 359 [1500/2589 (58%)]\tLoss: 181.639572\n",
      "Train Epoch: 359 [1800/2589 (70%)]\tLoss: 304.331085\n",
      "Train Epoch: 359 [2100/2589 (81%)]\tLoss: 202.970367\n",
      "Train Epoch: 359 [2400/2589 (93%)]\tLoss: 196.813812\n",
      "====> Epoch: 359 Average train loss: 246.8792\n",
      "====> Epoch: 359 Average test loss: 955.8262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 360 [0/2589 (0%)]\tLoss: 219.823883\n",
      "Train Epoch: 360 [300/2589 (12%)]\tLoss: 305.827728\n",
      "Train Epoch: 360 [600/2589 (23%)]\tLoss: 320.840485\n",
      "Train Epoch: 360 [900/2589 (35%)]\tLoss: 270.036407\n",
      "Train Epoch: 360 [1200/2589 (46%)]\tLoss: 306.980316\n",
      "Train Epoch: 360 [1500/2589 (58%)]\tLoss: 183.100540\n",
      "Train Epoch: 360 [1800/2589 (70%)]\tLoss: 240.769150\n",
      "Train Epoch: 360 [2100/2589 (81%)]\tLoss: 310.538055\n",
      "Train Epoch: 360 [2400/2589 (93%)]\tLoss: 180.973663\n",
      "====> Epoch: 360 Average train loss: 263.9293\n",
      "====> Epoch: 360 Average test loss: 937.1301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 361 [0/2589 (0%)]\tLoss: 244.498215\n",
      "Train Epoch: 361 [300/2589 (12%)]\tLoss: 448.055786\n",
      "Train Epoch: 361 [600/2589 (23%)]\tLoss: 289.296570\n",
      "Train Epoch: 361 [900/2589 (35%)]\tLoss: 239.837723\n",
      "Train Epoch: 361 [1200/2589 (46%)]\tLoss: 176.704269\n",
      "Train Epoch: 361 [1500/2589 (58%)]\tLoss: 183.482620\n",
      "Train Epoch: 361 [1800/2589 (70%)]\tLoss: 226.535461\n",
      "Train Epoch: 361 [2100/2589 (81%)]\tLoss: 248.062805\n",
      "Train Epoch: 361 [2400/2589 (93%)]\tLoss: 219.267899\n",
      "====> Epoch: 361 Average train loss: 258.2462\n",
      "====> Epoch: 361 Average test loss: 936.5776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 362 [0/2589 (0%)]\tLoss: 138.480316\n",
      "Train Epoch: 362 [300/2589 (12%)]\tLoss: 306.478363\n",
      "Train Epoch: 362 [600/2589 (23%)]\tLoss: 187.258163\n",
      "Train Epoch: 362 [900/2589 (35%)]\tLoss: 217.048889\n",
      "Train Epoch: 362 [1200/2589 (46%)]\tLoss: 235.330032\n",
      "Train Epoch: 362 [1500/2589 (58%)]\tLoss: 228.714874\n",
      "Train Epoch: 362 [1800/2589 (70%)]\tLoss: 389.810089\n",
      "Train Epoch: 362 [2100/2589 (81%)]\tLoss: 306.004120\n",
      "Train Epoch: 362 [2400/2589 (93%)]\tLoss: 317.051971\n",
      "====> Epoch: 362 Average train loss: 247.2429\n",
      "====> Epoch: 362 Average test loss: 953.4880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 363 [0/2589 (0%)]\tLoss: 292.805298\n",
      "Train Epoch: 363 [300/2589 (12%)]\tLoss: 193.947586\n",
      "Train Epoch: 363 [600/2589 (23%)]\tLoss: 209.883255\n",
      "Train Epoch: 363 [900/2589 (35%)]\tLoss: 233.219971\n",
      "Train Epoch: 363 [1200/2589 (46%)]\tLoss: 250.868103\n",
      "Train Epoch: 363 [1500/2589 (58%)]\tLoss: 299.713348\n",
      "Train Epoch: 363 [1800/2589 (70%)]\tLoss: 302.847534\n",
      "Train Epoch: 363 [2100/2589 (81%)]\tLoss: 251.470978\n",
      "Train Epoch: 363 [2400/2589 (93%)]\tLoss: 215.636627\n",
      "====> Epoch: 363 Average train loss: 264.2370\n",
      "====> Epoch: 363 Average test loss: 930.0495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 364 [0/2589 (0%)]\tLoss: 281.292175\n",
      "Train Epoch: 364 [300/2589 (12%)]\tLoss: 199.482239\n",
      "Train Epoch: 364 [600/2589 (23%)]\tLoss: 194.015625\n",
      "Train Epoch: 364 [900/2589 (35%)]\tLoss: 270.741730\n",
      "Train Epoch: 364 [1200/2589 (46%)]\tLoss: 238.478226\n",
      "Train Epoch: 364 [1500/2589 (58%)]\tLoss: 255.955276\n",
      "Train Epoch: 364 [1800/2589 (70%)]\tLoss: 172.544922\n",
      "Train Epoch: 364 [2100/2589 (81%)]\tLoss: 244.800674\n",
      "Train Epoch: 364 [2400/2589 (93%)]\tLoss: 245.959244\n",
      "====> Epoch: 364 Average train loss: 264.2267\n",
      "====> Epoch: 364 Average test loss: 935.4619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 365 [0/2589 (0%)]\tLoss: 197.271881\n",
      "Train Epoch: 365 [300/2589 (12%)]\tLoss: 261.125519\n",
      "Train Epoch: 365 [600/2589 (23%)]\tLoss: 296.344177\n",
      "Train Epoch: 365 [900/2589 (35%)]\tLoss: 216.577133\n",
      "Train Epoch: 365 [1200/2589 (46%)]\tLoss: 493.636383\n",
      "Train Epoch: 365 [1500/2589 (58%)]\tLoss: 397.377991\n",
      "Train Epoch: 365 [1800/2589 (70%)]\tLoss: 274.675903\n",
      "Train Epoch: 365 [2100/2589 (81%)]\tLoss: 406.837616\n",
      "Train Epoch: 365 [2400/2589 (93%)]\tLoss: 206.723160\n",
      "====> Epoch: 365 Average train loss: 254.0549\n",
      "====> Epoch: 365 Average test loss: 945.0838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 366 [0/2589 (0%)]\tLoss: 239.087158\n",
      "Train Epoch: 366 [300/2589 (12%)]\tLoss: 273.386536\n",
      "Train Epoch: 366 [600/2589 (23%)]\tLoss: 323.308289\n",
      "Train Epoch: 366 [900/2589 (35%)]\tLoss: 221.330399\n",
      "Train Epoch: 366 [1200/2589 (46%)]\tLoss: 198.336929\n",
      "Train Epoch: 366 [1500/2589 (58%)]\tLoss: 196.882034\n",
      "Train Epoch: 366 [1800/2589 (70%)]\tLoss: 252.319473\n",
      "Train Epoch: 366 [2100/2589 (81%)]\tLoss: 439.087585\n",
      "Train Epoch: 366 [2400/2589 (93%)]\tLoss: 215.278030\n",
      "====> Epoch: 366 Average train loss: 249.0074\n",
      "====> Epoch: 366 Average test loss: 934.4811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 367 [0/2589 (0%)]\tLoss: 269.220673\n",
      "Train Epoch: 367 [300/2589 (12%)]\tLoss: 262.975555\n",
      "Train Epoch: 367 [600/2589 (23%)]\tLoss: 268.424866\n",
      "Train Epoch: 367 [900/2589 (35%)]\tLoss: 261.701538\n",
      "Train Epoch: 367 [1200/2589 (46%)]\tLoss: 381.750153\n",
      "Train Epoch: 367 [1500/2589 (58%)]\tLoss: 305.686340\n",
      "Train Epoch: 367 [1800/2589 (70%)]\tLoss: 294.036041\n",
      "Train Epoch: 367 [2100/2589 (81%)]\tLoss: 314.597260\n",
      "Train Epoch: 367 [2400/2589 (93%)]\tLoss: 218.581940\n",
      "====> Epoch: 367 Average train loss: 263.6609\n",
      "====> Epoch: 367 Average test loss: 953.8215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 368 [0/2589 (0%)]\tLoss: 283.932800\n",
      "Train Epoch: 368 [300/2589 (12%)]\tLoss: 169.323257\n",
      "Train Epoch: 368 [600/2589 (23%)]\tLoss: 240.098450\n",
      "Train Epoch: 368 [900/2589 (35%)]\tLoss: 218.989578\n",
      "Train Epoch: 368 [1200/2589 (46%)]\tLoss: 459.905273\n",
      "Train Epoch: 368 [1500/2589 (58%)]\tLoss: 260.544830\n",
      "Train Epoch: 368 [1800/2589 (70%)]\tLoss: 238.010574\n",
      "Train Epoch: 368 [2100/2589 (81%)]\tLoss: 106.866646\n",
      "Train Epoch: 368 [2400/2589 (93%)]\tLoss: 323.139282\n",
      "====> Epoch: 368 Average train loss: 246.3014\n",
      "====> Epoch: 368 Average test loss: 935.7025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 369 [0/2589 (0%)]\tLoss: 280.970825\n",
      "Train Epoch: 369 [300/2589 (12%)]\tLoss: 165.324875\n",
      "Train Epoch: 369 [600/2589 (23%)]\tLoss: 329.741821\n",
      "Train Epoch: 369 [900/2589 (35%)]\tLoss: 250.533035\n",
      "Train Epoch: 369 [1200/2589 (46%)]\tLoss: 225.082321\n",
      "Train Epoch: 369 [1500/2589 (58%)]\tLoss: 244.471100\n",
      "Train Epoch: 369 [1800/2589 (70%)]\tLoss: 228.405106\n",
      "Train Epoch: 369 [2100/2589 (81%)]\tLoss: 258.020691\n",
      "Train Epoch: 369 [2400/2589 (93%)]\tLoss: 147.301086\n",
      "====> Epoch: 369 Average train loss: 255.2820\n",
      "====> Epoch: 369 Average test loss: 944.5346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 370 [0/2589 (0%)]\tLoss: 251.602142\n",
      "Train Epoch: 370 [300/2589 (12%)]\tLoss: 282.066467\n",
      "Train Epoch: 370 [600/2589 (23%)]\tLoss: 418.403412\n",
      "Train Epoch: 370 [900/2589 (35%)]\tLoss: 302.785370\n",
      "Train Epoch: 370 [1200/2589 (46%)]\tLoss: 240.631027\n",
      "Train Epoch: 370 [1500/2589 (58%)]\tLoss: 273.792786\n",
      "Train Epoch: 370 [1800/2589 (70%)]\tLoss: 243.333893\n",
      "Train Epoch: 370 [2100/2589 (81%)]\tLoss: 209.474655\n",
      "Train Epoch: 370 [2400/2589 (93%)]\tLoss: 284.656860\n",
      "====> Epoch: 370 Average train loss: 260.7522\n",
      "====> Epoch: 370 Average test loss: 945.7510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 371 [0/2589 (0%)]\tLoss: 249.111633\n",
      "Train Epoch: 371 [300/2589 (12%)]\tLoss: 275.861908\n",
      "Train Epoch: 371 [600/2589 (23%)]\tLoss: 227.886963\n",
      "Train Epoch: 371 [900/2589 (35%)]\tLoss: 171.717453\n",
      "Train Epoch: 371 [1200/2589 (46%)]\tLoss: 343.352814\n",
      "Train Epoch: 371 [1500/2589 (58%)]\tLoss: 312.362610\n",
      "Train Epoch: 371 [1800/2589 (70%)]\tLoss: 257.917358\n",
      "Train Epoch: 371 [2100/2589 (81%)]\tLoss: 247.864075\n",
      "Train Epoch: 371 [2400/2589 (93%)]\tLoss: 309.485352\n",
      "====> Epoch: 371 Average train loss: 256.9789\n",
      "====> Epoch: 371 Average test loss: 939.1662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 372 [0/2589 (0%)]\tLoss: 315.369659\n",
      "Train Epoch: 372 [300/2589 (12%)]\tLoss: 231.147385\n",
      "Train Epoch: 372 [600/2589 (23%)]\tLoss: 185.164200\n",
      "Train Epoch: 372 [900/2589 (35%)]\tLoss: 281.882751\n",
      "Train Epoch: 372 [1200/2589 (46%)]\tLoss: 277.878143\n",
      "Train Epoch: 372 [1500/2589 (58%)]\tLoss: 388.429779\n",
      "Train Epoch: 372 [1800/2589 (70%)]\tLoss: 215.551270\n",
      "Train Epoch: 372 [2100/2589 (81%)]\tLoss: 294.543060\n",
      "Train Epoch: 372 [2400/2589 (93%)]\tLoss: 274.218048\n",
      "====> Epoch: 372 Average train loss: 266.1878\n",
      "====> Epoch: 372 Average test loss: 954.9326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 373 [0/2589 (0%)]\tLoss: 300.705597\n",
      "Train Epoch: 373 [300/2589 (12%)]\tLoss: 232.181152\n",
      "Train Epoch: 373 [600/2589 (23%)]\tLoss: 155.750793\n",
      "Train Epoch: 373 [900/2589 (35%)]\tLoss: 216.580338\n",
      "Train Epoch: 373 [1200/2589 (46%)]\tLoss: 267.684143\n",
      "Train Epoch: 373 [1500/2589 (58%)]\tLoss: 203.957016\n",
      "Train Epoch: 373 [1800/2589 (70%)]\tLoss: 229.213867\n",
      "Train Epoch: 373 [2100/2589 (81%)]\tLoss: 314.163422\n",
      "Train Epoch: 373 [2400/2589 (93%)]\tLoss: 236.135971\n",
      "====> Epoch: 373 Average train loss: 249.4835\n",
      "====> Epoch: 373 Average test loss: 951.4661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 374 [0/2589 (0%)]\tLoss: 280.317993\n",
      "Train Epoch: 374 [300/2589 (12%)]\tLoss: 228.932480\n",
      "Train Epoch: 374 [600/2589 (23%)]\tLoss: 269.956696\n",
      "Train Epoch: 374 [900/2589 (35%)]\tLoss: 344.743103\n",
      "Train Epoch: 374 [1200/2589 (46%)]\tLoss: 237.096283\n",
      "Train Epoch: 374 [1500/2589 (58%)]\tLoss: 204.093735\n",
      "Train Epoch: 374 [1800/2589 (70%)]\tLoss: 209.851593\n",
      "Train Epoch: 374 [2100/2589 (81%)]\tLoss: 312.744476\n",
      "Train Epoch: 374 [2400/2589 (93%)]\tLoss: 316.878998\n",
      "====> Epoch: 374 Average train loss: 260.0376\n",
      "====> Epoch: 374 Average test loss: 945.7491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 375 [0/2589 (0%)]\tLoss: 232.107025\n",
      "Train Epoch: 375 [300/2589 (12%)]\tLoss: 252.725555\n",
      "Train Epoch: 375 [600/2589 (23%)]\tLoss: 222.988632\n",
      "Train Epoch: 375 [900/2589 (35%)]\tLoss: 224.895279\n",
      "Train Epoch: 375 [1200/2589 (46%)]\tLoss: 230.277771\n",
      "Train Epoch: 375 [1500/2589 (58%)]\tLoss: 207.531586\n",
      "Train Epoch: 375 [1800/2589 (70%)]\tLoss: 267.463074\n",
      "Train Epoch: 375 [2100/2589 (81%)]\tLoss: 173.963593\n",
      "Train Epoch: 375 [2400/2589 (93%)]\tLoss: 220.338715\n",
      "====> Epoch: 375 Average train loss: 249.9332\n",
      "====> Epoch: 375 Average test loss: 920.1699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 376 [0/2589 (0%)]\tLoss: 215.366898\n",
      "Train Epoch: 376 [300/2589 (12%)]\tLoss: 321.032593\n",
      "Train Epoch: 376 [600/2589 (23%)]\tLoss: 284.090363\n",
      "Train Epoch: 376 [900/2589 (35%)]\tLoss: 303.409241\n",
      "Train Epoch: 376 [1200/2589 (46%)]\tLoss: 186.916367\n",
      "Train Epoch: 376 [1500/2589 (58%)]\tLoss: 240.663895\n",
      "Train Epoch: 376 [1800/2589 (70%)]\tLoss: 271.187897\n",
      "Train Epoch: 376 [2100/2589 (81%)]\tLoss: 272.673096\n",
      "Train Epoch: 376 [2400/2589 (93%)]\tLoss: 226.269669\n",
      "====> Epoch: 376 Average train loss: 251.5891\n",
      "====> Epoch: 376 Average test loss: 959.1415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 377 [0/2589 (0%)]\tLoss: 224.642441\n",
      "Train Epoch: 377 [300/2589 (12%)]\tLoss: 239.054794\n",
      "Train Epoch: 377 [600/2589 (23%)]\tLoss: 224.535797\n",
      "Train Epoch: 377 [900/2589 (35%)]\tLoss: 261.532379\n",
      "Train Epoch: 377 [1200/2589 (46%)]\tLoss: 287.045441\n",
      "Train Epoch: 377 [1500/2589 (58%)]\tLoss: 255.255722\n",
      "Train Epoch: 377 [1800/2589 (70%)]\tLoss: 323.792755\n",
      "Train Epoch: 377 [2100/2589 (81%)]\tLoss: 193.711594\n",
      "Train Epoch: 377 [2400/2589 (93%)]\tLoss: 248.045502\n",
      "====> Epoch: 377 Average train loss: 254.4917\n",
      "====> Epoch: 377 Average test loss: 937.5497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 378 [0/2589 (0%)]\tLoss: 314.950836\n",
      "Train Epoch: 378 [300/2589 (12%)]\tLoss: 665.476013\n",
      "Train Epoch: 378 [600/2589 (23%)]\tLoss: 272.499603\n",
      "Train Epoch: 378 [900/2589 (35%)]\tLoss: 153.417145\n",
      "Train Epoch: 378 [1200/2589 (46%)]\tLoss: 302.589844\n",
      "Train Epoch: 378 [1500/2589 (58%)]\tLoss: 299.492218\n",
      "Train Epoch: 378 [1800/2589 (70%)]\tLoss: 231.761002\n",
      "Train Epoch: 378 [2100/2589 (81%)]\tLoss: 275.847595\n",
      "Train Epoch: 378 [2400/2589 (93%)]\tLoss: 198.126816\n",
      "====> Epoch: 378 Average train loss: 255.3538\n",
      "====> Epoch: 378 Average test loss: 940.1991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 379 [0/2589 (0%)]\tLoss: 210.749512\n",
      "Train Epoch: 379 [300/2589 (12%)]\tLoss: 281.220886\n",
      "Train Epoch: 379 [600/2589 (23%)]\tLoss: 264.220428\n",
      "Train Epoch: 379 [900/2589 (35%)]\tLoss: 192.478714\n",
      "Train Epoch: 379 [1200/2589 (46%)]\tLoss: 273.083557\n",
      "Train Epoch: 379 [1500/2589 (58%)]\tLoss: 274.984039\n",
      "Train Epoch: 379 [1800/2589 (70%)]\tLoss: 273.469727\n",
      "Train Epoch: 379 [2100/2589 (81%)]\tLoss: 263.600220\n",
      "Train Epoch: 379 [2400/2589 (93%)]\tLoss: 236.622330\n",
      "====> Epoch: 379 Average train loss: 261.4786\n",
      "====> Epoch: 379 Average test loss: 944.0287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 380 [0/2589 (0%)]\tLoss: 209.036926\n",
      "Train Epoch: 380 [300/2589 (12%)]\tLoss: 220.916702\n",
      "Train Epoch: 380 [600/2589 (23%)]\tLoss: 284.089081\n",
      "Train Epoch: 380 [900/2589 (35%)]\tLoss: 184.609909\n",
      "Train Epoch: 380 [1200/2589 (46%)]\tLoss: 316.978302\n",
      "Train Epoch: 380 [1500/2589 (58%)]\tLoss: 254.058105\n",
      "Train Epoch: 380 [1800/2589 (70%)]\tLoss: 222.224442\n",
      "Train Epoch: 380 [2100/2589 (81%)]\tLoss: 199.767517\n",
      "Train Epoch: 380 [2400/2589 (93%)]\tLoss: 233.783371\n",
      "====> Epoch: 380 Average train loss: 258.8616\n",
      "====> Epoch: 380 Average test loss: 962.0023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 381 [0/2589 (0%)]\tLoss: 240.485184\n",
      "Train Epoch: 381 [300/2589 (12%)]\tLoss: 261.773407\n",
      "Train Epoch: 381 [600/2589 (23%)]\tLoss: 220.639359\n",
      "Train Epoch: 381 [900/2589 (35%)]\tLoss: 213.977890\n",
      "Train Epoch: 381 [1200/2589 (46%)]\tLoss: 283.313202\n",
      "Train Epoch: 381 [1500/2589 (58%)]\tLoss: 349.688599\n",
      "Train Epoch: 381 [1800/2589 (70%)]\tLoss: 280.948334\n",
      "Train Epoch: 381 [2100/2589 (81%)]\tLoss: 268.267151\n",
      "Train Epoch: 381 [2400/2589 (93%)]\tLoss: 260.214600\n",
      "====> Epoch: 381 Average train loss: 263.2006\n",
      "====> Epoch: 381 Average test loss: 939.7959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 382 [0/2589 (0%)]\tLoss: 247.558746\n",
      "Train Epoch: 382 [300/2589 (12%)]\tLoss: 307.180237\n",
      "Train Epoch: 382 [600/2589 (23%)]\tLoss: 267.085846\n",
      "Train Epoch: 382 [900/2589 (35%)]\tLoss: 421.244995\n",
      "Train Epoch: 382 [1200/2589 (46%)]\tLoss: 186.687790\n",
      "Train Epoch: 382 [1500/2589 (58%)]\tLoss: 286.465637\n",
      "Train Epoch: 382 [1800/2589 (70%)]\tLoss: 218.316711\n",
      "Train Epoch: 382 [2100/2589 (81%)]\tLoss: 197.685806\n",
      "Train Epoch: 382 [2400/2589 (93%)]\tLoss: 170.559921\n",
      "====> Epoch: 382 Average train loss: 247.2971\n",
      "====> Epoch: 382 Average test loss: 958.1138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 383 [0/2589 (0%)]\tLoss: 216.863708\n",
      "Train Epoch: 383 [300/2589 (12%)]\tLoss: 203.998856\n",
      "Train Epoch: 383 [600/2589 (23%)]\tLoss: 210.652084\n",
      "Train Epoch: 383 [900/2589 (35%)]\tLoss: 260.648315\n",
      "Train Epoch: 383 [1200/2589 (46%)]\tLoss: 309.906158\n",
      "Train Epoch: 383 [1500/2589 (58%)]\tLoss: 246.219452\n",
      "Train Epoch: 383 [1800/2589 (70%)]\tLoss: 230.208588\n",
      "Train Epoch: 383 [2100/2589 (81%)]\tLoss: 283.611206\n",
      "Train Epoch: 383 [2400/2589 (93%)]\tLoss: 169.558655\n",
      "====> Epoch: 383 Average train loss: 251.4205\n",
      "====> Epoch: 383 Average test loss: 939.3318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 384 [0/2589 (0%)]\tLoss: 223.110596\n",
      "Train Epoch: 384 [300/2589 (12%)]\tLoss: 195.707275\n",
      "Train Epoch: 384 [600/2589 (23%)]\tLoss: 199.938919\n",
      "Train Epoch: 384 [900/2589 (35%)]\tLoss: 268.494690\n",
      "Train Epoch: 384 [1200/2589 (46%)]\tLoss: 253.470917\n",
      "Train Epoch: 384 [1500/2589 (58%)]\tLoss: 257.880219\n",
      "Train Epoch: 384 [1800/2589 (70%)]\tLoss: 173.252197\n",
      "Train Epoch: 384 [2100/2589 (81%)]\tLoss: 162.703201\n",
      "Train Epoch: 384 [2400/2589 (93%)]\tLoss: 156.108429\n",
      "====> Epoch: 384 Average train loss: 266.7634\n",
      "====> Epoch: 384 Average test loss: 931.5944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 385 [0/2589 (0%)]\tLoss: 267.297852\n",
      "Train Epoch: 385 [300/2589 (12%)]\tLoss: 245.289902\n",
      "Train Epoch: 385 [600/2589 (23%)]\tLoss: 284.792267\n",
      "Train Epoch: 385 [900/2589 (35%)]\tLoss: 298.715485\n",
      "Train Epoch: 385 [1200/2589 (46%)]\tLoss: 297.748901\n",
      "Train Epoch: 385 [1500/2589 (58%)]\tLoss: 177.349777\n",
      "Train Epoch: 385 [1800/2589 (70%)]\tLoss: 350.725555\n",
      "Train Epoch: 385 [2100/2589 (81%)]\tLoss: 221.216446\n",
      "Train Epoch: 385 [2400/2589 (93%)]\tLoss: 178.667496\n",
      "====> Epoch: 385 Average train loss: 264.7143\n",
      "====> Epoch: 385 Average test loss: 928.8928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 386 [0/2589 (0%)]\tLoss: 254.624451\n",
      "Train Epoch: 386 [300/2589 (12%)]\tLoss: 249.282639\n",
      "Train Epoch: 386 [600/2589 (23%)]\tLoss: 235.630219\n",
      "Train Epoch: 386 [900/2589 (35%)]\tLoss: 207.816620\n",
      "Train Epoch: 386 [1200/2589 (46%)]\tLoss: 237.869736\n",
      "Train Epoch: 386 [1500/2589 (58%)]\tLoss: 192.724625\n",
      "Train Epoch: 386 [1800/2589 (70%)]\tLoss: 219.968857\n",
      "Train Epoch: 386 [2100/2589 (81%)]\tLoss: 197.189148\n",
      "Train Epoch: 386 [2400/2589 (93%)]\tLoss: 313.685059\n",
      "====> Epoch: 386 Average train loss: 252.4182\n",
      "====> Epoch: 386 Average test loss: 949.6311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 387 [0/2589 (0%)]\tLoss: 202.845505\n",
      "Train Epoch: 387 [300/2589 (12%)]\tLoss: 187.758408\n",
      "Train Epoch: 387 [600/2589 (23%)]\tLoss: 307.995117\n",
      "Train Epoch: 387 [900/2589 (35%)]\tLoss: 199.743256\n",
      "Train Epoch: 387 [1200/2589 (46%)]\tLoss: 268.084839\n",
      "Train Epoch: 387 [1500/2589 (58%)]\tLoss: 219.972183\n",
      "Train Epoch: 387 [1800/2589 (70%)]\tLoss: 261.338684\n",
      "Train Epoch: 387 [2100/2589 (81%)]\tLoss: 233.199844\n",
      "Train Epoch: 387 [2400/2589 (93%)]\tLoss: 247.152313\n",
      "====> Epoch: 387 Average train loss: 244.5802\n",
      "====> Epoch: 387 Average test loss: 935.8424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 388 [0/2589 (0%)]\tLoss: 231.780731\n",
      "Train Epoch: 388 [300/2589 (12%)]\tLoss: 247.509460\n",
      "Train Epoch: 388 [600/2589 (23%)]\tLoss: 246.893066\n",
      "Train Epoch: 388 [900/2589 (35%)]\tLoss: 245.680450\n",
      "Train Epoch: 388 [1200/2589 (46%)]\tLoss: 234.475723\n",
      "Train Epoch: 388 [1500/2589 (58%)]\tLoss: 195.062302\n",
      "Train Epoch: 388 [1800/2589 (70%)]\tLoss: 510.532715\n",
      "Train Epoch: 388 [2100/2589 (81%)]\tLoss: 271.305695\n",
      "Train Epoch: 388 [2400/2589 (93%)]\tLoss: 301.109833\n",
      "====> Epoch: 388 Average train loss: 251.2036\n",
      "====> Epoch: 388 Average test loss: 939.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 389 [0/2589 (0%)]\tLoss: 183.047287\n",
      "Train Epoch: 389 [300/2589 (12%)]\tLoss: 217.309921\n",
      "Train Epoch: 389 [600/2589 (23%)]\tLoss: 297.004272\n",
      "Train Epoch: 389 [900/2589 (35%)]\tLoss: 424.085327\n",
      "Train Epoch: 389 [1200/2589 (46%)]\tLoss: 311.598724\n",
      "Train Epoch: 389 [1500/2589 (58%)]\tLoss: 267.240479\n",
      "Train Epoch: 389 [1800/2589 (70%)]\tLoss: 235.315002\n",
      "Train Epoch: 389 [2100/2589 (81%)]\tLoss: 219.040359\n",
      "Train Epoch: 389 [2400/2589 (93%)]\tLoss: 234.454788\n",
      "====> Epoch: 389 Average train loss: 254.1225\n",
      "====> Epoch: 389 Average test loss: 947.2115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 390 [0/2589 (0%)]\tLoss: 211.216492\n",
      "Train Epoch: 390 [300/2589 (12%)]\tLoss: 238.121445\n",
      "Train Epoch: 390 [600/2589 (23%)]\tLoss: 248.482162\n",
      "Train Epoch: 390 [900/2589 (35%)]\tLoss: 245.317383\n",
      "Train Epoch: 390 [1200/2589 (46%)]\tLoss: 203.977859\n",
      "Train Epoch: 390 [1500/2589 (58%)]\tLoss: 238.562424\n",
      "Train Epoch: 390 [1800/2589 (70%)]\tLoss: 256.800720\n",
      "Train Epoch: 390 [2100/2589 (81%)]\tLoss: 196.353668\n",
      "Train Epoch: 390 [2400/2589 (93%)]\tLoss: 211.208206\n",
      "====> Epoch: 390 Average train loss: 252.3188\n",
      "====> Epoch: 390 Average test loss: 945.7823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 391 [0/2589 (0%)]\tLoss: 244.767410\n",
      "Train Epoch: 391 [300/2589 (12%)]\tLoss: 274.363770\n",
      "Train Epoch: 391 [600/2589 (23%)]\tLoss: 242.487076\n",
      "Train Epoch: 391 [900/2589 (35%)]\tLoss: 216.358124\n",
      "Train Epoch: 391 [1200/2589 (46%)]\tLoss: 215.467590\n",
      "Train Epoch: 391 [1500/2589 (58%)]\tLoss: 198.905853\n",
      "Train Epoch: 391 [1800/2589 (70%)]\tLoss: 260.756500\n",
      "Train Epoch: 391 [2100/2589 (81%)]\tLoss: 357.689758\n",
      "Train Epoch: 391 [2400/2589 (93%)]\tLoss: 162.181366\n",
      "====> Epoch: 391 Average train loss: 248.7729\n",
      "====> Epoch: 391 Average test loss: 925.3140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 392 [0/2589 (0%)]\tLoss: 208.171463\n",
      "Train Epoch: 392 [300/2589 (12%)]\tLoss: 174.721329\n",
      "Train Epoch: 392 [600/2589 (23%)]\tLoss: 245.187897\n",
      "Train Epoch: 392 [900/2589 (35%)]\tLoss: 223.059387\n",
      "Train Epoch: 392 [1200/2589 (46%)]\tLoss: 216.879257\n",
      "Train Epoch: 392 [1500/2589 (58%)]\tLoss: 252.025940\n",
      "Train Epoch: 392 [1800/2589 (70%)]\tLoss: 295.888763\n",
      "Train Epoch: 392 [2100/2589 (81%)]\tLoss: 259.774994\n",
      "Train Epoch: 392 [2400/2589 (93%)]\tLoss: 404.828217\n",
      "====> Epoch: 392 Average train loss: 260.7106\n",
      "====> Epoch: 392 Average test loss: 927.3264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 393 [0/2589 (0%)]\tLoss: 199.763214\n",
      "Train Epoch: 393 [300/2589 (12%)]\tLoss: 311.492371\n",
      "Train Epoch: 393 [600/2589 (23%)]\tLoss: 198.907059\n",
      "Train Epoch: 393 [900/2589 (35%)]\tLoss: 190.672882\n",
      "Train Epoch: 393 [1200/2589 (46%)]\tLoss: 271.176819\n",
      "Train Epoch: 393 [1500/2589 (58%)]\tLoss: 450.114410\n",
      "Train Epoch: 393 [1800/2589 (70%)]\tLoss: 209.536652\n",
      "Train Epoch: 393 [2100/2589 (81%)]\tLoss: 292.182495\n",
      "Train Epoch: 393 [2400/2589 (93%)]\tLoss: 228.734131\n",
      "====> Epoch: 393 Average train loss: 260.4640\n",
      "====> Epoch: 393 Average test loss: 926.0548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 394 [0/2589 (0%)]\tLoss: 212.165192\n",
      "Train Epoch: 394 [300/2589 (12%)]\tLoss: 142.433685\n",
      "Train Epoch: 394 [600/2589 (23%)]\tLoss: 247.071609\n",
      "Train Epoch: 394 [900/2589 (35%)]\tLoss: 280.852631\n",
      "Train Epoch: 394 [1200/2589 (46%)]\tLoss: 187.520416\n",
      "Train Epoch: 394 [1500/2589 (58%)]\tLoss: 274.126984\n",
      "Train Epoch: 394 [1800/2589 (70%)]\tLoss: 180.556808\n",
      "Train Epoch: 394 [2100/2589 (81%)]\tLoss: 227.113358\n",
      "Train Epoch: 394 [2400/2589 (93%)]\tLoss: 210.651184\n",
      "====> Epoch: 394 Average train loss: 249.8428\n",
      "====> Epoch: 394 Average test loss: 915.4385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 395 [0/2589 (0%)]\tLoss: 216.877106\n",
      "Train Epoch: 395 [300/2589 (12%)]\tLoss: 212.558807\n",
      "Train Epoch: 395 [600/2589 (23%)]\tLoss: 222.997055\n",
      "Train Epoch: 395 [900/2589 (35%)]\tLoss: 191.176590\n",
      "Train Epoch: 395 [1200/2589 (46%)]\tLoss: 262.137268\n",
      "Train Epoch: 395 [1500/2589 (58%)]\tLoss: 307.141418\n",
      "Train Epoch: 395 [1800/2589 (70%)]\tLoss: 177.440216\n",
      "Train Epoch: 395 [2100/2589 (81%)]\tLoss: 240.178482\n",
      "Train Epoch: 395 [2400/2589 (93%)]\tLoss: 233.538162\n",
      "====> Epoch: 395 Average train loss: 259.1407\n",
      "====> Epoch: 395 Average test loss: 921.6974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 396 [0/2589 (0%)]\tLoss: 193.997971\n",
      "Train Epoch: 396 [300/2589 (12%)]\tLoss: 210.992371\n",
      "Train Epoch: 396 [600/2589 (23%)]\tLoss: 321.169434\n",
      "Train Epoch: 396 [900/2589 (35%)]\tLoss: 299.616547\n",
      "Train Epoch: 396 [1200/2589 (46%)]\tLoss: 254.835938\n",
      "Train Epoch: 396 [1500/2589 (58%)]\tLoss: 198.804001\n",
      "Train Epoch: 396 [1800/2589 (70%)]\tLoss: 207.662445\n",
      "Train Epoch: 396 [2100/2589 (81%)]\tLoss: 302.636871\n",
      "Train Epoch: 396 [2400/2589 (93%)]\tLoss: 357.522583\n",
      "====> Epoch: 396 Average train loss: 251.2978\n",
      "====> Epoch: 396 Average test loss: 956.8038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 397 [0/2589 (0%)]\tLoss: 253.839310\n",
      "Train Epoch: 397 [300/2589 (12%)]\tLoss: 247.924698\n",
      "Train Epoch: 397 [600/2589 (23%)]\tLoss: 202.410614\n",
      "Train Epoch: 397 [900/2589 (35%)]\tLoss: 191.639587\n",
      "Train Epoch: 397 [1200/2589 (46%)]\tLoss: 236.904083\n",
      "Train Epoch: 397 [1500/2589 (58%)]\tLoss: 250.051819\n",
      "Train Epoch: 397 [1800/2589 (70%)]\tLoss: 217.025238\n",
      "Train Epoch: 397 [2100/2589 (81%)]\tLoss: 213.856293\n",
      "Train Epoch: 397 [2400/2589 (93%)]\tLoss: 322.961395\n",
      "====> Epoch: 397 Average train loss: 251.9208\n",
      "====> Epoch: 397 Average test loss: 960.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 398 [0/2589 (0%)]\tLoss: 222.948914\n",
      "Train Epoch: 398 [300/2589 (12%)]\tLoss: 304.671417\n",
      "Train Epoch: 398 [600/2589 (23%)]\tLoss: 210.720215\n",
      "Train Epoch: 398 [900/2589 (35%)]\tLoss: 189.240128\n",
      "Train Epoch: 398 [1200/2589 (46%)]\tLoss: 303.432739\n",
      "Train Epoch: 398 [1500/2589 (58%)]\tLoss: 188.387039\n",
      "Train Epoch: 398 [1800/2589 (70%)]\tLoss: 202.599518\n",
      "Train Epoch: 398 [2100/2589 (81%)]\tLoss: 221.277283\n",
      "Train Epoch: 398 [2400/2589 (93%)]\tLoss: 193.628510\n",
      "====> Epoch: 398 Average train loss: 236.6460\n",
      "====> Epoch: 398 Average test loss: 952.6353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 399 [0/2589 (0%)]\tLoss: 278.859589\n",
      "Train Epoch: 399 [300/2589 (12%)]\tLoss: 201.032166\n",
      "Train Epoch: 399 [600/2589 (23%)]\tLoss: 281.577240\n",
      "Train Epoch: 399 [900/2589 (35%)]\tLoss: 238.602142\n",
      "Train Epoch: 399 [1200/2589 (46%)]\tLoss: 188.779953\n",
      "Train Epoch: 399 [1500/2589 (58%)]\tLoss: 373.828400\n",
      "Train Epoch: 399 [1800/2589 (70%)]\tLoss: 226.569107\n",
      "Train Epoch: 399 [2100/2589 (81%)]\tLoss: 255.627365\n",
      "Train Epoch: 399 [2400/2589 (93%)]\tLoss: 295.097961\n",
      "====> Epoch: 399 Average train loss: 247.9621\n",
      "====> Epoch: 399 Average test loss: 932.2720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 400 [0/2589 (0%)]\tLoss: 345.275208\n",
      "Train Epoch: 400 [300/2589 (12%)]\tLoss: 188.865982\n",
      "Train Epoch: 400 [600/2589 (23%)]\tLoss: 245.478729\n",
      "Train Epoch: 400 [900/2589 (35%)]\tLoss: 267.609650\n",
      "Train Epoch: 400 [1200/2589 (46%)]\tLoss: 234.076599\n",
      "Train Epoch: 400 [1500/2589 (58%)]\tLoss: 232.227509\n",
      "Train Epoch: 400 [1800/2589 (70%)]\tLoss: 207.041061\n",
      "Train Epoch: 400 [2100/2589 (81%)]\tLoss: 189.465668\n",
      "Train Epoch: 400 [2400/2589 (93%)]\tLoss: 263.673706\n",
      "====> Epoch: 400 Average train loss: 251.2146\n",
      "====> Epoch: 400 Average test loss: 953.0095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 401 [0/2589 (0%)]\tLoss: 205.116180\n",
      "Train Epoch: 401 [300/2589 (12%)]\tLoss: 248.865768\n",
      "Train Epoch: 401 [600/2589 (23%)]\tLoss: 209.090012\n",
      "Train Epoch: 401 [900/2589 (35%)]\tLoss: 427.007385\n",
      "Train Epoch: 401 [1200/2589 (46%)]\tLoss: 212.798813\n",
      "Train Epoch: 401 [1500/2589 (58%)]\tLoss: 341.717224\n",
      "Train Epoch: 401 [1800/2589 (70%)]\tLoss: 221.377838\n",
      "Train Epoch: 401 [2100/2589 (81%)]\tLoss: 166.245453\n",
      "Train Epoch: 401 [2400/2589 (93%)]\tLoss: 194.902405\n",
      "====> Epoch: 401 Average train loss: 246.9460\n",
      "====> Epoch: 401 Average test loss: 934.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 402 [0/2589 (0%)]\tLoss: 368.393219\n",
      "Train Epoch: 402 [300/2589 (12%)]\tLoss: 278.380646\n",
      "Train Epoch: 402 [600/2589 (23%)]\tLoss: 443.679688\n",
      "Train Epoch: 402 [900/2589 (35%)]\tLoss: 324.400238\n",
      "Train Epoch: 402 [1200/2589 (46%)]\tLoss: 226.317047\n",
      "Train Epoch: 402 [1500/2589 (58%)]\tLoss: 200.127213\n",
      "Train Epoch: 402 [1800/2589 (70%)]\tLoss: 175.463577\n",
      "Train Epoch: 402 [2100/2589 (81%)]\tLoss: 266.002228\n",
      "Train Epoch: 402 [2400/2589 (93%)]\tLoss: 228.923737\n",
      "====> Epoch: 402 Average train loss: 264.9139\n",
      "====> Epoch: 402 Average test loss: 934.2823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 403 [0/2589 (0%)]\tLoss: 254.689423\n",
      "Train Epoch: 403 [300/2589 (12%)]\tLoss: 182.477859\n",
      "Train Epoch: 403 [600/2589 (23%)]\tLoss: 439.245056\n",
      "Train Epoch: 403 [900/2589 (35%)]\tLoss: 180.881851\n",
      "Train Epoch: 403 [1200/2589 (46%)]\tLoss: 230.174545\n",
      "Train Epoch: 403 [1500/2589 (58%)]\tLoss: 206.124710\n",
      "Train Epoch: 403 [1800/2589 (70%)]\tLoss: 225.688828\n",
      "Train Epoch: 403 [2100/2589 (81%)]\tLoss: 197.364456\n",
      "Train Epoch: 403 [2400/2589 (93%)]\tLoss: 272.841461\n",
      "====> Epoch: 403 Average train loss: 246.1090\n",
      "====> Epoch: 403 Average test loss: 939.6639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 404 [0/2589 (0%)]\tLoss: 512.956970\n",
      "Train Epoch: 404 [300/2589 (12%)]\tLoss: 172.836929\n",
      "Train Epoch: 404 [600/2589 (23%)]\tLoss: 177.685028\n",
      "Train Epoch: 404 [900/2589 (35%)]\tLoss: 220.272598\n",
      "Train Epoch: 404 [1200/2589 (46%)]\tLoss: 302.587891\n",
      "Train Epoch: 404 [1500/2589 (58%)]\tLoss: 196.898117\n",
      "Train Epoch: 404 [1800/2589 (70%)]\tLoss: 231.785492\n",
      "Train Epoch: 404 [2100/2589 (81%)]\tLoss: 293.246155\n",
      "Train Epoch: 404 [2400/2589 (93%)]\tLoss: 230.323776\n",
      "====> Epoch: 404 Average train loss: 254.5652\n",
      "====> Epoch: 404 Average test loss: 962.0424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 405 [0/2589 (0%)]\tLoss: 212.291595\n",
      "Train Epoch: 405 [300/2589 (12%)]\tLoss: 228.499176\n",
      "Train Epoch: 405 [600/2589 (23%)]\tLoss: 291.212311\n",
      "Train Epoch: 405 [900/2589 (35%)]\tLoss: 275.819336\n",
      "Train Epoch: 405 [1200/2589 (46%)]\tLoss: 283.664276\n",
      "Train Epoch: 405 [1500/2589 (58%)]\tLoss: 257.617798\n",
      "Train Epoch: 405 [1800/2589 (70%)]\tLoss: 213.619919\n",
      "Train Epoch: 405 [2100/2589 (81%)]\tLoss: 239.271805\n",
      "Train Epoch: 405 [2400/2589 (93%)]\tLoss: 265.426636\n",
      "====> Epoch: 405 Average train loss: 242.9148\n",
      "====> Epoch: 405 Average test loss: 937.6823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 406 [0/2589 (0%)]\tLoss: 204.709488\n",
      "Train Epoch: 406 [300/2589 (12%)]\tLoss: 192.995590\n",
      "Train Epoch: 406 [600/2589 (23%)]\tLoss: 160.124161\n",
      "Train Epoch: 406 [900/2589 (35%)]\tLoss: 393.787170\n",
      "Train Epoch: 406 [1200/2589 (46%)]\tLoss: 240.370529\n",
      "Train Epoch: 406 [1500/2589 (58%)]\tLoss: 183.922531\n",
      "Train Epoch: 406 [1800/2589 (70%)]\tLoss: 283.120880\n",
      "Train Epoch: 406 [2100/2589 (81%)]\tLoss: 287.814453\n",
      "Train Epoch: 406 [2400/2589 (93%)]\tLoss: 333.913757\n",
      "====> Epoch: 406 Average train loss: 246.9130\n",
      "====> Epoch: 406 Average test loss: 952.0463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 407 [0/2589 (0%)]\tLoss: 176.499130\n",
      "Train Epoch: 407 [300/2589 (12%)]\tLoss: 199.292908\n",
      "Train Epoch: 407 [600/2589 (23%)]\tLoss: 244.035583\n",
      "Train Epoch: 407 [900/2589 (35%)]\tLoss: 275.520355\n",
      "Train Epoch: 407 [1200/2589 (46%)]\tLoss: 223.823547\n",
      "Train Epoch: 407 [1500/2589 (58%)]\tLoss: 216.952713\n",
      "Train Epoch: 407 [1800/2589 (70%)]\tLoss: 270.695038\n",
      "Train Epoch: 407 [2100/2589 (81%)]\tLoss: 178.633560\n",
      "Train Epoch: 407 [2400/2589 (93%)]\tLoss: 302.136414\n",
      "====> Epoch: 407 Average train loss: 251.8750\n",
      "====> Epoch: 407 Average test loss: 929.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 408 [0/2589 (0%)]\tLoss: 223.145859\n",
      "Train Epoch: 408 [300/2589 (12%)]\tLoss: 230.654617\n",
      "Train Epoch: 408 [600/2589 (23%)]\tLoss: 179.936615\n",
      "Train Epoch: 408 [900/2589 (35%)]\tLoss: 198.404495\n",
      "Train Epoch: 408 [1200/2589 (46%)]\tLoss: 277.625610\n",
      "Train Epoch: 408 [1500/2589 (58%)]\tLoss: 227.970566\n",
      "Train Epoch: 408 [1800/2589 (70%)]\tLoss: 232.931213\n",
      "Train Epoch: 408 [2100/2589 (81%)]\tLoss: 348.081146\n",
      "Train Epoch: 408 [2400/2589 (93%)]\tLoss: 276.284637\n",
      "====> Epoch: 408 Average train loss: 260.6438\n",
      "====> Epoch: 408 Average test loss: 928.3941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 409 [0/2589 (0%)]\tLoss: 380.887634\n",
      "Train Epoch: 409 [300/2589 (12%)]\tLoss: 226.666824\n",
      "Train Epoch: 409 [600/2589 (23%)]\tLoss: 261.885590\n",
      "Train Epoch: 409 [900/2589 (35%)]\tLoss: 339.356049\n",
      "Train Epoch: 409 [1200/2589 (46%)]\tLoss: 345.989594\n",
      "Train Epoch: 409 [1500/2589 (58%)]\tLoss: 199.514832\n",
      "Train Epoch: 409 [1800/2589 (70%)]\tLoss: 293.235443\n",
      "Train Epoch: 409 [2100/2589 (81%)]\tLoss: 195.389709\n",
      "Train Epoch: 409 [2400/2589 (93%)]\tLoss: 258.474670\n",
      "====> Epoch: 409 Average train loss: 258.1627\n",
      "====> Epoch: 409 Average test loss: 952.4744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 410 [0/2589 (0%)]\tLoss: 297.837616\n",
      "Train Epoch: 410 [300/2589 (12%)]\tLoss: 270.025421\n",
      "Train Epoch: 410 [600/2589 (23%)]\tLoss: 204.795670\n",
      "Train Epoch: 410 [900/2589 (35%)]\tLoss: 209.321640\n",
      "Train Epoch: 410 [1200/2589 (46%)]\tLoss: 195.752609\n",
      "Train Epoch: 410 [1500/2589 (58%)]\tLoss: 199.396866\n",
      "Train Epoch: 410 [1800/2589 (70%)]\tLoss: 237.767365\n",
      "Train Epoch: 410 [2100/2589 (81%)]\tLoss: 168.723114\n",
      "Train Epoch: 410 [2400/2589 (93%)]\tLoss: 281.768463\n",
      "====> Epoch: 410 Average train loss: 245.6702\n",
      "====> Epoch: 410 Average test loss: 943.4377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 411 [0/2589 (0%)]\tLoss: 183.649872\n",
      "Train Epoch: 411 [300/2589 (12%)]\tLoss: 273.042419\n",
      "Train Epoch: 411 [600/2589 (23%)]\tLoss: 296.622223\n",
      "Train Epoch: 411 [900/2589 (35%)]\tLoss: 138.282303\n",
      "Train Epoch: 411 [1200/2589 (46%)]\tLoss: 292.639801\n",
      "Train Epoch: 411 [1500/2589 (58%)]\tLoss: 249.076675\n",
      "Train Epoch: 411 [1800/2589 (70%)]\tLoss: 197.640366\n",
      "Train Epoch: 411 [2100/2589 (81%)]\tLoss: 289.982605\n",
      "Train Epoch: 411 [2400/2589 (93%)]\tLoss: 221.089401\n",
      "====> Epoch: 411 Average train loss: 243.3591\n",
      "====> Epoch: 411 Average test loss: 934.0870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 412 [0/2589 (0%)]\tLoss: 209.930740\n",
      "Train Epoch: 412 [300/2589 (12%)]\tLoss: 233.624161\n",
      "Train Epoch: 412 [600/2589 (23%)]\tLoss: 199.115814\n",
      "Train Epoch: 412 [900/2589 (35%)]\tLoss: 209.346329\n",
      "Train Epoch: 412 [1200/2589 (46%)]\tLoss: 329.933502\n",
      "Train Epoch: 412 [1500/2589 (58%)]\tLoss: 238.388519\n",
      "Train Epoch: 412 [1800/2589 (70%)]\tLoss: 222.198792\n",
      "Train Epoch: 412 [2100/2589 (81%)]\tLoss: 218.046890\n",
      "Train Epoch: 412 [2400/2589 (93%)]\tLoss: 330.591858\n",
      "====> Epoch: 412 Average train loss: 245.2986\n",
      "====> Epoch: 412 Average test loss: 940.5776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 413 [0/2589 (0%)]\tLoss: 249.585297\n",
      "Train Epoch: 413 [300/2589 (12%)]\tLoss: 224.441833\n",
      "Train Epoch: 413 [600/2589 (23%)]\tLoss: 240.425644\n",
      "Train Epoch: 413 [900/2589 (35%)]\tLoss: 205.249649\n",
      "Train Epoch: 413 [1200/2589 (46%)]\tLoss: 226.068268\n",
      "Train Epoch: 413 [1500/2589 (58%)]\tLoss: 393.605621\n",
      "Train Epoch: 413 [1800/2589 (70%)]\tLoss: 210.304153\n",
      "Train Epoch: 413 [2100/2589 (81%)]\tLoss: 212.831955\n",
      "Train Epoch: 413 [2400/2589 (93%)]\tLoss: 272.273438\n",
      "====> Epoch: 413 Average train loss: 253.3809\n",
      "====> Epoch: 413 Average test loss: 928.3470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 414 [0/2589 (0%)]\tLoss: 430.979034\n",
      "Train Epoch: 414 [300/2589 (12%)]\tLoss: 386.919159\n",
      "Train Epoch: 414 [600/2589 (23%)]\tLoss: 237.160049\n",
      "Train Epoch: 414 [900/2589 (35%)]\tLoss: 176.641220\n",
      "Train Epoch: 414 [1200/2589 (46%)]\tLoss: 210.380554\n",
      "Train Epoch: 414 [1500/2589 (58%)]\tLoss: 248.815903\n",
      "Train Epoch: 414 [1800/2589 (70%)]\tLoss: 198.925385\n",
      "Train Epoch: 414 [2100/2589 (81%)]\tLoss: 250.313904\n",
      "Train Epoch: 414 [2400/2589 (93%)]\tLoss: 221.931061\n",
      "====> Epoch: 414 Average train loss: 261.9082\n",
      "====> Epoch: 414 Average test loss: 922.6257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 415 [0/2589 (0%)]\tLoss: 203.931854\n",
      "Train Epoch: 415 [300/2589 (12%)]\tLoss: 186.132416\n",
      "Train Epoch: 415 [600/2589 (23%)]\tLoss: 226.497467\n",
      "Train Epoch: 415 [900/2589 (35%)]\tLoss: 271.365448\n",
      "Train Epoch: 415 [1200/2589 (46%)]\tLoss: 379.995789\n",
      "Train Epoch: 415 [1500/2589 (58%)]\tLoss: 210.039734\n",
      "Train Epoch: 415 [1800/2589 (70%)]\tLoss: 213.615326\n",
      "Train Epoch: 415 [2100/2589 (81%)]\tLoss: 218.616379\n",
      "Train Epoch: 415 [2400/2589 (93%)]\tLoss: 252.507858\n",
      "====> Epoch: 415 Average train loss: 256.0601\n",
      "====> Epoch: 415 Average test loss: 948.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 416 [0/2589 (0%)]\tLoss: 236.132782\n",
      "Train Epoch: 416 [300/2589 (12%)]\tLoss: 233.341766\n",
      "Train Epoch: 416 [600/2589 (23%)]\tLoss: 255.616867\n",
      "Train Epoch: 416 [900/2589 (35%)]\tLoss: 174.694275\n",
      "Train Epoch: 416 [1200/2589 (46%)]\tLoss: 279.970764\n",
      "Train Epoch: 416 [1500/2589 (58%)]\tLoss: 212.935806\n",
      "Train Epoch: 416 [1800/2589 (70%)]\tLoss: 198.454178\n",
      "Train Epoch: 416 [2100/2589 (81%)]\tLoss: 299.116547\n",
      "Train Epoch: 416 [2400/2589 (93%)]\tLoss: 395.073395\n",
      "====> Epoch: 416 Average train loss: 259.4940\n",
      "====> Epoch: 416 Average test loss: 941.6132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 417 [0/2589 (0%)]\tLoss: 202.774551\n",
      "Train Epoch: 417 [300/2589 (12%)]\tLoss: 254.775208\n",
      "Train Epoch: 417 [600/2589 (23%)]\tLoss: 168.598038\n",
      "Train Epoch: 417 [900/2589 (35%)]\tLoss: 281.087128\n",
      "Train Epoch: 417 [1200/2589 (46%)]\tLoss: 327.281250\n",
      "Train Epoch: 417 [1500/2589 (58%)]\tLoss: 233.492157\n",
      "Train Epoch: 417 [1800/2589 (70%)]\tLoss: 225.669891\n",
      "Train Epoch: 417 [2100/2589 (81%)]\tLoss: 313.961426\n",
      "Train Epoch: 417 [2400/2589 (93%)]\tLoss: 258.516907\n",
      "====> Epoch: 417 Average train loss: 254.7074\n",
      "====> Epoch: 417 Average test loss: 927.8553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 418 [0/2589 (0%)]\tLoss: 185.612305\n",
      "Train Epoch: 418 [300/2589 (12%)]\tLoss: 249.030472\n",
      "Train Epoch: 418 [600/2589 (23%)]\tLoss: 228.814316\n",
      "Train Epoch: 418 [900/2589 (35%)]\tLoss: 172.286758\n",
      "Train Epoch: 418 [1200/2589 (46%)]\tLoss: 198.695160\n",
      "Train Epoch: 418 [1500/2589 (58%)]\tLoss: 251.069839\n",
      "Train Epoch: 418 [1800/2589 (70%)]\tLoss: 206.995255\n",
      "Train Epoch: 418 [2100/2589 (81%)]\tLoss: 236.101669\n",
      "Train Epoch: 418 [2400/2589 (93%)]\tLoss: 210.903641\n",
      "====> Epoch: 418 Average train loss: 238.4677\n",
      "====> Epoch: 418 Average test loss: 931.7001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 419 [0/2589 (0%)]\tLoss: 297.424133\n",
      "Train Epoch: 419 [300/2589 (12%)]\tLoss: 283.872131\n",
      "Train Epoch: 419 [600/2589 (23%)]\tLoss: 310.176147\n",
      "Train Epoch: 419 [900/2589 (35%)]\tLoss: 278.188599\n",
      "Train Epoch: 419 [1200/2589 (46%)]\tLoss: 178.944077\n",
      "Train Epoch: 419 [1500/2589 (58%)]\tLoss: 214.290726\n",
      "Train Epoch: 419 [1800/2589 (70%)]\tLoss: 300.436646\n",
      "Train Epoch: 419 [2100/2589 (81%)]\tLoss: 309.704407\n",
      "Train Epoch: 419 [2400/2589 (93%)]\tLoss: 381.299622\n",
      "====> Epoch: 419 Average train loss: 253.9382\n",
      "====> Epoch: 419 Average test loss: 941.9567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 420 [0/2589 (0%)]\tLoss: 230.969147\n",
      "Train Epoch: 420 [300/2589 (12%)]\tLoss: 471.627167\n",
      "Train Epoch: 420 [600/2589 (23%)]\tLoss: 241.817673\n",
      "Train Epoch: 420 [900/2589 (35%)]\tLoss: 315.895081\n",
      "Train Epoch: 420 [1200/2589 (46%)]\tLoss: 256.195953\n",
      "Train Epoch: 420 [1500/2589 (58%)]\tLoss: 241.377991\n",
      "Train Epoch: 420 [1800/2589 (70%)]\tLoss: 245.641220\n",
      "Train Epoch: 420 [2100/2589 (81%)]\tLoss: 287.106964\n",
      "Train Epoch: 420 [2400/2589 (93%)]\tLoss: 315.889374\n",
      "====> Epoch: 420 Average train loss: 242.0989\n",
      "====> Epoch: 420 Average test loss: 956.1702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 421 [0/2589 (0%)]\tLoss: 274.042511\n",
      "Train Epoch: 421 [300/2589 (12%)]\tLoss: 210.466629\n",
      "Train Epoch: 421 [600/2589 (23%)]\tLoss: 285.976440\n",
      "Train Epoch: 421 [900/2589 (35%)]\tLoss: 193.742676\n",
      "Train Epoch: 421 [1200/2589 (46%)]\tLoss: 277.496094\n",
      "Train Epoch: 421 [1500/2589 (58%)]\tLoss: 271.670105\n",
      "Train Epoch: 421 [1800/2589 (70%)]\tLoss: 181.972809\n",
      "Train Epoch: 421 [2100/2589 (81%)]\tLoss: 189.976654\n",
      "Train Epoch: 421 [2400/2589 (93%)]\tLoss: 154.004532\n",
      "====> Epoch: 421 Average train loss: 244.7791\n",
      "====> Epoch: 421 Average test loss: 935.7040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 422 [0/2589 (0%)]\tLoss: 184.202057\n",
      "Train Epoch: 422 [300/2589 (12%)]\tLoss: 245.080460\n",
      "Train Epoch: 422 [600/2589 (23%)]\tLoss: 259.194397\n",
      "Train Epoch: 422 [900/2589 (35%)]\tLoss: 252.237518\n",
      "Train Epoch: 422 [1200/2589 (46%)]\tLoss: 253.238510\n",
      "Train Epoch: 422 [1500/2589 (58%)]\tLoss: 258.185638\n",
      "Train Epoch: 422 [1800/2589 (70%)]\tLoss: 217.882553\n",
      "Train Epoch: 422 [2100/2589 (81%)]\tLoss: 327.773407\n",
      "Train Epoch: 422 [2400/2589 (93%)]\tLoss: 236.422455\n",
      "====> Epoch: 422 Average train loss: 247.0449\n",
      "====> Epoch: 422 Average test loss: 937.7954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 423 [0/2589 (0%)]\tLoss: 354.127747\n",
      "Train Epoch: 423 [300/2589 (12%)]\tLoss: 295.933990\n",
      "Train Epoch: 423 [600/2589 (23%)]\tLoss: 254.115753\n",
      "Train Epoch: 423 [900/2589 (35%)]\tLoss: 180.022018\n",
      "Train Epoch: 423 [1200/2589 (46%)]\tLoss: 273.340454\n",
      "Train Epoch: 423 [1500/2589 (58%)]\tLoss: 196.240128\n",
      "Train Epoch: 423 [1800/2589 (70%)]\tLoss: 206.140106\n",
      "Train Epoch: 423 [2100/2589 (81%)]\tLoss: 194.917343\n",
      "Train Epoch: 423 [2400/2589 (93%)]\tLoss: 305.262695\n",
      "====> Epoch: 423 Average train loss: 259.6731\n",
      "====> Epoch: 423 Average test loss: 931.5181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 424 [0/2589 (0%)]\tLoss: 187.150681\n",
      "Train Epoch: 424 [300/2589 (12%)]\tLoss: 259.111023\n",
      "Train Epoch: 424 [600/2589 (23%)]\tLoss: 198.938751\n",
      "Train Epoch: 424 [900/2589 (35%)]\tLoss: 296.453217\n",
      "Train Epoch: 424 [1200/2589 (46%)]\tLoss: 237.481583\n",
      "Train Epoch: 424 [1500/2589 (58%)]\tLoss: 218.160904\n",
      "Train Epoch: 424 [1800/2589 (70%)]\tLoss: 256.741882\n",
      "Train Epoch: 424 [2100/2589 (81%)]\tLoss: 204.354828\n",
      "Train Epoch: 424 [2400/2589 (93%)]\tLoss: 190.895508\n",
      "====> Epoch: 424 Average train loss: 265.2580\n",
      "====> Epoch: 424 Average test loss: 924.2442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 425 [0/2589 (0%)]\tLoss: 149.215179\n",
      "Train Epoch: 425 [300/2589 (12%)]\tLoss: 264.263245\n",
      "Train Epoch: 425 [600/2589 (23%)]\tLoss: 190.276672\n",
      "Train Epoch: 425 [900/2589 (35%)]\tLoss: 191.272141\n",
      "Train Epoch: 425 [1200/2589 (46%)]\tLoss: 314.520203\n",
      "Train Epoch: 425 [1500/2589 (58%)]\tLoss: 235.983459\n",
      "Train Epoch: 425 [1800/2589 (70%)]\tLoss: 240.924149\n",
      "Train Epoch: 425 [2100/2589 (81%)]\tLoss: 248.339828\n",
      "Train Epoch: 425 [2400/2589 (93%)]\tLoss: 244.834213\n",
      "====> Epoch: 425 Average train loss: 259.0190\n",
      "====> Epoch: 425 Average test loss: 966.7729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 426 [0/2589 (0%)]\tLoss: 206.137756\n",
      "Train Epoch: 426 [300/2589 (12%)]\tLoss: 221.251266\n",
      "Train Epoch: 426 [600/2589 (23%)]\tLoss: 265.601776\n",
      "Train Epoch: 426 [900/2589 (35%)]\tLoss: 166.372299\n",
      "Train Epoch: 426 [1200/2589 (46%)]\tLoss: 229.416733\n",
      "Train Epoch: 426 [1500/2589 (58%)]\tLoss: 241.206787\n",
      "Train Epoch: 426 [1800/2589 (70%)]\tLoss: 173.656555\n",
      "Train Epoch: 426 [2100/2589 (81%)]\tLoss: 220.595047\n",
      "Train Epoch: 426 [2400/2589 (93%)]\tLoss: 389.505188\n",
      "====> Epoch: 426 Average train loss: 245.3721\n",
      "====> Epoch: 426 Average test loss: 923.1602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 427 [0/2589 (0%)]\tLoss: 237.564346\n",
      "Train Epoch: 427 [300/2589 (12%)]\tLoss: 150.031631\n",
      "Train Epoch: 427 [600/2589 (23%)]\tLoss: 324.781891\n",
      "Train Epoch: 427 [900/2589 (35%)]\tLoss: 200.188293\n",
      "Train Epoch: 427 [1200/2589 (46%)]\tLoss: 262.837952\n",
      "Train Epoch: 427 [1500/2589 (58%)]\tLoss: 288.880524\n",
      "Train Epoch: 427 [1800/2589 (70%)]\tLoss: 224.523361\n",
      "Train Epoch: 427 [2100/2589 (81%)]\tLoss: 352.920898\n",
      "Train Epoch: 427 [2400/2589 (93%)]\tLoss: 226.122375\n",
      "====> Epoch: 427 Average train loss: 245.1305\n",
      "====> Epoch: 427 Average test loss: 937.6133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 428 [0/2589 (0%)]\tLoss: 200.970215\n",
      "Train Epoch: 428 [300/2589 (12%)]\tLoss: 227.993790\n",
      "Train Epoch: 428 [600/2589 (23%)]\tLoss: 162.511551\n",
      "Train Epoch: 428 [900/2589 (35%)]\tLoss: 273.667877\n",
      "Train Epoch: 428 [1200/2589 (46%)]\tLoss: 168.634537\n",
      "Train Epoch: 428 [1500/2589 (58%)]\tLoss: 290.457245\n",
      "Train Epoch: 428 [1800/2589 (70%)]\tLoss: 156.550690\n",
      "Train Epoch: 428 [2100/2589 (81%)]\tLoss: 183.605225\n",
      "Train Epoch: 428 [2400/2589 (93%)]\tLoss: 248.056870\n",
      "====> Epoch: 428 Average train loss: 249.7812\n",
      "====> Epoch: 428 Average test loss: 928.4556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 429 [0/2589 (0%)]\tLoss: 313.618713\n",
      "Train Epoch: 429 [300/2589 (12%)]\tLoss: 255.512985\n",
      "Train Epoch: 429 [600/2589 (23%)]\tLoss: 167.461517\n",
      "Train Epoch: 429 [900/2589 (35%)]\tLoss: 334.925140\n",
      "Train Epoch: 429 [1200/2589 (46%)]\tLoss: 306.476227\n",
      "Train Epoch: 429 [1500/2589 (58%)]\tLoss: 178.216141\n",
      "Train Epoch: 429 [1800/2589 (70%)]\tLoss: 315.709412\n",
      "Train Epoch: 429 [2100/2589 (81%)]\tLoss: 232.948990\n",
      "Train Epoch: 429 [2400/2589 (93%)]\tLoss: 425.143616\n",
      "====> Epoch: 429 Average train loss: 245.3071\n",
      "====> Epoch: 429 Average test loss: 957.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 430 [0/2589 (0%)]\tLoss: 353.855652\n",
      "Train Epoch: 430 [300/2589 (12%)]\tLoss: 287.250214\n",
      "Train Epoch: 430 [600/2589 (23%)]\tLoss: 343.843109\n",
      "Train Epoch: 430 [900/2589 (35%)]\tLoss: 212.009567\n",
      "Train Epoch: 430 [1200/2589 (46%)]\tLoss: 174.346100\n",
      "Train Epoch: 430 [1500/2589 (58%)]\tLoss: 231.865723\n",
      "Train Epoch: 430 [1800/2589 (70%)]\tLoss: 171.117767\n",
      "Train Epoch: 430 [2100/2589 (81%)]\tLoss: 152.181931\n",
      "Train Epoch: 430 [2400/2589 (93%)]\tLoss: 198.253082\n",
      "====> Epoch: 430 Average train loss: 244.3102\n",
      "====> Epoch: 430 Average test loss: 939.3787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 431 [0/2589 (0%)]\tLoss: 191.895447\n",
      "Train Epoch: 431 [300/2589 (12%)]\tLoss: 192.645233\n",
      "Train Epoch: 431 [600/2589 (23%)]\tLoss: 229.599792\n",
      "Train Epoch: 431 [900/2589 (35%)]\tLoss: 304.138611\n",
      "Train Epoch: 431 [1200/2589 (46%)]\tLoss: 191.015945\n",
      "Train Epoch: 431 [1500/2589 (58%)]\tLoss: 194.267563\n",
      "Train Epoch: 431 [1800/2589 (70%)]\tLoss: 238.785553\n",
      "Train Epoch: 431 [2100/2589 (81%)]\tLoss: 235.597977\n",
      "Train Epoch: 431 [2400/2589 (93%)]\tLoss: 205.662277\n",
      "====> Epoch: 431 Average train loss: 238.7695\n",
      "====> Epoch: 431 Average test loss: 942.4780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 432 [0/2589 (0%)]\tLoss: 187.248932\n",
      "Train Epoch: 432 [300/2589 (12%)]\tLoss: 173.604431\n",
      "Train Epoch: 432 [600/2589 (23%)]\tLoss: 421.310272\n",
      "Train Epoch: 432 [900/2589 (35%)]\tLoss: 212.657578\n",
      "Train Epoch: 432 [1200/2589 (46%)]\tLoss: 196.389557\n",
      "Train Epoch: 432 [1500/2589 (58%)]\tLoss: 258.288666\n",
      "Train Epoch: 432 [1800/2589 (70%)]\tLoss: 322.468445\n",
      "Train Epoch: 432 [2100/2589 (81%)]\tLoss: 231.554993\n"
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "tr_x = '../data/rnn_train_x.npy'\n",
    "tr_y = '../data/rnn_train_y.npy'\n",
    "tet_x = '../data/rnn_test_x.npy'\n",
    "tet_y = '../data/rnn_test_y.npy'\n",
    "num_epochs = 2000\n",
    "batch_size = 30\n",
    "verbose = True\n",
    "# set models and loss\n",
    "#model = TS_rnn(num_inp = 1, num_hidden = 32, num_layers = 2, dropout = 0, num_dim_mlp = 16) # (self, num_inp = 13, num_hidden = 64, num_layers = 2, dropout = 0.5, num_dim_mlp = 16)\n",
    "model = MLP(num_inp = 44, num_hidden = 256, num_hidden2 = 64) # (self, num_inp = 1, num_hidden = 64, num_hidden2 = 16)\n",
    "#model = TS_rnn()\n",
    "#loss = PDLoss()\n",
    "loss = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)\n",
    "# set the scheduler\n",
    "lamb1 = lambda x: .1**(x//30)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda = lamb1)\n",
    "# loda data\n",
    "train = Data(tr_x, tr_y)\n",
    "test = Data(tet_x, tet_y)\n",
    "dl_train = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "dl_test = DataLoader(test, batch_size = batch_size, shuffle = True)\n",
    "#train the model\n",
    "for epoch in range(num_epochs):\n",
    "    #scheduler.step()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    counter = 0\n",
    "    for batch_idx, dat in enumerate(dl_train):\n",
    "        counter += 1\n",
    "        # train the model\n",
    "        optimizer.zero_grad()\n",
    "        inp, target = dat\n",
    "        #print('----------------')\n",
    "        out = model(inp)\n",
    "        #print(out.squeeze())\n",
    "        #print(target)\n",
    "        lo = loss(out.squeeze(), target)\n",
    "        lo.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += lo.data\n",
    "        if verbose:\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch,\n",
    "                    batch_idx * batch_size,\n",
    "                    len(train),\n",
    "                    100.*batch_idx*batch_size/len(train),\n",
    "                    lo.data\n",
    "                    ))\n",
    "    test_lo = test_model(dl_test, model, loss)\n",
    "    #hit_rate = significant_test(dl_test, model, loss)\n",
    "    if verbose:\n",
    "        # train loss\n",
    "        print('====> Epoch: {} Average train loss: {:.4f}'.format(\n",
    "            epoch,\n",
    "            train_loss/counter\n",
    "            ))\n",
    "        # test loss\n",
    "        print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
    "            epoch,\n",
    "            test_lo\n",
    "            ))\n",
    "        # significant test\n",
    "        #print('====> Epoch: {} Average hit rate in 10 candidate: {: .4f}'.format(\n",
    "        #    epoch,\n",
    "        #    hit_rate\n",
    "        #))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.from_numpy(test_x).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = out[:, -1]\n",
    "#out1 = test_y[:, -1, 0]\n",
    "out1=  test_y[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a28de4550>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a28dd8518>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out.data[100:200].numpy())\n",
    "plt.plot(out1[100:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a29260e10>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_y[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a29f0f828>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_x[:100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2589, 5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor()\n",
    "mlp = mlp.fit(train_x, train_y)\n",
    "out = mlp.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2900c710>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a28ffb668>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out[:100])\n",
    "plt.plot(test_y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
