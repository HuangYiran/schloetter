{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from gensim.models import word2vec\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler# 好处在于可以保存训练集中的参数（均值、方差）\n",
    "from scipy.stats import stats\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "import gc\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../codes/self_defined_function.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing and feature selection\n",
    "take ArtNr '200032' as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/Artikelbewegungen ab 1996.txt', sep=';', encoding = 'ISO-8859-1', header=None)\n",
    "#df = pd.read_excel('../data/Artikelbewegungen.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid table create\n",
    "tmp = create_grid_data_for_an_article('200032', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection, only weekday\n",
    "tmp['weekday'] = tmp.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove weekend\n",
    "tmp = tmp[tmp['weekday'] != 5]\n",
    "tmp = tmp[tmp['weekday'] != 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset_from_timeseries(df, targetname = 'Menge', lookback = 5):\n",
    "    \"\"\"\n",
    "    df should not contain the features, which will not used in the traning of the model\n",
    "    \"\"\"\n",
    "    for i in range(lookback):\n",
    "        df[targetname+'_'+str(i+1)] = df[targetname].shift(i+1)\n",
    "    cols = df.columns.to_list()\n",
    "    cols_x = [i for i in cols if i not in [targetname]]\n",
    "    cols_y = [targetname]\n",
    "    dat_x = df[cols_x].iloc[lookback:, :].values\n",
    "    dat_y = df[cols_y].iloc[lookback:, :].values\n",
    "    return dat_x, dat_y\n",
    "def extract_dataset_from_timeseries_with_diff(df, targetname = 'Menge', lookback = 5):\n",
    "    \"\"\"\n",
    "    df should not contain the features, which will not used in the traning of the model\n",
    "    \"\"\"\n",
    "    for i in range(lookback):\n",
    "        df[targetname+'_'+str(i+1)] = df[targetname].shift(i+1)\n",
    "    if lookback >=5:\n",
    "        df['diff_1'] = df[targetname+'_'+str(1)] - df[targetname+'_'+str(2)]\n",
    "        df['diff_2'] = df[targetname+'_'+str(3)] - df[targetname+'_'+str(4)]\n",
    "        df['diff2_1'] = df['diff_1'] - df['diff_2']\n",
    "    cols = df.columns.to_list()\n",
    "    cols_x = [i for i in cols if i not in [targetname]]\n",
    "    cols_y = [targetname]\n",
    "    dat_x = df[cols_x].iloc[lookback:, :].values\n",
    "    dat_y = df[cols_y].iloc[lookback:, :].values\n",
    "    return dat_x, dat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset for mlp\n",
    "dat_x, dat_y = extract_dataset_from_timeseries_with_diff(tmp, lookback = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dat_x[:2589, :]\n",
    "test_x = dat_x[2589:, :]\n",
    "train_y = dat_y[:2589, :].reshape(-1)\n",
    "test_y = dat_y[2589:, :].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to the local system\n",
    "np.save('../data/rnn_train_x', train_x)\n",
    "np.save('../data/rnn_train_y', train_y)\n",
    "np.save('../data/rnn_test_x', test_x)\n",
    "np.save('../data/rnn_test_y', test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset for lstm\n",
    "dat_x, dat_y = extract_dataset_from_timeseries(tmp[['Menge']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dat_x[:2589, :].reshape(-1, 4, 1)\n",
    "test_x = dat_x[2589:, :].reshape(-1, 4, 1)\n",
    "train_y = dat_y[:2589, :].reshape(-1)\n",
    "test_y = dat_y[2589:, :].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/rnn_train_x', train_x)\n",
    "np.save('../data/rnn_train_y', train_y)\n",
    "np.save('../data/rnn_test_x', test_x)\n",
    "np.save('../data/rnn_test_y', test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test data\n",
    "train_y = train_x[:,1] * 10 + 2 - 3\n",
    "test_y = test_x[:, 1] * 10 + 2 - 3\n",
    "np.save('../data/rnn_train_x', train_x)\n",
    "np.save('../data/rnn_train_y', train_y)\n",
    "np.save('../data/rnn_test_x', test_x)\n",
    "np.save('../data/rnn_test_y', test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2589, 4, 1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with mlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/2589 (0%)]\tLoss: 1034.118408\n",
      "Train Epoch: 0 [300/2589 (12%)]\tLoss: 1287.755859\n",
      "Train Epoch: 0 [600/2589 (23%)]\tLoss: 857.657104\n",
      "Train Epoch: 0 [900/2589 (35%)]\tLoss: 1040.218750\n",
      "Train Epoch: 0 [1200/2589 (46%)]\tLoss: 1278.734009\n",
      "Train Epoch: 0 [1500/2589 (58%)]\tLoss: 1119.141235\n",
      "Train Epoch: 0 [1800/2589 (70%)]\tLoss: 984.965698\n",
      "Train Epoch: 0 [2100/2589 (81%)]\tLoss: 763.185852\n",
      "Train Epoch: 0 [2400/2589 (93%)]\tLoss: 1194.788208\n",
      "====> Epoch: 0 Average train loss: 1124.0521\n",
      "====> Epoch: 0 Average test loss: 1248.1989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2589 (0%)]\tLoss: 1058.995361\n",
      "Train Epoch: 1 [300/2589 (12%)]\tLoss: 1365.283447\n",
      "Train Epoch: 1 [600/2589 (23%)]\tLoss: 915.353271\n",
      "Train Epoch: 1 [900/2589 (35%)]\tLoss: 1068.613159\n",
      "Train Epoch: 1 [1200/2589 (46%)]\tLoss: 827.312439\n",
      "Train Epoch: 1 [1500/2589 (58%)]\tLoss: 1011.582031\n",
      "Train Epoch: 1 [1800/2589 (70%)]\tLoss: 836.534302\n",
      "Train Epoch: 1 [2100/2589 (81%)]\tLoss: 1217.847656\n",
      "Train Epoch: 1 [2400/2589 (93%)]\tLoss: 1245.559692\n",
      "====> Epoch: 1 Average train loss: 940.8314\n",
      "====> Epoch: 1 Average test loss: 984.0328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/2589 (0%)]\tLoss: 974.218140\n",
      "Train Epoch: 2 [300/2589 (12%)]\tLoss: 1053.898926\n",
      "Train Epoch: 2 [600/2589 (23%)]\tLoss: 839.788513\n",
      "Train Epoch: 2 [900/2589 (35%)]\tLoss: 566.921204\n",
      "Train Epoch: 2 [1200/2589 (46%)]\tLoss: 817.167053\n",
      "Train Epoch: 2 [1500/2589 (58%)]\tLoss: 487.572174\n",
      "Train Epoch: 2 [1800/2589 (70%)]\tLoss: 493.112701\n",
      "Train Epoch: 2 [2100/2589 (81%)]\tLoss: 715.618958\n",
      "Train Epoch: 2 [2400/2589 (93%)]\tLoss: 536.647095\n",
      "====> Epoch: 2 Average train loss: 759.3914\n",
      "====> Epoch: 2 Average test loss: 902.6270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [0/2589 (0%)]\tLoss: 816.065369\n",
      "Train Epoch: 3 [300/2589 (12%)]\tLoss: 679.389343\n",
      "Train Epoch: 3 [600/2589 (23%)]\tLoss: 799.853577\n",
      "Train Epoch: 3 [900/2589 (35%)]\tLoss: 826.399475\n",
      "Train Epoch: 3 [1200/2589 (46%)]\tLoss: 587.113586\n",
      "Train Epoch: 3 [1500/2589 (58%)]\tLoss: 506.178406\n",
      "Train Epoch: 3 [1800/2589 (70%)]\tLoss: 610.702087\n",
      "Train Epoch: 3 [2100/2589 (81%)]\tLoss: 615.046997\n",
      "Train Epoch: 3 [2400/2589 (93%)]\tLoss: 550.841248\n",
      "====> Epoch: 3 Average train loss: 689.2419\n",
      "====> Epoch: 3 Average test loss: 888.2711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [0/2589 (0%)]\tLoss: 726.119263\n",
      "Train Epoch: 4 [300/2589 (12%)]\tLoss: 736.628357\n",
      "Train Epoch: 4 [600/2589 (23%)]\tLoss: 632.222595\n",
      "Train Epoch: 4 [900/2589 (35%)]\tLoss: 741.041077\n",
      "Train Epoch: 4 [1200/2589 (46%)]\tLoss: 820.840454\n",
      "Train Epoch: 4 [1500/2589 (58%)]\tLoss: 697.835083\n",
      "Train Epoch: 4 [1800/2589 (70%)]\tLoss: 725.500244\n",
      "Train Epoch: 4 [2100/2589 (81%)]\tLoss: 488.669830\n",
      "Train Epoch: 4 [2400/2589 (93%)]\tLoss: 746.513062\n",
      "====> Epoch: 4 Average train loss: 674.1551\n",
      "====> Epoch: 4 Average test loss: 866.5549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/2589 (0%)]\tLoss: 573.769165\n",
      "Train Epoch: 5 [300/2589 (12%)]\tLoss: 709.228882\n",
      "Train Epoch: 5 [600/2589 (23%)]\tLoss: 556.298157\n",
      "Train Epoch: 5 [900/2589 (35%)]\tLoss: 521.945312\n",
      "Train Epoch: 5 [1200/2589 (46%)]\tLoss: 513.300171\n",
      "Train Epoch: 5 [1500/2589 (58%)]\tLoss: 725.674805\n",
      "Train Epoch: 5 [1800/2589 (70%)]\tLoss: 703.434875\n",
      "Train Epoch: 5 [2100/2589 (81%)]\tLoss: 656.334717\n",
      "Train Epoch: 5 [2400/2589 (93%)]\tLoss: 503.350525\n",
      "====> Epoch: 5 Average train loss: 653.7802\n",
      "====> Epoch: 5 Average test loss: 869.5367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [0/2589 (0%)]\tLoss: 555.971985\n",
      "Train Epoch: 6 [300/2589 (12%)]\tLoss: 682.222595\n",
      "Train Epoch: 6 [600/2589 (23%)]\tLoss: 596.391418\n",
      "Train Epoch: 6 [900/2589 (35%)]\tLoss: 591.607300\n",
      "Train Epoch: 6 [1200/2589 (46%)]\tLoss: 662.716248\n",
      "Train Epoch: 6 [1500/2589 (58%)]\tLoss: 475.148773\n",
      "Train Epoch: 6 [1800/2589 (70%)]\tLoss: 651.677612\n",
      "Train Epoch: 6 [2100/2589 (81%)]\tLoss: 721.373657\n",
      "Train Epoch: 6 [2400/2589 (93%)]\tLoss: 746.892700\n",
      "====> Epoch: 6 Average train loss: 641.6806\n",
      "====> Epoch: 6 Average test loss: 866.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [0/2589 (0%)]\tLoss: 618.348999\n",
      "Train Epoch: 7 [300/2589 (12%)]\tLoss: 712.786804\n",
      "Train Epoch: 7 [600/2589 (23%)]\tLoss: 650.264648\n",
      "Train Epoch: 7 [900/2589 (35%)]\tLoss: 656.344971\n",
      "Train Epoch: 7 [1200/2589 (46%)]\tLoss: 658.390869\n",
      "Train Epoch: 7 [1500/2589 (58%)]\tLoss: 531.723633\n",
      "Train Epoch: 7 [1800/2589 (70%)]\tLoss: 708.957336\n",
      "Train Epoch: 7 [2100/2589 (81%)]\tLoss: 600.540100\n",
      "Train Epoch: 7 [2400/2589 (93%)]\tLoss: 657.737915\n",
      "====> Epoch: 7 Average train loss: 630.3264\n",
      "====> Epoch: 7 Average test loss: 875.1235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [0/2589 (0%)]\tLoss: 452.755554\n",
      "Train Epoch: 8 [300/2589 (12%)]\tLoss: 547.470520\n",
      "Train Epoch: 8 [600/2589 (23%)]\tLoss: 821.385803\n",
      "Train Epoch: 8 [900/2589 (35%)]\tLoss: 549.443909\n",
      "Train Epoch: 8 [1200/2589 (46%)]\tLoss: 594.273865\n",
      "Train Epoch: 8 [1500/2589 (58%)]\tLoss: 629.631592\n",
      "Train Epoch: 8 [1800/2589 (70%)]\tLoss: 645.890442\n",
      "Train Epoch: 8 [2100/2589 (81%)]\tLoss: 561.455933\n",
      "Train Epoch: 8 [2400/2589 (93%)]\tLoss: 595.500793\n",
      "====> Epoch: 8 Average train loss: 623.2726\n",
      "====> Epoch: 8 Average test loss: 881.2080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/2589 (0%)]\tLoss: 595.696045\n",
      "Train Epoch: 9 [300/2589 (12%)]\tLoss: 690.179626\n",
      "Train Epoch: 9 [600/2589 (23%)]\tLoss: 728.523438\n",
      "Train Epoch: 9 [900/2589 (35%)]\tLoss: 476.530487\n",
      "Train Epoch: 9 [1200/2589 (46%)]\tLoss: 682.819763\n",
      "Train Epoch: 9 [1500/2589 (58%)]\tLoss: 452.055756\n",
      "Train Epoch: 9 [1800/2589 (70%)]\tLoss: 590.863953\n",
      "Train Epoch: 9 [2100/2589 (81%)]\tLoss: 548.569519\n",
      "Train Epoch: 9 [2400/2589 (93%)]\tLoss: 724.425415\n",
      "====> Epoch: 9 Average train loss: 608.1130\n",
      "====> Epoch: 9 Average test loss: 880.1544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [0/2589 (0%)]\tLoss: 486.986816\n",
      "Train Epoch: 10 [300/2589 (12%)]\tLoss: 627.999451\n",
      "Train Epoch: 10 [600/2589 (23%)]\tLoss: 593.190979\n",
      "Train Epoch: 10 [900/2589 (35%)]\tLoss: 597.857666\n",
      "Train Epoch: 10 [1200/2589 (46%)]\tLoss: 560.259888\n",
      "Train Epoch: 10 [1500/2589 (58%)]\tLoss: 618.617859\n",
      "Train Epoch: 10 [1800/2589 (70%)]\tLoss: 408.853394\n",
      "Train Epoch: 10 [2100/2589 (81%)]\tLoss: 624.896240\n",
      "Train Epoch: 10 [2400/2589 (93%)]\tLoss: 638.011841\n",
      "====> Epoch: 10 Average train loss: 598.1495\n",
      "====> Epoch: 10 Average test loss: 873.0856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [0/2589 (0%)]\tLoss: 636.713196\n",
      "Train Epoch: 11 [300/2589 (12%)]\tLoss: 454.728790\n",
      "Train Epoch: 11 [600/2589 (23%)]\tLoss: 432.179535\n",
      "Train Epoch: 11 [900/2589 (35%)]\tLoss: 752.641907\n",
      "Train Epoch: 11 [1200/2589 (46%)]\tLoss: 615.634155\n",
      "Train Epoch: 11 [1500/2589 (58%)]\tLoss: 769.405823\n",
      "Train Epoch: 11 [1800/2589 (70%)]\tLoss: 616.921631\n",
      "Train Epoch: 11 [2100/2589 (81%)]\tLoss: 606.082214\n",
      "Train Epoch: 11 [2400/2589 (93%)]\tLoss: 537.269714\n",
      "====> Epoch: 11 Average train loss: 583.6353\n",
      "====> Epoch: 11 Average test loss: 884.1157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [0/2589 (0%)]\tLoss: 531.289490\n",
      "Train Epoch: 12 [300/2589 (12%)]\tLoss: 594.013123\n",
      "Train Epoch: 12 [600/2589 (23%)]\tLoss: 529.759033\n",
      "Train Epoch: 12 [900/2589 (35%)]\tLoss: 438.398346\n",
      "Train Epoch: 12 [1200/2589 (46%)]\tLoss: 368.092499\n",
      "Train Epoch: 12 [1500/2589 (58%)]\tLoss: 485.672150\n",
      "Train Epoch: 12 [1800/2589 (70%)]\tLoss: 604.298096\n",
      "Train Epoch: 12 [2100/2589 (81%)]\tLoss: 628.296814\n",
      "Train Epoch: 12 [2400/2589 (93%)]\tLoss: 413.055176\n",
      "====> Epoch: 12 Average train loss: 576.5279\n",
      "====> Epoch: 12 Average test loss: 874.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [0/2589 (0%)]\tLoss: 456.176849\n",
      "Train Epoch: 13 [300/2589 (12%)]\tLoss: 448.134949\n",
      "Train Epoch: 13 [600/2589 (23%)]\tLoss: 621.687683\n",
      "Train Epoch: 13 [900/2589 (35%)]\tLoss: 584.987671\n",
      "Train Epoch: 13 [1200/2589 (46%)]\tLoss: 647.064819\n",
      "Train Epoch: 13 [1500/2589 (58%)]\tLoss: 517.975708\n",
      "Train Epoch: 13 [1800/2589 (70%)]\tLoss: 621.737915\n",
      "Train Epoch: 13 [2100/2589 (81%)]\tLoss: 490.450195\n",
      "Train Epoch: 13 [2400/2589 (93%)]\tLoss: 665.291382\n",
      "====> Epoch: 13 Average train loss: 569.4730\n",
      "====> Epoch: 13 Average test loss: 881.3408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [0/2589 (0%)]\tLoss: 472.963226\n",
      "Train Epoch: 14 [300/2589 (12%)]\tLoss: 647.286560\n",
      "Train Epoch: 14 [600/2589 (23%)]\tLoss: 670.813538\n",
      "Train Epoch: 14 [900/2589 (35%)]\tLoss: 485.149872\n",
      "Train Epoch: 14 [1200/2589 (46%)]\tLoss: 458.461243\n",
      "Train Epoch: 14 [1500/2589 (58%)]\tLoss: 556.832275\n",
      "Train Epoch: 14 [1800/2589 (70%)]\tLoss: 533.122742\n",
      "Train Epoch: 14 [2100/2589 (81%)]\tLoss: 457.956909\n",
      "Train Epoch: 14 [2400/2589 (93%)]\tLoss: 769.373352\n",
      "====> Epoch: 14 Average train loss: 558.3900\n",
      "====> Epoch: 14 Average test loss: 883.7785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [0/2589 (0%)]\tLoss: 470.398407\n",
      "Train Epoch: 15 [300/2589 (12%)]\tLoss: 497.408539\n",
      "Train Epoch: 15 [600/2589 (23%)]\tLoss: 769.868774\n",
      "Train Epoch: 15 [900/2589 (35%)]\tLoss: 488.938324\n",
      "Train Epoch: 15 [1200/2589 (46%)]\tLoss: 574.893616\n",
      "Train Epoch: 15 [1500/2589 (58%)]\tLoss: 562.018188\n",
      "Train Epoch: 15 [1800/2589 (70%)]\tLoss: 548.969116\n",
      "Train Epoch: 15 [2100/2589 (81%)]\tLoss: 544.554138\n",
      "Train Epoch: 15 [2400/2589 (93%)]\tLoss: 422.059967\n",
      "====> Epoch: 15 Average train loss: 551.7845\n",
      "====> Epoch: 15 Average test loss: 895.6132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [0/2589 (0%)]\tLoss: 533.333679\n",
      "Train Epoch: 16 [300/2589 (12%)]\tLoss: 440.410553\n",
      "Train Epoch: 16 [600/2589 (23%)]\tLoss: 729.725403\n",
      "Train Epoch: 16 [900/2589 (35%)]\tLoss: 477.464966\n",
      "Train Epoch: 16 [1200/2589 (46%)]\tLoss: 648.695068\n",
      "Train Epoch: 16 [1500/2589 (58%)]\tLoss: 556.325012\n",
      "Train Epoch: 16 [1800/2589 (70%)]\tLoss: 396.364136\n",
      "Train Epoch: 16 [2100/2589 (81%)]\tLoss: 537.271484\n",
      "Train Epoch: 16 [2400/2589 (93%)]\tLoss: 668.029419\n",
      "====> Epoch: 16 Average train loss: 544.1252\n",
      "====> Epoch: 16 Average test loss: 894.0781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [0/2589 (0%)]\tLoss: 418.173126\n",
      "Train Epoch: 17 [300/2589 (12%)]\tLoss: 428.842773\n",
      "Train Epoch: 17 [600/2589 (23%)]\tLoss: 583.443298\n",
      "Train Epoch: 17 [900/2589 (35%)]\tLoss: 507.480591\n",
      "Train Epoch: 17 [1200/2589 (46%)]\tLoss: 485.887817\n",
      "Train Epoch: 17 [1500/2589 (58%)]\tLoss: 400.461639\n",
      "Train Epoch: 17 [1800/2589 (70%)]\tLoss: 649.962646\n",
      "Train Epoch: 17 [2100/2589 (81%)]\tLoss: 564.781372\n",
      "Train Epoch: 17 [2400/2589 (93%)]\tLoss: 551.142639\n",
      "====> Epoch: 17 Average train loss: 540.3969\n",
      "====> Epoch: 17 Average test loss: 889.4615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [0/2589 (0%)]\tLoss: 570.609436\n",
      "Train Epoch: 18 [300/2589 (12%)]\tLoss: 583.955933\n",
      "Train Epoch: 18 [600/2589 (23%)]\tLoss: 541.332153\n",
      "Train Epoch: 18 [900/2589 (35%)]\tLoss: 643.010864\n",
      "Train Epoch: 18 [1200/2589 (46%)]\tLoss: 558.167175\n",
      "Train Epoch: 18 [1500/2589 (58%)]\tLoss: 496.657532\n",
      "Train Epoch: 18 [1800/2589 (70%)]\tLoss: 522.277771\n",
      "Train Epoch: 18 [2100/2589 (81%)]\tLoss: 516.689331\n",
      "Train Epoch: 18 [2400/2589 (93%)]\tLoss: 524.578979\n",
      "====> Epoch: 18 Average train loss: 531.3946\n",
      "====> Epoch: 18 Average test loss: 891.0446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [0/2589 (0%)]\tLoss: 666.726196\n",
      "Train Epoch: 19 [300/2589 (12%)]\tLoss: 449.321686\n",
      "Train Epoch: 19 [600/2589 (23%)]\tLoss: 433.826965\n",
      "Train Epoch: 19 [900/2589 (35%)]\tLoss: 371.625031\n",
      "Train Epoch: 19 [1200/2589 (46%)]\tLoss: 611.963135\n",
      "Train Epoch: 19 [1500/2589 (58%)]\tLoss: 494.973907\n",
      "Train Epoch: 19 [1800/2589 (70%)]\tLoss: 483.578156\n",
      "Train Epoch: 19 [2100/2589 (81%)]\tLoss: 606.826843\n",
      "Train Epoch: 19 [2400/2589 (93%)]\tLoss: 616.726196\n",
      "====> Epoch: 19 Average train loss: 522.7849\n",
      "====> Epoch: 19 Average test loss: 897.2014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [0/2589 (0%)]\tLoss: 478.045074\n",
      "Train Epoch: 20 [300/2589 (12%)]\tLoss: 656.875916\n",
      "Train Epoch: 20 [600/2589 (23%)]\tLoss: 574.543945\n",
      "Train Epoch: 20 [900/2589 (35%)]\tLoss: 458.922333\n",
      "Train Epoch: 20 [1200/2589 (46%)]\tLoss: 514.171143\n",
      "Train Epoch: 20 [1500/2589 (58%)]\tLoss: 486.906036\n",
      "Train Epoch: 20 [1800/2589 (70%)]\tLoss: 651.012451\n",
      "Train Epoch: 20 [2100/2589 (81%)]\tLoss: 421.139618\n",
      "Train Epoch: 20 [2400/2589 (93%)]\tLoss: 566.788330\n",
      "====> Epoch: 20 Average train loss: 518.8209\n",
      "====> Epoch: 20 Average test loss: 899.2273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [0/2589 (0%)]\tLoss: 491.888031\n",
      "Train Epoch: 21 [300/2589 (12%)]\tLoss: 514.692810\n",
      "Train Epoch: 21 [600/2589 (23%)]\tLoss: 554.045166\n",
      "Train Epoch: 21 [900/2589 (35%)]\tLoss: 519.960022\n",
      "Train Epoch: 21 [1200/2589 (46%)]\tLoss: 600.433777\n",
      "Train Epoch: 21 [1500/2589 (58%)]\tLoss: 588.287170\n",
      "Train Epoch: 21 [1800/2589 (70%)]\tLoss: 585.802612\n",
      "Train Epoch: 21 [2100/2589 (81%)]\tLoss: 567.372742\n",
      "Train Epoch: 21 [2400/2589 (93%)]\tLoss: 460.017609\n",
      "====> Epoch: 21 Average train loss: 510.5963\n",
      "====> Epoch: 21 Average test loss: 923.9307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [0/2589 (0%)]\tLoss: 740.969543\n",
      "Train Epoch: 22 [300/2589 (12%)]\tLoss: 457.388153\n",
      "Train Epoch: 22 [600/2589 (23%)]\tLoss: 407.566986\n",
      "Train Epoch: 22 [900/2589 (35%)]\tLoss: 510.550262\n",
      "Train Epoch: 22 [1200/2589 (46%)]\tLoss: 658.720337\n",
      "Train Epoch: 22 [1500/2589 (58%)]\tLoss: 524.640991\n",
      "Train Epoch: 22 [1800/2589 (70%)]\tLoss: 456.696289\n",
      "Train Epoch: 22 [2100/2589 (81%)]\tLoss: 518.256042\n",
      "Train Epoch: 22 [2400/2589 (93%)]\tLoss: 394.935120\n",
      "====> Epoch: 22 Average train loss: 508.6902\n",
      "====> Epoch: 22 Average test loss: 894.5046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [0/2589 (0%)]\tLoss: 408.072693\n",
      "Train Epoch: 23 [300/2589 (12%)]\tLoss: 454.774384\n",
      "Train Epoch: 23 [600/2589 (23%)]\tLoss: 392.284637\n",
      "Train Epoch: 23 [900/2589 (35%)]\tLoss: 548.875793\n",
      "Train Epoch: 23 [1200/2589 (46%)]\tLoss: 536.004456\n",
      "Train Epoch: 23 [1500/2589 (58%)]\tLoss: 413.383240\n",
      "Train Epoch: 23 [1800/2589 (70%)]\tLoss: 418.218872\n",
      "Train Epoch: 23 [2100/2589 (81%)]\tLoss: 525.714050\n",
      "Train Epoch: 23 [2400/2589 (93%)]\tLoss: 424.650482\n",
      "====> Epoch: 23 Average train loss: 493.9523\n",
      "====> Epoch: 23 Average test loss: 891.5113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [0/2589 (0%)]\tLoss: 399.268402\n",
      "Train Epoch: 24 [300/2589 (12%)]\tLoss: 496.805878\n",
      "Train Epoch: 24 [600/2589 (23%)]\tLoss: 437.748749\n",
      "Train Epoch: 24 [900/2589 (35%)]\tLoss: 450.244812\n",
      "Train Epoch: 24 [1200/2589 (46%)]\tLoss: 616.871887\n",
      "Train Epoch: 24 [1500/2589 (58%)]\tLoss: 518.959351\n",
      "Train Epoch: 24 [1800/2589 (70%)]\tLoss: 444.304260\n",
      "Train Epoch: 24 [2100/2589 (81%)]\tLoss: 563.659729\n",
      "Train Epoch: 24 [2400/2589 (93%)]\tLoss: 538.801514\n",
      "====> Epoch: 24 Average train loss: 490.5856\n",
      "====> Epoch: 24 Average test loss: 888.0637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [0/2589 (0%)]\tLoss: 352.932526\n",
      "Train Epoch: 25 [300/2589 (12%)]\tLoss: 496.166718\n",
      "Train Epoch: 25 [600/2589 (23%)]\tLoss: 612.908508\n",
      "Train Epoch: 25 [900/2589 (35%)]\tLoss: 428.265228\n",
      "Train Epoch: 25 [1200/2589 (46%)]\tLoss: 492.014191\n",
      "Train Epoch: 25 [1500/2589 (58%)]\tLoss: 563.574768\n",
      "Train Epoch: 25 [1800/2589 (70%)]\tLoss: 576.779175\n",
      "Train Epoch: 25 [2100/2589 (81%)]\tLoss: 605.088196\n",
      "Train Epoch: 25 [2400/2589 (93%)]\tLoss: 419.171722\n",
      "====> Epoch: 25 Average train loss: 486.4406\n",
      "====> Epoch: 25 Average test loss: 909.9299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [0/2589 (0%)]\tLoss: 502.263672\n",
      "Train Epoch: 26 [300/2589 (12%)]\tLoss: 391.968475\n",
      "Train Epoch: 26 [600/2589 (23%)]\tLoss: 366.464905\n",
      "Train Epoch: 26 [900/2589 (35%)]\tLoss: 318.835938\n",
      "Train Epoch: 26 [1200/2589 (46%)]\tLoss: 419.401184\n",
      "Train Epoch: 26 [1500/2589 (58%)]\tLoss: 425.918884\n",
      "Train Epoch: 26 [1800/2589 (70%)]\tLoss: 674.927673\n",
      "Train Epoch: 26 [2100/2589 (81%)]\tLoss: 536.488892\n",
      "Train Epoch: 26 [2400/2589 (93%)]\tLoss: 400.106262\n",
      "====> Epoch: 26 Average train loss: 481.5728\n",
      "====> Epoch: 26 Average test loss: 903.7350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [0/2589 (0%)]\tLoss: 331.028717\n",
      "Train Epoch: 27 [300/2589 (12%)]\tLoss: 412.798004\n",
      "Train Epoch: 27 [600/2589 (23%)]\tLoss: 529.942566\n",
      "Train Epoch: 27 [900/2589 (35%)]\tLoss: 469.547852\n",
      "Train Epoch: 27 [1200/2589 (46%)]\tLoss: 793.806824\n",
      "Train Epoch: 27 [1500/2589 (58%)]\tLoss: 575.235107\n",
      "Train Epoch: 27 [1800/2589 (70%)]\tLoss: 552.406006\n",
      "Train Epoch: 27 [2100/2589 (81%)]\tLoss: 476.967438\n",
      "Train Epoch: 27 [2400/2589 (93%)]\tLoss: 527.779053\n",
      "====> Epoch: 27 Average train loss: 474.3504\n",
      "====> Epoch: 27 Average test loss: 910.5386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [0/2589 (0%)]\tLoss: 437.383942\n",
      "Train Epoch: 28 [300/2589 (12%)]\tLoss: 381.077667\n",
      "Train Epoch: 28 [600/2589 (23%)]\tLoss: 427.767609\n",
      "Train Epoch: 28 [900/2589 (35%)]\tLoss: 502.531921\n",
      "Train Epoch: 28 [1200/2589 (46%)]\tLoss: 315.755554\n",
      "Train Epoch: 28 [1500/2589 (58%)]\tLoss: 559.604431\n",
      "Train Epoch: 28 [1800/2589 (70%)]\tLoss: 632.122742\n",
      "Train Epoch: 28 [2100/2589 (81%)]\tLoss: 339.730927\n",
      "Train Epoch: 28 [2400/2589 (93%)]\tLoss: 381.727539\n",
      "====> Epoch: 28 Average train loss: 474.9620\n",
      "====> Epoch: 28 Average test loss: 914.6547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 [0/2589 (0%)]\tLoss: 447.295197\n",
      "Train Epoch: 29 [300/2589 (12%)]\tLoss: 338.396393\n",
      "Train Epoch: 29 [600/2589 (23%)]\tLoss: 449.292175\n",
      "Train Epoch: 29 [900/2589 (35%)]\tLoss: 445.609711\n",
      "Train Epoch: 29 [1200/2589 (46%)]\tLoss: 724.316589\n",
      "Train Epoch: 29 [1500/2589 (58%)]\tLoss: 475.128723\n",
      "Train Epoch: 29 [1800/2589 (70%)]\tLoss: 537.919067\n",
      "Train Epoch: 29 [2100/2589 (81%)]\tLoss: 472.842133\n",
      "Train Epoch: 29 [2400/2589 (93%)]\tLoss: 431.181488\n",
      "====> Epoch: 29 Average train loss: 462.2716\n",
      "====> Epoch: 29 Average test loss: 923.3673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [0/2589 (0%)]\tLoss: 496.332916\n",
      "Train Epoch: 30 [300/2589 (12%)]\tLoss: 406.037811\n",
      "Train Epoch: 30 [600/2589 (23%)]\tLoss: 341.243713\n",
      "Train Epoch: 30 [900/2589 (35%)]\tLoss: 688.276123\n",
      "Train Epoch: 30 [1200/2589 (46%)]\tLoss: 394.043304\n",
      "Train Epoch: 30 [1500/2589 (58%)]\tLoss: 507.998932\n",
      "Train Epoch: 30 [1800/2589 (70%)]\tLoss: 467.287292\n",
      "Train Epoch: 30 [2100/2589 (81%)]\tLoss: 451.375763\n",
      "Train Epoch: 30 [2400/2589 (93%)]\tLoss: 390.097290\n",
      "====> Epoch: 30 Average train loss: 461.7606\n",
      "====> Epoch: 30 Average test loss: 923.9494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [0/2589 (0%)]\tLoss: 689.903381\n",
      "Train Epoch: 31 [300/2589 (12%)]\tLoss: 447.384247\n",
      "Train Epoch: 31 [600/2589 (23%)]\tLoss: 473.419098\n",
      "Train Epoch: 31 [900/2589 (35%)]\tLoss: 351.656372\n",
      "Train Epoch: 31 [1200/2589 (46%)]\tLoss: 331.674622\n",
      "Train Epoch: 31 [1500/2589 (58%)]\tLoss: 384.621094\n",
      "Train Epoch: 31 [1800/2589 (70%)]\tLoss: 361.161194\n",
      "Train Epoch: 31 [2100/2589 (81%)]\tLoss: 382.837006\n",
      "Train Epoch: 31 [2400/2589 (93%)]\tLoss: 483.629486\n",
      "====> Epoch: 31 Average train loss: 451.5160\n",
      "====> Epoch: 31 Average test loss: 908.0502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [0/2589 (0%)]\tLoss: 580.896729\n",
      "Train Epoch: 32 [300/2589 (12%)]\tLoss: 435.371887\n",
      "Train Epoch: 32 [600/2589 (23%)]\tLoss: 394.320129\n",
      "Train Epoch: 32 [900/2589 (35%)]\tLoss: 515.434631\n",
      "Train Epoch: 32 [1200/2589 (46%)]\tLoss: 482.433502\n",
      "Train Epoch: 32 [1500/2589 (58%)]\tLoss: 490.144989\n",
      "Train Epoch: 32 [1800/2589 (70%)]\tLoss: 434.217865\n",
      "Train Epoch: 32 [2100/2589 (81%)]\tLoss: 397.243164\n",
      "Train Epoch: 32 [2400/2589 (93%)]\tLoss: 437.529388\n",
      "====> Epoch: 32 Average train loss: 454.6642\n",
      "====> Epoch: 32 Average test loss: 919.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [0/2589 (0%)]\tLoss: 396.300812\n",
      "Train Epoch: 33 [300/2589 (12%)]\tLoss: 481.021088\n",
      "Train Epoch: 33 [600/2589 (23%)]\tLoss: 712.870972\n",
      "Train Epoch: 33 [900/2589 (35%)]\tLoss: 509.826477\n",
      "Train Epoch: 33 [1200/2589 (46%)]\tLoss: 502.983704\n",
      "Train Epoch: 33 [1500/2589 (58%)]\tLoss: 510.999908\n",
      "Train Epoch: 33 [1800/2589 (70%)]\tLoss: 481.275543\n",
      "Train Epoch: 33 [2100/2589 (81%)]\tLoss: 578.683167\n",
      "Train Epoch: 33 [2400/2589 (93%)]\tLoss: 376.188660\n",
      "====> Epoch: 33 Average train loss: 455.4979\n",
      "====> Epoch: 33 Average test loss: 939.0751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 [0/2589 (0%)]\tLoss: 630.701172\n",
      "Train Epoch: 34 [300/2589 (12%)]\tLoss: 590.201965\n",
      "Train Epoch: 34 [600/2589 (23%)]\tLoss: 344.553741\n",
      "Train Epoch: 34 [900/2589 (35%)]\tLoss: 420.001953\n",
      "Train Epoch: 34 [1200/2589 (46%)]\tLoss: 438.170837\n",
      "Train Epoch: 34 [1500/2589 (58%)]\tLoss: 394.965485\n",
      "Train Epoch: 34 [1800/2589 (70%)]\tLoss: 510.170868\n",
      "Train Epoch: 34 [2100/2589 (81%)]\tLoss: 447.705200\n",
      "Train Epoch: 34 [2400/2589 (93%)]\tLoss: 385.003326\n",
      "====> Epoch: 34 Average train loss: 455.3193\n",
      "====> Epoch: 34 Average test loss: 917.5809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [0/2589 (0%)]\tLoss: 397.451233\n",
      "Train Epoch: 35 [300/2589 (12%)]\tLoss: 595.028076\n",
      "Train Epoch: 35 [600/2589 (23%)]\tLoss: 295.154205\n",
      "Train Epoch: 35 [900/2589 (35%)]\tLoss: 542.652039\n",
      "Train Epoch: 35 [1200/2589 (46%)]\tLoss: 603.904236\n",
      "Train Epoch: 35 [1500/2589 (58%)]\tLoss: 452.173309\n",
      "Train Epoch: 35 [1800/2589 (70%)]\tLoss: 521.700806\n",
      "Train Epoch: 35 [2100/2589 (81%)]\tLoss: 277.345184\n",
      "Train Epoch: 35 [2400/2589 (93%)]\tLoss: 361.925873\n",
      "====> Epoch: 35 Average train loss: 447.9405\n",
      "====> Epoch: 35 Average test loss: 919.1805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [0/2589 (0%)]\tLoss: 429.272186\n",
      "Train Epoch: 36 [300/2589 (12%)]\tLoss: 478.994080\n",
      "Train Epoch: 36 [600/2589 (23%)]\tLoss: 339.102997\n",
      "Train Epoch: 36 [900/2589 (35%)]\tLoss: 367.451599\n",
      "Train Epoch: 36 [1200/2589 (46%)]\tLoss: 391.656433\n",
      "Train Epoch: 36 [1500/2589 (58%)]\tLoss: 479.534119\n",
      "Train Epoch: 36 [1800/2589 (70%)]\tLoss: 411.192596\n",
      "Train Epoch: 36 [2100/2589 (81%)]\tLoss: 437.292999\n",
      "Train Epoch: 36 [2400/2589 (93%)]\tLoss: 414.356506\n",
      "====> Epoch: 36 Average train loss: 448.5386\n",
      "====> Epoch: 36 Average test loss: 956.6995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [0/2589 (0%)]\tLoss: 381.869354\n",
      "Train Epoch: 37 [300/2589 (12%)]\tLoss: 500.394257\n",
      "Train Epoch: 37 [600/2589 (23%)]\tLoss: 465.971802\n",
      "Train Epoch: 37 [900/2589 (35%)]\tLoss: 404.335175\n",
      "Train Epoch: 37 [1200/2589 (46%)]\tLoss: 525.579224\n",
      "Train Epoch: 37 [1500/2589 (58%)]\tLoss: 258.060638\n",
      "Train Epoch: 37 [1800/2589 (70%)]\tLoss: 605.563416\n",
      "Train Epoch: 37 [2100/2589 (81%)]\tLoss: 444.093781\n",
      "Train Epoch: 37 [2400/2589 (93%)]\tLoss: 474.976166\n",
      "====> Epoch: 37 Average train loss: 432.4633\n",
      "====> Epoch: 37 Average test loss: 932.2764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [0/2589 (0%)]\tLoss: 556.752075\n",
      "Train Epoch: 38 [300/2589 (12%)]\tLoss: 421.933685\n",
      "Train Epoch: 38 [600/2589 (23%)]\tLoss: 543.056763\n",
      "Train Epoch: 38 [900/2589 (35%)]\tLoss: 517.417725\n",
      "Train Epoch: 38 [1200/2589 (46%)]\tLoss: 431.864960\n",
      "Train Epoch: 38 [1500/2589 (58%)]\tLoss: 365.041382\n",
      "Train Epoch: 38 [1800/2589 (70%)]\tLoss: 331.848846\n",
      "Train Epoch: 38 [2100/2589 (81%)]\tLoss: 535.440857\n",
      "Train Epoch: 38 [2400/2589 (93%)]\tLoss: 356.988220\n",
      "====> Epoch: 38 Average train loss: 434.5523\n",
      "====> Epoch: 38 Average test loss: 934.4127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [0/2589 (0%)]\tLoss: 390.810730\n",
      "Train Epoch: 39 [300/2589 (12%)]\tLoss: 431.963287\n",
      "Train Epoch: 39 [600/2589 (23%)]\tLoss: 581.601501\n",
      "Train Epoch: 39 [900/2589 (35%)]\tLoss: 507.851471\n",
      "Train Epoch: 39 [1200/2589 (46%)]\tLoss: 443.084045\n",
      "Train Epoch: 39 [1500/2589 (58%)]\tLoss: 389.443420\n",
      "Train Epoch: 39 [1800/2589 (70%)]\tLoss: 347.964447\n",
      "Train Epoch: 39 [2100/2589 (81%)]\tLoss: 486.851868\n",
      "Train Epoch: 39 [2400/2589 (93%)]\tLoss: 459.067230\n",
      "====> Epoch: 39 Average train loss: 429.9722\n",
      "====> Epoch: 39 Average test loss: 930.3264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [0/2589 (0%)]\tLoss: 378.117371\n",
      "Train Epoch: 40 [300/2589 (12%)]\tLoss: 364.171661\n",
      "Train Epoch: 40 [600/2589 (23%)]\tLoss: 465.545776\n",
      "Train Epoch: 40 [900/2589 (35%)]\tLoss: 482.313293\n",
      "Train Epoch: 40 [1200/2589 (46%)]\tLoss: 334.468231\n",
      "Train Epoch: 40 [1500/2589 (58%)]\tLoss: 399.151367\n",
      "Train Epoch: 40 [1800/2589 (70%)]\tLoss: 381.297272\n",
      "Train Epoch: 40 [2100/2589 (81%)]\tLoss: 437.088470\n",
      "Train Epoch: 40 [2400/2589 (93%)]\tLoss: 323.961823\n",
      "====> Epoch: 40 Average train loss: 427.6449\n",
      "====> Epoch: 40 Average test loss: 939.4470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41 [0/2589 (0%)]\tLoss: 342.215271\n",
      "Train Epoch: 41 [300/2589 (12%)]\tLoss: 330.022949\n",
      "Train Epoch: 41 [600/2589 (23%)]\tLoss: 272.620239\n",
      "Train Epoch: 41 [900/2589 (35%)]\tLoss: 597.907104\n",
      "Train Epoch: 41 [1200/2589 (46%)]\tLoss: 364.971161\n",
      "Train Epoch: 41 [1500/2589 (58%)]\tLoss: 406.633881\n",
      "Train Epoch: 41 [1800/2589 (70%)]\tLoss: 474.479370\n",
      "Train Epoch: 41 [2100/2589 (81%)]\tLoss: 470.766388\n",
      "Train Epoch: 41 [2400/2589 (93%)]\tLoss: 386.157288\n",
      "====> Epoch: 41 Average train loss: 433.5561\n",
      "====> Epoch: 41 Average test loss: 923.5214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [0/2589 (0%)]\tLoss: 429.766632\n",
      "Train Epoch: 42 [300/2589 (12%)]\tLoss: 337.348145\n",
      "Train Epoch: 42 [600/2589 (23%)]\tLoss: 352.853699\n",
      "Train Epoch: 42 [900/2589 (35%)]\tLoss: 347.124847\n",
      "Train Epoch: 42 [1200/2589 (46%)]\tLoss: 388.192322\n",
      "Train Epoch: 42 [1500/2589 (58%)]\tLoss: 313.467346\n",
      "Train Epoch: 42 [1800/2589 (70%)]\tLoss: 561.742981\n",
      "Train Epoch: 42 [2100/2589 (81%)]\tLoss: 509.624542\n",
      "Train Epoch: 42 [2400/2589 (93%)]\tLoss: 453.902710\n",
      "====> Epoch: 42 Average train loss: 419.3669\n",
      "====> Epoch: 42 Average test loss: 950.0268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [0/2589 (0%)]\tLoss: 454.395782\n",
      "Train Epoch: 43 [300/2589 (12%)]\tLoss: 405.255798\n",
      "Train Epoch: 43 [600/2589 (23%)]\tLoss: 443.124481\n",
      "Train Epoch: 43 [900/2589 (35%)]\tLoss: 316.200562\n",
      "Train Epoch: 43 [1200/2589 (46%)]\tLoss: 418.155426\n",
      "Train Epoch: 43 [1500/2589 (58%)]\tLoss: 465.228210\n",
      "Train Epoch: 43 [1800/2589 (70%)]\tLoss: 492.096741\n",
      "Train Epoch: 43 [2100/2589 (81%)]\tLoss: 531.669800\n",
      "Train Epoch: 43 [2400/2589 (93%)]\tLoss: 431.767517\n",
      "====> Epoch: 43 Average train loss: 422.6905\n",
      "====> Epoch: 43 Average test loss: 960.6830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 [0/2589 (0%)]\tLoss: 429.146484\n",
      "Train Epoch: 44 [300/2589 (12%)]\tLoss: 573.921265\n",
      "Train Epoch: 44 [600/2589 (23%)]\tLoss: 559.931091\n",
      "Train Epoch: 44 [900/2589 (35%)]\tLoss: 466.347473\n",
      "Train Epoch: 44 [1200/2589 (46%)]\tLoss: 399.746002\n",
      "Train Epoch: 44 [1500/2589 (58%)]\tLoss: 559.840149\n",
      "Train Epoch: 44 [1800/2589 (70%)]\tLoss: 265.004578\n",
      "Train Epoch: 44 [2100/2589 (81%)]\tLoss: 468.669861\n",
      "Train Epoch: 44 [2400/2589 (93%)]\tLoss: 229.796860\n",
      "====> Epoch: 44 Average train loss: 408.0473\n",
      "====> Epoch: 44 Average test loss: 952.4708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [0/2589 (0%)]\tLoss: 353.657227\n",
      "Train Epoch: 45 [300/2589 (12%)]\tLoss: 460.925262\n",
      "Train Epoch: 45 [600/2589 (23%)]\tLoss: 216.351883\n",
      "Train Epoch: 45 [900/2589 (35%)]\tLoss: 365.435944\n",
      "Train Epoch: 45 [1200/2589 (46%)]\tLoss: 310.739258\n",
      "Train Epoch: 45 [1500/2589 (58%)]\tLoss: 431.949738\n",
      "Train Epoch: 45 [1800/2589 (70%)]\tLoss: 369.746887\n",
      "Train Epoch: 45 [2100/2589 (81%)]\tLoss: 278.248596\n",
      "Train Epoch: 45 [2400/2589 (93%)]\tLoss: 390.212982\n",
      "====> Epoch: 45 Average train loss: 417.9800\n",
      "====> Epoch: 45 Average test loss: 921.5839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 46 [0/2589 (0%)]\tLoss: 305.372375\n",
      "Train Epoch: 46 [300/2589 (12%)]\tLoss: 577.855591\n",
      "Train Epoch: 46 [600/2589 (23%)]\tLoss: 459.664551\n",
      "Train Epoch: 46 [900/2589 (35%)]\tLoss: 397.988831\n",
      "Train Epoch: 46 [1200/2589 (46%)]\tLoss: 339.214508\n",
      "Train Epoch: 46 [1500/2589 (58%)]\tLoss: 313.438202\n",
      "Train Epoch: 46 [1800/2589 (70%)]\tLoss: 307.890594\n",
      "Train Epoch: 46 [2100/2589 (81%)]\tLoss: 465.095520\n",
      "Train Epoch: 46 [2400/2589 (93%)]\tLoss: 423.852844\n",
      "====> Epoch: 46 Average train loss: 417.3113\n",
      "====> Epoch: 46 Average test loss: 940.3619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [0/2589 (0%)]\tLoss: 340.624298\n",
      "Train Epoch: 47 [300/2589 (12%)]\tLoss: 312.520721\n",
      "Train Epoch: 47 [600/2589 (23%)]\tLoss: 360.882812\n",
      "Train Epoch: 47 [900/2589 (35%)]\tLoss: 378.416870\n",
      "Train Epoch: 47 [1200/2589 (46%)]\tLoss: 363.983398\n",
      "Train Epoch: 47 [1500/2589 (58%)]\tLoss: 554.953491\n",
      "Train Epoch: 47 [1800/2589 (70%)]\tLoss: 442.536102\n",
      "Train Epoch: 47 [2100/2589 (81%)]\tLoss: 328.149292\n",
      "Train Epoch: 47 [2400/2589 (93%)]\tLoss: 390.757782\n",
      "====> Epoch: 47 Average train loss: 419.7925\n",
      "====> Epoch: 47 Average test loss: 933.3900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [0/2589 (0%)]\tLoss: 367.322632\n",
      "Train Epoch: 48 [300/2589 (12%)]\tLoss: 334.337372\n",
      "Train Epoch: 48 [600/2589 (23%)]\tLoss: 506.184143\n",
      "Train Epoch: 48 [900/2589 (35%)]\tLoss: 569.965515\n",
      "Train Epoch: 48 [1200/2589 (46%)]\tLoss: 344.939850\n",
      "Train Epoch: 48 [1500/2589 (58%)]\tLoss: 532.592529\n",
      "Train Epoch: 48 [1800/2589 (70%)]\tLoss: 486.933502\n",
      "Train Epoch: 48 [2100/2589 (81%)]\tLoss: 358.071747\n",
      "Train Epoch: 48 [2400/2589 (93%)]\tLoss: 354.833679\n",
      "====> Epoch: 48 Average train loss: 407.7558\n",
      "====> Epoch: 48 Average test loss: 947.2791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 49 [0/2589 (0%)]\tLoss: 751.601746\n",
      "Train Epoch: 49 [300/2589 (12%)]\tLoss: 425.024628\n",
      "Train Epoch: 49 [600/2589 (23%)]\tLoss: 544.692017\n",
      "Train Epoch: 49 [900/2589 (35%)]\tLoss: 377.508820\n",
      "Train Epoch: 49 [1200/2589 (46%)]\tLoss: 381.597839\n",
      "Train Epoch: 49 [1500/2589 (58%)]\tLoss: 439.909760\n",
      "Train Epoch: 49 [1800/2589 (70%)]\tLoss: 385.063782\n",
      "Train Epoch: 49 [2100/2589 (81%)]\tLoss: 483.281921\n",
      "Train Epoch: 49 [2400/2589 (93%)]\tLoss: 691.889099\n",
      "====> Epoch: 49 Average train loss: 414.2922\n",
      "====> Epoch: 49 Average test loss: 933.7014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 50 [0/2589 (0%)]\tLoss: 331.261078\n",
      "Train Epoch: 50 [300/2589 (12%)]\tLoss: 445.278595\n",
      "Train Epoch: 50 [600/2589 (23%)]\tLoss: 363.711639\n",
      "Train Epoch: 50 [900/2589 (35%)]\tLoss: 414.095490\n",
      "Train Epoch: 50 [1200/2589 (46%)]\tLoss: 603.718811\n",
      "Train Epoch: 50 [1500/2589 (58%)]\tLoss: 428.832611\n",
      "Train Epoch: 50 [1800/2589 (70%)]\tLoss: 349.428680\n",
      "Train Epoch: 50 [2100/2589 (81%)]\tLoss: 527.004028\n",
      "Train Epoch: 50 [2400/2589 (93%)]\tLoss: 430.179962\n",
      "====> Epoch: 50 Average train loss: 405.6186\n",
      "====> Epoch: 50 Average test loss: 929.3186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 51 [0/2589 (0%)]\tLoss: 332.023834\n",
      "Train Epoch: 51 [300/2589 (12%)]\tLoss: 258.500458\n",
      "Train Epoch: 51 [600/2589 (23%)]\tLoss: 291.159210\n",
      "Train Epoch: 51 [900/2589 (35%)]\tLoss: 491.650116\n",
      "Train Epoch: 51 [1200/2589 (46%)]\tLoss: 302.266815\n",
      "Train Epoch: 51 [1500/2589 (58%)]\tLoss: 365.906677\n",
      "Train Epoch: 51 [1800/2589 (70%)]\tLoss: 408.450714\n",
      "Train Epoch: 51 [2100/2589 (81%)]\tLoss: 538.495361\n",
      "Train Epoch: 51 [2400/2589 (93%)]\tLoss: 407.116974\n",
      "====> Epoch: 51 Average train loss: 402.8474\n",
      "====> Epoch: 51 Average test loss: 927.4473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 52 [0/2589 (0%)]\tLoss: 334.485077\n",
      "Train Epoch: 52 [300/2589 (12%)]\tLoss: 375.301605\n",
      "Train Epoch: 52 [600/2589 (23%)]\tLoss: 420.879822\n",
      "Train Epoch: 52 [900/2589 (35%)]\tLoss: 414.528320\n",
      "Train Epoch: 52 [1200/2589 (46%)]\tLoss: 342.303162\n",
      "Train Epoch: 52 [1500/2589 (58%)]\tLoss: 310.304718\n",
      "Train Epoch: 52 [1800/2589 (70%)]\tLoss: 377.818390\n",
      "Train Epoch: 52 [2100/2589 (81%)]\tLoss: 502.615814\n",
      "Train Epoch: 52 [2400/2589 (93%)]\tLoss: 481.570862\n",
      "====> Epoch: 52 Average train loss: 400.0707\n",
      "====> Epoch: 52 Average test loss: 932.2186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [0/2589 (0%)]\tLoss: 347.422241\n",
      "Train Epoch: 53 [300/2589 (12%)]\tLoss: 319.692810\n",
      "Train Epoch: 53 [600/2589 (23%)]\tLoss: 381.886871\n",
      "Train Epoch: 53 [900/2589 (35%)]\tLoss: 473.079193\n",
      "Train Epoch: 53 [1200/2589 (46%)]\tLoss: 367.219238\n",
      "Train Epoch: 53 [1500/2589 (58%)]\tLoss: 360.682922\n",
      "Train Epoch: 53 [1800/2589 (70%)]\tLoss: 375.509064\n",
      "Train Epoch: 53 [2100/2589 (81%)]\tLoss: 372.823456\n",
      "Train Epoch: 53 [2400/2589 (93%)]\tLoss: 426.322235\n",
      "====> Epoch: 53 Average train loss: 397.9776\n",
      "====> Epoch: 53 Average test loss: 938.6765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 54 [0/2589 (0%)]\tLoss: 282.873474\n",
      "Train Epoch: 54 [300/2589 (12%)]\tLoss: 503.159271\n",
      "Train Epoch: 54 [600/2589 (23%)]\tLoss: 379.193970\n",
      "Train Epoch: 54 [900/2589 (35%)]\tLoss: 486.985352\n",
      "Train Epoch: 54 [1200/2589 (46%)]\tLoss: 511.618622\n",
      "Train Epoch: 54 [1500/2589 (58%)]\tLoss: 399.985474\n",
      "Train Epoch: 54 [1800/2589 (70%)]\tLoss: 405.920044\n",
      "Train Epoch: 54 [2100/2589 (81%)]\tLoss: 436.593048\n",
      "Train Epoch: 54 [2400/2589 (93%)]\tLoss: 482.485931\n",
      "====> Epoch: 54 Average train loss: 395.8831\n",
      "====> Epoch: 54 Average test loss: 934.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 55 [0/2589 (0%)]\tLoss: 331.170074\n",
      "Train Epoch: 55 [300/2589 (12%)]\tLoss: 432.828644\n",
      "Train Epoch: 55 [600/2589 (23%)]\tLoss: 372.601196\n",
      "Train Epoch: 55 [900/2589 (35%)]\tLoss: 378.969910\n",
      "Train Epoch: 55 [1200/2589 (46%)]\tLoss: 534.354675\n",
      "Train Epoch: 55 [1500/2589 (58%)]\tLoss: 309.259155\n",
      "Train Epoch: 55 [1800/2589 (70%)]\tLoss: 327.566864\n",
      "Train Epoch: 55 [2100/2589 (81%)]\tLoss: 285.030457\n",
      "Train Epoch: 55 [2400/2589 (93%)]\tLoss: 481.356934\n",
      "====> Epoch: 55 Average train loss: 397.8540\n",
      "====> Epoch: 55 Average test loss: 952.6467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [0/2589 (0%)]\tLoss: 364.100647\n",
      "Train Epoch: 56 [300/2589 (12%)]\tLoss: 367.606567\n",
      "Train Epoch: 56 [600/2589 (23%)]\tLoss: 394.067566\n",
      "Train Epoch: 56 [900/2589 (35%)]\tLoss: 407.238281\n",
      "Train Epoch: 56 [1200/2589 (46%)]\tLoss: 441.078766\n",
      "Train Epoch: 56 [1500/2589 (58%)]\tLoss: 315.025757\n",
      "Train Epoch: 56 [1800/2589 (70%)]\tLoss: 339.470276\n",
      "Train Epoch: 56 [2100/2589 (81%)]\tLoss: 405.202423\n",
      "Train Epoch: 56 [2400/2589 (93%)]\tLoss: 325.666595\n",
      "====> Epoch: 56 Average train loss: 389.6751\n",
      "====> Epoch: 56 Average test loss: 940.4711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 57 [0/2589 (0%)]\tLoss: 335.335663\n",
      "Train Epoch: 57 [300/2589 (12%)]\tLoss: 520.671997\n",
      "Train Epoch: 57 [600/2589 (23%)]\tLoss: 354.409393\n",
      "Train Epoch: 57 [900/2589 (35%)]\tLoss: 366.939056\n",
      "Train Epoch: 57 [1200/2589 (46%)]\tLoss: 412.378052\n",
      "Train Epoch: 57 [1500/2589 (58%)]\tLoss: 360.361450\n",
      "Train Epoch: 57 [1800/2589 (70%)]\tLoss: 368.610626\n",
      "Train Epoch: 57 [2100/2589 (81%)]\tLoss: 373.191467\n",
      "Train Epoch: 57 [2400/2589 (93%)]\tLoss: 461.323669\n",
      "====> Epoch: 57 Average train loss: 386.5832\n",
      "====> Epoch: 57 Average test loss: 944.3632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 58 [0/2589 (0%)]\tLoss: 308.455841\n",
      "Train Epoch: 58 [300/2589 (12%)]\tLoss: 315.799408\n",
      "Train Epoch: 58 [600/2589 (23%)]\tLoss: 409.783203\n",
      "Train Epoch: 58 [900/2589 (35%)]\tLoss: 463.645325\n",
      "Train Epoch: 58 [1200/2589 (46%)]\tLoss: 424.681915\n",
      "Train Epoch: 58 [1500/2589 (58%)]\tLoss: 318.608887\n",
      "Train Epoch: 58 [1800/2589 (70%)]\tLoss: 332.137878\n",
      "Train Epoch: 58 [2100/2589 (81%)]\tLoss: 373.983582\n",
      "Train Epoch: 58 [2400/2589 (93%)]\tLoss: 422.734070\n",
      "====> Epoch: 58 Average train loss: 378.1669\n",
      "====> Epoch: 58 Average test loss: 931.5571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 59 [0/2589 (0%)]\tLoss: 253.799667\n",
      "Train Epoch: 59 [300/2589 (12%)]\tLoss: 421.564789\n",
      "Train Epoch: 59 [600/2589 (23%)]\tLoss: 320.409302\n",
      "Train Epoch: 59 [900/2589 (35%)]\tLoss: 278.421967\n",
      "Train Epoch: 59 [1200/2589 (46%)]\tLoss: 471.866516\n",
      "Train Epoch: 59 [1500/2589 (58%)]\tLoss: 442.690948\n",
      "Train Epoch: 59 [1800/2589 (70%)]\tLoss: 191.873474\n",
      "Train Epoch: 59 [2100/2589 (81%)]\tLoss: 243.693878\n",
      "Train Epoch: 59 [2400/2589 (93%)]\tLoss: 306.223633\n",
      "====> Epoch: 59 Average train loss: 378.0986\n",
      "====> Epoch: 59 Average test loss: 937.4637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60 [0/2589 (0%)]\tLoss: 351.471588\n",
      "Train Epoch: 60 [300/2589 (12%)]\tLoss: 319.410217\n",
      "Train Epoch: 60 [600/2589 (23%)]\tLoss: 336.231262\n",
      "Train Epoch: 60 [900/2589 (35%)]\tLoss: 563.595520\n",
      "Train Epoch: 60 [1200/2589 (46%)]\tLoss: 448.542999\n",
      "Train Epoch: 60 [1500/2589 (58%)]\tLoss: 390.853455\n",
      "Train Epoch: 60 [1800/2589 (70%)]\tLoss: 441.638672\n",
      "Train Epoch: 60 [2100/2589 (81%)]\tLoss: 434.234375\n",
      "Train Epoch: 60 [2400/2589 (93%)]\tLoss: 611.146729\n",
      "====> Epoch: 60 Average train loss: 380.5029\n",
      "====> Epoch: 60 Average test loss: 946.6053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 61 [0/2589 (0%)]\tLoss: 330.639099\n",
      "Train Epoch: 61 [300/2589 (12%)]\tLoss: 346.179199\n",
      "Train Epoch: 61 [600/2589 (23%)]\tLoss: 412.868774\n",
      "Train Epoch: 61 [900/2589 (35%)]\tLoss: 426.595428\n",
      "Train Epoch: 61 [1200/2589 (46%)]\tLoss: 420.752106\n",
      "Train Epoch: 61 [1500/2589 (58%)]\tLoss: 294.793579\n",
      "Train Epoch: 61 [1800/2589 (70%)]\tLoss: 341.187683\n",
      "Train Epoch: 61 [2100/2589 (81%)]\tLoss: 365.967804\n",
      "Train Epoch: 61 [2400/2589 (93%)]\tLoss: 339.238770\n",
      "====> Epoch: 61 Average train loss: 383.1741\n",
      "====> Epoch: 61 Average test loss: 931.3373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 62 [0/2589 (0%)]\tLoss: 404.834137\n",
      "Train Epoch: 62 [300/2589 (12%)]\tLoss: 276.299225\n",
      "Train Epoch: 62 [600/2589 (23%)]\tLoss: 316.171539\n",
      "Train Epoch: 62 [900/2589 (35%)]\tLoss: 414.005310\n",
      "Train Epoch: 62 [1200/2589 (46%)]\tLoss: 355.992065\n",
      "Train Epoch: 62 [1500/2589 (58%)]\tLoss: 301.906830\n",
      "Train Epoch: 62 [1800/2589 (70%)]\tLoss: 447.850311\n",
      "Train Epoch: 62 [2100/2589 (81%)]\tLoss: 408.031403\n",
      "Train Epoch: 62 [2400/2589 (93%)]\tLoss: 438.114624\n",
      "====> Epoch: 62 Average train loss: 385.4059\n",
      "====> Epoch: 62 Average test loss: 947.1248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 63 [0/2589 (0%)]\tLoss: 404.774139\n",
      "Train Epoch: 63 [300/2589 (12%)]\tLoss: 381.236267\n",
      "Train Epoch: 63 [600/2589 (23%)]\tLoss: 385.135376\n",
      "Train Epoch: 63 [900/2589 (35%)]\tLoss: 375.292877\n",
      "Train Epoch: 63 [1200/2589 (46%)]\tLoss: 495.991791\n",
      "Train Epoch: 63 [1500/2589 (58%)]\tLoss: 492.534637\n",
      "Train Epoch: 63 [1800/2589 (70%)]\tLoss: 321.796722\n",
      "Train Epoch: 63 [2100/2589 (81%)]\tLoss: 348.396912\n",
      "Train Epoch: 63 [2400/2589 (93%)]\tLoss: 346.324890\n",
      "====> Epoch: 63 Average train loss: 371.5776\n",
      "====> Epoch: 63 Average test loss: 954.6412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 64 [0/2589 (0%)]\tLoss: 299.181335\n",
      "Train Epoch: 64 [300/2589 (12%)]\tLoss: 299.221100\n",
      "Train Epoch: 64 [600/2589 (23%)]\tLoss: 329.250275\n",
      "Train Epoch: 64 [900/2589 (35%)]\tLoss: 363.957367\n",
      "Train Epoch: 64 [1200/2589 (46%)]\tLoss: 402.318817\n",
      "Train Epoch: 64 [1500/2589 (58%)]\tLoss: 343.501038\n",
      "Train Epoch: 64 [1800/2589 (70%)]\tLoss: 519.020630\n",
      "Train Epoch: 64 [2100/2589 (81%)]\tLoss: 484.892426\n",
      "Train Epoch: 64 [2400/2589 (93%)]\tLoss: 353.956757\n",
      "====> Epoch: 64 Average train loss: 379.4034\n",
      "====> Epoch: 64 Average test loss: 944.0536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 65 [0/2589 (0%)]\tLoss: 382.848022\n",
      "Train Epoch: 65 [300/2589 (12%)]\tLoss: 352.157623\n",
      "Train Epoch: 65 [600/2589 (23%)]\tLoss: 308.156250\n",
      "Train Epoch: 65 [900/2589 (35%)]\tLoss: 243.945099\n",
      "Train Epoch: 65 [1200/2589 (46%)]\tLoss: 294.443207\n",
      "Train Epoch: 65 [1500/2589 (58%)]\tLoss: 382.883911\n",
      "Train Epoch: 65 [1800/2589 (70%)]\tLoss: 257.612885\n",
      "Train Epoch: 65 [2100/2589 (81%)]\tLoss: 452.560059\n",
      "Train Epoch: 65 [2400/2589 (93%)]\tLoss: 335.281891\n",
      "====> Epoch: 65 Average train loss: 376.9571\n",
      "====> Epoch: 65 Average test loss: 932.6029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 66 [0/2589 (0%)]\tLoss: 457.260345\n",
      "Train Epoch: 66 [300/2589 (12%)]\tLoss: 328.321960\n",
      "Train Epoch: 66 [600/2589 (23%)]\tLoss: 333.416443\n",
      "Train Epoch: 66 [900/2589 (35%)]\tLoss: 352.787445\n",
      "Train Epoch: 66 [1200/2589 (46%)]\tLoss: 418.780304\n",
      "Train Epoch: 66 [1500/2589 (58%)]\tLoss: 357.428558\n",
      "Train Epoch: 66 [1800/2589 (70%)]\tLoss: 305.443970\n",
      "Train Epoch: 66 [2100/2589 (81%)]\tLoss: 379.632111\n",
      "Train Epoch: 66 [2400/2589 (93%)]\tLoss: 349.447784\n",
      "====> Epoch: 66 Average train loss: 380.8258\n",
      "====> Epoch: 66 Average test loss: 972.6159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 67 [0/2589 (0%)]\tLoss: 440.206360\n",
      "Train Epoch: 67 [300/2589 (12%)]\tLoss: 315.776001\n",
      "Train Epoch: 67 [600/2589 (23%)]\tLoss: 412.694153\n",
      "Train Epoch: 67 [900/2589 (35%)]\tLoss: 358.109283\n",
      "Train Epoch: 67 [1200/2589 (46%)]\tLoss: 428.843353\n",
      "Train Epoch: 67 [1500/2589 (58%)]\tLoss: 386.210266\n",
      "Train Epoch: 67 [1800/2589 (70%)]\tLoss: 286.219543\n",
      "Train Epoch: 67 [2100/2589 (81%)]\tLoss: 246.962387\n",
      "Train Epoch: 67 [2400/2589 (93%)]\tLoss: 353.001862\n",
      "====> Epoch: 67 Average train loss: 370.8002\n",
      "====> Epoch: 67 Average test loss: 943.1704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 68 [0/2589 (0%)]\tLoss: 447.586395\n",
      "Train Epoch: 68 [300/2589 (12%)]\tLoss: 326.389679\n",
      "Train Epoch: 68 [600/2589 (23%)]\tLoss: 355.779663\n",
      "Train Epoch: 68 [900/2589 (35%)]\tLoss: 310.422974\n",
      "Train Epoch: 68 [1200/2589 (46%)]\tLoss: 324.364960\n",
      "Train Epoch: 68 [1500/2589 (58%)]\tLoss: 320.248169\n",
      "Train Epoch: 68 [1800/2589 (70%)]\tLoss: 345.482269\n",
      "Train Epoch: 68 [2100/2589 (81%)]\tLoss: 277.572296\n",
      "Train Epoch: 68 [2400/2589 (93%)]\tLoss: 397.440582\n",
      "====> Epoch: 68 Average train loss: 366.6071\n",
      "====> Epoch: 68 Average test loss: 968.0443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 69 [0/2589 (0%)]\tLoss: 541.029053\n",
      "Train Epoch: 69 [300/2589 (12%)]\tLoss: 341.365326\n",
      "Train Epoch: 69 [600/2589 (23%)]\tLoss: 228.609833\n",
      "Train Epoch: 69 [900/2589 (35%)]\tLoss: 369.956757\n",
      "Train Epoch: 69 [1200/2589 (46%)]\tLoss: 383.342926\n",
      "Train Epoch: 69 [1500/2589 (58%)]\tLoss: 350.021545\n",
      "Train Epoch: 69 [1800/2589 (70%)]\tLoss: 419.085327\n",
      "Train Epoch: 69 [2100/2589 (81%)]\tLoss: 370.730682\n",
      "Train Epoch: 69 [2400/2589 (93%)]\tLoss: 275.933167\n",
      "====> Epoch: 69 Average train loss: 367.8340\n",
      "====> Epoch: 69 Average test loss: 986.7255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 70 [0/2589 (0%)]\tLoss: 409.811646\n",
      "Train Epoch: 70 [300/2589 (12%)]\tLoss: 339.033386\n",
      "Train Epoch: 70 [600/2589 (23%)]\tLoss: 307.887360\n",
      "Train Epoch: 70 [900/2589 (35%)]\tLoss: 305.522003\n",
      "Train Epoch: 70 [1200/2589 (46%)]\tLoss: 293.595642\n",
      "Train Epoch: 70 [1500/2589 (58%)]\tLoss: 393.065918\n",
      "Train Epoch: 70 [1800/2589 (70%)]\tLoss: 374.522919\n",
      "Train Epoch: 70 [2100/2589 (81%)]\tLoss: 341.221680\n",
      "Train Epoch: 70 [2400/2589 (93%)]\tLoss: 403.088928\n",
      "====> Epoch: 70 Average train loss: 358.8125\n",
      "====> Epoch: 70 Average test loss: 980.2476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 71 [0/2589 (0%)]\tLoss: 375.746216\n",
      "Train Epoch: 71 [300/2589 (12%)]\tLoss: 266.725861\n",
      "Train Epoch: 71 [600/2589 (23%)]\tLoss: 298.532684\n",
      "Train Epoch: 71 [900/2589 (35%)]\tLoss: 275.714966\n",
      "Train Epoch: 71 [1200/2589 (46%)]\tLoss: 431.133148\n",
      "Train Epoch: 71 [1500/2589 (58%)]\tLoss: 282.981750\n",
      "Train Epoch: 71 [1800/2589 (70%)]\tLoss: 306.288666\n",
      "Train Epoch: 71 [2100/2589 (81%)]\tLoss: 276.776978\n",
      "Train Epoch: 71 [2400/2589 (93%)]\tLoss: 342.010223\n",
      "====> Epoch: 71 Average train loss: 360.6806\n",
      "====> Epoch: 71 Average test loss: 935.3177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [0/2589 (0%)]\tLoss: 300.057037\n",
      "Train Epoch: 72 [300/2589 (12%)]\tLoss: 412.033875\n",
      "Train Epoch: 72 [600/2589 (23%)]\tLoss: 368.216125\n",
      "Train Epoch: 72 [900/2589 (35%)]\tLoss: 549.629272\n",
      "Train Epoch: 72 [1200/2589 (46%)]\tLoss: 262.190430\n",
      "Train Epoch: 72 [1500/2589 (58%)]\tLoss: 302.926361\n",
      "Train Epoch: 72 [1800/2589 (70%)]\tLoss: 285.910736\n",
      "Train Epoch: 72 [2100/2589 (81%)]\tLoss: 318.641754\n",
      "Train Epoch: 72 [2400/2589 (93%)]\tLoss: 390.668579\n",
      "====> Epoch: 72 Average train loss: 352.9947\n",
      "====> Epoch: 72 Average test loss: 958.4211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [0/2589 (0%)]\tLoss: 405.750854\n",
      "Train Epoch: 73 [300/2589 (12%)]\tLoss: 370.559021\n",
      "Train Epoch: 73 [600/2589 (23%)]\tLoss: 328.243439\n",
      "Train Epoch: 73 [900/2589 (35%)]\tLoss: 295.563660\n",
      "Train Epoch: 73 [1200/2589 (46%)]\tLoss: 340.001892\n",
      "Train Epoch: 73 [1500/2589 (58%)]\tLoss: 403.528412\n",
      "Train Epoch: 73 [1800/2589 (70%)]\tLoss: 431.423248\n",
      "Train Epoch: 73 [2100/2589 (81%)]\tLoss: 464.269226\n",
      "Train Epoch: 73 [2400/2589 (93%)]\tLoss: 447.408020\n",
      "====> Epoch: 73 Average train loss: 358.3520\n",
      "====> Epoch: 73 Average test loss: 947.1361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 74 [0/2589 (0%)]\tLoss: 387.756714\n",
      "Train Epoch: 74 [300/2589 (12%)]\tLoss: 480.018616\n",
      "Train Epoch: 74 [600/2589 (23%)]\tLoss: 362.033844\n",
      "Train Epoch: 74 [900/2589 (35%)]\tLoss: 390.848755\n",
      "Train Epoch: 74 [1200/2589 (46%)]\tLoss: 412.233704\n",
      "Train Epoch: 74 [1500/2589 (58%)]\tLoss: 413.491302\n",
      "Train Epoch: 74 [1800/2589 (70%)]\tLoss: 439.350952\n",
      "Train Epoch: 74 [2100/2589 (81%)]\tLoss: 478.650665\n",
      "Train Epoch: 74 [2400/2589 (93%)]\tLoss: 440.214233\n",
      "====> Epoch: 74 Average train loss: 358.4761\n",
      "====> Epoch: 74 Average test loss: 935.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 75 [0/2589 (0%)]\tLoss: 294.107758\n",
      "Train Epoch: 75 [300/2589 (12%)]\tLoss: 356.330414\n",
      "Train Epoch: 75 [600/2589 (23%)]\tLoss: 305.438171\n",
      "Train Epoch: 75 [900/2589 (35%)]\tLoss: 368.428345\n",
      "Train Epoch: 75 [1200/2589 (46%)]\tLoss: 390.918732\n",
      "Train Epoch: 75 [1500/2589 (58%)]\tLoss: 320.985992\n",
      "Train Epoch: 75 [1800/2589 (70%)]\tLoss: 261.164856\n",
      "Train Epoch: 75 [2100/2589 (81%)]\tLoss: 389.507477\n",
      "Train Epoch: 75 [2400/2589 (93%)]\tLoss: 227.315033\n",
      "====> Epoch: 75 Average train loss: 361.0345\n",
      "====> Epoch: 75 Average test loss: 952.7463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 76 [0/2589 (0%)]\tLoss: 257.324249\n",
      "Train Epoch: 76 [300/2589 (12%)]\tLoss: 450.911560\n",
      "Train Epoch: 76 [600/2589 (23%)]\tLoss: 433.782715\n",
      "Train Epoch: 76 [900/2589 (35%)]\tLoss: 335.773438\n",
      "Train Epoch: 76 [1200/2589 (46%)]\tLoss: 329.296997\n",
      "Train Epoch: 76 [1500/2589 (58%)]\tLoss: 266.727661\n",
      "Train Epoch: 76 [1800/2589 (70%)]\tLoss: 408.976501\n",
      "Train Epoch: 76 [2100/2589 (81%)]\tLoss: 429.525208\n",
      "Train Epoch: 76 [2400/2589 (93%)]\tLoss: 295.237732\n",
      "====> Epoch: 76 Average train loss: 363.3425\n",
      "====> Epoch: 76 Average test loss: 960.7448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 77 [0/2589 (0%)]\tLoss: 430.064453\n",
      "Train Epoch: 77 [300/2589 (12%)]\tLoss: 458.611816\n",
      "Train Epoch: 77 [600/2589 (23%)]\tLoss: 322.329498\n",
      "Train Epoch: 77 [900/2589 (35%)]\tLoss: 413.234894\n",
      "Train Epoch: 77 [1200/2589 (46%)]\tLoss: 389.392517\n",
      "Train Epoch: 77 [1500/2589 (58%)]\tLoss: 238.908493\n",
      "Train Epoch: 77 [1800/2589 (70%)]\tLoss: 278.094269\n",
      "Train Epoch: 77 [2100/2589 (81%)]\tLoss: 286.462219\n",
      "Train Epoch: 77 [2400/2589 (93%)]\tLoss: 394.942993\n",
      "====> Epoch: 77 Average train loss: 358.6756\n",
      "====> Epoch: 77 Average test loss: 934.2775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 78 [0/2589 (0%)]\tLoss: 437.785461\n",
      "Train Epoch: 78 [300/2589 (12%)]\tLoss: 330.567169\n",
      "Train Epoch: 78 [600/2589 (23%)]\tLoss: 403.896759\n",
      "Train Epoch: 78 [900/2589 (35%)]\tLoss: 308.719086\n",
      "Train Epoch: 78 [1200/2589 (46%)]\tLoss: 408.335754\n",
      "Train Epoch: 78 [1500/2589 (58%)]\tLoss: 387.688660\n",
      "Train Epoch: 78 [1800/2589 (70%)]\tLoss: 465.290161\n",
      "Train Epoch: 78 [2100/2589 (81%)]\tLoss: 317.912476\n",
      "Train Epoch: 78 [2400/2589 (93%)]\tLoss: 300.429291\n",
      "====> Epoch: 78 Average train loss: 357.4406\n",
      "====> Epoch: 78 Average test loss: 949.5006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 79 [0/2589 (0%)]\tLoss: 394.163910\n",
      "Train Epoch: 79 [300/2589 (12%)]\tLoss: 241.225296\n",
      "Train Epoch: 79 [600/2589 (23%)]\tLoss: 283.330078\n",
      "Train Epoch: 79 [900/2589 (35%)]\tLoss: 398.082397\n",
      "Train Epoch: 79 [1200/2589 (46%)]\tLoss: 326.946991\n",
      "Train Epoch: 79 [1500/2589 (58%)]\tLoss: 418.987030\n",
      "Train Epoch: 79 [1800/2589 (70%)]\tLoss: 227.674377\n",
      "Train Epoch: 79 [2100/2589 (81%)]\tLoss: 303.294098\n",
      "Train Epoch: 79 [2400/2589 (93%)]\tLoss: 300.294586\n",
      "====> Epoch: 79 Average train loss: 347.3038\n",
      "====> Epoch: 79 Average test loss: 940.0397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 80 [0/2589 (0%)]\tLoss: 471.675385\n",
      "Train Epoch: 80 [300/2589 (12%)]\tLoss: 326.934265\n",
      "Train Epoch: 80 [600/2589 (23%)]\tLoss: 233.919357\n",
      "Train Epoch: 80 [900/2589 (35%)]\tLoss: 369.890625\n",
      "Train Epoch: 80 [1200/2589 (46%)]\tLoss: 292.379395\n",
      "Train Epoch: 80 [1500/2589 (58%)]\tLoss: 310.795380\n",
      "Train Epoch: 80 [1800/2589 (70%)]\tLoss: 277.603088\n",
      "Train Epoch: 80 [2100/2589 (81%)]\tLoss: 314.207031\n",
      "Train Epoch: 80 [2400/2589 (93%)]\tLoss: 436.382294\n",
      "====> Epoch: 80 Average train loss: 361.5138\n",
      "====> Epoch: 80 Average test loss: 979.0884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 81 [0/2589 (0%)]\tLoss: 269.029327\n",
      "Train Epoch: 81 [300/2589 (12%)]\tLoss: 256.295227\n",
      "Train Epoch: 81 [600/2589 (23%)]\tLoss: 408.722748\n",
      "Train Epoch: 81 [900/2589 (35%)]\tLoss: 448.662445\n",
      "Train Epoch: 81 [1200/2589 (46%)]\tLoss: 251.996643\n",
      "Train Epoch: 81 [1500/2589 (58%)]\tLoss: 340.028778\n",
      "Train Epoch: 81 [1800/2589 (70%)]\tLoss: 532.258484\n",
      "Train Epoch: 81 [2100/2589 (81%)]\tLoss: 414.528931\n",
      "Train Epoch: 81 [2400/2589 (93%)]\tLoss: 240.443420\n",
      "====> Epoch: 81 Average train loss: 346.4799\n",
      "====> Epoch: 81 Average test loss: 954.8261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 82 [0/2589 (0%)]\tLoss: 283.176361\n",
      "Train Epoch: 82 [300/2589 (12%)]\tLoss: 363.401550\n",
      "Train Epoch: 82 [600/2589 (23%)]\tLoss: 339.144135\n",
      "Train Epoch: 82 [900/2589 (35%)]\tLoss: 261.483978\n",
      "Train Epoch: 82 [1200/2589 (46%)]\tLoss: 381.751404\n",
      "Train Epoch: 82 [1500/2589 (58%)]\tLoss: 342.806366\n",
      "Train Epoch: 82 [1800/2589 (70%)]\tLoss: 295.425751\n",
      "Train Epoch: 82 [2100/2589 (81%)]\tLoss: 363.227844\n",
      "Train Epoch: 82 [2400/2589 (93%)]\tLoss: 257.589630\n",
      "====> Epoch: 82 Average train loss: 348.2157\n",
      "====> Epoch: 82 Average test loss: 964.2443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 83 [0/2589 (0%)]\tLoss: 351.148529\n",
      "Train Epoch: 83 [300/2589 (12%)]\tLoss: 366.234985\n",
      "Train Epoch: 83 [600/2589 (23%)]\tLoss: 287.775757\n",
      "Train Epoch: 83 [900/2589 (35%)]\tLoss: 349.365326\n",
      "Train Epoch: 83 [1200/2589 (46%)]\tLoss: 419.030823\n",
      "Train Epoch: 83 [1500/2589 (58%)]\tLoss: 371.236633\n",
      "Train Epoch: 83 [1800/2589 (70%)]\tLoss: 255.483459\n",
      "Train Epoch: 83 [2100/2589 (81%)]\tLoss: 440.393707\n",
      "Train Epoch: 83 [2400/2589 (93%)]\tLoss: 439.175476\n",
      "====> Epoch: 83 Average train loss: 350.6359\n",
      "====> Epoch: 83 Average test loss: 955.9120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 84 [0/2589 (0%)]\tLoss: 308.359436\n",
      "Train Epoch: 84 [300/2589 (12%)]\tLoss: 252.608749\n",
      "Train Epoch: 84 [600/2589 (23%)]\tLoss: 305.568939\n",
      "Train Epoch: 84 [900/2589 (35%)]\tLoss: 280.081512\n",
      "Train Epoch: 84 [1200/2589 (46%)]\tLoss: 365.243835\n",
      "Train Epoch: 84 [1500/2589 (58%)]\tLoss: 456.293274\n",
      "Train Epoch: 84 [1800/2589 (70%)]\tLoss: 252.010483\n",
      "Train Epoch: 84 [2100/2589 (81%)]\tLoss: 379.540100\n",
      "Train Epoch: 84 [2400/2589 (93%)]\tLoss: 288.497162\n",
      "====> Epoch: 84 Average train loss: 346.0239\n",
      "====> Epoch: 84 Average test loss: 976.0338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 85 [0/2589 (0%)]\tLoss: 259.294952\n",
      "Train Epoch: 85 [300/2589 (12%)]\tLoss: 329.366241\n",
      "Train Epoch: 85 [600/2589 (23%)]\tLoss: 229.135605\n",
      "Train Epoch: 85 [900/2589 (35%)]\tLoss: 312.243927\n",
      "Train Epoch: 85 [1200/2589 (46%)]\tLoss: 353.631226\n",
      "Train Epoch: 85 [1500/2589 (58%)]\tLoss: 298.068665\n",
      "Train Epoch: 85 [1800/2589 (70%)]\tLoss: 298.757172\n",
      "Train Epoch: 85 [2100/2589 (81%)]\tLoss: 344.420471\n",
      "Train Epoch: 85 [2400/2589 (93%)]\tLoss: 274.154266\n",
      "====> Epoch: 85 Average train loss: 343.3639\n",
      "====> Epoch: 85 Average test loss: 973.3776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 86 [0/2589 (0%)]\tLoss: 351.937164\n",
      "Train Epoch: 86 [300/2589 (12%)]\tLoss: 213.381149\n",
      "Train Epoch: 86 [600/2589 (23%)]\tLoss: 360.105865\n",
      "Train Epoch: 86 [900/2589 (35%)]\tLoss: 355.804138\n",
      "Train Epoch: 86 [1200/2589 (46%)]\tLoss: 450.591522\n",
      "Train Epoch: 86 [1500/2589 (58%)]\tLoss: 497.863892\n",
      "Train Epoch: 86 [1800/2589 (70%)]\tLoss: 513.873352\n",
      "Train Epoch: 86 [2100/2589 (81%)]\tLoss: 355.827454\n",
      "Train Epoch: 86 [2400/2589 (93%)]\tLoss: 332.820435\n",
      "====> Epoch: 86 Average train loss: 344.2160\n",
      "====> Epoch: 86 Average test loss: 974.9186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 87 [0/2589 (0%)]\tLoss: 318.416107\n",
      "Train Epoch: 87 [300/2589 (12%)]\tLoss: 293.608063\n",
      "Train Epoch: 87 [600/2589 (23%)]\tLoss: 419.319946\n",
      "Train Epoch: 87 [900/2589 (35%)]\tLoss: 316.409973\n",
      "Train Epoch: 87 [1200/2589 (46%)]\tLoss: 370.842896\n",
      "Train Epoch: 87 [1500/2589 (58%)]\tLoss: 200.580215\n",
      "Train Epoch: 87 [1800/2589 (70%)]\tLoss: 307.102051\n",
      "Train Epoch: 87 [2100/2589 (81%)]\tLoss: 352.352570\n",
      "Train Epoch: 87 [2400/2589 (93%)]\tLoss: 337.784271\n",
      "====> Epoch: 87 Average train loss: 341.8547\n",
      "====> Epoch: 87 Average test loss: 956.3986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 88 [0/2589 (0%)]\tLoss: 348.561310\n",
      "Train Epoch: 88 [300/2589 (12%)]\tLoss: 390.233978\n",
      "Train Epoch: 88 [600/2589 (23%)]\tLoss: 300.088013\n",
      "Train Epoch: 88 [900/2589 (35%)]\tLoss: 430.847046\n",
      "Train Epoch: 88 [1200/2589 (46%)]\tLoss: 348.843719\n",
      "Train Epoch: 88 [1500/2589 (58%)]\tLoss: 317.634277\n",
      "Train Epoch: 88 [1800/2589 (70%)]\tLoss: 417.847260\n",
      "Train Epoch: 88 [2100/2589 (81%)]\tLoss: 202.448441\n",
      "Train Epoch: 88 [2400/2589 (93%)]\tLoss: 322.536407\n",
      "====> Epoch: 88 Average train loss: 343.0482\n",
      "====> Epoch: 88 Average test loss: 959.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 89 [0/2589 (0%)]\tLoss: 298.095245\n",
      "Train Epoch: 89 [300/2589 (12%)]\tLoss: 223.979599\n",
      "Train Epoch: 89 [600/2589 (23%)]\tLoss: 339.420380\n",
      "Train Epoch: 89 [900/2589 (35%)]\tLoss: 322.971680\n",
      "Train Epoch: 89 [1200/2589 (46%)]\tLoss: 613.030457\n",
      "Train Epoch: 89 [1500/2589 (58%)]\tLoss: 464.721466\n",
      "Train Epoch: 89 [1800/2589 (70%)]\tLoss: 405.562561\n",
      "Train Epoch: 89 [2100/2589 (81%)]\tLoss: 242.089462\n",
      "Train Epoch: 89 [2400/2589 (93%)]\tLoss: 244.121979\n",
      "====> Epoch: 89 Average train loss: 341.7867\n",
      "====> Epoch: 89 Average test loss: 958.7591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 90 [0/2589 (0%)]\tLoss: 216.632645\n",
      "Train Epoch: 90 [300/2589 (12%)]\tLoss: 232.249649\n",
      "Train Epoch: 90 [600/2589 (23%)]\tLoss: 313.684235\n",
      "Train Epoch: 90 [900/2589 (35%)]\tLoss: 412.557831\n",
      "Train Epoch: 90 [1200/2589 (46%)]\tLoss: 309.756134\n",
      "Train Epoch: 90 [1500/2589 (58%)]\tLoss: 391.421234\n",
      "Train Epoch: 90 [1800/2589 (70%)]\tLoss: 231.250275\n",
      "Train Epoch: 90 [2100/2589 (81%)]\tLoss: 306.996216\n",
      "Train Epoch: 90 [2400/2589 (93%)]\tLoss: 323.676788\n",
      "====> Epoch: 90 Average train loss: 339.3578\n",
      "====> Epoch: 90 Average test loss: 993.0330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 91 [0/2589 (0%)]\tLoss: 319.230377\n",
      "Train Epoch: 91 [300/2589 (12%)]\tLoss: 383.257019\n",
      "Train Epoch: 91 [600/2589 (23%)]\tLoss: 289.664124\n",
      "Train Epoch: 91 [900/2589 (35%)]\tLoss: 331.891602\n",
      "Train Epoch: 91 [1200/2589 (46%)]\tLoss: 400.702850\n",
      "Train Epoch: 91 [1500/2589 (58%)]\tLoss: 411.198029\n",
      "Train Epoch: 91 [1800/2589 (70%)]\tLoss: 393.947754\n",
      "Train Epoch: 91 [2100/2589 (81%)]\tLoss: 422.920197\n",
      "Train Epoch: 91 [2400/2589 (93%)]\tLoss: 335.657166\n",
      "====> Epoch: 91 Average train loss: 338.4229\n",
      "====> Epoch: 91 Average test loss: 969.6166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 92 [0/2589 (0%)]\tLoss: 277.503784\n",
      "Train Epoch: 92 [300/2589 (12%)]\tLoss: 245.821625\n",
      "Train Epoch: 92 [600/2589 (23%)]\tLoss: 357.177887\n",
      "Train Epoch: 92 [900/2589 (35%)]\tLoss: 337.430298\n",
      "Train Epoch: 92 [1200/2589 (46%)]\tLoss: 334.425720\n",
      "Train Epoch: 92 [1500/2589 (58%)]\tLoss: 435.879486\n",
      "Train Epoch: 92 [1800/2589 (70%)]\tLoss: 351.593872\n",
      "Train Epoch: 92 [2100/2589 (81%)]\tLoss: 427.033295\n",
      "Train Epoch: 92 [2400/2589 (93%)]\tLoss: 407.475433\n",
      "====> Epoch: 92 Average train loss: 347.8771\n",
      "====> Epoch: 92 Average test loss: 938.7603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 93 [0/2589 (0%)]\tLoss: 203.302155\n",
      "Train Epoch: 93 [300/2589 (12%)]\tLoss: 384.976898\n",
      "Train Epoch: 93 [600/2589 (23%)]\tLoss: 265.714417\n",
      "Train Epoch: 93 [900/2589 (35%)]\tLoss: 264.150940\n",
      "Train Epoch: 93 [1200/2589 (46%)]\tLoss: 517.801575\n",
      "Train Epoch: 93 [1500/2589 (58%)]\tLoss: 277.442078\n",
      "Train Epoch: 93 [1800/2589 (70%)]\tLoss: 358.852936\n",
      "Train Epoch: 93 [2100/2589 (81%)]\tLoss: 316.801239\n",
      "Train Epoch: 93 [2400/2589 (93%)]\tLoss: 386.137756\n",
      "====> Epoch: 93 Average train loss: 339.4553\n",
      "====> Epoch: 93 Average test loss: 963.2021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 94 [0/2589 (0%)]\tLoss: 502.712433\n",
      "Train Epoch: 94 [300/2589 (12%)]\tLoss: 451.669769\n",
      "Train Epoch: 94 [600/2589 (23%)]\tLoss: 417.321259\n",
      "Train Epoch: 94 [900/2589 (35%)]\tLoss: 248.673615\n",
      "Train Epoch: 94 [1200/2589 (46%)]\tLoss: 270.685394\n",
      "Train Epoch: 94 [1500/2589 (58%)]\tLoss: 387.628235\n",
      "Train Epoch: 94 [1800/2589 (70%)]\tLoss: 265.832947\n",
      "Train Epoch: 94 [2100/2589 (81%)]\tLoss: 447.515076\n",
      "Train Epoch: 94 [2400/2589 (93%)]\tLoss: 365.823364\n",
      "====> Epoch: 94 Average train loss: 341.1661\n",
      "====> Epoch: 94 Average test loss: 972.1973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 95 [0/2589 (0%)]\tLoss: 350.875092\n",
      "Train Epoch: 95 [300/2589 (12%)]\tLoss: 364.792847\n",
      "Train Epoch: 95 [600/2589 (23%)]\tLoss: 394.244507\n",
      "Train Epoch: 95 [900/2589 (35%)]\tLoss: 252.724991\n",
      "Train Epoch: 95 [1200/2589 (46%)]\tLoss: 275.572754\n",
      "Train Epoch: 95 [1500/2589 (58%)]\tLoss: 359.697083\n",
      "Train Epoch: 95 [1800/2589 (70%)]\tLoss: 343.412262\n",
      "Train Epoch: 95 [2100/2589 (81%)]\tLoss: 276.612122\n",
      "Train Epoch: 95 [2400/2589 (93%)]\tLoss: 330.155884\n",
      "====> Epoch: 95 Average train loss: 328.5024\n",
      "====> Epoch: 95 Average test loss: 949.0389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 96 [0/2589 (0%)]\tLoss: 352.553070\n",
      "Train Epoch: 96 [300/2589 (12%)]\tLoss: 272.498962\n",
      "Train Epoch: 96 [600/2589 (23%)]\tLoss: 336.368256\n",
      "Train Epoch: 96 [900/2589 (35%)]\tLoss: 326.245697\n",
      "Train Epoch: 96 [1200/2589 (46%)]\tLoss: 323.819214\n",
      "Train Epoch: 96 [1500/2589 (58%)]\tLoss: 274.751434\n",
      "Train Epoch: 96 [1800/2589 (70%)]\tLoss: 380.857758\n",
      "Train Epoch: 96 [2100/2589 (81%)]\tLoss: 470.478882\n",
      "Train Epoch: 96 [2400/2589 (93%)]\tLoss: 287.950562\n",
      "====> Epoch: 96 Average train loss: 332.4037\n",
      "====> Epoch: 96 Average test loss: 977.4015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 97 [0/2589 (0%)]\tLoss: 251.073303\n",
      "Train Epoch: 97 [300/2589 (12%)]\tLoss: 348.823059\n",
      "Train Epoch: 97 [600/2589 (23%)]\tLoss: 375.643829\n",
      "Train Epoch: 97 [900/2589 (35%)]\tLoss: 317.860474\n",
      "Train Epoch: 97 [1200/2589 (46%)]\tLoss: 312.276672\n",
      "Train Epoch: 97 [1500/2589 (58%)]\tLoss: 286.287170\n",
      "Train Epoch: 97 [1800/2589 (70%)]\tLoss: 263.274475\n",
      "Train Epoch: 97 [2100/2589 (81%)]\tLoss: 307.288574\n",
      "Train Epoch: 97 [2400/2589 (93%)]\tLoss: 239.611191\n",
      "====> Epoch: 97 Average train loss: 340.5896\n",
      "====> Epoch: 97 Average test loss: 974.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 98 [0/2589 (0%)]\tLoss: 350.837738\n",
      "Train Epoch: 98 [300/2589 (12%)]\tLoss: 477.356659\n",
      "Train Epoch: 98 [600/2589 (23%)]\tLoss: 567.165649\n",
      "Train Epoch: 98 [900/2589 (35%)]\tLoss: 306.927643\n",
      "Train Epoch: 98 [1200/2589 (46%)]\tLoss: 459.943970\n",
      "Train Epoch: 98 [1500/2589 (58%)]\tLoss: 289.097137\n",
      "Train Epoch: 98 [1800/2589 (70%)]\tLoss: 313.999542\n",
      "Train Epoch: 98 [2100/2589 (81%)]\tLoss: 409.659149\n",
      "Train Epoch: 98 [2400/2589 (93%)]\tLoss: 287.987488\n",
      "====> Epoch: 98 Average train loss: 345.6075\n",
      "====> Epoch: 98 Average test loss: 938.5838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 99 [0/2589 (0%)]\tLoss: 288.890900\n",
      "Train Epoch: 99 [300/2589 (12%)]\tLoss: 363.316864\n",
      "Train Epoch: 99 [600/2589 (23%)]\tLoss: 343.580139\n",
      "Train Epoch: 99 [900/2589 (35%)]\tLoss: 301.471954\n",
      "Train Epoch: 99 [1200/2589 (46%)]\tLoss: 277.727814\n",
      "Train Epoch: 99 [1500/2589 (58%)]\tLoss: 324.176697\n",
      "Train Epoch: 99 [1800/2589 (70%)]\tLoss: 382.231476\n",
      "Train Epoch: 99 [2100/2589 (81%)]\tLoss: 368.551605\n",
      "Train Epoch: 99 [2400/2589 (93%)]\tLoss: 233.863052\n",
      "====> Epoch: 99 Average train loss: 351.5699\n",
      "====> Epoch: 99 Average test loss: 952.3362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/2589 (0%)]\tLoss: 306.996796\n",
      "Train Epoch: 100 [300/2589 (12%)]\tLoss: 257.034241\n",
      "Train Epoch: 100 [600/2589 (23%)]\tLoss: 325.716339\n",
      "Train Epoch: 100 [900/2589 (35%)]\tLoss: 362.103424\n",
      "Train Epoch: 100 [1200/2589 (46%)]\tLoss: 447.285370\n",
      "Train Epoch: 100 [1500/2589 (58%)]\tLoss: 416.342621\n",
      "Train Epoch: 100 [1800/2589 (70%)]\tLoss: 253.028458\n",
      "Train Epoch: 100 [2100/2589 (81%)]\tLoss: 334.235901\n",
      "Train Epoch: 100 [2400/2589 (93%)]\tLoss: 297.031525\n",
      "====> Epoch: 100 Average train loss: 338.4789\n",
      "====> Epoch: 100 Average test loss: 927.6988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 101 [0/2589 (0%)]\tLoss: 284.198456\n",
      "Train Epoch: 101 [300/2589 (12%)]\tLoss: 395.399597\n",
      "Train Epoch: 101 [600/2589 (23%)]\tLoss: 309.725403\n",
      "Train Epoch: 101 [900/2589 (35%)]\tLoss: 417.389038\n",
      "Train Epoch: 101 [1200/2589 (46%)]\tLoss: 299.280457\n",
      "Train Epoch: 101 [1500/2589 (58%)]\tLoss: 316.676697\n",
      "Train Epoch: 101 [1800/2589 (70%)]\tLoss: 284.095978\n",
      "Train Epoch: 101 [2100/2589 (81%)]\tLoss: 297.459351\n",
      "Train Epoch: 101 [2400/2589 (93%)]\tLoss: 391.176178\n",
      "====> Epoch: 101 Average train loss: 322.4482\n",
      "====> Epoch: 101 Average test loss: 932.8209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 102 [0/2589 (0%)]\tLoss: 327.457214\n",
      "Train Epoch: 102 [300/2589 (12%)]\tLoss: 284.071106\n",
      "Train Epoch: 102 [600/2589 (23%)]\tLoss: 305.860626\n",
      "Train Epoch: 102 [900/2589 (35%)]\tLoss: 463.685211\n",
      "Train Epoch: 102 [1200/2589 (46%)]\tLoss: 524.869568\n",
      "Train Epoch: 102 [1500/2589 (58%)]\tLoss: 235.557312\n",
      "Train Epoch: 102 [1800/2589 (70%)]\tLoss: 245.196228\n",
      "Train Epoch: 102 [2100/2589 (81%)]\tLoss: 341.427917\n",
      "Train Epoch: 102 [2400/2589 (93%)]\tLoss: 370.680847\n",
      "====> Epoch: 102 Average train loss: 332.1342\n",
      "====> Epoch: 102 Average test loss: 930.3229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 103 [0/2589 (0%)]\tLoss: 287.848969\n",
      "Train Epoch: 103 [300/2589 (12%)]\tLoss: 334.568481\n",
      "Train Epoch: 103 [600/2589 (23%)]\tLoss: 327.785767\n",
      "Train Epoch: 103 [900/2589 (35%)]\tLoss: 273.671417\n",
      "Train Epoch: 103 [1200/2589 (46%)]\tLoss: 250.770508\n",
      "Train Epoch: 103 [1500/2589 (58%)]\tLoss: 362.921082\n",
      "Train Epoch: 103 [1800/2589 (70%)]\tLoss: 309.932526\n",
      "Train Epoch: 103 [2100/2589 (81%)]\tLoss: 282.447205\n",
      "Train Epoch: 103 [2400/2589 (93%)]\tLoss: 259.774017\n",
      "====> Epoch: 103 Average train loss: 324.7520\n",
      "====> Epoch: 103 Average test loss: 982.3641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 104 [0/2589 (0%)]\tLoss: 387.161682\n",
      "Train Epoch: 104 [300/2589 (12%)]\tLoss: 336.715881\n",
      "Train Epoch: 104 [600/2589 (23%)]\tLoss: 360.399139\n",
      "Train Epoch: 104 [900/2589 (35%)]\tLoss: 447.540680\n",
      "Train Epoch: 104 [1200/2589 (46%)]\tLoss: 341.497955\n",
      "Train Epoch: 104 [1500/2589 (58%)]\tLoss: 427.376740\n",
      "Train Epoch: 104 [1800/2589 (70%)]\tLoss: 268.785614\n",
      "Train Epoch: 104 [2100/2589 (81%)]\tLoss: 382.364441\n",
      "Train Epoch: 104 [2400/2589 (93%)]\tLoss: 386.465881\n",
      "====> Epoch: 104 Average train loss: 333.2766\n",
      "====> Epoch: 104 Average test loss: 953.7135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 105 [0/2589 (0%)]\tLoss: 270.092224\n",
      "Train Epoch: 105 [300/2589 (12%)]\tLoss: 305.460938\n",
      "Train Epoch: 105 [600/2589 (23%)]\tLoss: 353.750977\n",
      "Train Epoch: 105 [900/2589 (35%)]\tLoss: 281.756714\n",
      "Train Epoch: 105 [1200/2589 (46%)]\tLoss: 307.747437\n",
      "Train Epoch: 105 [1500/2589 (58%)]\tLoss: 274.484833\n",
      "Train Epoch: 105 [1800/2589 (70%)]\tLoss: 537.868469\n",
      "Train Epoch: 105 [2100/2589 (81%)]\tLoss: 381.689178\n",
      "Train Epoch: 105 [2400/2589 (93%)]\tLoss: 280.623413\n",
      "====> Epoch: 105 Average train loss: 326.5977\n",
      "====> Epoch: 105 Average test loss: 936.0273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 106 [0/2589 (0%)]\tLoss: 423.344543\n",
      "Train Epoch: 106 [300/2589 (12%)]\tLoss: 261.251740\n",
      "Train Epoch: 106 [600/2589 (23%)]\tLoss: 257.442078\n",
      "Train Epoch: 106 [900/2589 (35%)]\tLoss: 342.316010\n",
      "Train Epoch: 106 [1200/2589 (46%)]\tLoss: 319.360016\n",
      "Train Epoch: 106 [1500/2589 (58%)]\tLoss: 281.915436\n",
      "Train Epoch: 106 [1800/2589 (70%)]\tLoss: 348.875854\n",
      "Train Epoch: 106 [2100/2589 (81%)]\tLoss: 318.358063\n",
      "Train Epoch: 106 [2400/2589 (93%)]\tLoss: 440.222534\n",
      "====> Epoch: 106 Average train loss: 316.2711\n",
      "====> Epoch: 106 Average test loss: 957.2432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 107 [0/2589 (0%)]\tLoss: 217.402649\n",
      "Train Epoch: 107 [300/2589 (12%)]\tLoss: 319.551971\n",
      "Train Epoch: 107 [600/2589 (23%)]\tLoss: 366.684265\n",
      "Train Epoch: 107 [900/2589 (35%)]\tLoss: 321.874786\n",
      "Train Epoch: 107 [1200/2589 (46%)]\tLoss: 294.181000\n",
      "Train Epoch: 107 [1500/2589 (58%)]\tLoss: 281.948853\n",
      "Train Epoch: 107 [1800/2589 (70%)]\tLoss: 273.302277\n",
      "Train Epoch: 107 [2100/2589 (81%)]\tLoss: 278.272156\n",
      "Train Epoch: 107 [2400/2589 (93%)]\tLoss: 240.628616\n",
      "====> Epoch: 107 Average train loss: 323.8973\n",
      "====> Epoch: 107 Average test loss: 970.4144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 108 [0/2589 (0%)]\tLoss: 479.482727\n",
      "Train Epoch: 108 [300/2589 (12%)]\tLoss: 674.266602\n",
      "Train Epoch: 108 [600/2589 (23%)]\tLoss: 388.174164\n",
      "Train Epoch: 108 [900/2589 (35%)]\tLoss: 306.769226\n",
      "Train Epoch: 108 [1200/2589 (46%)]\tLoss: 542.086548\n",
      "Train Epoch: 108 [1500/2589 (58%)]\tLoss: 327.756348\n",
      "Train Epoch: 108 [1800/2589 (70%)]\tLoss: 403.982849\n",
      "Train Epoch: 108 [2100/2589 (81%)]\tLoss: 335.222229\n",
      "Train Epoch: 108 [2400/2589 (93%)]\tLoss: 437.792419\n",
      "====> Epoch: 108 Average train loss: 342.1807\n",
      "====> Epoch: 108 Average test loss: 948.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [0/2589 (0%)]\tLoss: 362.037933\n",
      "Train Epoch: 109 [300/2589 (12%)]\tLoss: 294.728668\n",
      "Train Epoch: 109 [600/2589 (23%)]\tLoss: 344.154724\n",
      "Train Epoch: 109 [900/2589 (35%)]\tLoss: 383.555878\n",
      "Train Epoch: 109 [1200/2589 (46%)]\tLoss: 310.419128\n",
      "Train Epoch: 109 [1500/2589 (58%)]\tLoss: 335.156250\n",
      "Train Epoch: 109 [1800/2589 (70%)]\tLoss: 247.145279\n",
      "Train Epoch: 109 [2100/2589 (81%)]\tLoss: 276.122467\n",
      "Train Epoch: 109 [2400/2589 (93%)]\tLoss: 377.765930\n",
      "====> Epoch: 109 Average train loss: 325.0555\n",
      "====> Epoch: 109 Average test loss: 972.3555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 110 [0/2589 (0%)]\tLoss: 307.829437\n",
      "Train Epoch: 110 [300/2589 (12%)]\tLoss: 341.949097\n",
      "Train Epoch: 110 [600/2589 (23%)]\tLoss: 298.095917\n",
      "Train Epoch: 110 [900/2589 (35%)]\tLoss: 391.015350\n",
      "Train Epoch: 110 [1200/2589 (46%)]\tLoss: 322.035034\n",
      "Train Epoch: 110 [1500/2589 (58%)]\tLoss: 249.613449\n",
      "Train Epoch: 110 [1800/2589 (70%)]\tLoss: 351.620270\n",
      "Train Epoch: 110 [2100/2589 (81%)]\tLoss: 268.743103\n",
      "Train Epoch: 110 [2400/2589 (93%)]\tLoss: 211.049667\n",
      "====> Epoch: 110 Average train loss: 333.3139\n",
      "====> Epoch: 110 Average test loss: 948.4443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 111 [0/2589 (0%)]\tLoss: 346.575195\n",
      "Train Epoch: 111 [300/2589 (12%)]\tLoss: 280.534393\n",
      "Train Epoch: 111 [600/2589 (23%)]\tLoss: 309.985291\n",
      "Train Epoch: 111 [900/2589 (35%)]\tLoss: 345.204163\n",
      "Train Epoch: 111 [1200/2589 (46%)]\tLoss: 534.181030\n",
      "Train Epoch: 111 [1500/2589 (58%)]\tLoss: 193.390640\n",
      "Train Epoch: 111 [1800/2589 (70%)]\tLoss: 319.429413\n",
      "Train Epoch: 111 [2100/2589 (81%)]\tLoss: 364.625214\n",
      "Train Epoch: 111 [2400/2589 (93%)]\tLoss: 463.148499\n",
      "====> Epoch: 111 Average train loss: 327.3484\n",
      "====> Epoch: 111 Average test loss: 957.2665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 112 [0/2589 (0%)]\tLoss: 265.149048\n",
      "Train Epoch: 112 [300/2589 (12%)]\tLoss: 322.616333\n",
      "Train Epoch: 112 [600/2589 (23%)]\tLoss: 310.669586\n",
      "Train Epoch: 112 [900/2589 (35%)]\tLoss: 355.477539\n",
      "Train Epoch: 112 [1200/2589 (46%)]\tLoss: 341.401855\n",
      "Train Epoch: 112 [1500/2589 (58%)]\tLoss: 308.231506\n",
      "Train Epoch: 112 [1800/2589 (70%)]\tLoss: 444.053253\n",
      "Train Epoch: 112 [2100/2589 (81%)]\tLoss: 347.479675\n",
      "Train Epoch: 112 [2400/2589 (93%)]\tLoss: 381.369934\n",
      "====> Epoch: 112 Average train loss: 331.4291\n",
      "====> Epoch: 112 Average test loss: 973.0709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 113 [0/2589 (0%)]\tLoss: 230.539566\n",
      "Train Epoch: 113 [300/2589 (12%)]\tLoss: 339.979492\n",
      "Train Epoch: 113 [600/2589 (23%)]\tLoss: 486.110352\n",
      "Train Epoch: 113 [900/2589 (35%)]\tLoss: 375.069672\n",
      "Train Epoch: 113 [1200/2589 (46%)]\tLoss: 380.081390\n",
      "Train Epoch: 113 [1500/2589 (58%)]\tLoss: 326.928894\n",
      "Train Epoch: 113 [1800/2589 (70%)]\tLoss: 333.129059\n",
      "Train Epoch: 113 [2100/2589 (81%)]\tLoss: 357.788208\n",
      "Train Epoch: 113 [2400/2589 (93%)]\tLoss: 370.791595\n",
      "====> Epoch: 113 Average train loss: 325.5642\n",
      "====> Epoch: 113 Average test loss: 945.1518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 114 [0/2589 (0%)]\tLoss: 418.684082\n",
      "Train Epoch: 114 [300/2589 (12%)]\tLoss: 363.369843\n",
      "Train Epoch: 114 [600/2589 (23%)]\tLoss: 220.680115\n",
      "Train Epoch: 114 [900/2589 (35%)]\tLoss: 334.163513\n",
      "Train Epoch: 114 [1200/2589 (46%)]\tLoss: 295.565491\n",
      "Train Epoch: 114 [1500/2589 (58%)]\tLoss: 319.016815\n",
      "Train Epoch: 114 [1800/2589 (70%)]\tLoss: 384.581970\n",
      "Train Epoch: 114 [2100/2589 (81%)]\tLoss: 419.461487\n",
      "Train Epoch: 114 [2400/2589 (93%)]\tLoss: 236.305771\n",
      "====> Epoch: 114 Average train loss: 320.4059\n",
      "====> Epoch: 114 Average test loss: 957.2931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 115 [0/2589 (0%)]\tLoss: 254.035416\n",
      "Train Epoch: 115 [300/2589 (12%)]\tLoss: 408.733795\n",
      "Train Epoch: 115 [600/2589 (23%)]\tLoss: 325.773560\n",
      "Train Epoch: 115 [900/2589 (35%)]\tLoss: 254.128754\n",
      "Train Epoch: 115 [1200/2589 (46%)]\tLoss: 274.533783\n",
      "Train Epoch: 115 [1500/2589 (58%)]\tLoss: 350.935822\n",
      "Train Epoch: 115 [1800/2589 (70%)]\tLoss: 338.962708\n",
      "Train Epoch: 115 [2100/2589 (81%)]\tLoss: 410.496307\n",
      "Train Epoch: 115 [2400/2589 (93%)]\tLoss: 274.926361\n",
      "====> Epoch: 115 Average train loss: 319.3234\n",
      "====> Epoch: 115 Average test loss: 950.5748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 116 [0/2589 (0%)]\tLoss: 358.844574\n",
      "Train Epoch: 116 [300/2589 (12%)]\tLoss: 281.693237\n",
      "Train Epoch: 116 [600/2589 (23%)]\tLoss: 232.752930\n",
      "Train Epoch: 116 [900/2589 (35%)]\tLoss: 233.906509\n",
      "Train Epoch: 116 [1200/2589 (46%)]\tLoss: 252.371277\n",
      "Train Epoch: 116 [1500/2589 (58%)]\tLoss: 343.556427\n",
      "Train Epoch: 116 [1800/2589 (70%)]\tLoss: 409.300873\n",
      "Train Epoch: 116 [2100/2589 (81%)]\tLoss: 200.139343\n",
      "Train Epoch: 116 [2400/2589 (93%)]\tLoss: 295.544342\n",
      "====> Epoch: 116 Average train loss: 310.0840\n",
      "====> Epoch: 116 Average test loss: 953.3301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 117 [0/2589 (0%)]\tLoss: 274.911346\n",
      "Train Epoch: 117 [300/2589 (12%)]\tLoss: 378.954651\n",
      "Train Epoch: 117 [600/2589 (23%)]\tLoss: 323.113373\n",
      "Train Epoch: 117 [900/2589 (35%)]\tLoss: 273.119995\n",
      "Train Epoch: 117 [1200/2589 (46%)]\tLoss: 452.788727\n",
      "Train Epoch: 117 [1500/2589 (58%)]\tLoss: 464.269836\n",
      "Train Epoch: 117 [1800/2589 (70%)]\tLoss: 362.328583\n",
      "Train Epoch: 117 [2100/2589 (81%)]\tLoss: 395.031036\n",
      "Train Epoch: 117 [2400/2589 (93%)]\tLoss: 270.439209\n",
      "====> Epoch: 117 Average train loss: 317.6530\n",
      "====> Epoch: 117 Average test loss: 968.8362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 118 [0/2589 (0%)]\tLoss: 275.115692\n",
      "Train Epoch: 118 [300/2589 (12%)]\tLoss: 470.854004\n",
      "Train Epoch: 118 [600/2589 (23%)]\tLoss: 370.022919\n",
      "Train Epoch: 118 [900/2589 (35%)]\tLoss: 209.907059\n",
      "Train Epoch: 118 [1200/2589 (46%)]\tLoss: 360.684448\n",
      "Train Epoch: 118 [1500/2589 (58%)]\tLoss: 292.781311\n",
      "Train Epoch: 118 [1800/2589 (70%)]\tLoss: 296.725220\n",
      "Train Epoch: 118 [2100/2589 (81%)]\tLoss: 261.879913\n",
      "Train Epoch: 118 [2400/2589 (93%)]\tLoss: 491.999725\n",
      "====> Epoch: 118 Average train loss: 328.2742\n",
      "====> Epoch: 118 Average test loss: 993.9598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 119 [0/2589 (0%)]\tLoss: 277.230011\n",
      "Train Epoch: 119 [300/2589 (12%)]\tLoss: 327.882141\n",
      "Train Epoch: 119 [600/2589 (23%)]\tLoss: 333.341431\n",
      "Train Epoch: 119 [900/2589 (35%)]\tLoss: 263.153198\n",
      "Train Epoch: 119 [1200/2589 (46%)]\tLoss: 276.427948\n",
      "Train Epoch: 119 [1500/2589 (58%)]\tLoss: 433.608124\n",
      "Train Epoch: 119 [1800/2589 (70%)]\tLoss: 368.590820\n",
      "Train Epoch: 119 [2100/2589 (81%)]\tLoss: 388.086853\n",
      "Train Epoch: 119 [2400/2589 (93%)]\tLoss: 259.769562\n",
      "====> Epoch: 119 Average train loss: 315.0166\n",
      "====> Epoch: 119 Average test loss: 965.6818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 120 [0/2589 (0%)]\tLoss: 211.426468\n",
      "Train Epoch: 120 [300/2589 (12%)]\tLoss: 305.654663\n",
      "Train Epoch: 120 [600/2589 (23%)]\tLoss: 250.940369\n",
      "Train Epoch: 120 [900/2589 (35%)]\tLoss: 451.689392\n",
      "Train Epoch: 120 [1200/2589 (46%)]\tLoss: 242.782913\n",
      "Train Epoch: 120 [1500/2589 (58%)]\tLoss: 298.718231\n",
      "Train Epoch: 120 [1800/2589 (70%)]\tLoss: 273.576660\n",
      "Train Epoch: 120 [2100/2589 (81%)]\tLoss: 201.347839\n",
      "Train Epoch: 120 [2400/2589 (93%)]\tLoss: 423.157349\n",
      "====> Epoch: 120 Average train loss: 318.4530\n",
      "====> Epoch: 120 Average test loss: 960.5876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 121 [0/2589 (0%)]\tLoss: 294.018921\n",
      "Train Epoch: 121 [300/2589 (12%)]\tLoss: 380.040192\n",
      "Train Epoch: 121 [600/2589 (23%)]\tLoss: 209.352814\n",
      "Train Epoch: 121 [900/2589 (35%)]\tLoss: 316.435272\n",
      "Train Epoch: 121 [1200/2589 (46%)]\tLoss: 426.473267\n",
      "Train Epoch: 121 [1500/2589 (58%)]\tLoss: 348.350647\n",
      "Train Epoch: 121 [1800/2589 (70%)]\tLoss: 253.267899\n",
      "Train Epoch: 121 [2100/2589 (81%)]\tLoss: 301.884125\n",
      "Train Epoch: 121 [2400/2589 (93%)]\tLoss: 333.714478\n",
      "====> Epoch: 121 Average train loss: 329.4672\n",
      "====> Epoch: 121 Average test loss: 937.3013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122 [0/2589 (0%)]\tLoss: 420.795471\n",
      "Train Epoch: 122 [300/2589 (12%)]\tLoss: 340.436615\n",
      "Train Epoch: 122 [600/2589 (23%)]\tLoss: 338.977051\n",
      "Train Epoch: 122 [900/2589 (35%)]\tLoss: 277.934662\n",
      "Train Epoch: 122 [1200/2589 (46%)]\tLoss: 384.315247\n",
      "Train Epoch: 122 [1500/2589 (58%)]\tLoss: 262.138947\n",
      "Train Epoch: 122 [1800/2589 (70%)]\tLoss: 335.404297\n",
      "Train Epoch: 122 [2100/2589 (81%)]\tLoss: 266.464294\n",
      "Train Epoch: 122 [2400/2589 (93%)]\tLoss: 432.670959\n",
      "====> Epoch: 122 Average train loss: 315.2819\n",
      "====> Epoch: 122 Average test loss: 931.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 123 [0/2589 (0%)]\tLoss: 372.996155\n",
      "Train Epoch: 123 [300/2589 (12%)]\tLoss: 338.237885\n",
      "Train Epoch: 123 [600/2589 (23%)]\tLoss: 367.406647\n",
      "Train Epoch: 123 [900/2589 (35%)]\tLoss: 270.926178\n",
      "Train Epoch: 123 [1200/2589 (46%)]\tLoss: 333.136902\n",
      "Train Epoch: 123 [1500/2589 (58%)]\tLoss: 273.141296\n",
      "Train Epoch: 123 [1800/2589 (70%)]\tLoss: 234.938934\n",
      "Train Epoch: 123 [2100/2589 (81%)]\tLoss: 268.999176\n",
      "Train Epoch: 123 [2400/2589 (93%)]\tLoss: 362.773315\n",
      "====> Epoch: 123 Average train loss: 327.1321\n",
      "====> Epoch: 123 Average test loss: 926.5654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 124 [0/2589 (0%)]\tLoss: 337.051270\n",
      "Train Epoch: 124 [300/2589 (12%)]\tLoss: 467.547058\n",
      "Train Epoch: 124 [600/2589 (23%)]\tLoss: 268.867859\n",
      "Train Epoch: 124 [900/2589 (35%)]\tLoss: 631.831909\n",
      "Train Epoch: 124 [1200/2589 (46%)]\tLoss: 232.204681\n",
      "Train Epoch: 124 [1500/2589 (58%)]\tLoss: 313.799316\n",
      "Train Epoch: 124 [1800/2589 (70%)]\tLoss: 260.320953\n",
      "Train Epoch: 124 [2100/2589 (81%)]\tLoss: 296.923279\n",
      "Train Epoch: 124 [2400/2589 (93%)]\tLoss: 326.161346\n",
      "====> Epoch: 124 Average train loss: 315.9258\n",
      "====> Epoch: 124 Average test loss: 955.8672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 125 [0/2589 (0%)]\tLoss: 314.675140\n",
      "Train Epoch: 125 [300/2589 (12%)]\tLoss: 328.462250\n",
      "Train Epoch: 125 [600/2589 (23%)]\tLoss: 344.673767\n",
      "Train Epoch: 125 [900/2589 (35%)]\tLoss: 244.846863\n",
      "Train Epoch: 125 [1200/2589 (46%)]\tLoss: 271.647522\n",
      "Train Epoch: 125 [1500/2589 (58%)]\tLoss: 350.088715\n",
      "Train Epoch: 125 [1800/2589 (70%)]\tLoss: 397.168762\n",
      "Train Epoch: 125 [2100/2589 (81%)]\tLoss: 526.555786\n",
      "Train Epoch: 125 [2400/2589 (93%)]\tLoss: 416.541290\n",
      "====> Epoch: 125 Average train loss: 313.4901\n",
      "====> Epoch: 125 Average test loss: 944.0171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 126 [0/2589 (0%)]\tLoss: 330.412231\n",
      "Train Epoch: 126 [300/2589 (12%)]\tLoss: 331.621796\n",
      "Train Epoch: 126 [600/2589 (23%)]\tLoss: 398.770020\n",
      "Train Epoch: 126 [900/2589 (35%)]\tLoss: 463.246063\n",
      "Train Epoch: 126 [1200/2589 (46%)]\tLoss: 266.653412\n",
      "Train Epoch: 126 [1500/2589 (58%)]\tLoss: 213.212753\n",
      "Train Epoch: 126 [1800/2589 (70%)]\tLoss: 486.203400\n",
      "Train Epoch: 126 [2100/2589 (81%)]\tLoss: 440.144257\n",
      "Train Epoch: 126 [2400/2589 (93%)]\tLoss: 329.622040\n",
      "====> Epoch: 126 Average train loss: 325.7055\n",
      "====> Epoch: 126 Average test loss: 954.0568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 127 [0/2589 (0%)]\tLoss: 202.486496\n",
      "Train Epoch: 127 [300/2589 (12%)]\tLoss: 336.389374\n",
      "Train Epoch: 127 [600/2589 (23%)]\tLoss: 247.066727\n",
      "Train Epoch: 127 [900/2589 (35%)]\tLoss: 269.646881\n",
      "Train Epoch: 127 [1200/2589 (46%)]\tLoss: 248.453598\n",
      "Train Epoch: 127 [1500/2589 (58%)]\tLoss: 328.038177\n",
      "Train Epoch: 127 [1800/2589 (70%)]\tLoss: 233.079880\n",
      "Train Epoch: 127 [2100/2589 (81%)]\tLoss: 247.666245\n",
      "Train Epoch: 127 [2400/2589 (93%)]\tLoss: 307.417480\n",
      "====> Epoch: 127 Average train loss: 306.0570\n",
      "====> Epoch: 127 Average test loss: 948.4123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 128 [0/2589 (0%)]\tLoss: 289.502563\n",
      "Train Epoch: 128 [300/2589 (12%)]\tLoss: 308.612030\n",
      "Train Epoch: 128 [600/2589 (23%)]\tLoss: 248.739639\n",
      "Train Epoch: 128 [900/2589 (35%)]\tLoss: 266.332550\n",
      "Train Epoch: 128 [1200/2589 (46%)]\tLoss: 296.203339\n",
      "Train Epoch: 128 [1500/2589 (58%)]\tLoss: 271.800079\n",
      "Train Epoch: 128 [1800/2589 (70%)]\tLoss: 247.055557\n",
      "Train Epoch: 128 [2100/2589 (81%)]\tLoss: 292.246185\n",
      "Train Epoch: 128 [2400/2589 (93%)]\tLoss: 269.559906\n",
      "====> Epoch: 128 Average train loss: 320.0558\n",
      "====> Epoch: 128 Average test loss: 971.1561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 129 [0/2589 (0%)]\tLoss: 295.994568\n",
      "Train Epoch: 129 [300/2589 (12%)]\tLoss: 313.300018\n",
      "Train Epoch: 129 [600/2589 (23%)]\tLoss: 290.229218\n",
      "Train Epoch: 129 [900/2589 (35%)]\tLoss: 298.600250\n",
      "Train Epoch: 129 [1200/2589 (46%)]\tLoss: 229.892029\n",
      "Train Epoch: 129 [1500/2589 (58%)]\tLoss: 325.440399\n",
      "Train Epoch: 129 [1800/2589 (70%)]\tLoss: 286.110931\n",
      "Train Epoch: 129 [2100/2589 (81%)]\tLoss: 390.291718\n",
      "Train Epoch: 129 [2400/2589 (93%)]\tLoss: 355.289215\n",
      "====> Epoch: 129 Average train loss: 313.4424\n",
      "====> Epoch: 129 Average test loss: 984.1972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 130 [0/2589 (0%)]\tLoss: 222.580627\n",
      "Train Epoch: 130 [300/2589 (12%)]\tLoss: 309.437836\n",
      "Train Epoch: 130 [600/2589 (23%)]\tLoss: 480.298309\n",
      "Train Epoch: 130 [900/2589 (35%)]\tLoss: 336.623474\n",
      "Train Epoch: 130 [1200/2589 (46%)]\tLoss: 274.734100\n",
      "Train Epoch: 130 [1500/2589 (58%)]\tLoss: 250.780273\n",
      "Train Epoch: 130 [1800/2589 (70%)]\tLoss: 204.784119\n",
      "Train Epoch: 130 [2100/2589 (81%)]\tLoss: 280.692688\n",
      "Train Epoch: 130 [2400/2589 (93%)]\tLoss: 358.290039\n",
      "====> Epoch: 130 Average train loss: 313.2222\n",
      "====> Epoch: 130 Average test loss: 993.5314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 131 [0/2589 (0%)]\tLoss: 321.592651\n",
      "Train Epoch: 131 [300/2589 (12%)]\tLoss: 514.077271\n",
      "Train Epoch: 131 [600/2589 (23%)]\tLoss: 379.867889\n",
      "Train Epoch: 131 [900/2589 (35%)]\tLoss: 459.211060\n",
      "Train Epoch: 131 [1200/2589 (46%)]\tLoss: 334.849640\n",
      "Train Epoch: 131 [1500/2589 (58%)]\tLoss: 321.745911\n",
      "Train Epoch: 131 [1800/2589 (70%)]\tLoss: 311.701752\n",
      "Train Epoch: 131 [2100/2589 (81%)]\tLoss: 439.709381\n",
      "Train Epoch: 131 [2400/2589 (93%)]\tLoss: 322.426208\n",
      "====> Epoch: 131 Average train loss: 324.6414\n",
      "====> Epoch: 131 Average test loss: 942.9069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 132 [0/2589 (0%)]\tLoss: 197.794937\n",
      "Train Epoch: 132 [300/2589 (12%)]\tLoss: 338.439575\n",
      "Train Epoch: 132 [600/2589 (23%)]\tLoss: 357.918762\n",
      "Train Epoch: 132 [900/2589 (35%)]\tLoss: 337.782043\n",
      "Train Epoch: 132 [1200/2589 (46%)]\tLoss: 262.815887\n",
      "Train Epoch: 132 [1500/2589 (58%)]\tLoss: 504.547699\n",
      "Train Epoch: 132 [1800/2589 (70%)]\tLoss: 196.290237\n",
      "Train Epoch: 132 [2100/2589 (81%)]\tLoss: 300.682190\n",
      "Train Epoch: 132 [2400/2589 (93%)]\tLoss: 233.460907\n",
      "====> Epoch: 132 Average train loss: 312.3437\n",
      "====> Epoch: 132 Average test loss: 971.6245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 133 [0/2589 (0%)]\tLoss: 249.273880\n",
      "Train Epoch: 133 [300/2589 (12%)]\tLoss: 311.829926\n",
      "Train Epoch: 133 [600/2589 (23%)]\tLoss: 203.310974\n",
      "Train Epoch: 133 [900/2589 (35%)]\tLoss: 350.508972\n",
      "Train Epoch: 133 [1200/2589 (46%)]\tLoss: 404.878571\n",
      "Train Epoch: 133 [1500/2589 (58%)]\tLoss: 404.421722\n",
      "Train Epoch: 133 [1800/2589 (70%)]\tLoss: 310.201447\n",
      "Train Epoch: 133 [2100/2589 (81%)]\tLoss: 439.143372\n",
      "Train Epoch: 133 [2400/2589 (93%)]\tLoss: 258.512848\n",
      "====> Epoch: 133 Average train loss: 311.5475\n",
      "====> Epoch: 133 Average test loss: 969.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 134 [0/2589 (0%)]\tLoss: 286.804962\n",
      "Train Epoch: 134 [300/2589 (12%)]\tLoss: 290.020874\n",
      "Train Epoch: 134 [600/2589 (23%)]\tLoss: 245.704483\n",
      "Train Epoch: 134 [900/2589 (35%)]\tLoss: 286.765594\n",
      "Train Epoch: 134 [1200/2589 (46%)]\tLoss: 818.232239\n",
      "Train Epoch: 134 [1500/2589 (58%)]\tLoss: 306.940063\n",
      "Train Epoch: 134 [1800/2589 (70%)]\tLoss: 267.695526\n",
      "Train Epoch: 134 [2100/2589 (81%)]\tLoss: 295.148285\n",
      "Train Epoch: 134 [2400/2589 (93%)]\tLoss: 346.458191\n",
      "====> Epoch: 134 Average train loss: 311.1465\n",
      "====> Epoch: 134 Average test loss: 955.8380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 135 [0/2589 (0%)]\tLoss: 328.725311\n",
      "Train Epoch: 135 [300/2589 (12%)]\tLoss: 342.318420\n",
      "Train Epoch: 135 [600/2589 (23%)]\tLoss: 344.277344\n",
      "Train Epoch: 135 [900/2589 (35%)]\tLoss: 455.991791\n",
      "Train Epoch: 135 [1200/2589 (46%)]\tLoss: 208.741882\n",
      "Train Epoch: 135 [1500/2589 (58%)]\tLoss: 359.086578\n",
      "Train Epoch: 135 [1800/2589 (70%)]\tLoss: 311.688843\n",
      "Train Epoch: 135 [2100/2589 (81%)]\tLoss: 367.605957\n",
      "Train Epoch: 135 [2400/2589 (93%)]\tLoss: 309.779907\n",
      "====> Epoch: 135 Average train loss: 309.2940\n",
      "====> Epoch: 135 Average test loss: 971.8181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 136 [0/2589 (0%)]\tLoss: 290.945618\n",
      "Train Epoch: 136 [300/2589 (12%)]\tLoss: 383.686432\n",
      "Train Epoch: 136 [600/2589 (23%)]\tLoss: 213.676422\n",
      "Train Epoch: 136 [900/2589 (35%)]\tLoss: 406.917084\n",
      "Train Epoch: 136 [1200/2589 (46%)]\tLoss: 319.430695\n",
      "Train Epoch: 136 [1500/2589 (58%)]\tLoss: 256.567413\n",
      "Train Epoch: 136 [1800/2589 (70%)]\tLoss: 430.261230\n",
      "Train Epoch: 136 [2100/2589 (81%)]\tLoss: 282.606934\n",
      "Train Epoch: 136 [2400/2589 (93%)]\tLoss: 265.817200\n",
      "====> Epoch: 136 Average train loss: 316.0909\n",
      "====> Epoch: 136 Average test loss: 983.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 137 [0/2589 (0%)]\tLoss: 315.518921\n",
      "Train Epoch: 137 [300/2589 (12%)]\tLoss: 314.015991\n",
      "Train Epoch: 137 [600/2589 (23%)]\tLoss: 129.954269\n",
      "Train Epoch: 137 [900/2589 (35%)]\tLoss: 289.260406\n",
      "Train Epoch: 137 [1200/2589 (46%)]\tLoss: 291.824585\n",
      "Train Epoch: 137 [1500/2589 (58%)]\tLoss: 257.920624\n",
      "Train Epoch: 137 [1800/2589 (70%)]\tLoss: 418.875305\n",
      "Train Epoch: 137 [2100/2589 (81%)]\tLoss: 303.104156\n",
      "Train Epoch: 137 [2400/2589 (93%)]\tLoss: 216.478546\n",
      "====> Epoch: 137 Average train loss: 312.6290\n",
      "====> Epoch: 137 Average test loss: 975.2307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 138 [0/2589 (0%)]\tLoss: 453.495056\n",
      "Train Epoch: 138 [300/2589 (12%)]\tLoss: 330.280945\n",
      "Train Epoch: 138 [600/2589 (23%)]\tLoss: 309.340759\n",
      "Train Epoch: 138 [900/2589 (35%)]\tLoss: 383.137878\n",
      "Train Epoch: 138 [1200/2589 (46%)]\tLoss: 233.455719\n",
      "Train Epoch: 138 [1500/2589 (58%)]\tLoss: 272.744202\n",
      "Train Epoch: 138 [1800/2589 (70%)]\tLoss: 290.120422\n",
      "Train Epoch: 138 [2100/2589 (81%)]\tLoss: 385.336456\n",
      "Train Epoch: 138 [2400/2589 (93%)]\tLoss: 283.547394\n",
      "====> Epoch: 138 Average train loss: 313.5687\n",
      "====> Epoch: 138 Average test loss: 968.0496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 139 [0/2589 (0%)]\tLoss: 224.716125\n",
      "Train Epoch: 139 [300/2589 (12%)]\tLoss: 225.273087\n",
      "Train Epoch: 139 [600/2589 (23%)]\tLoss: 352.198547\n",
      "Train Epoch: 139 [900/2589 (35%)]\tLoss: 341.931580\n",
      "Train Epoch: 139 [1200/2589 (46%)]\tLoss: 472.659668\n",
      "Train Epoch: 139 [1500/2589 (58%)]\tLoss: 351.275360\n",
      "Train Epoch: 139 [1800/2589 (70%)]\tLoss: 244.463379\n",
      "Train Epoch: 139 [2100/2589 (81%)]\tLoss: 382.883209\n",
      "Train Epoch: 139 [2400/2589 (93%)]\tLoss: 312.773590\n",
      "====> Epoch: 139 Average train loss: 313.7963\n",
      "====> Epoch: 139 Average test loss: 959.0716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 140 [0/2589 (0%)]\tLoss: 223.500748\n",
      "Train Epoch: 140 [300/2589 (12%)]\tLoss: 220.398895\n",
      "Train Epoch: 140 [600/2589 (23%)]\tLoss: 353.569305\n",
      "Train Epoch: 140 [900/2589 (35%)]\tLoss: 266.569641\n",
      "Train Epoch: 140 [1200/2589 (46%)]\tLoss: 314.986938\n",
      "Train Epoch: 140 [1500/2589 (58%)]\tLoss: 337.475403\n",
      "Train Epoch: 140 [1800/2589 (70%)]\tLoss: 441.925568\n",
      "Train Epoch: 140 [2100/2589 (81%)]\tLoss: 344.531433\n",
      "Train Epoch: 140 [2400/2589 (93%)]\tLoss: 223.394623\n",
      "====> Epoch: 140 Average train loss: 305.9673\n",
      "====> Epoch: 140 Average test loss: 991.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 141 [0/2589 (0%)]\tLoss: 217.787399\n",
      "Train Epoch: 141 [300/2589 (12%)]\tLoss: 334.605255\n",
      "Train Epoch: 141 [600/2589 (23%)]\tLoss: 342.235046\n",
      "Train Epoch: 141 [900/2589 (35%)]\tLoss: 286.877106\n",
      "Train Epoch: 141 [1200/2589 (46%)]\tLoss: 337.890015\n",
      "Train Epoch: 141 [1500/2589 (58%)]\tLoss: 290.961639\n",
      "Train Epoch: 141 [1800/2589 (70%)]\tLoss: 287.369751\n",
      "Train Epoch: 141 [2100/2589 (81%)]\tLoss: 285.484497\n",
      "Train Epoch: 141 [2400/2589 (93%)]\tLoss: 298.667999\n",
      "====> Epoch: 141 Average train loss: 311.9897\n",
      "====> Epoch: 141 Average test loss: 953.1882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 142 [0/2589 (0%)]\tLoss: 364.673401\n",
      "Train Epoch: 142 [300/2589 (12%)]\tLoss: 269.200653\n",
      "Train Epoch: 142 [600/2589 (23%)]\tLoss: 275.325958\n",
      "Train Epoch: 142 [900/2589 (35%)]\tLoss: 209.485352\n",
      "Train Epoch: 142 [1200/2589 (46%)]\tLoss: 222.510895\n",
      "Train Epoch: 142 [1500/2589 (58%)]\tLoss: 450.797211\n",
      "Train Epoch: 142 [1800/2589 (70%)]\tLoss: 315.379242\n",
      "Train Epoch: 142 [2100/2589 (81%)]\tLoss: 186.909851\n",
      "Train Epoch: 142 [2400/2589 (93%)]\tLoss: 259.984283\n",
      "====> Epoch: 142 Average train loss: 305.9269\n",
      "====> Epoch: 142 Average test loss: 936.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 143 [0/2589 (0%)]\tLoss: 297.876495\n",
      "Train Epoch: 143 [300/2589 (12%)]\tLoss: 409.329895\n",
      "Train Epoch: 143 [600/2589 (23%)]\tLoss: 297.125488\n",
      "Train Epoch: 143 [900/2589 (35%)]\tLoss: 308.332855\n",
      "Train Epoch: 143 [1200/2589 (46%)]\tLoss: 207.399414\n",
      "Train Epoch: 143 [1500/2589 (58%)]\tLoss: 294.115143\n",
      "Train Epoch: 143 [1800/2589 (70%)]\tLoss: 222.805832\n",
      "Train Epoch: 143 [2100/2589 (81%)]\tLoss: 271.512909\n",
      "Train Epoch: 143 [2400/2589 (93%)]\tLoss: 258.902222\n",
      "====> Epoch: 143 Average train loss: 310.3594\n",
      "====> Epoch: 143 Average test loss: 964.3604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 144 [0/2589 (0%)]\tLoss: 245.138321\n",
      "Train Epoch: 144 [300/2589 (12%)]\tLoss: 244.932343\n",
      "Train Epoch: 144 [600/2589 (23%)]\tLoss: 235.254257\n",
      "Train Epoch: 144 [900/2589 (35%)]\tLoss: 226.243881\n",
      "Train Epoch: 144 [1200/2589 (46%)]\tLoss: 235.296890\n",
      "Train Epoch: 144 [1500/2589 (58%)]\tLoss: 217.262695\n",
      "Train Epoch: 144 [1800/2589 (70%)]\tLoss: 250.368057\n",
      "Train Epoch: 144 [2100/2589 (81%)]\tLoss: 262.887360\n",
      "Train Epoch: 144 [2400/2589 (93%)]\tLoss: 237.708557\n",
      "====> Epoch: 144 Average train loss: 292.1918\n",
      "====> Epoch: 144 Average test loss: 956.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [0/2589 (0%)]\tLoss: 270.685242\n",
      "Train Epoch: 145 [300/2589 (12%)]\tLoss: 212.095673\n",
      "Train Epoch: 145 [600/2589 (23%)]\tLoss: 330.753265\n",
      "Train Epoch: 145 [900/2589 (35%)]\tLoss: 215.091263\n",
      "Train Epoch: 145 [1200/2589 (46%)]\tLoss: 256.369659\n",
      "Train Epoch: 145 [1500/2589 (58%)]\tLoss: 278.589020\n",
      "Train Epoch: 145 [1800/2589 (70%)]\tLoss: 245.780533\n",
      "Train Epoch: 145 [2100/2589 (81%)]\tLoss: 247.369461\n",
      "Train Epoch: 145 [2400/2589 (93%)]\tLoss: 306.102722\n",
      "====> Epoch: 145 Average train loss: 299.6701\n",
      "====> Epoch: 145 Average test loss: 948.5739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 146 [0/2589 (0%)]\tLoss: 232.947601\n",
      "Train Epoch: 146 [300/2589 (12%)]\tLoss: 235.759125\n",
      "Train Epoch: 146 [600/2589 (23%)]\tLoss: 284.850464\n",
      "Train Epoch: 146 [900/2589 (35%)]\tLoss: 330.405304\n",
      "Train Epoch: 146 [1200/2589 (46%)]\tLoss: 314.084961\n",
      "Train Epoch: 146 [1500/2589 (58%)]\tLoss: 254.677322\n",
      "Train Epoch: 146 [1800/2589 (70%)]\tLoss: 273.338928\n",
      "Train Epoch: 146 [2100/2589 (81%)]\tLoss: 271.421234\n",
      "Train Epoch: 146 [2400/2589 (93%)]\tLoss: 379.495636\n",
      "====> Epoch: 146 Average train loss: 305.2812\n",
      "====> Epoch: 146 Average test loss: 961.7281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 147 [0/2589 (0%)]\tLoss: 243.139328\n",
      "Train Epoch: 147 [300/2589 (12%)]\tLoss: 362.387878\n",
      "Train Epoch: 147 [600/2589 (23%)]\tLoss: 194.701202\n",
      "Train Epoch: 147 [900/2589 (35%)]\tLoss: 238.942825\n",
      "Train Epoch: 147 [1200/2589 (46%)]\tLoss: 322.669128\n",
      "Train Epoch: 147 [1500/2589 (58%)]\tLoss: 378.173065\n",
      "Train Epoch: 147 [1800/2589 (70%)]\tLoss: 229.736328\n",
      "Train Epoch: 147 [2100/2589 (81%)]\tLoss: 275.925476\n",
      "Train Epoch: 147 [2400/2589 (93%)]\tLoss: 244.863480\n",
      "====> Epoch: 147 Average train loss: 303.7032\n",
      "====> Epoch: 147 Average test loss: 924.4402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 148 [0/2589 (0%)]\tLoss: 335.464752\n",
      "Train Epoch: 148 [300/2589 (12%)]\tLoss: 426.043335\n",
      "Train Epoch: 148 [600/2589 (23%)]\tLoss: 276.056641\n",
      "Train Epoch: 148 [900/2589 (35%)]\tLoss: 316.109314\n",
      "Train Epoch: 148 [1200/2589 (46%)]\tLoss: 321.574890\n",
      "Train Epoch: 148 [1500/2589 (58%)]\tLoss: 298.313751\n",
      "Train Epoch: 148 [1800/2589 (70%)]\tLoss: 319.862427\n",
      "Train Epoch: 148 [2100/2589 (81%)]\tLoss: 263.808624\n",
      "Train Epoch: 148 [2400/2589 (93%)]\tLoss: 194.997574\n",
      "====> Epoch: 148 Average train loss: 312.4003\n",
      "====> Epoch: 148 Average test loss: 952.2524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 149 [0/2589 (0%)]\tLoss: 310.251038\n",
      "Train Epoch: 149 [300/2589 (12%)]\tLoss: 205.879883\n",
      "Train Epoch: 149 [600/2589 (23%)]\tLoss: 437.121155\n",
      "Train Epoch: 149 [900/2589 (35%)]\tLoss: 287.393585\n",
      "Train Epoch: 149 [1200/2589 (46%)]\tLoss: 259.480316\n",
      "Train Epoch: 149 [1500/2589 (58%)]\tLoss: 320.989441\n",
      "Train Epoch: 149 [1800/2589 (70%)]\tLoss: 359.608978\n",
      "Train Epoch: 149 [2100/2589 (81%)]\tLoss: 289.219055\n",
      "Train Epoch: 149 [2400/2589 (93%)]\tLoss: 337.409088\n",
      "====> Epoch: 149 Average train loss: 302.6485\n",
      "====> Epoch: 149 Average test loss: 963.7783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 150 [0/2589 (0%)]\tLoss: 285.356628\n",
      "Train Epoch: 150 [300/2589 (12%)]\tLoss: 301.464844\n",
      "Train Epoch: 150 [600/2589 (23%)]\tLoss: 220.501511\n",
      "Train Epoch: 150 [900/2589 (35%)]\tLoss: 209.304520\n",
      "Train Epoch: 150 [1200/2589 (46%)]\tLoss: 204.247421\n",
      "Train Epoch: 150 [1500/2589 (58%)]\tLoss: 279.236450\n",
      "Train Epoch: 150 [1800/2589 (70%)]\tLoss: 258.951447\n",
      "Train Epoch: 150 [2100/2589 (81%)]\tLoss: 448.575409\n",
      "Train Epoch: 150 [2400/2589 (93%)]\tLoss: 267.544189\n",
      "====> Epoch: 150 Average train loss: 311.7900\n",
      "====> Epoch: 150 Average test loss: 989.9393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 151 [0/2589 (0%)]\tLoss: 397.033142\n",
      "Train Epoch: 151 [300/2589 (12%)]\tLoss: 207.043396\n",
      "Train Epoch: 151 [600/2589 (23%)]\tLoss: 264.599762\n",
      "Train Epoch: 151 [900/2589 (35%)]\tLoss: 247.464188\n",
      "Train Epoch: 151 [1200/2589 (46%)]\tLoss: 279.868988\n",
      "Train Epoch: 151 [1500/2589 (58%)]\tLoss: 288.671692\n",
      "Train Epoch: 151 [1800/2589 (70%)]\tLoss: 424.844574\n",
      "Train Epoch: 151 [2100/2589 (81%)]\tLoss: 255.450027\n",
      "Train Epoch: 151 [2400/2589 (93%)]\tLoss: 230.865982\n",
      "====> Epoch: 151 Average train loss: 299.5473\n",
      "====> Epoch: 151 Average test loss: 969.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 152 [0/2589 (0%)]\tLoss: 418.346527\n",
      "Train Epoch: 152 [300/2589 (12%)]\tLoss: 256.558441\n",
      "Train Epoch: 152 [600/2589 (23%)]\tLoss: 308.157990\n",
      "Train Epoch: 152 [900/2589 (35%)]\tLoss: 278.913971\n",
      "Train Epoch: 152 [1200/2589 (46%)]\tLoss: 206.951324\n",
      "Train Epoch: 152 [1500/2589 (58%)]\tLoss: 252.959320\n",
      "Train Epoch: 152 [1800/2589 (70%)]\tLoss: 247.847610\n",
      "Train Epoch: 152 [2100/2589 (81%)]\tLoss: 238.614578\n",
      "Train Epoch: 152 [2400/2589 (93%)]\tLoss: 288.407990\n",
      "====> Epoch: 152 Average train loss: 298.3241\n",
      "====> Epoch: 152 Average test loss: 929.3180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 153 [0/2589 (0%)]\tLoss: 357.020905\n",
      "Train Epoch: 153 [300/2589 (12%)]\tLoss: 399.472321\n",
      "Train Epoch: 153 [600/2589 (23%)]\tLoss: 279.838165\n",
      "Train Epoch: 153 [900/2589 (35%)]\tLoss: 308.192688\n",
      "Train Epoch: 153 [1200/2589 (46%)]\tLoss: 295.701691\n",
      "Train Epoch: 153 [1500/2589 (58%)]\tLoss: 176.830658\n",
      "Train Epoch: 153 [1800/2589 (70%)]\tLoss: 276.712067\n",
      "Train Epoch: 153 [2100/2589 (81%)]\tLoss: 280.409210\n",
      "Train Epoch: 153 [2400/2589 (93%)]\tLoss: 238.246399\n",
      "====> Epoch: 153 Average train loss: 310.6136\n",
      "====> Epoch: 153 Average test loss: 970.9718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 154 [0/2589 (0%)]\tLoss: 207.384445\n",
      "Train Epoch: 154 [300/2589 (12%)]\tLoss: 295.619171\n",
      "Train Epoch: 154 [600/2589 (23%)]\tLoss: 315.231964\n",
      "Train Epoch: 154 [900/2589 (35%)]\tLoss: 194.877533\n",
      "Train Epoch: 154 [1200/2589 (46%)]\tLoss: 341.976257\n",
      "Train Epoch: 154 [1500/2589 (58%)]\tLoss: 181.592834\n",
      "Train Epoch: 154 [1800/2589 (70%)]\tLoss: 330.004395\n",
      "Train Epoch: 154 [2100/2589 (81%)]\tLoss: 279.087341\n",
      "Train Epoch: 154 [2400/2589 (93%)]\tLoss: 296.160034\n",
      "====> Epoch: 154 Average train loss: 302.5952\n",
      "====> Epoch: 154 Average test loss: 951.7415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 155 [0/2589 (0%)]\tLoss: 335.246643\n",
      "Train Epoch: 155 [300/2589 (12%)]\tLoss: 229.002686\n",
      "Train Epoch: 155 [600/2589 (23%)]\tLoss: 321.855408\n",
      "Train Epoch: 155 [900/2589 (35%)]\tLoss: 229.488434\n",
      "Train Epoch: 155 [1200/2589 (46%)]\tLoss: 384.315399\n",
      "Train Epoch: 155 [1500/2589 (58%)]\tLoss: 273.796844\n",
      "Train Epoch: 155 [1800/2589 (70%)]\tLoss: 305.399017\n",
      "Train Epoch: 155 [2100/2589 (81%)]\tLoss: 493.403168\n",
      "Train Epoch: 155 [2400/2589 (93%)]\tLoss: 214.844025\n",
      "====> Epoch: 155 Average train loss: 292.2742\n",
      "====> Epoch: 155 Average test loss: 951.7609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 156 [0/2589 (0%)]\tLoss: 275.880890\n",
      "Train Epoch: 156 [300/2589 (12%)]\tLoss: 232.735413\n",
      "Train Epoch: 156 [600/2589 (23%)]\tLoss: 221.105179\n",
      "Train Epoch: 156 [900/2589 (35%)]\tLoss: 357.489227\n",
      "Train Epoch: 156 [1200/2589 (46%)]\tLoss: 271.012177\n",
      "Train Epoch: 156 [1500/2589 (58%)]\tLoss: 283.120300\n",
      "Train Epoch: 156 [1800/2589 (70%)]\tLoss: 196.137070\n",
      "Train Epoch: 156 [2100/2589 (81%)]\tLoss: 428.669952\n",
      "Train Epoch: 156 [2400/2589 (93%)]\tLoss: 285.690033\n",
      "====> Epoch: 156 Average train loss: 295.4678\n",
      "====> Epoch: 156 Average test loss: 951.7236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 157 [0/2589 (0%)]\tLoss: 282.150513\n",
      "Train Epoch: 157 [300/2589 (12%)]\tLoss: 293.671173\n",
      "Train Epoch: 157 [600/2589 (23%)]\tLoss: 281.567352\n",
      "Train Epoch: 157 [900/2589 (35%)]\tLoss: 290.888489\n",
      "Train Epoch: 157 [1200/2589 (46%)]\tLoss: 337.245270\n",
      "Train Epoch: 157 [1500/2589 (58%)]\tLoss: 368.882690\n",
      "Train Epoch: 157 [1800/2589 (70%)]\tLoss: 272.685516\n",
      "Train Epoch: 157 [2100/2589 (81%)]\tLoss: 289.633972\n",
      "Train Epoch: 157 [2400/2589 (93%)]\tLoss: 299.800446\n",
      "====> Epoch: 157 Average train loss: 300.9035\n",
      "====> Epoch: 157 Average test loss: 950.2237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 158 [0/2589 (0%)]\tLoss: 358.262665\n",
      "Train Epoch: 158 [300/2589 (12%)]\tLoss: 382.216278\n",
      "Train Epoch: 158 [600/2589 (23%)]\tLoss: 275.324371\n",
      "Train Epoch: 158 [900/2589 (35%)]\tLoss: 275.855347\n",
      "Train Epoch: 158 [1200/2589 (46%)]\tLoss: 265.290100\n",
      "Train Epoch: 158 [1500/2589 (58%)]\tLoss: 578.969604\n",
      "Train Epoch: 158 [1800/2589 (70%)]\tLoss: 285.195862\n",
      "Train Epoch: 158 [2100/2589 (81%)]\tLoss: 260.452209\n",
      "Train Epoch: 158 [2400/2589 (93%)]\tLoss: 277.745728\n",
      "====> Epoch: 158 Average train loss: 290.5256\n",
      "====> Epoch: 158 Average test loss: 959.2640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 159 [0/2589 (0%)]\tLoss: 383.973785\n",
      "Train Epoch: 159 [300/2589 (12%)]\tLoss: 296.439789\n",
      "Train Epoch: 159 [600/2589 (23%)]\tLoss: 334.683441\n",
      "Train Epoch: 159 [900/2589 (35%)]\tLoss: 245.395279\n",
      "Train Epoch: 159 [1200/2589 (46%)]\tLoss: 318.957123\n",
      "Train Epoch: 159 [1500/2589 (58%)]\tLoss: 268.839569\n",
      "Train Epoch: 159 [1800/2589 (70%)]\tLoss: 241.539841\n",
      "Train Epoch: 159 [2100/2589 (81%)]\tLoss: 262.088165\n",
      "Train Epoch: 159 [2400/2589 (93%)]\tLoss: 277.266876\n",
      "====> Epoch: 159 Average train loss: 306.8628\n",
      "====> Epoch: 159 Average test loss: 970.4388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 160 [0/2589 (0%)]\tLoss: 309.410248\n",
      "Train Epoch: 160 [300/2589 (12%)]\tLoss: 258.290619\n",
      "Train Epoch: 160 [600/2589 (23%)]\tLoss: 381.720276\n",
      "Train Epoch: 160 [900/2589 (35%)]\tLoss: 257.866089\n",
      "Train Epoch: 160 [1200/2589 (46%)]\tLoss: 289.440063\n",
      "Train Epoch: 160 [1500/2589 (58%)]\tLoss: 320.660675\n",
      "Train Epoch: 160 [1800/2589 (70%)]\tLoss: 295.834045\n",
      "Train Epoch: 160 [2100/2589 (81%)]\tLoss: 325.035370\n",
      "Train Epoch: 160 [2400/2589 (93%)]\tLoss: 248.468903\n",
      "====> Epoch: 160 Average train loss: 310.9529\n",
      "====> Epoch: 160 Average test loss: 967.4301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 161 [0/2589 (0%)]\tLoss: 309.919861\n",
      "Train Epoch: 161 [300/2589 (12%)]\tLoss: 217.783493\n",
      "Train Epoch: 161 [600/2589 (23%)]\tLoss: 297.190247\n",
      "Train Epoch: 161 [900/2589 (35%)]\tLoss: 278.590057\n",
      "Train Epoch: 161 [1200/2589 (46%)]\tLoss: 256.893280\n",
      "Train Epoch: 161 [1500/2589 (58%)]\tLoss: 375.790680\n",
      "Train Epoch: 161 [1800/2589 (70%)]\tLoss: 233.016129\n",
      "Train Epoch: 161 [2100/2589 (81%)]\tLoss: 417.187775\n",
      "Train Epoch: 161 [2400/2589 (93%)]\tLoss: 322.257202\n",
      "====> Epoch: 161 Average train loss: 306.3364\n",
      "====> Epoch: 161 Average test loss: 974.9544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 162 [0/2589 (0%)]\tLoss: 343.942932\n",
      "Train Epoch: 162 [300/2589 (12%)]\tLoss: 405.095032\n",
      "Train Epoch: 162 [600/2589 (23%)]\tLoss: 321.842133\n",
      "Train Epoch: 162 [900/2589 (35%)]\tLoss: 260.144989\n",
      "Train Epoch: 162 [1200/2589 (46%)]\tLoss: 314.947723\n",
      "Train Epoch: 162 [1500/2589 (58%)]\tLoss: 379.996155\n",
      "Train Epoch: 162 [1800/2589 (70%)]\tLoss: 257.722687\n",
      "Train Epoch: 162 [2100/2589 (81%)]\tLoss: 451.740570\n",
      "Train Epoch: 162 [2400/2589 (93%)]\tLoss: 329.483490\n",
      "====> Epoch: 162 Average train loss: 297.7580\n",
      "====> Epoch: 162 Average test loss: 936.2174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 163 [0/2589 (0%)]\tLoss: 134.764587\n",
      "Train Epoch: 163 [300/2589 (12%)]\tLoss: 233.853043\n",
      "Train Epoch: 163 [600/2589 (23%)]\tLoss: 251.040176\n",
      "Train Epoch: 163 [900/2589 (35%)]\tLoss: 261.267426\n",
      "Train Epoch: 163 [1200/2589 (46%)]\tLoss: 339.227142\n",
      "Train Epoch: 163 [1500/2589 (58%)]\tLoss: 327.669922\n",
      "Train Epoch: 163 [1800/2589 (70%)]\tLoss: 240.273895\n",
      "Train Epoch: 163 [2100/2589 (81%)]\tLoss: 495.556854\n",
      "Train Epoch: 163 [2400/2589 (93%)]\tLoss: 311.825287\n",
      "====> Epoch: 163 Average train loss: 294.3129\n",
      "====> Epoch: 163 Average test loss: 958.3674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 164 [0/2589 (0%)]\tLoss: 348.195862\n",
      "Train Epoch: 164 [300/2589 (12%)]\tLoss: 293.778870\n",
      "Train Epoch: 164 [600/2589 (23%)]\tLoss: 215.245956\n",
      "Train Epoch: 164 [900/2589 (35%)]\tLoss: 257.500610\n",
      "Train Epoch: 164 [1200/2589 (46%)]\tLoss: 266.446625\n",
      "Train Epoch: 164 [1500/2589 (58%)]\tLoss: 271.837097\n",
      "Train Epoch: 164 [1800/2589 (70%)]\tLoss: 461.363342\n",
      "Train Epoch: 164 [2100/2589 (81%)]\tLoss: 402.411774\n",
      "Train Epoch: 164 [2400/2589 (93%)]\tLoss: 237.647888\n",
      "====> Epoch: 164 Average train loss: 282.3434\n",
      "====> Epoch: 164 Average test loss: 966.5026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 165 [0/2589 (0%)]\tLoss: 319.030853\n",
      "Train Epoch: 165 [300/2589 (12%)]\tLoss: 304.489044\n",
      "Train Epoch: 165 [600/2589 (23%)]\tLoss: 191.620422\n",
      "Train Epoch: 165 [900/2589 (35%)]\tLoss: 294.940765\n",
      "Train Epoch: 165 [1200/2589 (46%)]\tLoss: 258.564026\n",
      "Train Epoch: 165 [1500/2589 (58%)]\tLoss: 212.815491\n",
      "Train Epoch: 165 [1800/2589 (70%)]\tLoss: 462.671082\n",
      "Train Epoch: 165 [2100/2589 (81%)]\tLoss: 254.284637\n",
      "Train Epoch: 165 [2400/2589 (93%)]\tLoss: 372.254028\n",
      "====> Epoch: 165 Average train loss: 292.7350\n",
      "====> Epoch: 165 Average test loss: 958.5152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 166 [0/2589 (0%)]\tLoss: 365.095642\n",
      "Train Epoch: 166 [300/2589 (12%)]\tLoss: 336.775208\n",
      "Train Epoch: 166 [600/2589 (23%)]\tLoss: 392.900604\n",
      "Train Epoch: 166 [900/2589 (35%)]\tLoss: 395.888184\n",
      "Train Epoch: 166 [1200/2589 (46%)]\tLoss: 240.161087\n",
      "Train Epoch: 166 [1500/2589 (58%)]\tLoss: 513.519409\n",
      "Train Epoch: 166 [1800/2589 (70%)]\tLoss: 388.164032\n",
      "Train Epoch: 166 [2100/2589 (81%)]\tLoss: 257.369904\n",
      "Train Epoch: 166 [2400/2589 (93%)]\tLoss: 252.560150\n",
      "====> Epoch: 166 Average train loss: 301.5169\n",
      "====> Epoch: 166 Average test loss: 955.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 167 [0/2589 (0%)]\tLoss: 247.659393\n",
      "Train Epoch: 167 [300/2589 (12%)]\tLoss: 244.166046\n",
      "Train Epoch: 167 [600/2589 (23%)]\tLoss: 314.283295\n",
      "Train Epoch: 167 [900/2589 (35%)]\tLoss: 255.221619\n",
      "Train Epoch: 167 [1200/2589 (46%)]\tLoss: 277.149536\n",
      "Train Epoch: 167 [1500/2589 (58%)]\tLoss: 318.424011\n",
      "Train Epoch: 167 [1800/2589 (70%)]\tLoss: 252.186981\n",
      "Train Epoch: 167 [2100/2589 (81%)]\tLoss: 334.661804\n",
      "Train Epoch: 167 [2400/2589 (93%)]\tLoss: 325.009491\n",
      "====> Epoch: 167 Average train loss: 295.1907\n",
      "====> Epoch: 167 Average test loss: 978.9627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 168 [0/2589 (0%)]\tLoss: 314.689880\n",
      "Train Epoch: 168 [300/2589 (12%)]\tLoss: 329.968384\n",
      "Train Epoch: 168 [600/2589 (23%)]\tLoss: 242.553650\n",
      "Train Epoch: 168 [900/2589 (35%)]\tLoss: 219.970917\n",
      "Train Epoch: 168 [1200/2589 (46%)]\tLoss: 272.497772\n",
      "Train Epoch: 168 [1500/2589 (58%)]\tLoss: 282.971283\n",
      "Train Epoch: 168 [1800/2589 (70%)]\tLoss: 457.247864\n",
      "Train Epoch: 168 [2100/2589 (81%)]\tLoss: 265.731598\n",
      "Train Epoch: 168 [2400/2589 (93%)]\tLoss: 326.755859\n",
      "====> Epoch: 168 Average train loss: 302.0107\n",
      "====> Epoch: 168 Average test loss: 948.6024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 169 [0/2589 (0%)]\tLoss: 269.419861\n",
      "Train Epoch: 169 [300/2589 (12%)]\tLoss: 244.048096\n",
      "Train Epoch: 169 [600/2589 (23%)]\tLoss: 317.940582\n",
      "Train Epoch: 169 [900/2589 (35%)]\tLoss: 320.985840\n",
      "Train Epoch: 169 [1200/2589 (46%)]\tLoss: 347.778320\n",
      "Train Epoch: 169 [1500/2589 (58%)]\tLoss: 311.087799\n",
      "Train Epoch: 169 [1800/2589 (70%)]\tLoss: 243.460892\n",
      "Train Epoch: 169 [2100/2589 (81%)]\tLoss: 336.765137\n",
      "Train Epoch: 169 [2400/2589 (93%)]\tLoss: 325.428131\n",
      "====> Epoch: 169 Average train loss: 304.6606\n",
      "====> Epoch: 169 Average test loss: 939.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 170 [0/2589 (0%)]\tLoss: 325.619690\n",
      "Train Epoch: 170 [300/2589 (12%)]\tLoss: 211.792236\n",
      "Train Epoch: 170 [600/2589 (23%)]\tLoss: 452.898254\n",
      "Train Epoch: 170 [900/2589 (35%)]\tLoss: 264.985565\n",
      "Train Epoch: 170 [1200/2589 (46%)]\tLoss: 237.214218\n",
      "Train Epoch: 170 [1500/2589 (58%)]\tLoss: 269.697662\n",
      "Train Epoch: 170 [1800/2589 (70%)]\tLoss: 307.927765\n",
      "Train Epoch: 170 [2100/2589 (81%)]\tLoss: 228.472626\n",
      "Train Epoch: 170 [2400/2589 (93%)]\tLoss: 265.799011\n",
      "====> Epoch: 170 Average train loss: 308.3304\n",
      "====> Epoch: 170 Average test loss: 959.4663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 171 [0/2589 (0%)]\tLoss: 220.775330\n",
      "Train Epoch: 171 [300/2589 (12%)]\tLoss: 232.988693\n",
      "Train Epoch: 171 [600/2589 (23%)]\tLoss: 201.387314\n",
      "Train Epoch: 171 [900/2589 (35%)]\tLoss: 271.189636\n",
      "Train Epoch: 171 [1200/2589 (46%)]\tLoss: 314.333405\n",
      "Train Epoch: 171 [1500/2589 (58%)]\tLoss: 358.003418\n",
      "Train Epoch: 171 [1800/2589 (70%)]\tLoss: 262.123444\n",
      "Train Epoch: 171 [2100/2589 (81%)]\tLoss: 316.020325\n",
      "Train Epoch: 171 [2400/2589 (93%)]\tLoss: 295.362183\n",
      "====> Epoch: 171 Average train loss: 293.8205\n",
      "====> Epoch: 171 Average test loss: 959.4623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 172 [0/2589 (0%)]\tLoss: 288.364532\n",
      "Train Epoch: 172 [300/2589 (12%)]\tLoss: 270.746399\n",
      "Train Epoch: 172 [600/2589 (23%)]\tLoss: 391.751770\n",
      "Train Epoch: 172 [900/2589 (35%)]\tLoss: 292.225098\n",
      "Train Epoch: 172 [1200/2589 (46%)]\tLoss: 301.217682\n",
      "Train Epoch: 172 [1500/2589 (58%)]\tLoss: 180.437515\n",
      "Train Epoch: 172 [1800/2589 (70%)]\tLoss: 393.338348\n",
      "Train Epoch: 172 [2100/2589 (81%)]\tLoss: 251.828186\n",
      "Train Epoch: 172 [2400/2589 (93%)]\tLoss: 370.687469\n",
      "====> Epoch: 172 Average train loss: 299.9631\n",
      "====> Epoch: 172 Average test loss: 953.5529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 173 [0/2589 (0%)]\tLoss: 175.631287\n",
      "Train Epoch: 173 [300/2589 (12%)]\tLoss: 251.988678\n",
      "Train Epoch: 173 [600/2589 (23%)]\tLoss: 427.515533\n",
      "Train Epoch: 173 [900/2589 (35%)]\tLoss: 237.190750\n",
      "Train Epoch: 173 [1200/2589 (46%)]\tLoss: 257.512878\n",
      "Train Epoch: 173 [1500/2589 (58%)]\tLoss: 256.191742\n",
      "Train Epoch: 173 [1800/2589 (70%)]\tLoss: 258.508698\n",
      "Train Epoch: 173 [2100/2589 (81%)]\tLoss: 337.834534\n",
      "Train Epoch: 173 [2400/2589 (93%)]\tLoss: 373.818665\n",
      "====> Epoch: 173 Average train loss: 288.6295\n",
      "====> Epoch: 173 Average test loss: 965.6863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 174 [0/2589 (0%)]\tLoss: 223.649185\n",
      "Train Epoch: 174 [300/2589 (12%)]\tLoss: 230.262619\n",
      "Train Epoch: 174 [600/2589 (23%)]\tLoss: 278.710114\n",
      "Train Epoch: 174 [900/2589 (35%)]\tLoss: 385.686554\n",
      "Train Epoch: 174 [1200/2589 (46%)]\tLoss: 287.055756\n",
      "Train Epoch: 174 [1500/2589 (58%)]\tLoss: 270.301483\n",
      "Train Epoch: 174 [1800/2589 (70%)]\tLoss: 387.674896\n",
      "Train Epoch: 174 [2100/2589 (81%)]\tLoss: 216.230515\n",
      "Train Epoch: 174 [2400/2589 (93%)]\tLoss: 286.897095\n",
      "====> Epoch: 174 Average train loss: 297.1048\n",
      "====> Epoch: 174 Average test loss: 952.3953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 175 [0/2589 (0%)]\tLoss: 221.549103\n",
      "Train Epoch: 175 [300/2589 (12%)]\tLoss: 324.668488\n",
      "Train Epoch: 175 [600/2589 (23%)]\tLoss: 319.036804\n",
      "Train Epoch: 175 [900/2589 (35%)]\tLoss: 326.302063\n",
      "Train Epoch: 175 [1200/2589 (46%)]\tLoss: 280.993561\n",
      "Train Epoch: 175 [1500/2589 (58%)]\tLoss: 304.316467\n",
      "Train Epoch: 175 [1800/2589 (70%)]\tLoss: 320.737823\n",
      "Train Epoch: 175 [2100/2589 (81%)]\tLoss: 376.915039\n",
      "Train Epoch: 175 [2400/2589 (93%)]\tLoss: 299.245819\n",
      "====> Epoch: 175 Average train loss: 287.7318\n",
      "====> Epoch: 175 Average test loss: 958.2136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 176 [0/2589 (0%)]\tLoss: 257.054871\n",
      "Train Epoch: 176 [300/2589 (12%)]\tLoss: 315.235504\n",
      "Train Epoch: 176 [600/2589 (23%)]\tLoss: 372.723450\n",
      "Train Epoch: 176 [900/2589 (35%)]\tLoss: 301.150330\n",
      "Train Epoch: 176 [1200/2589 (46%)]\tLoss: 321.754944\n",
      "Train Epoch: 176 [1500/2589 (58%)]\tLoss: 253.559631\n",
      "Train Epoch: 176 [1800/2589 (70%)]\tLoss: 251.776993\n",
      "Train Epoch: 176 [2100/2589 (81%)]\tLoss: 350.374390\n",
      "Train Epoch: 176 [2400/2589 (93%)]\tLoss: 330.561005\n",
      "====> Epoch: 176 Average train loss: 296.0452\n",
      "====> Epoch: 176 Average test loss: 950.5170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 177 [0/2589 (0%)]\tLoss: 404.291992\n",
      "Train Epoch: 177 [300/2589 (12%)]\tLoss: 323.939392\n",
      "Train Epoch: 177 [600/2589 (23%)]\tLoss: 359.639526\n",
      "Train Epoch: 177 [900/2589 (35%)]\tLoss: 325.754364\n",
      "Train Epoch: 177 [1200/2589 (46%)]\tLoss: 308.824829\n",
      "Train Epoch: 177 [1500/2589 (58%)]\tLoss: 315.424408\n",
      "Train Epoch: 177 [1800/2589 (70%)]\tLoss: 271.928040\n",
      "Train Epoch: 177 [2100/2589 (81%)]\tLoss: 204.168854\n",
      "Train Epoch: 177 [2400/2589 (93%)]\tLoss: 266.629120\n",
      "====> Epoch: 177 Average train loss: 295.0491\n",
      "====> Epoch: 177 Average test loss: 949.3898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 178 [0/2589 (0%)]\tLoss: 248.279861\n",
      "Train Epoch: 178 [300/2589 (12%)]\tLoss: 310.898773\n",
      "Train Epoch: 178 [600/2589 (23%)]\tLoss: 218.645264\n",
      "Train Epoch: 178 [900/2589 (35%)]\tLoss: 268.441315\n",
      "Train Epoch: 178 [1200/2589 (46%)]\tLoss: 187.240921\n",
      "Train Epoch: 178 [1500/2589 (58%)]\tLoss: 445.751465\n",
      "Train Epoch: 178 [1800/2589 (70%)]\tLoss: 191.813309\n",
      "Train Epoch: 178 [2100/2589 (81%)]\tLoss: 259.184937\n",
      "Train Epoch: 178 [2400/2589 (93%)]\tLoss: 293.532196\n",
      "====> Epoch: 178 Average train loss: 295.3596\n",
      "====> Epoch: 178 Average test loss: 948.5417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 179 [0/2589 (0%)]\tLoss: 248.499557\n",
      "Train Epoch: 179 [300/2589 (12%)]\tLoss: 274.178314\n",
      "Train Epoch: 179 [600/2589 (23%)]\tLoss: 254.926315\n",
      "Train Epoch: 179 [900/2589 (35%)]\tLoss: 220.520172\n",
      "Train Epoch: 179 [1200/2589 (46%)]\tLoss: 323.223022\n",
      "Train Epoch: 179 [1500/2589 (58%)]\tLoss: 304.780212\n",
      "Train Epoch: 179 [1800/2589 (70%)]\tLoss: 324.372833\n",
      "Train Epoch: 179 [2100/2589 (81%)]\tLoss: 393.728180\n",
      "Train Epoch: 179 [2400/2589 (93%)]\tLoss: 438.264191\n",
      "====> Epoch: 179 Average train loss: 290.2683\n",
      "====> Epoch: 179 Average test loss: 931.3939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 180 [0/2589 (0%)]\tLoss: 196.207611\n",
      "Train Epoch: 180 [300/2589 (12%)]\tLoss: 265.519623\n",
      "Train Epoch: 180 [600/2589 (23%)]\tLoss: 313.003998\n",
      "Train Epoch: 180 [900/2589 (35%)]\tLoss: 287.828705\n",
      "Train Epoch: 180 [1200/2589 (46%)]\tLoss: 341.311462\n",
      "Train Epoch: 180 [1500/2589 (58%)]\tLoss: 250.035477\n",
      "Train Epoch: 180 [1800/2589 (70%)]\tLoss: 302.186462\n",
      "Train Epoch: 180 [2100/2589 (81%)]\tLoss: 260.247772\n",
      "Train Epoch: 180 [2400/2589 (93%)]\tLoss: 267.152405\n",
      "====> Epoch: 180 Average train loss: 289.1649\n",
      "====> Epoch: 180 Average test loss: 948.9381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181 [0/2589 (0%)]\tLoss: 322.895325\n",
      "Train Epoch: 181 [300/2589 (12%)]\tLoss: 215.409424\n",
      "Train Epoch: 181 [600/2589 (23%)]\tLoss: 285.749481\n",
      "Train Epoch: 181 [900/2589 (35%)]\tLoss: 247.562012\n",
      "Train Epoch: 181 [1200/2589 (46%)]\tLoss: 304.269043\n",
      "Train Epoch: 181 [1500/2589 (58%)]\tLoss: 210.803513\n",
      "Train Epoch: 181 [1800/2589 (70%)]\tLoss: 266.005524\n",
      "Train Epoch: 181 [2100/2589 (81%)]\tLoss: 246.729507\n",
      "Train Epoch: 181 [2400/2589 (93%)]\tLoss: 286.144562\n",
      "====> Epoch: 181 Average train loss: 278.7682\n",
      "====> Epoch: 181 Average test loss: 955.0710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 182 [0/2589 (0%)]\tLoss: 221.016190\n",
      "Train Epoch: 182 [300/2589 (12%)]\tLoss: 239.893524\n",
      "Train Epoch: 182 [600/2589 (23%)]\tLoss: 295.571686\n",
      "Train Epoch: 182 [900/2589 (35%)]\tLoss: 231.212585\n",
      "Train Epoch: 182 [1200/2589 (46%)]\tLoss: 166.389542\n",
      "Train Epoch: 182 [1500/2589 (58%)]\tLoss: 227.149658\n",
      "Train Epoch: 182 [1800/2589 (70%)]\tLoss: 259.360474\n",
      "Train Epoch: 182 [2100/2589 (81%)]\tLoss: 299.336395\n",
      "Train Epoch: 182 [2400/2589 (93%)]\tLoss: 354.368439\n",
      "====> Epoch: 182 Average train loss: 298.3679\n",
      "====> Epoch: 182 Average test loss: 967.7408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 183 [0/2589 (0%)]\tLoss: 228.090134\n",
      "Train Epoch: 183 [300/2589 (12%)]\tLoss: 242.619614\n",
      "Train Epoch: 183 [600/2589 (23%)]\tLoss: 301.167450\n",
      "Train Epoch: 183 [900/2589 (35%)]\tLoss: 238.881378\n",
      "Train Epoch: 183 [1200/2589 (46%)]\tLoss: 470.008514\n",
      "Train Epoch: 183 [1500/2589 (58%)]\tLoss: 342.030853\n",
      "Train Epoch: 183 [1800/2589 (70%)]\tLoss: 179.459824\n",
      "Train Epoch: 183 [2100/2589 (81%)]\tLoss: 399.124847\n",
      "Train Epoch: 183 [2400/2589 (93%)]\tLoss: 260.671295\n",
      "====> Epoch: 183 Average train loss: 293.7868\n",
      "====> Epoch: 183 Average test loss: 940.5209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 184 [0/2589 (0%)]\tLoss: 227.744827\n",
      "Train Epoch: 184 [300/2589 (12%)]\tLoss: 313.766296\n",
      "Train Epoch: 184 [600/2589 (23%)]\tLoss: 318.499878\n",
      "Train Epoch: 184 [900/2589 (35%)]\tLoss: 340.801605\n",
      "Train Epoch: 184 [1200/2589 (46%)]\tLoss: 374.733826\n",
      "Train Epoch: 184 [1500/2589 (58%)]\tLoss: 288.294434\n",
      "Train Epoch: 184 [1800/2589 (70%)]\tLoss: 338.170258\n",
      "Train Epoch: 184 [2100/2589 (81%)]\tLoss: 260.611145\n",
      "Train Epoch: 184 [2400/2589 (93%)]\tLoss: 295.410706\n",
      "====> Epoch: 184 Average train loss: 287.4435\n",
      "====> Epoch: 184 Average test loss: 959.6196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 185 [0/2589 (0%)]\tLoss: 241.610336\n",
      "Train Epoch: 185 [300/2589 (12%)]\tLoss: 313.572235\n",
      "Train Epoch: 185 [600/2589 (23%)]\tLoss: 316.286957\n",
      "Train Epoch: 185 [900/2589 (35%)]\tLoss: 269.143158\n",
      "Train Epoch: 185 [1200/2589 (46%)]\tLoss: 201.189926\n",
      "Train Epoch: 185 [1500/2589 (58%)]\tLoss: 238.089096\n",
      "Train Epoch: 185 [1800/2589 (70%)]\tLoss: 248.863174\n",
      "Train Epoch: 185 [2100/2589 (81%)]\tLoss: 475.568390\n",
      "Train Epoch: 185 [2400/2589 (93%)]\tLoss: 371.936340\n",
      "====> Epoch: 185 Average train loss: 289.3261\n",
      "====> Epoch: 185 Average test loss: 937.6472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 186 [0/2589 (0%)]\tLoss: 315.810852\n",
      "Train Epoch: 186 [300/2589 (12%)]\tLoss: 236.739929\n",
      "Train Epoch: 186 [600/2589 (23%)]\tLoss: 259.917633\n",
      "Train Epoch: 186 [900/2589 (35%)]\tLoss: 271.525238\n",
      "Train Epoch: 186 [1200/2589 (46%)]\tLoss: 286.948883\n",
      "Train Epoch: 186 [1500/2589 (58%)]\tLoss: 347.303009\n",
      "Train Epoch: 186 [1800/2589 (70%)]\tLoss: 333.766174\n",
      "Train Epoch: 186 [2100/2589 (81%)]\tLoss: 288.783356\n",
      "Train Epoch: 186 [2400/2589 (93%)]\tLoss: 233.111725\n",
      "====> Epoch: 186 Average train loss: 291.3074\n",
      "====> Epoch: 186 Average test loss: 976.1365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 187 [0/2589 (0%)]\tLoss: 264.264069\n",
      "Train Epoch: 187 [300/2589 (12%)]\tLoss: 240.024597\n",
      "Train Epoch: 187 [600/2589 (23%)]\tLoss: 252.842865\n",
      "Train Epoch: 187 [900/2589 (35%)]\tLoss: 301.756226\n",
      "Train Epoch: 187 [1200/2589 (46%)]\tLoss: 275.153809\n",
      "Train Epoch: 187 [1500/2589 (58%)]\tLoss: 253.156647\n",
      "Train Epoch: 187 [1800/2589 (70%)]\tLoss: 346.027039\n",
      "Train Epoch: 187 [2100/2589 (81%)]\tLoss: 261.297089\n",
      "Train Epoch: 187 [2400/2589 (93%)]\tLoss: 294.910950\n",
      "====> Epoch: 187 Average train loss: 281.7763\n",
      "====> Epoch: 187 Average test loss: 954.8184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 188 [0/2589 (0%)]\tLoss: 194.428391\n",
      "Train Epoch: 188 [300/2589 (12%)]\tLoss: 244.827911\n",
      "Train Epoch: 188 [600/2589 (23%)]\tLoss: 295.702026\n",
      "Train Epoch: 188 [900/2589 (35%)]\tLoss: 295.274231\n",
      "Train Epoch: 188 [1200/2589 (46%)]\tLoss: 274.119415\n",
      "Train Epoch: 188 [1500/2589 (58%)]\tLoss: 298.597870\n",
      "Train Epoch: 188 [1800/2589 (70%)]\tLoss: 240.046417\n",
      "Train Epoch: 188 [2100/2589 (81%)]\tLoss: 352.797333\n",
      "Train Epoch: 188 [2400/2589 (93%)]\tLoss: 352.588806\n",
      "====> Epoch: 188 Average train loss: 291.9143\n",
      "====> Epoch: 188 Average test loss: 950.1817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 189 [0/2589 (0%)]\tLoss: 213.303650\n",
      "Train Epoch: 189 [300/2589 (12%)]\tLoss: 256.962830\n",
      "Train Epoch: 189 [600/2589 (23%)]\tLoss: 263.301941\n",
      "Train Epoch: 189 [900/2589 (35%)]\tLoss: 283.014709\n",
      "Train Epoch: 189 [1200/2589 (46%)]\tLoss: 228.742844\n",
      "Train Epoch: 189 [1500/2589 (58%)]\tLoss: 385.896942\n",
      "Train Epoch: 189 [1800/2589 (70%)]\tLoss: 212.246613\n",
      "Train Epoch: 189 [2100/2589 (81%)]\tLoss: 316.306458\n",
      "Train Epoch: 189 [2400/2589 (93%)]\tLoss: 220.260712\n",
      "====> Epoch: 189 Average train loss: 289.9069\n",
      "====> Epoch: 189 Average test loss: 926.9161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 190 [0/2589 (0%)]\tLoss: 288.215607\n",
      "Train Epoch: 190 [300/2589 (12%)]\tLoss: 364.063965\n",
      "Train Epoch: 190 [600/2589 (23%)]\tLoss: 288.874115\n",
      "Train Epoch: 190 [900/2589 (35%)]\tLoss: 314.707703\n",
      "Train Epoch: 190 [1200/2589 (46%)]\tLoss: 354.455383\n",
      "Train Epoch: 190 [1500/2589 (58%)]\tLoss: 175.325851\n",
      "Train Epoch: 190 [1800/2589 (70%)]\tLoss: 281.789734\n",
      "Train Epoch: 190 [2100/2589 (81%)]\tLoss: 303.661316\n",
      "Train Epoch: 190 [2400/2589 (93%)]\tLoss: 257.351593\n",
      "====> Epoch: 190 Average train loss: 294.9245\n",
      "====> Epoch: 190 Average test loss: 958.0129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 191 [0/2589 (0%)]\tLoss: 314.360443\n",
      "Train Epoch: 191 [300/2589 (12%)]\tLoss: 221.615982\n",
      "Train Epoch: 191 [600/2589 (23%)]\tLoss: 588.824646\n",
      "Train Epoch: 191 [900/2589 (35%)]\tLoss: 289.614594\n",
      "Train Epoch: 191 [1200/2589 (46%)]\tLoss: 253.706039\n",
      "Train Epoch: 191 [1500/2589 (58%)]\tLoss: 303.913086\n",
      "Train Epoch: 191 [1800/2589 (70%)]\tLoss: 242.582626\n",
      "Train Epoch: 191 [2100/2589 (81%)]\tLoss: 386.713745\n",
      "Train Epoch: 191 [2400/2589 (93%)]\tLoss: 297.345703\n",
      "====> Epoch: 191 Average train loss: 285.8623\n",
      "====> Epoch: 191 Average test loss: 938.1819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 192 [0/2589 (0%)]\tLoss: 199.406540\n",
      "Train Epoch: 192 [300/2589 (12%)]\tLoss: 280.438843\n",
      "Train Epoch: 192 [600/2589 (23%)]\tLoss: 211.465302\n",
      "Train Epoch: 192 [900/2589 (35%)]\tLoss: 209.100693\n",
      "Train Epoch: 192 [1200/2589 (46%)]\tLoss: 272.988922\n",
      "Train Epoch: 192 [1500/2589 (58%)]\tLoss: 415.046478\n",
      "Train Epoch: 192 [1800/2589 (70%)]\tLoss: 350.085358\n",
      "Train Epoch: 192 [2100/2589 (81%)]\tLoss: 264.449097\n",
      "Train Epoch: 192 [2400/2589 (93%)]\tLoss: 201.135284\n",
      "====> Epoch: 192 Average train loss: 287.0969\n",
      "====> Epoch: 192 Average test loss: 986.2358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 193 [0/2589 (0%)]\tLoss: 212.320053\n",
      "Train Epoch: 193 [300/2589 (12%)]\tLoss: 373.498901\n",
      "Train Epoch: 193 [600/2589 (23%)]\tLoss: 261.984467\n",
      "Train Epoch: 193 [900/2589 (35%)]\tLoss: 312.239075\n",
      "Train Epoch: 193 [1200/2589 (46%)]\tLoss: 235.676529\n",
      "Train Epoch: 193 [1500/2589 (58%)]\tLoss: 325.241028\n",
      "Train Epoch: 193 [1800/2589 (70%)]\tLoss: 350.665161\n",
      "Train Epoch: 193 [2100/2589 (81%)]\tLoss: 305.423859\n",
      "Train Epoch: 193 [2400/2589 (93%)]\tLoss: 340.454132\n",
      "====> Epoch: 193 Average train loss: 293.5056\n",
      "====> Epoch: 193 Average test loss: 947.2255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 194 [0/2589 (0%)]\tLoss: 277.539246\n",
      "Train Epoch: 194 [300/2589 (12%)]\tLoss: 241.523926\n",
      "Train Epoch: 194 [600/2589 (23%)]\tLoss: 258.112030\n",
      "Train Epoch: 194 [900/2589 (35%)]\tLoss: 287.875183\n",
      "Train Epoch: 194 [1200/2589 (46%)]\tLoss: 211.298050\n",
      "Train Epoch: 194 [1500/2589 (58%)]\tLoss: 296.029327\n",
      "Train Epoch: 194 [1800/2589 (70%)]\tLoss: 227.023453\n",
      "Train Epoch: 194 [2100/2589 (81%)]\tLoss: 225.928772\n",
      "Train Epoch: 194 [2400/2589 (93%)]\tLoss: 241.137726\n",
      "====> Epoch: 194 Average train loss: 278.7362\n",
      "====> Epoch: 194 Average test loss: 954.2830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 195 [0/2589 (0%)]\tLoss: 273.734253\n",
      "Train Epoch: 195 [300/2589 (12%)]\tLoss: 296.269592\n",
      "Train Epoch: 195 [600/2589 (23%)]\tLoss: 246.888275\n",
      "Train Epoch: 195 [900/2589 (35%)]\tLoss: 432.073547\n",
      "Train Epoch: 195 [1200/2589 (46%)]\tLoss: 207.211884\n",
      "Train Epoch: 195 [1500/2589 (58%)]\tLoss: 286.653961\n",
      "Train Epoch: 195 [1800/2589 (70%)]\tLoss: 221.157578\n",
      "Train Epoch: 195 [2100/2589 (81%)]\tLoss: 245.665253\n",
      "Train Epoch: 195 [2400/2589 (93%)]\tLoss: 265.530853\n",
      "====> Epoch: 195 Average train loss: 291.1597\n",
      "====> Epoch: 195 Average test loss: 965.3250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 196 [0/2589 (0%)]\tLoss: 217.946930\n",
      "Train Epoch: 196 [300/2589 (12%)]\tLoss: 326.390900\n",
      "Train Epoch: 196 [600/2589 (23%)]\tLoss: 219.510422\n",
      "Train Epoch: 196 [900/2589 (35%)]\tLoss: 417.509003\n",
      "Train Epoch: 196 [1200/2589 (46%)]\tLoss: 320.565796\n",
      "Train Epoch: 196 [1500/2589 (58%)]\tLoss: 260.507538\n",
      "Train Epoch: 196 [1800/2589 (70%)]\tLoss: 343.948853\n",
      "Train Epoch: 196 [2100/2589 (81%)]\tLoss: 355.298035\n",
      "Train Epoch: 196 [2400/2589 (93%)]\tLoss: 392.000214\n",
      "====> Epoch: 196 Average train loss: 286.5055\n",
      "====> Epoch: 196 Average test loss: 954.8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 197 [0/2589 (0%)]\tLoss: 267.191437\n",
      "Train Epoch: 197 [300/2589 (12%)]\tLoss: 312.838684\n",
      "Train Epoch: 197 [600/2589 (23%)]\tLoss: 343.446808\n",
      "Train Epoch: 197 [900/2589 (35%)]\tLoss: 309.458649\n",
      "Train Epoch: 197 [1200/2589 (46%)]\tLoss: 301.882294\n",
      "Train Epoch: 197 [1500/2589 (58%)]\tLoss: 195.716476\n",
      "Train Epoch: 197 [1800/2589 (70%)]\tLoss: 154.876144\n",
      "Train Epoch: 197 [2100/2589 (81%)]\tLoss: 270.969635\n",
      "Train Epoch: 197 [2400/2589 (93%)]\tLoss: 261.238983\n",
      "====> Epoch: 197 Average train loss: 288.3584\n",
      "====> Epoch: 197 Average test loss: 948.9534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 198 [0/2589 (0%)]\tLoss: 263.187469\n",
      "Train Epoch: 198 [300/2589 (12%)]\tLoss: 267.415802\n",
      "Train Epoch: 198 [600/2589 (23%)]\tLoss: 383.326569\n",
      "Train Epoch: 198 [900/2589 (35%)]\tLoss: 238.026520\n",
      "Train Epoch: 198 [1200/2589 (46%)]\tLoss: 264.297302\n",
      "Train Epoch: 198 [1500/2589 (58%)]\tLoss: 259.852539\n",
      "Train Epoch: 198 [1800/2589 (70%)]\tLoss: 286.223053\n",
      "Train Epoch: 198 [2100/2589 (81%)]\tLoss: 226.921158\n",
      "Train Epoch: 198 [2400/2589 (93%)]\tLoss: 340.064362\n",
      "====> Epoch: 198 Average train loss: 279.1180\n",
      "====> Epoch: 198 Average test loss: 973.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 199 [0/2589 (0%)]\tLoss: 248.664246\n",
      "Train Epoch: 199 [300/2589 (12%)]\tLoss: 285.570129\n",
      "Train Epoch: 199 [600/2589 (23%)]\tLoss: 237.786484\n",
      "Train Epoch: 199 [900/2589 (35%)]\tLoss: 283.206909\n",
      "Train Epoch: 199 [1200/2589 (46%)]\tLoss: 226.645859\n",
      "Train Epoch: 199 [1500/2589 (58%)]\tLoss: 289.032562\n",
      "Train Epoch: 199 [1800/2589 (70%)]\tLoss: 239.986618\n",
      "Train Epoch: 199 [2100/2589 (81%)]\tLoss: 265.882935\n",
      "Train Epoch: 199 [2400/2589 (93%)]\tLoss: 274.600739\n",
      "====> Epoch: 199 Average train loss: 281.2591\n",
      "====> Epoch: 199 Average test loss: 952.5858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 200 [0/2589 (0%)]\tLoss: 216.661377\n",
      "Train Epoch: 200 [300/2589 (12%)]\tLoss: 419.977264\n",
      "Train Epoch: 200 [600/2589 (23%)]\tLoss: 205.633133\n",
      "Train Epoch: 200 [900/2589 (35%)]\tLoss: 254.591034\n",
      "Train Epoch: 200 [1200/2589 (46%)]\tLoss: 220.217133\n",
      "Train Epoch: 200 [1500/2589 (58%)]\tLoss: 306.606995\n",
      "Train Epoch: 200 [1800/2589 (70%)]\tLoss: 284.388947\n",
      "Train Epoch: 200 [2100/2589 (81%)]\tLoss: 325.449219\n",
      "Train Epoch: 200 [2400/2589 (93%)]\tLoss: 217.714005\n",
      "====> Epoch: 200 Average train loss: 277.3325\n",
      "====> Epoch: 200 Average test loss: 962.5599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 201 [0/2589 (0%)]\tLoss: 307.321350\n",
      "Train Epoch: 201 [300/2589 (12%)]\tLoss: 390.546478\n",
      "Train Epoch: 201 [600/2589 (23%)]\tLoss: 271.325470\n",
      "Train Epoch: 201 [900/2589 (35%)]\tLoss: 210.923660\n",
      "Train Epoch: 201 [1200/2589 (46%)]\tLoss: 205.743484\n",
      "Train Epoch: 201 [1500/2589 (58%)]\tLoss: 282.767181\n",
      "Train Epoch: 201 [1800/2589 (70%)]\tLoss: 315.500214\n",
      "Train Epoch: 201 [2100/2589 (81%)]\tLoss: 253.393509\n",
      "Train Epoch: 201 [2400/2589 (93%)]\tLoss: 437.091949\n",
      "====> Epoch: 201 Average train loss: 288.7359\n",
      "====> Epoch: 201 Average test loss: 949.5732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 202 [0/2589 (0%)]\tLoss: 223.859406\n",
      "Train Epoch: 202 [300/2589 (12%)]\tLoss: 335.843414\n",
      "Train Epoch: 202 [600/2589 (23%)]\tLoss: 497.150482\n",
      "Train Epoch: 202 [900/2589 (35%)]\tLoss: 289.146881\n",
      "Train Epoch: 202 [1200/2589 (46%)]\tLoss: 270.964508\n",
      "Train Epoch: 202 [1500/2589 (58%)]\tLoss: 298.309509\n",
      "Train Epoch: 202 [1800/2589 (70%)]\tLoss: 182.120544\n",
      "Train Epoch: 202 [2100/2589 (81%)]\tLoss: 279.383240\n",
      "Train Epoch: 202 [2400/2589 (93%)]\tLoss: 334.069031\n",
      "====> Epoch: 202 Average train loss: 282.6682\n",
      "====> Epoch: 202 Average test loss: 951.7338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 203 [0/2589 (0%)]\tLoss: 298.644836\n",
      "Train Epoch: 203 [300/2589 (12%)]\tLoss: 463.187469\n",
      "Train Epoch: 203 [600/2589 (23%)]\tLoss: 229.218521\n",
      "Train Epoch: 203 [900/2589 (35%)]\tLoss: 263.946167\n",
      "Train Epoch: 203 [1200/2589 (46%)]\tLoss: 196.263107\n",
      "Train Epoch: 203 [1500/2589 (58%)]\tLoss: 356.706451\n",
      "Train Epoch: 203 [1800/2589 (70%)]\tLoss: 285.504395\n",
      "Train Epoch: 203 [2100/2589 (81%)]\tLoss: 277.682648\n",
      "Train Epoch: 203 [2400/2589 (93%)]\tLoss: 428.458679\n",
      "====> Epoch: 203 Average train loss: 296.2076\n",
      "====> Epoch: 203 Average test loss: 948.2977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 204 [0/2589 (0%)]\tLoss: 256.924408\n",
      "Train Epoch: 204 [300/2589 (12%)]\tLoss: 240.428848\n",
      "Train Epoch: 204 [600/2589 (23%)]\tLoss: 358.177826\n",
      "Train Epoch: 204 [900/2589 (35%)]\tLoss: 332.831085\n",
      "Train Epoch: 204 [1200/2589 (46%)]\tLoss: 305.989471\n",
      "Train Epoch: 204 [1500/2589 (58%)]\tLoss: 239.443634\n",
      "Train Epoch: 204 [1800/2589 (70%)]\tLoss: 255.039627\n",
      "Train Epoch: 204 [2100/2589 (81%)]\tLoss: 281.160767\n",
      "Train Epoch: 204 [2400/2589 (93%)]\tLoss: 268.224152\n",
      "====> Epoch: 204 Average train loss: 282.1770\n",
      "====> Epoch: 204 Average test loss: 932.2148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 205 [0/2589 (0%)]\tLoss: 324.393066\n",
      "Train Epoch: 205 [300/2589 (12%)]\tLoss: 483.037567\n",
      "Train Epoch: 205 [600/2589 (23%)]\tLoss: 273.792694\n",
      "Train Epoch: 205 [900/2589 (35%)]\tLoss: 400.688446\n",
      "Train Epoch: 205 [1200/2589 (46%)]\tLoss: 369.727112\n",
      "Train Epoch: 205 [1500/2589 (58%)]\tLoss: 335.174683\n",
      "Train Epoch: 205 [1800/2589 (70%)]\tLoss: 223.213104\n",
      "Train Epoch: 205 [2100/2589 (81%)]\tLoss: 253.428055\n",
      "Train Epoch: 205 [2400/2589 (93%)]\tLoss: 300.696350\n",
      "====> Epoch: 205 Average train loss: 297.6444\n",
      "====> Epoch: 205 Average test loss: 943.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 206 [0/2589 (0%)]\tLoss: 296.737823\n",
      "Train Epoch: 206 [300/2589 (12%)]\tLoss: 302.354004\n",
      "Train Epoch: 206 [600/2589 (23%)]\tLoss: 340.116333\n",
      "Train Epoch: 206 [900/2589 (35%)]\tLoss: 440.200806\n",
      "Train Epoch: 206 [1200/2589 (46%)]\tLoss: 200.729294\n",
      "Train Epoch: 206 [1500/2589 (58%)]\tLoss: 242.328156\n",
      "Train Epoch: 206 [1800/2589 (70%)]\tLoss: 231.562790\n",
      "Train Epoch: 206 [2100/2589 (81%)]\tLoss: 191.847427\n",
      "Train Epoch: 206 [2400/2589 (93%)]\tLoss: 329.063080\n",
      "====> Epoch: 206 Average train loss: 274.8850\n",
      "====> Epoch: 206 Average test loss: 951.4783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 207 [0/2589 (0%)]\tLoss: 183.600540\n",
      "Train Epoch: 207 [300/2589 (12%)]\tLoss: 324.014954\n",
      "Train Epoch: 207 [600/2589 (23%)]\tLoss: 301.119904\n",
      "Train Epoch: 207 [900/2589 (35%)]\tLoss: 221.520859\n",
      "Train Epoch: 207 [1200/2589 (46%)]\tLoss: 449.490051\n",
      "Train Epoch: 207 [1500/2589 (58%)]\tLoss: 292.544525\n",
      "Train Epoch: 207 [1800/2589 (70%)]\tLoss: 312.101135\n",
      "Train Epoch: 207 [2100/2589 (81%)]\tLoss: 224.242249\n",
      "Train Epoch: 207 [2400/2589 (93%)]\tLoss: 214.830795\n",
      "====> Epoch: 207 Average train loss: 284.7482\n",
      "====> Epoch: 207 Average test loss: 957.3763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 208 [0/2589 (0%)]\tLoss: 210.936951\n",
      "Train Epoch: 208 [300/2589 (12%)]\tLoss: 218.645676\n",
      "Train Epoch: 208 [600/2589 (23%)]\tLoss: 223.422668\n",
      "Train Epoch: 208 [900/2589 (35%)]\tLoss: 265.359741\n",
      "Train Epoch: 208 [1200/2589 (46%)]\tLoss: 262.385040\n",
      "Train Epoch: 208 [1500/2589 (58%)]\tLoss: 529.537231\n",
      "Train Epoch: 208 [1800/2589 (70%)]\tLoss: 359.194397\n",
      "Train Epoch: 208 [2100/2589 (81%)]\tLoss: 381.391602\n",
      "Train Epoch: 208 [2400/2589 (93%)]\tLoss: 326.292908\n",
      "====> Epoch: 208 Average train loss: 279.4568\n",
      "====> Epoch: 208 Average test loss: 945.2461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 209 [0/2589 (0%)]\tLoss: 284.292267\n",
      "Train Epoch: 209 [300/2589 (12%)]\tLoss: 229.370804\n",
      "Train Epoch: 209 [600/2589 (23%)]\tLoss: 296.640503\n",
      "Train Epoch: 209 [900/2589 (35%)]\tLoss: 204.448456\n",
      "Train Epoch: 209 [1200/2589 (46%)]\tLoss: 283.330627\n",
      "Train Epoch: 209 [1500/2589 (58%)]\tLoss: 324.016479\n",
      "Train Epoch: 209 [1800/2589 (70%)]\tLoss: 392.491882\n",
      "Train Epoch: 209 [2100/2589 (81%)]\tLoss: 394.374664\n",
      "Train Epoch: 209 [2400/2589 (93%)]\tLoss: 329.722504\n",
      "====> Epoch: 209 Average train loss: 299.6629\n",
      "====> Epoch: 209 Average test loss: 979.5190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 210 [0/2589 (0%)]\tLoss: 186.950714\n",
      "Train Epoch: 210 [300/2589 (12%)]\tLoss: 222.946869\n",
      "Train Epoch: 210 [600/2589 (23%)]\tLoss: 174.124161\n",
      "Train Epoch: 210 [900/2589 (35%)]\tLoss: 246.285553\n",
      "Train Epoch: 210 [1200/2589 (46%)]\tLoss: 277.934174\n",
      "Train Epoch: 210 [1500/2589 (58%)]\tLoss: 280.586487\n",
      "Train Epoch: 210 [1800/2589 (70%)]\tLoss: 256.037750\n",
      "Train Epoch: 210 [2100/2589 (81%)]\tLoss: 305.881073\n",
      "Train Epoch: 210 [2400/2589 (93%)]\tLoss: 206.863617\n",
      "====> Epoch: 210 Average train loss: 279.2535\n",
      "====> Epoch: 210 Average test loss: 954.4168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 211 [0/2589 (0%)]\tLoss: 216.761246\n",
      "Train Epoch: 211 [300/2589 (12%)]\tLoss: 429.292114\n",
      "Train Epoch: 211 [600/2589 (23%)]\tLoss: 254.404007\n",
      "Train Epoch: 211 [900/2589 (35%)]\tLoss: 343.986450\n",
      "Train Epoch: 211 [1200/2589 (46%)]\tLoss: 426.852356\n",
      "Train Epoch: 211 [1500/2589 (58%)]\tLoss: 343.061829\n",
      "Train Epoch: 211 [1800/2589 (70%)]\tLoss: 294.336304\n",
      "Train Epoch: 211 [2100/2589 (81%)]\tLoss: 258.040100\n",
      "Train Epoch: 211 [2400/2589 (93%)]\tLoss: 338.251587\n",
      "====> Epoch: 211 Average train loss: 286.8362\n",
      "====> Epoch: 211 Average test loss: 957.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 212 [0/2589 (0%)]\tLoss: 160.205612\n",
      "Train Epoch: 212 [300/2589 (12%)]\tLoss: 297.654297\n",
      "Train Epoch: 212 [600/2589 (23%)]\tLoss: 305.619812\n",
      "Train Epoch: 212 [900/2589 (35%)]\tLoss: 255.084946\n",
      "Train Epoch: 212 [1200/2589 (46%)]\tLoss: 308.597992\n",
      "Train Epoch: 212 [1500/2589 (58%)]\tLoss: 266.415924\n",
      "Train Epoch: 212 [1800/2589 (70%)]\tLoss: 264.323334\n",
      "Train Epoch: 212 [2100/2589 (81%)]\tLoss: 237.931671\n",
      "Train Epoch: 212 [2400/2589 (93%)]\tLoss: 434.719940\n",
      "====> Epoch: 212 Average train loss: 282.1609\n",
      "====> Epoch: 212 Average test loss: 956.1771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 213 [0/2589 (0%)]\tLoss: 198.539612\n",
      "Train Epoch: 213 [300/2589 (12%)]\tLoss: 263.908569\n",
      "Train Epoch: 213 [600/2589 (23%)]\tLoss: 540.262817\n",
      "Train Epoch: 213 [900/2589 (35%)]\tLoss: 189.849609\n",
      "Train Epoch: 213 [1200/2589 (46%)]\tLoss: 235.437042\n",
      "Train Epoch: 213 [1500/2589 (58%)]\tLoss: 249.696152\n",
      "Train Epoch: 213 [1800/2589 (70%)]\tLoss: 195.595184\n",
      "Train Epoch: 213 [2100/2589 (81%)]\tLoss: 308.688324\n",
      "Train Epoch: 213 [2400/2589 (93%)]\tLoss: 211.753693\n",
      "====> Epoch: 213 Average train loss: 283.0846\n",
      "====> Epoch: 213 Average test loss: 956.3666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 214 [0/2589 (0%)]\tLoss: 293.632355\n",
      "Train Epoch: 214 [300/2589 (12%)]\tLoss: 297.430145\n",
      "Train Epoch: 214 [600/2589 (23%)]\tLoss: 289.466583\n",
      "Train Epoch: 214 [900/2589 (35%)]\tLoss: 236.519562\n",
      "Train Epoch: 214 [1200/2589 (46%)]\tLoss: 220.228195\n",
      "Train Epoch: 214 [1500/2589 (58%)]\tLoss: 295.376404\n",
      "Train Epoch: 214 [1800/2589 (70%)]\tLoss: 276.003754\n",
      "Train Epoch: 214 [2100/2589 (81%)]\tLoss: 264.498230\n",
      "Train Epoch: 214 [2400/2589 (93%)]\tLoss: 314.633636\n",
      "====> Epoch: 214 Average train loss: 283.1988\n",
      "====> Epoch: 214 Average test loss: 953.8370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 215 [0/2589 (0%)]\tLoss: 239.253174\n",
      "Train Epoch: 215 [300/2589 (12%)]\tLoss: 218.015137\n",
      "Train Epoch: 215 [600/2589 (23%)]\tLoss: 275.291412\n",
      "Train Epoch: 215 [900/2589 (35%)]\tLoss: 455.240540\n",
      "Train Epoch: 215 [1200/2589 (46%)]\tLoss: 249.612335\n",
      "Train Epoch: 215 [1500/2589 (58%)]\tLoss: 221.739349\n",
      "Train Epoch: 215 [1800/2589 (70%)]\tLoss: 508.838531\n",
      "Train Epoch: 215 [2100/2589 (81%)]\tLoss: 203.336044\n",
      "Train Epoch: 215 [2400/2589 (93%)]\tLoss: 287.497986\n",
      "====> Epoch: 215 Average train loss: 283.4595\n",
      "====> Epoch: 215 Average test loss: 947.8553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 216 [0/2589 (0%)]\tLoss: 274.758331\n",
      "Train Epoch: 216 [300/2589 (12%)]\tLoss: 392.616608\n",
      "Train Epoch: 216 [600/2589 (23%)]\tLoss: 304.699707\n",
      "Train Epoch: 216 [900/2589 (35%)]\tLoss: 332.632324\n",
      "Train Epoch: 216 [1200/2589 (46%)]\tLoss: 270.986847\n",
      "Train Epoch: 216 [1500/2589 (58%)]\tLoss: 236.456146\n",
      "Train Epoch: 216 [1800/2589 (70%)]\tLoss: 288.603790\n",
      "Train Epoch: 216 [2100/2589 (81%)]\tLoss: 247.198425\n",
      "Train Epoch: 216 [2400/2589 (93%)]\tLoss: 225.283630\n",
      "====> Epoch: 216 Average train loss: 281.8930\n",
      "====> Epoch: 216 Average test loss: 948.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 217 [0/2589 (0%)]\tLoss: 245.383133\n",
      "Train Epoch: 217 [300/2589 (12%)]\tLoss: 231.574997\n",
      "Train Epoch: 217 [600/2589 (23%)]\tLoss: 271.894958\n",
      "Train Epoch: 217 [900/2589 (35%)]\tLoss: 170.459442\n",
      "Train Epoch: 217 [1200/2589 (46%)]\tLoss: 332.139008\n",
      "Train Epoch: 217 [1500/2589 (58%)]\tLoss: 298.537170\n",
      "Train Epoch: 217 [1800/2589 (70%)]\tLoss: 351.155823\n",
      "Train Epoch: 217 [2100/2589 (81%)]\tLoss: 225.831833\n",
      "Train Epoch: 217 [2400/2589 (93%)]\tLoss: 284.908722\n",
      "====> Epoch: 217 Average train loss: 277.1074\n",
      "====> Epoch: 217 Average test loss: 945.3123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 218 [0/2589 (0%)]\tLoss: 305.289734\n",
      "Train Epoch: 218 [300/2589 (12%)]\tLoss: 231.113571\n",
      "Train Epoch: 218 [600/2589 (23%)]\tLoss: 287.257843\n",
      "Train Epoch: 218 [900/2589 (35%)]\tLoss: 263.404236\n",
      "Train Epoch: 218 [1200/2589 (46%)]\tLoss: 188.949524\n",
      "Train Epoch: 218 [1500/2589 (58%)]\tLoss: 288.198639\n",
      "Train Epoch: 218 [1800/2589 (70%)]\tLoss: 392.477844\n",
      "Train Epoch: 218 [2100/2589 (81%)]\tLoss: 258.383453\n",
      "Train Epoch: 218 [2400/2589 (93%)]\tLoss: 281.386353\n",
      "====> Epoch: 218 Average train loss: 286.6068\n",
      "====> Epoch: 218 Average test loss: 956.5764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 219 [0/2589 (0%)]\tLoss: 283.227142\n",
      "Train Epoch: 219 [300/2589 (12%)]\tLoss: 268.967438\n",
      "Train Epoch: 219 [600/2589 (23%)]\tLoss: 396.702301\n",
      "Train Epoch: 219 [900/2589 (35%)]\tLoss: 247.216049\n",
      "Train Epoch: 219 [1200/2589 (46%)]\tLoss: 309.634796\n",
      "Train Epoch: 219 [1500/2589 (58%)]\tLoss: 296.617615\n",
      "Train Epoch: 219 [1800/2589 (70%)]\tLoss: 400.675507\n",
      "Train Epoch: 219 [2100/2589 (81%)]\tLoss: 307.259857\n",
      "Train Epoch: 219 [2400/2589 (93%)]\tLoss: 326.203766\n",
      "====> Epoch: 219 Average train loss: 287.3362\n",
      "====> Epoch: 219 Average test loss: 962.5220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 220 [0/2589 (0%)]\tLoss: 343.225708\n",
      "Train Epoch: 220 [300/2589 (12%)]\tLoss: 244.499695\n",
      "Train Epoch: 220 [600/2589 (23%)]\tLoss: 217.065659\n",
      "Train Epoch: 220 [900/2589 (35%)]\tLoss: 207.666733\n",
      "Train Epoch: 220 [1200/2589 (46%)]\tLoss: 244.840591\n",
      "Train Epoch: 220 [1500/2589 (58%)]\tLoss: 244.145248\n",
      "Train Epoch: 220 [1800/2589 (70%)]\tLoss: 422.342255\n",
      "Train Epoch: 220 [2100/2589 (81%)]\tLoss: 321.033661\n",
      "Train Epoch: 220 [2400/2589 (93%)]\tLoss: 304.181946\n",
      "====> Epoch: 220 Average train loss: 280.0851\n",
      "====> Epoch: 220 Average test loss: 949.6780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 221 [0/2589 (0%)]\tLoss: 289.393097\n",
      "Train Epoch: 221 [300/2589 (12%)]\tLoss: 247.461655\n",
      "Train Epoch: 221 [600/2589 (23%)]\tLoss: 424.055359\n",
      "Train Epoch: 221 [900/2589 (35%)]\tLoss: 373.200378\n",
      "Train Epoch: 221 [1200/2589 (46%)]\tLoss: 363.068665\n",
      "Train Epoch: 221 [1500/2589 (58%)]\tLoss: 270.187958\n",
      "Train Epoch: 221 [1800/2589 (70%)]\tLoss: 250.645691\n",
      "Train Epoch: 221 [2100/2589 (81%)]\tLoss: 172.599152\n",
      "Train Epoch: 221 [2400/2589 (93%)]\tLoss: 198.926651\n",
      "====> Epoch: 221 Average train loss: 279.4026\n",
      "====> Epoch: 221 Average test loss: 956.1382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 222 [0/2589 (0%)]\tLoss: 259.320343\n",
      "Train Epoch: 222 [300/2589 (12%)]\tLoss: 223.008362\n",
      "Train Epoch: 222 [600/2589 (23%)]\tLoss: 269.755310\n",
      "Train Epoch: 222 [900/2589 (35%)]\tLoss: 249.556702\n",
      "Train Epoch: 222 [1200/2589 (46%)]\tLoss: 452.386017\n",
      "Train Epoch: 222 [1500/2589 (58%)]\tLoss: 183.552307\n",
      "Train Epoch: 222 [1800/2589 (70%)]\tLoss: 233.842667\n",
      "Train Epoch: 222 [2100/2589 (81%)]\tLoss: 219.636780\n",
      "Train Epoch: 222 [2400/2589 (93%)]\tLoss: 272.274750\n",
      "====> Epoch: 222 Average train loss: 287.9443\n",
      "====> Epoch: 222 Average test loss: 954.2374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 223 [0/2589 (0%)]\tLoss: 272.537781\n",
      "Train Epoch: 223 [300/2589 (12%)]\tLoss: 477.986694\n",
      "Train Epoch: 223 [600/2589 (23%)]\tLoss: 481.293274\n",
      "Train Epoch: 223 [900/2589 (35%)]\tLoss: 253.361191\n",
      "Train Epoch: 223 [1200/2589 (46%)]\tLoss: 269.403717\n",
      "Train Epoch: 223 [1500/2589 (58%)]\tLoss: 194.791016\n",
      "Train Epoch: 223 [1800/2589 (70%)]\tLoss: 351.722015\n",
      "Train Epoch: 223 [2100/2589 (81%)]\tLoss: 304.056213\n",
      "Train Epoch: 223 [2400/2589 (93%)]\tLoss: 346.625183\n",
      "====> Epoch: 223 Average train loss: 281.1707\n",
      "====> Epoch: 223 Average test loss: 945.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 224 [0/2589 (0%)]\tLoss: 313.963745\n",
      "Train Epoch: 224 [300/2589 (12%)]\tLoss: 297.251282\n",
      "Train Epoch: 224 [600/2589 (23%)]\tLoss: 214.310150\n",
      "Train Epoch: 224 [900/2589 (35%)]\tLoss: 282.153931\n",
      "Train Epoch: 224 [1200/2589 (46%)]\tLoss: 306.076172\n",
      "Train Epoch: 224 [1500/2589 (58%)]\tLoss: 335.961456\n",
      "Train Epoch: 224 [1800/2589 (70%)]\tLoss: 401.844208\n",
      "Train Epoch: 224 [2100/2589 (81%)]\tLoss: 232.771973\n",
      "Train Epoch: 224 [2400/2589 (93%)]\tLoss: 201.550293\n",
      "====> Epoch: 224 Average train loss: 292.4003\n",
      "====> Epoch: 224 Average test loss: 951.0888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 225 [0/2589 (0%)]\tLoss: 345.399353\n",
      "Train Epoch: 225 [300/2589 (12%)]\tLoss: 277.696808\n",
      "Train Epoch: 225 [600/2589 (23%)]\tLoss: 297.932922\n",
      "Train Epoch: 225 [900/2589 (35%)]\tLoss: 249.411133\n",
      "Train Epoch: 225 [1200/2589 (46%)]\tLoss: 476.194794\n",
      "Train Epoch: 225 [1500/2589 (58%)]\tLoss: 250.375046\n",
      "Train Epoch: 225 [1800/2589 (70%)]\tLoss: 304.798248\n",
      "Train Epoch: 225 [2100/2589 (81%)]\tLoss: 326.430115\n",
      "Train Epoch: 225 [2400/2589 (93%)]\tLoss: 267.497772\n",
      "====> Epoch: 225 Average train loss: 270.9002\n",
      "====> Epoch: 225 Average test loss: 969.2720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 226 [0/2589 (0%)]\tLoss: 343.073029\n",
      "Train Epoch: 226 [300/2589 (12%)]\tLoss: 214.530319\n",
      "Train Epoch: 226 [600/2589 (23%)]\tLoss: 253.145508\n",
      "Train Epoch: 226 [900/2589 (35%)]\tLoss: 231.414871\n",
      "Train Epoch: 226 [1200/2589 (46%)]\tLoss: 302.285339\n",
      "Train Epoch: 226 [1500/2589 (58%)]\tLoss: 294.691895\n",
      "Train Epoch: 226 [1800/2589 (70%)]\tLoss: 263.723358\n",
      "Train Epoch: 226 [2100/2589 (81%)]\tLoss: 310.627563\n",
      "Train Epoch: 226 [2400/2589 (93%)]\tLoss: 196.403641\n",
      "====> Epoch: 226 Average train loss: 268.6879\n",
      "====> Epoch: 226 Average test loss: 946.6650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 227 [0/2589 (0%)]\tLoss: 222.184799\n",
      "Train Epoch: 227 [300/2589 (12%)]\tLoss: 292.221863\n",
      "Train Epoch: 227 [600/2589 (23%)]\tLoss: 223.072220\n",
      "Train Epoch: 227 [900/2589 (35%)]\tLoss: 163.516953\n",
      "Train Epoch: 227 [1200/2589 (46%)]\tLoss: 232.472595\n",
      "Train Epoch: 227 [1500/2589 (58%)]\tLoss: 206.133469\n",
      "Train Epoch: 227 [1800/2589 (70%)]\tLoss: 360.670197\n",
      "Train Epoch: 227 [2100/2589 (81%)]\tLoss: 376.121124\n",
      "Train Epoch: 227 [2400/2589 (93%)]\tLoss: 205.975571\n",
      "====> Epoch: 227 Average train loss: 276.1469\n",
      "====> Epoch: 227 Average test loss: 942.1839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 228 [0/2589 (0%)]\tLoss: 207.672943\n",
      "Train Epoch: 228 [300/2589 (12%)]\tLoss: 179.651855\n",
      "Train Epoch: 228 [600/2589 (23%)]\tLoss: 286.435944\n",
      "Train Epoch: 228 [900/2589 (35%)]\tLoss: 209.605423\n",
      "Train Epoch: 228 [1200/2589 (46%)]\tLoss: 251.417664\n",
      "Train Epoch: 228 [1500/2589 (58%)]\tLoss: 329.778381\n",
      "Train Epoch: 228 [1800/2589 (70%)]\tLoss: 252.511169\n",
      "Train Epoch: 228 [2100/2589 (81%)]\tLoss: 271.801697\n",
      "Train Epoch: 228 [2400/2589 (93%)]\tLoss: 262.741272\n",
      "====> Epoch: 228 Average train loss: 273.4603\n",
      "====> Epoch: 228 Average test loss: 962.2717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 229 [0/2589 (0%)]\tLoss: 313.156616\n",
      "Train Epoch: 229 [300/2589 (12%)]\tLoss: 354.573181\n",
      "Train Epoch: 229 [600/2589 (23%)]\tLoss: 304.896149\n",
      "Train Epoch: 229 [900/2589 (35%)]\tLoss: 442.923065\n",
      "Train Epoch: 229 [1200/2589 (46%)]\tLoss: 232.553238\n",
      "Train Epoch: 229 [1500/2589 (58%)]\tLoss: 257.235565\n",
      "Train Epoch: 229 [1800/2589 (70%)]\tLoss: 188.701218\n",
      "Train Epoch: 229 [2100/2589 (81%)]\tLoss: 601.872681\n",
      "Train Epoch: 229 [2400/2589 (93%)]\tLoss: 204.800049\n",
      "====> Epoch: 229 Average train loss: 284.5630\n",
      "====> Epoch: 229 Average test loss: 922.2335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 230 [0/2589 (0%)]\tLoss: 314.272736\n",
      "Train Epoch: 230 [300/2589 (12%)]\tLoss: 317.578125\n",
      "Train Epoch: 230 [600/2589 (23%)]\tLoss: 277.318176\n",
      "Train Epoch: 230 [900/2589 (35%)]\tLoss: 359.205170\n",
      "Train Epoch: 230 [1200/2589 (46%)]\tLoss: 207.867645\n",
      "Train Epoch: 230 [1500/2589 (58%)]\tLoss: 235.635361\n",
      "Train Epoch: 230 [1800/2589 (70%)]\tLoss: 456.347260\n",
      "Train Epoch: 230 [2100/2589 (81%)]\tLoss: 304.551331\n",
      "Train Epoch: 230 [2400/2589 (93%)]\tLoss: 206.871353\n",
      "====> Epoch: 230 Average train loss: 279.6606\n",
      "====> Epoch: 230 Average test loss: 950.5285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 231 [0/2589 (0%)]\tLoss: 390.966278\n",
      "Train Epoch: 231 [300/2589 (12%)]\tLoss: 257.987488\n",
      "Train Epoch: 231 [600/2589 (23%)]\tLoss: 233.907745\n",
      "Train Epoch: 231 [900/2589 (35%)]\tLoss: 271.628845\n",
      "Train Epoch: 231 [1200/2589 (46%)]\tLoss: 220.813080\n",
      "Train Epoch: 231 [1500/2589 (58%)]\tLoss: 269.749664\n",
      "Train Epoch: 231 [1800/2589 (70%)]\tLoss: 324.232117\n",
      "Train Epoch: 231 [2100/2589 (81%)]\tLoss: 289.554321\n",
      "Train Epoch: 231 [2400/2589 (93%)]\tLoss: 222.684525\n",
      "====> Epoch: 231 Average train loss: 272.3907\n",
      "====> Epoch: 231 Average test loss: 948.0928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 232 [0/2589 (0%)]\tLoss: 296.771790\n",
      "Train Epoch: 232 [300/2589 (12%)]\tLoss: 268.623535\n",
      "Train Epoch: 232 [600/2589 (23%)]\tLoss: 233.851532\n",
      "Train Epoch: 232 [900/2589 (35%)]\tLoss: 356.793640\n",
      "Train Epoch: 232 [1200/2589 (46%)]\tLoss: 228.451752\n",
      "Train Epoch: 232 [1500/2589 (58%)]\tLoss: 201.392563\n",
      "Train Epoch: 232 [1800/2589 (70%)]\tLoss: 352.923401\n",
      "Train Epoch: 232 [2100/2589 (81%)]\tLoss: 247.349503\n",
      "Train Epoch: 232 [2400/2589 (93%)]\tLoss: 361.276855\n",
      "====> Epoch: 232 Average train loss: 283.8976\n",
      "====> Epoch: 232 Average test loss: 955.4910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 233 [0/2589 (0%)]\tLoss: 231.418701\n",
      "Train Epoch: 233 [300/2589 (12%)]\tLoss: 292.579620\n",
      "Train Epoch: 233 [600/2589 (23%)]\tLoss: 241.834320\n",
      "Train Epoch: 233 [900/2589 (35%)]\tLoss: 317.499207\n",
      "Train Epoch: 233 [1200/2589 (46%)]\tLoss: 193.593079\n",
      "Train Epoch: 233 [1500/2589 (58%)]\tLoss: 200.418213\n",
      "Train Epoch: 233 [1800/2589 (70%)]\tLoss: 234.099960\n",
      "Train Epoch: 233 [2100/2589 (81%)]\tLoss: 206.989151\n",
      "Train Epoch: 233 [2400/2589 (93%)]\tLoss: 248.065338\n",
      "====> Epoch: 233 Average train loss: 274.3226\n",
      "====> Epoch: 233 Average test loss: 957.3167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 234 [0/2589 (0%)]\tLoss: 269.667053\n",
      "Train Epoch: 234 [300/2589 (12%)]\tLoss: 296.972961\n",
      "Train Epoch: 234 [600/2589 (23%)]\tLoss: 211.868423\n",
      "Train Epoch: 234 [900/2589 (35%)]\tLoss: 198.359421\n",
      "Train Epoch: 234 [1200/2589 (46%)]\tLoss: 339.845306\n",
      "Train Epoch: 234 [1500/2589 (58%)]\tLoss: 192.990723\n",
      "Train Epoch: 234 [1800/2589 (70%)]\tLoss: 378.123505\n",
      "Train Epoch: 234 [2100/2589 (81%)]\tLoss: 254.320633\n",
      "Train Epoch: 234 [2400/2589 (93%)]\tLoss: 189.637207\n",
      "====> Epoch: 234 Average train loss: 275.8051\n",
      "====> Epoch: 234 Average test loss: 934.0971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 235 [0/2589 (0%)]\tLoss: 351.156891\n",
      "Train Epoch: 235 [300/2589 (12%)]\tLoss: 369.788208\n",
      "Train Epoch: 235 [600/2589 (23%)]\tLoss: 413.689819\n",
      "Train Epoch: 235 [900/2589 (35%)]\tLoss: 218.296463\n",
      "Train Epoch: 235 [1200/2589 (46%)]\tLoss: 265.856659\n",
      "Train Epoch: 235 [1500/2589 (58%)]\tLoss: 262.143280\n",
      "Train Epoch: 235 [1800/2589 (70%)]\tLoss: 266.458893\n",
      "Train Epoch: 235 [2100/2589 (81%)]\tLoss: 320.809906\n",
      "Train Epoch: 235 [2400/2589 (93%)]\tLoss: 268.404266\n",
      "====> Epoch: 235 Average train loss: 275.4742\n",
      "====> Epoch: 235 Average test loss: 962.5831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 236 [0/2589 (0%)]\tLoss: 253.091537\n",
      "Train Epoch: 236 [300/2589 (12%)]\tLoss: 230.771255\n",
      "Train Epoch: 236 [600/2589 (23%)]\tLoss: 271.991882\n",
      "Train Epoch: 236 [900/2589 (35%)]\tLoss: 227.133453\n",
      "Train Epoch: 236 [1200/2589 (46%)]\tLoss: 292.374817\n",
      "Train Epoch: 236 [1500/2589 (58%)]\tLoss: 272.215118\n",
      "Train Epoch: 236 [1800/2589 (70%)]\tLoss: 213.426590\n",
      "Train Epoch: 236 [2100/2589 (81%)]\tLoss: 296.054779\n",
      "Train Epoch: 236 [2400/2589 (93%)]\tLoss: 268.747101\n",
      "====> Epoch: 236 Average train loss: 285.0843\n",
      "====> Epoch: 236 Average test loss: 960.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 237 [0/2589 (0%)]\tLoss: 226.667953\n",
      "Train Epoch: 237 [300/2589 (12%)]\tLoss: 315.978577\n",
      "Train Epoch: 237 [600/2589 (23%)]\tLoss: 280.950378\n",
      "Train Epoch: 237 [900/2589 (35%)]\tLoss: 250.053543\n",
      "Train Epoch: 237 [1200/2589 (46%)]\tLoss: 278.936310\n",
      "Train Epoch: 237 [1500/2589 (58%)]\tLoss: 219.629532\n",
      "Train Epoch: 237 [1800/2589 (70%)]\tLoss: 247.803284\n",
      "Train Epoch: 237 [2100/2589 (81%)]\tLoss: 216.006729\n",
      "Train Epoch: 237 [2400/2589 (93%)]\tLoss: 364.562378\n",
      "====> Epoch: 237 Average train loss: 275.9194\n",
      "====> Epoch: 237 Average test loss: 947.3671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 238 [0/2589 (0%)]\tLoss: 234.966064\n",
      "Train Epoch: 238 [300/2589 (12%)]\tLoss: 410.792847\n",
      "Train Epoch: 238 [600/2589 (23%)]\tLoss: 259.159058\n",
      "Train Epoch: 238 [900/2589 (35%)]\tLoss: 352.810150\n",
      "Train Epoch: 238 [1200/2589 (46%)]\tLoss: 255.981659\n",
      "Train Epoch: 238 [1500/2589 (58%)]\tLoss: 324.898865\n",
      "Train Epoch: 238 [1800/2589 (70%)]\tLoss: 271.036377\n",
      "Train Epoch: 238 [2100/2589 (81%)]\tLoss: 470.694916\n",
      "Train Epoch: 238 [2400/2589 (93%)]\tLoss: 204.386520\n",
      "====> Epoch: 238 Average train loss: 281.3177\n",
      "====> Epoch: 238 Average test loss: 954.1545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 239 [0/2589 (0%)]\tLoss: 248.223862\n",
      "Train Epoch: 239 [300/2589 (12%)]\tLoss: 212.955505\n",
      "Train Epoch: 239 [600/2589 (23%)]\tLoss: 232.902512\n",
      "Train Epoch: 239 [900/2589 (35%)]\tLoss: 306.982483\n",
      "Train Epoch: 239 [1200/2589 (46%)]\tLoss: 227.159988\n",
      "Train Epoch: 239 [1500/2589 (58%)]\tLoss: 304.007904\n",
      "Train Epoch: 239 [1800/2589 (70%)]\tLoss: 241.894333\n",
      "Train Epoch: 239 [2100/2589 (81%)]\tLoss: 235.788818\n",
      "Train Epoch: 239 [2400/2589 (93%)]\tLoss: 234.420898\n",
      "====> Epoch: 239 Average train loss: 269.5574\n",
      "====> Epoch: 239 Average test loss: 960.9354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 240 [0/2589 (0%)]\tLoss: 261.486969\n",
      "Train Epoch: 240 [300/2589 (12%)]\tLoss: 326.352356\n",
      "Train Epoch: 240 [600/2589 (23%)]\tLoss: 282.717438\n",
      "Train Epoch: 240 [900/2589 (35%)]\tLoss: 241.570831\n",
      "Train Epoch: 240 [1200/2589 (46%)]\tLoss: 311.911407\n",
      "Train Epoch: 240 [1500/2589 (58%)]\tLoss: 210.713562\n",
      "Train Epoch: 240 [1800/2589 (70%)]\tLoss: 329.786682\n",
      "Train Epoch: 240 [2100/2589 (81%)]\tLoss: 303.511017\n",
      "Train Epoch: 240 [2400/2589 (93%)]\tLoss: 218.383377\n",
      "====> Epoch: 240 Average train loss: 290.3645\n",
      "====> Epoch: 240 Average test loss: 947.8688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 241 [0/2589 (0%)]\tLoss: 243.786758\n",
      "Train Epoch: 241 [300/2589 (12%)]\tLoss: 391.396362\n",
      "Train Epoch: 241 [600/2589 (23%)]\tLoss: 229.149155\n",
      "Train Epoch: 241 [900/2589 (35%)]\tLoss: 274.827606\n",
      "Train Epoch: 241 [1200/2589 (46%)]\tLoss: 261.744049\n",
      "Train Epoch: 241 [1500/2589 (58%)]\tLoss: 248.177078\n",
      "Train Epoch: 241 [1800/2589 (70%)]\tLoss: 174.155228\n",
      "Train Epoch: 241 [2100/2589 (81%)]\tLoss: 290.863373\n",
      "Train Epoch: 241 [2400/2589 (93%)]\tLoss: 372.261200\n",
      "====> Epoch: 241 Average train loss: 276.9535\n",
      "====> Epoch: 241 Average test loss: 941.8356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 242 [0/2589 (0%)]\tLoss: 192.784698\n",
      "Train Epoch: 242 [300/2589 (12%)]\tLoss: 319.874908\n",
      "Train Epoch: 242 [600/2589 (23%)]\tLoss: 254.952118\n",
      "Train Epoch: 242 [900/2589 (35%)]\tLoss: 180.572083\n",
      "Train Epoch: 242 [1200/2589 (46%)]\tLoss: 266.700134\n",
      "Train Epoch: 242 [1500/2589 (58%)]\tLoss: 274.033844\n",
      "Train Epoch: 242 [1800/2589 (70%)]\tLoss: 290.254181\n",
      "Train Epoch: 242 [2100/2589 (81%)]\tLoss: 310.711884\n",
      "Train Epoch: 242 [2400/2589 (93%)]\tLoss: 294.057526\n",
      "====> Epoch: 242 Average train loss: 279.5696\n",
      "====> Epoch: 242 Average test loss: 977.7775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 243 [0/2589 (0%)]\tLoss: 384.729126\n",
      "Train Epoch: 243 [300/2589 (12%)]\tLoss: 236.989807\n",
      "Train Epoch: 243 [600/2589 (23%)]\tLoss: 220.399384\n",
      "Train Epoch: 243 [900/2589 (35%)]\tLoss: 299.989929\n",
      "Train Epoch: 243 [1200/2589 (46%)]\tLoss: 250.561295\n",
      "Train Epoch: 243 [1500/2589 (58%)]\tLoss: 185.276855\n",
      "Train Epoch: 243 [1800/2589 (70%)]\tLoss: 365.589050\n",
      "Train Epoch: 243 [2100/2589 (81%)]\tLoss: 290.205353\n",
      "Train Epoch: 243 [2400/2589 (93%)]\tLoss: 211.690948\n",
      "====> Epoch: 243 Average train loss: 267.7878\n",
      "====> Epoch: 243 Average test loss: 946.0546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 244 [0/2589 (0%)]\tLoss: 285.638580\n",
      "Train Epoch: 244 [300/2589 (12%)]\tLoss: 261.636322\n",
      "Train Epoch: 244 [600/2589 (23%)]\tLoss: 354.306549\n",
      "Train Epoch: 244 [900/2589 (35%)]\tLoss: 399.682343\n",
      "Train Epoch: 244 [1200/2589 (46%)]\tLoss: 225.472610\n",
      "Train Epoch: 244 [1500/2589 (58%)]\tLoss: 232.842712\n",
      "Train Epoch: 244 [1800/2589 (70%)]\tLoss: 369.786774\n",
      "Train Epoch: 244 [2100/2589 (81%)]\tLoss: 191.762848\n",
      "Train Epoch: 244 [2400/2589 (93%)]\tLoss: 268.335754\n",
      "====> Epoch: 244 Average train loss: 274.0046\n",
      "====> Epoch: 244 Average test loss: 958.0830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 245 [0/2589 (0%)]\tLoss: 227.632278\n",
      "Train Epoch: 245 [300/2589 (12%)]\tLoss: 305.408661\n",
      "Train Epoch: 245 [600/2589 (23%)]\tLoss: 299.388031\n",
      "Train Epoch: 245 [900/2589 (35%)]\tLoss: 286.164490\n",
      "Train Epoch: 245 [1200/2589 (46%)]\tLoss: 316.730316\n",
      "Train Epoch: 245 [1500/2589 (58%)]\tLoss: 298.381683\n",
      "Train Epoch: 245 [1800/2589 (70%)]\tLoss: 343.534393\n",
      "Train Epoch: 245 [2100/2589 (81%)]\tLoss: 230.266312\n",
      "Train Epoch: 245 [2400/2589 (93%)]\tLoss: 258.646851\n",
      "====> Epoch: 245 Average train loss: 283.5545\n",
      "====> Epoch: 245 Average test loss: 943.3004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 246 [0/2589 (0%)]\tLoss: 244.877670\n",
      "Train Epoch: 246 [300/2589 (12%)]\tLoss: 173.432785\n",
      "Train Epoch: 246 [600/2589 (23%)]\tLoss: 283.697906\n",
      "Train Epoch: 246 [900/2589 (35%)]\tLoss: 266.721802\n",
      "Train Epoch: 246 [1200/2589 (46%)]\tLoss: 178.765930\n",
      "Train Epoch: 246 [1500/2589 (58%)]\tLoss: 342.696594\n",
      "Train Epoch: 246 [1800/2589 (70%)]\tLoss: 306.295929\n",
      "Train Epoch: 246 [2100/2589 (81%)]\tLoss: 309.595154\n",
      "Train Epoch: 246 [2400/2589 (93%)]\tLoss: 269.461609\n",
      "====> Epoch: 246 Average train loss: 280.0639\n",
      "====> Epoch: 246 Average test loss: 944.8895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 247 [0/2589 (0%)]\tLoss: 314.016785\n",
      "Train Epoch: 247 [300/2589 (12%)]\tLoss: 283.889832\n",
      "Train Epoch: 247 [600/2589 (23%)]\tLoss: 356.641754\n",
      "Train Epoch: 247 [900/2589 (35%)]\tLoss: 283.610962\n",
      "Train Epoch: 247 [1200/2589 (46%)]\tLoss: 327.927246\n",
      "Train Epoch: 247 [1500/2589 (58%)]\tLoss: 301.497467\n",
      "Train Epoch: 247 [1800/2589 (70%)]\tLoss: 225.167725\n",
      "Train Epoch: 247 [2100/2589 (81%)]\tLoss: 344.901245\n",
      "Train Epoch: 247 [2400/2589 (93%)]\tLoss: 267.353668\n",
      "====> Epoch: 247 Average train loss: 292.3107\n",
      "====> Epoch: 247 Average test loss: 966.2883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 248 [0/2589 (0%)]\tLoss: 173.856308\n",
      "Train Epoch: 248 [300/2589 (12%)]\tLoss: 270.450134\n",
      "Train Epoch: 248 [600/2589 (23%)]\tLoss: 199.073532\n",
      "Train Epoch: 248 [900/2589 (35%)]\tLoss: 428.994537\n",
      "Train Epoch: 248 [1200/2589 (46%)]\tLoss: 243.233948\n",
      "Train Epoch: 248 [1500/2589 (58%)]\tLoss: 358.570221\n",
      "Train Epoch: 248 [1800/2589 (70%)]\tLoss: 341.657562\n",
      "Train Epoch: 248 [2100/2589 (81%)]\tLoss: 376.844696\n",
      "Train Epoch: 248 [2400/2589 (93%)]\tLoss: 229.277145\n",
      "====> Epoch: 248 Average train loss: 275.6439\n",
      "====> Epoch: 248 Average test loss: 944.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 249 [0/2589 (0%)]\tLoss: 186.157166\n",
      "Train Epoch: 249 [300/2589 (12%)]\tLoss: 273.106628\n",
      "Train Epoch: 249 [600/2589 (23%)]\tLoss: 310.173431\n",
      "Train Epoch: 249 [900/2589 (35%)]\tLoss: 233.407974\n",
      "Train Epoch: 249 [1200/2589 (46%)]\tLoss: 236.987213\n",
      "Train Epoch: 249 [1500/2589 (58%)]\tLoss: 205.670929\n",
      "Train Epoch: 249 [1800/2589 (70%)]\tLoss: 279.590179\n",
      "Train Epoch: 249 [2100/2589 (81%)]\tLoss: 265.577179\n",
      "Train Epoch: 249 [2400/2589 (93%)]\tLoss: 281.272675\n",
      "====> Epoch: 249 Average train loss: 263.5925\n",
      "====> Epoch: 249 Average test loss: 961.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 250 [0/2589 (0%)]\tLoss: 238.320709\n",
      "Train Epoch: 250 [300/2589 (12%)]\tLoss: 314.670349\n",
      "Train Epoch: 250 [600/2589 (23%)]\tLoss: 373.237335\n",
      "Train Epoch: 250 [900/2589 (35%)]\tLoss: 236.819244\n",
      "Train Epoch: 250 [1200/2589 (46%)]\tLoss: 217.748276\n",
      "Train Epoch: 250 [1500/2589 (58%)]\tLoss: 240.062851\n",
      "Train Epoch: 250 [1800/2589 (70%)]\tLoss: 212.326721\n",
      "Train Epoch: 250 [2100/2589 (81%)]\tLoss: 242.912399\n",
      "Train Epoch: 250 [2400/2589 (93%)]\tLoss: 266.415222\n",
      "====> Epoch: 250 Average train loss: 274.6921\n",
      "====> Epoch: 250 Average test loss: 959.4420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 251 [0/2589 (0%)]\tLoss: 281.462402\n",
      "Train Epoch: 251 [300/2589 (12%)]\tLoss: 255.428558\n",
      "Train Epoch: 251 [600/2589 (23%)]\tLoss: 253.293289\n",
      "Train Epoch: 251 [900/2589 (35%)]\tLoss: 253.331894\n",
      "Train Epoch: 251 [1200/2589 (46%)]\tLoss: 350.979065\n",
      "Train Epoch: 251 [1500/2589 (58%)]\tLoss: 318.348846\n",
      "Train Epoch: 251 [1800/2589 (70%)]\tLoss: 327.448639\n",
      "Train Epoch: 251 [2100/2589 (81%)]\tLoss: 302.097046\n",
      "Train Epoch: 251 [2400/2589 (93%)]\tLoss: 212.993683\n",
      "====> Epoch: 251 Average train loss: 279.0173\n",
      "====> Epoch: 251 Average test loss: 946.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 252 [0/2589 (0%)]\tLoss: 239.854691\n",
      "Train Epoch: 252 [300/2589 (12%)]\tLoss: 245.657822\n",
      "Train Epoch: 252 [600/2589 (23%)]\tLoss: 281.193207\n",
      "Train Epoch: 252 [900/2589 (35%)]\tLoss: 210.645508\n",
      "Train Epoch: 252 [1200/2589 (46%)]\tLoss: 225.609360\n",
      "Train Epoch: 252 [1500/2589 (58%)]\tLoss: 305.252106\n",
      "Train Epoch: 252 [1800/2589 (70%)]\tLoss: 261.986938\n",
      "Train Epoch: 252 [2100/2589 (81%)]\tLoss: 250.108749\n",
      "Train Epoch: 252 [2400/2589 (93%)]\tLoss: 252.216797\n",
      "====> Epoch: 252 Average train loss: 276.1983\n",
      "====> Epoch: 252 Average test loss: 972.4064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 253 [0/2589 (0%)]\tLoss: 396.072418\n",
      "Train Epoch: 253 [300/2589 (12%)]\tLoss: 268.795990\n",
      "Train Epoch: 253 [600/2589 (23%)]\tLoss: 296.498810\n",
      "Train Epoch: 253 [900/2589 (35%)]\tLoss: 246.017670\n",
      "Train Epoch: 253 [1200/2589 (46%)]\tLoss: 219.523193\n",
      "Train Epoch: 253 [1500/2589 (58%)]\tLoss: 226.350479\n",
      "Train Epoch: 253 [1800/2589 (70%)]\tLoss: 303.448853\n",
      "Train Epoch: 253 [2100/2589 (81%)]\tLoss: 269.577728\n",
      "Train Epoch: 253 [2400/2589 (93%)]\tLoss: 213.028519\n",
      "====> Epoch: 253 Average train loss: 279.1970\n",
      "====> Epoch: 253 Average test loss: 947.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 254 [0/2589 (0%)]\tLoss: 199.908035\n",
      "Train Epoch: 254 [300/2589 (12%)]\tLoss: 190.295578\n",
      "Train Epoch: 254 [600/2589 (23%)]\tLoss: 272.638306\n",
      "Train Epoch: 254 [900/2589 (35%)]\tLoss: 214.834045\n",
      "Train Epoch: 254 [1200/2589 (46%)]\tLoss: 257.477203\n",
      "Train Epoch: 254 [1500/2589 (58%)]\tLoss: 344.937500\n",
      "Train Epoch: 254 [1800/2589 (70%)]\tLoss: 218.668167\n",
      "Train Epoch: 254 [2100/2589 (81%)]\tLoss: 305.913788\n",
      "Train Epoch: 254 [2400/2589 (93%)]\tLoss: 359.127228\n",
      "====> Epoch: 254 Average train loss: 276.8047\n",
      "====> Epoch: 254 Average test loss: 959.2897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 255 [0/2589 (0%)]\tLoss: 255.049637\n",
      "Train Epoch: 255 [300/2589 (12%)]\tLoss: 249.855774\n",
      "Train Epoch: 255 [600/2589 (23%)]\tLoss: 240.394211\n",
      "Train Epoch: 255 [900/2589 (35%)]\tLoss: 250.684708\n",
      "Train Epoch: 255 [1200/2589 (46%)]\tLoss: 274.520905\n",
      "Train Epoch: 255 [1500/2589 (58%)]\tLoss: 210.618484\n",
      "Train Epoch: 255 [1800/2589 (70%)]\tLoss: 256.417786\n",
      "Train Epoch: 255 [2100/2589 (81%)]\tLoss: 225.361084\n",
      "Train Epoch: 255 [2400/2589 (93%)]\tLoss: 344.901550\n",
      "====> Epoch: 255 Average train loss: 284.1618\n",
      "====> Epoch: 255 Average test loss: 945.7911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 256 [0/2589 (0%)]\tLoss: 305.814972\n",
      "Train Epoch: 256 [300/2589 (12%)]\tLoss: 303.992065\n",
      "Train Epoch: 256 [600/2589 (23%)]\tLoss: 392.121887\n",
      "Train Epoch: 256 [900/2589 (35%)]\tLoss: 279.020477\n",
      "Train Epoch: 256 [1200/2589 (46%)]\tLoss: 367.906189\n",
      "Train Epoch: 256 [1500/2589 (58%)]\tLoss: 225.788315\n",
      "Train Epoch: 256 [1800/2589 (70%)]\tLoss: 282.729156\n",
      "Train Epoch: 256 [2100/2589 (81%)]\tLoss: 233.947021\n",
      "Train Epoch: 256 [2400/2589 (93%)]\tLoss: 290.790863\n",
      "====> Epoch: 256 Average train loss: 276.9905\n",
      "====> Epoch: 256 Average test loss: 934.4705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 257 [0/2589 (0%)]\tLoss: 193.351593\n",
      "Train Epoch: 257 [300/2589 (12%)]\tLoss: 285.542450\n",
      "Train Epoch: 257 [600/2589 (23%)]\tLoss: 290.338745\n",
      "Train Epoch: 257 [900/2589 (35%)]\tLoss: 390.250336\n",
      "Train Epoch: 257 [1200/2589 (46%)]\tLoss: 173.181458\n",
      "Train Epoch: 257 [1500/2589 (58%)]\tLoss: 265.527924\n",
      "Train Epoch: 257 [1800/2589 (70%)]\tLoss: 322.074432\n",
      "Train Epoch: 257 [2100/2589 (81%)]\tLoss: 210.987991\n",
      "Train Epoch: 257 [2400/2589 (93%)]\tLoss: 217.086655\n",
      "====> Epoch: 257 Average train loss: 276.1016\n",
      "====> Epoch: 257 Average test loss: 953.3167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 258 [0/2589 (0%)]\tLoss: 221.113998\n",
      "Train Epoch: 258 [300/2589 (12%)]\tLoss: 196.654404\n",
      "Train Epoch: 258 [600/2589 (23%)]\tLoss: 293.048035\n",
      "Train Epoch: 258 [900/2589 (35%)]\tLoss: 422.587799\n",
      "Train Epoch: 258 [1200/2589 (46%)]\tLoss: 214.712265\n",
      "Train Epoch: 258 [1500/2589 (58%)]\tLoss: 179.079391\n",
      "Train Epoch: 258 [1800/2589 (70%)]\tLoss: 282.849396\n",
      "Train Epoch: 258 [2100/2589 (81%)]\tLoss: 148.004593\n",
      "Train Epoch: 258 [2400/2589 (93%)]\tLoss: 270.050446\n",
      "====> Epoch: 258 Average train loss: 273.0126\n",
      "====> Epoch: 258 Average test loss: 936.5139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 259 [0/2589 (0%)]\tLoss: 194.514359\n",
      "Train Epoch: 259 [300/2589 (12%)]\tLoss: 279.791199\n",
      "Train Epoch: 259 [600/2589 (23%)]\tLoss: 453.923492\n",
      "Train Epoch: 259 [900/2589 (35%)]\tLoss: 207.104401\n",
      "Train Epoch: 259 [1200/2589 (46%)]\tLoss: 273.661102\n",
      "Train Epoch: 259 [1500/2589 (58%)]\tLoss: 273.543091\n",
      "Train Epoch: 259 [1800/2589 (70%)]\tLoss: 263.601440\n",
      "Train Epoch: 259 [2100/2589 (81%)]\tLoss: 224.055496\n",
      "Train Epoch: 259 [2400/2589 (93%)]\tLoss: 266.703583\n",
      "====> Epoch: 259 Average train loss: 275.8659\n",
      "====> Epoch: 259 Average test loss: 939.3304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 260 [0/2589 (0%)]\tLoss: 267.906830\n",
      "Train Epoch: 260 [300/2589 (12%)]\tLoss: 248.184128\n",
      "Train Epoch: 260 [600/2589 (23%)]\tLoss: 229.149994\n",
      "Train Epoch: 260 [900/2589 (35%)]\tLoss: 342.944946\n",
      "Train Epoch: 260 [1200/2589 (46%)]\tLoss: 164.709000\n",
      "Train Epoch: 260 [1500/2589 (58%)]\tLoss: 341.889984\n",
      "Train Epoch: 260 [1800/2589 (70%)]\tLoss: 345.715912\n",
      "Train Epoch: 260 [2100/2589 (81%)]\tLoss: 220.480896\n",
      "Train Epoch: 260 [2400/2589 (93%)]\tLoss: 193.073990\n",
      "====> Epoch: 260 Average train loss: 278.6407\n",
      "====> Epoch: 260 Average test loss: 949.0807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 261 [0/2589 (0%)]\tLoss: 196.590042\n",
      "Train Epoch: 261 [300/2589 (12%)]\tLoss: 253.776306\n",
      "Train Epoch: 261 [600/2589 (23%)]\tLoss: 246.759064\n",
      "Train Epoch: 261 [900/2589 (35%)]\tLoss: 281.522278\n",
      "Train Epoch: 261 [1200/2589 (46%)]\tLoss: 281.251007\n",
      "Train Epoch: 261 [1500/2589 (58%)]\tLoss: 294.228973\n",
      "Train Epoch: 261 [1800/2589 (70%)]\tLoss: 225.154816\n",
      "Train Epoch: 261 [2100/2589 (81%)]\tLoss: 260.086121\n",
      "Train Epoch: 261 [2400/2589 (93%)]\tLoss: 310.340332\n",
      "====> Epoch: 261 Average train loss: 279.0631\n",
      "====> Epoch: 261 Average test loss: 940.3941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 262 [0/2589 (0%)]\tLoss: 265.212677\n",
      "Train Epoch: 262 [300/2589 (12%)]\tLoss: 329.279846\n",
      "Train Epoch: 262 [600/2589 (23%)]\tLoss: 311.620819\n",
      "Train Epoch: 262 [900/2589 (35%)]\tLoss: 259.169769\n",
      "Train Epoch: 262 [1200/2589 (46%)]\tLoss: 235.704788\n",
      "Train Epoch: 262 [1500/2589 (58%)]\tLoss: 220.691986\n",
      "Train Epoch: 262 [1800/2589 (70%)]\tLoss: 226.128937\n",
      "Train Epoch: 262 [2100/2589 (81%)]\tLoss: 217.888901\n",
      "Train Epoch: 262 [2400/2589 (93%)]\tLoss: 219.922363\n",
      "====> Epoch: 262 Average train loss: 271.8615\n",
      "====> Epoch: 262 Average test loss: 943.3442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 263 [0/2589 (0%)]\tLoss: 213.918457\n",
      "Train Epoch: 263 [300/2589 (12%)]\tLoss: 252.304428\n",
      "Train Epoch: 263 [600/2589 (23%)]\tLoss: 439.140961\n",
      "Train Epoch: 263 [900/2589 (35%)]\tLoss: 248.521774\n",
      "Train Epoch: 263 [1200/2589 (46%)]\tLoss: 275.103790\n",
      "Train Epoch: 263 [1500/2589 (58%)]\tLoss: 253.342941\n",
      "Train Epoch: 263 [1800/2589 (70%)]\tLoss: 232.912567\n",
      "Train Epoch: 263 [2100/2589 (81%)]\tLoss: 294.615204\n",
      "Train Epoch: 263 [2400/2589 (93%)]\tLoss: 333.456146\n",
      "====> Epoch: 263 Average train loss: 277.0902\n",
      "====> Epoch: 263 Average test loss: 945.3698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 264 [0/2589 (0%)]\tLoss: 253.892380\n",
      "Train Epoch: 264 [300/2589 (12%)]\tLoss: 249.084396\n",
      "Train Epoch: 264 [600/2589 (23%)]\tLoss: 248.325043\n",
      "Train Epoch: 264 [900/2589 (35%)]\tLoss: 254.963089\n",
      "Train Epoch: 264 [1200/2589 (46%)]\tLoss: 281.197662\n",
      "Train Epoch: 264 [1500/2589 (58%)]\tLoss: 237.945312\n",
      "Train Epoch: 264 [1800/2589 (70%)]\tLoss: 296.176880\n",
      "Train Epoch: 264 [2100/2589 (81%)]\tLoss: 211.528839\n",
      "Train Epoch: 264 [2400/2589 (93%)]\tLoss: 427.557281\n",
      "====> Epoch: 264 Average train loss: 277.3555\n",
      "====> Epoch: 264 Average test loss: 938.7479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 265 [0/2589 (0%)]\tLoss: 230.727066\n",
      "Train Epoch: 265 [300/2589 (12%)]\tLoss: 262.493713\n",
      "Train Epoch: 265 [600/2589 (23%)]\tLoss: 265.690826\n",
      "Train Epoch: 265 [900/2589 (35%)]\tLoss: 405.642853\n",
      "Train Epoch: 265 [1200/2589 (46%)]\tLoss: 267.761932\n",
      "Train Epoch: 265 [1500/2589 (58%)]\tLoss: 227.250702\n",
      "Train Epoch: 265 [1800/2589 (70%)]\tLoss: 259.898376\n",
      "Train Epoch: 265 [2100/2589 (81%)]\tLoss: 271.767792\n",
      "Train Epoch: 265 [2400/2589 (93%)]\tLoss: 288.187042\n",
      "====> Epoch: 265 Average train loss: 272.3608\n",
      "====> Epoch: 265 Average test loss: 944.4515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 266 [0/2589 (0%)]\tLoss: 392.891876\n",
      "Train Epoch: 266 [300/2589 (12%)]\tLoss: 250.925690\n",
      "Train Epoch: 266 [600/2589 (23%)]\tLoss: 289.921844\n",
      "Train Epoch: 266 [900/2589 (35%)]\tLoss: 290.474030\n",
      "Train Epoch: 266 [1200/2589 (46%)]\tLoss: 254.162216\n",
      "Train Epoch: 266 [1500/2589 (58%)]\tLoss: 168.060196\n",
      "Train Epoch: 266 [1800/2589 (70%)]\tLoss: 309.611603\n",
      "Train Epoch: 266 [2100/2589 (81%)]\tLoss: 287.745880\n",
      "Train Epoch: 266 [2400/2589 (93%)]\tLoss: 341.609497\n",
      "====> Epoch: 266 Average train loss: 275.1378\n",
      "====> Epoch: 266 Average test loss: 937.4523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 267 [0/2589 (0%)]\tLoss: 271.814087\n",
      "Train Epoch: 267 [300/2589 (12%)]\tLoss: 194.071960\n",
      "Train Epoch: 267 [600/2589 (23%)]\tLoss: 310.397339\n",
      "Train Epoch: 267 [900/2589 (35%)]\tLoss: 248.762970\n",
      "Train Epoch: 267 [1200/2589 (46%)]\tLoss: 254.755630\n",
      "Train Epoch: 267 [1500/2589 (58%)]\tLoss: 257.294006\n",
      "Train Epoch: 267 [1800/2589 (70%)]\tLoss: 296.206329\n",
      "Train Epoch: 267 [2100/2589 (81%)]\tLoss: 200.776215\n",
      "Train Epoch: 267 [2400/2589 (93%)]\tLoss: 253.087723\n",
      "====> Epoch: 267 Average train loss: 268.9020\n",
      "====> Epoch: 267 Average test loss: 951.6843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 268 [0/2589 (0%)]\tLoss: 263.174225\n",
      "Train Epoch: 268 [300/2589 (12%)]\tLoss: 373.252747\n",
      "Train Epoch: 268 [600/2589 (23%)]\tLoss: 292.067444\n",
      "Train Epoch: 268 [900/2589 (35%)]\tLoss: 330.426544\n",
      "Train Epoch: 268 [1200/2589 (46%)]\tLoss: 198.814209\n",
      "Train Epoch: 268 [1500/2589 (58%)]\tLoss: 374.425903\n",
      "Train Epoch: 268 [1800/2589 (70%)]\tLoss: 316.880280\n",
      "Train Epoch: 268 [2100/2589 (81%)]\tLoss: 229.163925\n",
      "Train Epoch: 268 [2400/2589 (93%)]\tLoss: 241.266068\n",
      "====> Epoch: 268 Average train loss: 281.6068\n",
      "====> Epoch: 268 Average test loss: 978.8264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 269 [0/2589 (0%)]\tLoss: 199.653168\n",
      "Train Epoch: 269 [300/2589 (12%)]\tLoss: 294.541351\n",
      "Train Epoch: 269 [600/2589 (23%)]\tLoss: 228.881790\n",
      "Train Epoch: 269 [900/2589 (35%)]\tLoss: 236.845474\n",
      "Train Epoch: 269 [1200/2589 (46%)]\tLoss: 284.355591\n",
      "Train Epoch: 269 [1500/2589 (58%)]\tLoss: 328.513733\n",
      "Train Epoch: 269 [1800/2589 (70%)]\tLoss: 272.084564\n",
      "Train Epoch: 269 [2100/2589 (81%)]\tLoss: 216.940369\n",
      "Train Epoch: 269 [2400/2589 (93%)]\tLoss: 238.608536\n",
      "====> Epoch: 269 Average train loss: 266.7095\n",
      "====> Epoch: 269 Average test loss: 954.1975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 270 [0/2589 (0%)]\tLoss: 232.265656\n",
      "Train Epoch: 270 [300/2589 (12%)]\tLoss: 263.035522\n",
      "Train Epoch: 270 [600/2589 (23%)]\tLoss: 287.779755\n",
      "Train Epoch: 270 [900/2589 (35%)]\tLoss: 248.352097\n",
      "Train Epoch: 270 [1200/2589 (46%)]\tLoss: 284.951569\n",
      "Train Epoch: 270 [1500/2589 (58%)]\tLoss: 366.225952\n",
      "Train Epoch: 270 [1800/2589 (70%)]\tLoss: 273.943207\n",
      "Train Epoch: 270 [2100/2589 (81%)]\tLoss: 251.546112\n",
      "Train Epoch: 270 [2400/2589 (93%)]\tLoss: 214.809982\n",
      "====> Epoch: 270 Average train loss: 266.8466\n",
      "====> Epoch: 270 Average test loss: 958.6299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 271 [0/2589 (0%)]\tLoss: 223.991455\n",
      "Train Epoch: 271 [300/2589 (12%)]\tLoss: 326.955444\n",
      "Train Epoch: 271 [600/2589 (23%)]\tLoss: 390.963501\n",
      "Train Epoch: 271 [900/2589 (35%)]\tLoss: 236.811462\n",
      "Train Epoch: 271 [1200/2589 (46%)]\tLoss: 204.048965\n",
      "Train Epoch: 271 [1500/2589 (58%)]\tLoss: 406.402374\n",
      "Train Epoch: 271 [1800/2589 (70%)]\tLoss: 297.333435\n",
      "Train Epoch: 271 [2100/2589 (81%)]\tLoss: 454.340912\n",
      "Train Epoch: 271 [2400/2589 (93%)]\tLoss: 306.724548\n",
      "====> Epoch: 271 Average train loss: 266.7924\n",
      "====> Epoch: 271 Average test loss: 990.0432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 272 [0/2589 (0%)]\tLoss: 344.608673\n",
      "Train Epoch: 272 [300/2589 (12%)]\tLoss: 193.109238\n",
      "Train Epoch: 272 [600/2589 (23%)]\tLoss: 276.674194\n",
      "Train Epoch: 272 [900/2589 (35%)]\tLoss: 238.649216\n",
      "Train Epoch: 272 [1200/2589 (46%)]\tLoss: 309.089020\n",
      "Train Epoch: 272 [1500/2589 (58%)]\tLoss: 273.653473\n",
      "Train Epoch: 272 [1800/2589 (70%)]\tLoss: 360.818665\n",
      "Train Epoch: 272 [2100/2589 (81%)]\tLoss: 262.507843\n",
      "Train Epoch: 272 [2400/2589 (93%)]\tLoss: 240.582733\n",
      "====> Epoch: 272 Average train loss: 273.5929\n",
      "====> Epoch: 272 Average test loss: 937.4767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 273 [0/2589 (0%)]\tLoss: 207.519119\n",
      "Train Epoch: 273 [300/2589 (12%)]\tLoss: 307.880341\n",
      "Train Epoch: 273 [600/2589 (23%)]\tLoss: 285.456543\n",
      "Train Epoch: 273 [900/2589 (35%)]\tLoss: 388.116180\n",
      "Train Epoch: 273 [1200/2589 (46%)]\tLoss: 357.454926\n",
      "Train Epoch: 273 [1500/2589 (58%)]\tLoss: 208.345932\n",
      "Train Epoch: 273 [1800/2589 (70%)]\tLoss: 191.424423\n",
      "Train Epoch: 273 [2100/2589 (81%)]\tLoss: 336.652069\n",
      "Train Epoch: 273 [2400/2589 (93%)]\tLoss: 257.519318\n",
      "====> Epoch: 273 Average train loss: 276.3306\n",
      "====> Epoch: 273 Average test loss: 955.8962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 274 [0/2589 (0%)]\tLoss: 383.386353\n",
      "Train Epoch: 274 [300/2589 (12%)]\tLoss: 293.554321\n",
      "Train Epoch: 274 [600/2589 (23%)]\tLoss: 253.648575\n",
      "Train Epoch: 274 [900/2589 (35%)]\tLoss: 182.344513\n",
      "Train Epoch: 274 [1200/2589 (46%)]\tLoss: 301.977142\n",
      "Train Epoch: 274 [1500/2589 (58%)]\tLoss: 333.615997\n",
      "Train Epoch: 274 [1800/2589 (70%)]\tLoss: 264.892303\n",
      "Train Epoch: 274 [2100/2589 (81%)]\tLoss: 204.179092\n",
      "Train Epoch: 274 [2400/2589 (93%)]\tLoss: 409.985626\n",
      "====> Epoch: 274 Average train loss: 275.3371\n",
      "====> Epoch: 274 Average test loss: 969.7827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 275 [0/2589 (0%)]\tLoss: 232.349457\n",
      "Train Epoch: 275 [300/2589 (12%)]\tLoss: 243.711319\n",
      "Train Epoch: 275 [600/2589 (23%)]\tLoss: 188.855927\n",
      "Train Epoch: 275 [900/2589 (35%)]\tLoss: 275.856262\n",
      "Train Epoch: 275 [1200/2589 (46%)]\tLoss: 337.476776\n",
      "Train Epoch: 275 [1500/2589 (58%)]\tLoss: 333.635742\n",
      "Train Epoch: 275 [1800/2589 (70%)]\tLoss: 346.042267\n",
      "Train Epoch: 275 [2100/2589 (81%)]\tLoss: 217.934967\n",
      "Train Epoch: 275 [2400/2589 (93%)]\tLoss: 292.948364\n",
      "====> Epoch: 275 Average train loss: 274.4039\n",
      "====> Epoch: 275 Average test loss: 932.4879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 276 [0/2589 (0%)]\tLoss: 230.071365\n",
      "Train Epoch: 276 [300/2589 (12%)]\tLoss: 273.552582\n",
      "Train Epoch: 276 [600/2589 (23%)]\tLoss: 415.897736\n",
      "Train Epoch: 276 [900/2589 (35%)]\tLoss: 300.402283\n",
      "Train Epoch: 276 [1200/2589 (46%)]\tLoss: 324.390564\n",
      "Train Epoch: 276 [1500/2589 (58%)]\tLoss: 404.751953\n",
      "Train Epoch: 276 [1800/2589 (70%)]\tLoss: 382.732422\n",
      "Train Epoch: 276 [2100/2589 (81%)]\tLoss: 283.831757\n",
      "Train Epoch: 276 [2400/2589 (93%)]\tLoss: 218.667969\n",
      "====> Epoch: 276 Average train loss: 274.8249\n",
      "====> Epoch: 276 Average test loss: 951.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 277 [0/2589 (0%)]\tLoss: 308.197723\n",
      "Train Epoch: 277 [300/2589 (12%)]\tLoss: 293.219208\n",
      "Train Epoch: 277 [600/2589 (23%)]\tLoss: 386.042938\n",
      "Train Epoch: 277 [900/2589 (35%)]\tLoss: 242.179703\n",
      "Train Epoch: 277 [1200/2589 (46%)]\tLoss: 247.730331\n",
      "Train Epoch: 277 [1500/2589 (58%)]\tLoss: 239.912048\n",
      "Train Epoch: 277 [1800/2589 (70%)]\tLoss: 251.247314\n",
      "Train Epoch: 277 [2100/2589 (81%)]\tLoss: 249.890198\n",
      "Train Epoch: 277 [2400/2589 (93%)]\tLoss: 228.798187\n",
      "====> Epoch: 277 Average train loss: 260.3414\n",
      "====> Epoch: 277 Average test loss: 969.0207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 278 [0/2589 (0%)]\tLoss: 317.735779\n",
      "Train Epoch: 278 [300/2589 (12%)]\tLoss: 241.480133\n",
      "Train Epoch: 278 [600/2589 (23%)]\tLoss: 182.408920\n",
      "Train Epoch: 278 [900/2589 (35%)]\tLoss: 301.003052\n",
      "Train Epoch: 278 [1200/2589 (46%)]\tLoss: 225.673767\n",
      "Train Epoch: 278 [1500/2589 (58%)]\tLoss: 284.613647\n",
      "Train Epoch: 278 [1800/2589 (70%)]\tLoss: 219.798340\n",
      "Train Epoch: 278 [2100/2589 (81%)]\tLoss: 267.502228\n",
      "Train Epoch: 278 [2400/2589 (93%)]\tLoss: 285.606232\n",
      "====> Epoch: 278 Average train loss: 267.7797\n",
      "====> Epoch: 278 Average test loss: 957.6791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 279 [0/2589 (0%)]\tLoss: 388.783112\n",
      "Train Epoch: 279 [300/2589 (12%)]\tLoss: 297.135223\n",
      "Train Epoch: 279 [600/2589 (23%)]\tLoss: 269.723236\n",
      "Train Epoch: 279 [900/2589 (35%)]\tLoss: 272.151489\n",
      "Train Epoch: 279 [1200/2589 (46%)]\tLoss: 250.724854\n",
      "Train Epoch: 279 [1500/2589 (58%)]\tLoss: 308.124939\n",
      "Train Epoch: 279 [1800/2589 (70%)]\tLoss: 291.094330\n",
      "Train Epoch: 279 [2100/2589 (81%)]\tLoss: 259.635529\n",
      "Train Epoch: 279 [2400/2589 (93%)]\tLoss: 230.680557\n",
      "====> Epoch: 279 Average train loss: 266.3253\n",
      "====> Epoch: 279 Average test loss: 921.5095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 280 [0/2589 (0%)]\tLoss: 226.886993\n",
      "Train Epoch: 280 [300/2589 (12%)]\tLoss: 233.493103\n",
      "Train Epoch: 280 [600/2589 (23%)]\tLoss: 214.172394\n",
      "Train Epoch: 280 [900/2589 (35%)]\tLoss: 210.156555\n",
      "Train Epoch: 280 [1200/2589 (46%)]\tLoss: 266.521057\n",
      "Train Epoch: 280 [1500/2589 (58%)]\tLoss: 361.916718\n",
      "Train Epoch: 280 [1800/2589 (70%)]\tLoss: 235.173019\n",
      "Train Epoch: 280 [2100/2589 (81%)]\tLoss: 263.011169\n",
      "Train Epoch: 280 [2400/2589 (93%)]\tLoss: 427.570801\n",
      "====> Epoch: 280 Average train loss: 270.0631\n",
      "====> Epoch: 280 Average test loss: 947.5970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 281 [0/2589 (0%)]\tLoss: 312.869751\n",
      "Train Epoch: 281 [300/2589 (12%)]\tLoss: 292.169464\n",
      "Train Epoch: 281 [600/2589 (23%)]\tLoss: 277.035431\n",
      "Train Epoch: 281 [900/2589 (35%)]\tLoss: 190.032486\n",
      "Train Epoch: 281 [1200/2589 (46%)]\tLoss: 348.942444\n",
      "Train Epoch: 281 [1500/2589 (58%)]\tLoss: 268.300812\n",
      "Train Epoch: 281 [1800/2589 (70%)]\tLoss: 224.423904\n",
      "Train Epoch: 281 [2100/2589 (81%)]\tLoss: 272.228577\n",
      "Train Epoch: 281 [2400/2589 (93%)]\tLoss: 275.911041\n",
      "====> Epoch: 281 Average train loss: 259.9094\n",
      "====> Epoch: 281 Average test loss: 952.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 282 [0/2589 (0%)]\tLoss: 227.653748\n",
      "Train Epoch: 282 [300/2589 (12%)]\tLoss: 174.429993\n",
      "Train Epoch: 282 [600/2589 (23%)]\tLoss: 309.443054\n",
      "Train Epoch: 282 [900/2589 (35%)]\tLoss: 230.360886\n",
      "Train Epoch: 282 [1200/2589 (46%)]\tLoss: 285.493317\n",
      "Train Epoch: 282 [1500/2589 (58%)]\tLoss: 362.813751\n",
      "Train Epoch: 282 [1800/2589 (70%)]\tLoss: 313.660156\n",
      "Train Epoch: 282 [2100/2589 (81%)]\tLoss: 189.960266\n",
      "Train Epoch: 282 [2400/2589 (93%)]\tLoss: 336.736969\n",
      "====> Epoch: 282 Average train loss: 270.5743\n",
      "====> Epoch: 282 Average test loss: 993.0489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 283 [0/2589 (0%)]\tLoss: 278.029572\n",
      "Train Epoch: 283 [300/2589 (12%)]\tLoss: 288.821564\n",
      "Train Epoch: 283 [600/2589 (23%)]\tLoss: 187.928452\n",
      "Train Epoch: 283 [900/2589 (35%)]\tLoss: 286.776215\n",
      "Train Epoch: 283 [1200/2589 (46%)]\tLoss: 369.210449\n",
      "Train Epoch: 283 [1500/2589 (58%)]\tLoss: 232.098389\n",
      "Train Epoch: 283 [1800/2589 (70%)]\tLoss: 281.265503\n",
      "Train Epoch: 283 [2100/2589 (81%)]\tLoss: 434.214966\n",
      "Train Epoch: 283 [2400/2589 (93%)]\tLoss: 308.559601\n",
      "====> Epoch: 283 Average train loss: 271.7831\n",
      "====> Epoch: 283 Average test loss: 943.5726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 284 [0/2589 (0%)]\tLoss: 175.616348\n",
      "Train Epoch: 284 [300/2589 (12%)]\tLoss: 225.746475\n",
      "Train Epoch: 284 [600/2589 (23%)]\tLoss: 384.497223\n",
      "Train Epoch: 284 [900/2589 (35%)]\tLoss: 210.274963\n",
      "Train Epoch: 284 [1200/2589 (46%)]\tLoss: 211.888840\n",
      "Train Epoch: 284 [1500/2589 (58%)]\tLoss: 201.098633\n",
      "Train Epoch: 284 [1800/2589 (70%)]\tLoss: 316.686249\n",
      "Train Epoch: 284 [2100/2589 (81%)]\tLoss: 187.104385\n",
      "Train Epoch: 284 [2400/2589 (93%)]\tLoss: 231.340988\n",
      "====> Epoch: 284 Average train loss: 264.6139\n",
      "====> Epoch: 284 Average test loss: 953.7394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 285 [0/2589 (0%)]\tLoss: 268.435913\n",
      "Train Epoch: 285 [300/2589 (12%)]\tLoss: 301.913544\n",
      "Train Epoch: 285 [600/2589 (23%)]\tLoss: 222.065414\n",
      "Train Epoch: 285 [900/2589 (35%)]\tLoss: 367.511383\n",
      "Train Epoch: 285 [1200/2589 (46%)]\tLoss: 283.076782\n",
      "Train Epoch: 285 [1500/2589 (58%)]\tLoss: 210.900360\n",
      "Train Epoch: 285 [1800/2589 (70%)]\tLoss: 236.502716\n",
      "Train Epoch: 285 [2100/2589 (81%)]\tLoss: 235.459564\n",
      "Train Epoch: 285 [2400/2589 (93%)]\tLoss: 299.403625\n",
      "====> Epoch: 285 Average train loss: 277.4544\n",
      "====> Epoch: 285 Average test loss: 928.6539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 286 [0/2589 (0%)]\tLoss: 260.143982\n",
      "Train Epoch: 286 [300/2589 (12%)]\tLoss: 218.712341\n",
      "Train Epoch: 286 [600/2589 (23%)]\tLoss: 265.277252\n",
      "Train Epoch: 286 [900/2589 (35%)]\tLoss: 217.329132\n",
      "Train Epoch: 286 [1200/2589 (46%)]\tLoss: 244.210693\n",
      "Train Epoch: 286 [1500/2589 (58%)]\tLoss: 225.082840\n",
      "Train Epoch: 286 [1800/2589 (70%)]\tLoss: 350.084259\n",
      "Train Epoch: 286 [2100/2589 (81%)]\tLoss: 241.578049\n",
      "Train Epoch: 286 [2400/2589 (93%)]\tLoss: 433.837799\n",
      "====> Epoch: 286 Average train loss: 270.0543\n",
      "====> Epoch: 286 Average test loss: 931.7021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 287 [0/2589 (0%)]\tLoss: 251.712662\n",
      "Train Epoch: 287 [300/2589 (12%)]\tLoss: 235.356018\n",
      "Train Epoch: 287 [600/2589 (23%)]\tLoss: 247.597610\n",
      "Train Epoch: 287 [900/2589 (35%)]\tLoss: 179.994598\n",
      "Train Epoch: 287 [1200/2589 (46%)]\tLoss: 176.812195\n",
      "Train Epoch: 287 [1500/2589 (58%)]\tLoss: 275.361145\n",
      "Train Epoch: 287 [1800/2589 (70%)]\tLoss: 198.713074\n",
      "Train Epoch: 287 [2100/2589 (81%)]\tLoss: 277.794739\n",
      "Train Epoch: 287 [2400/2589 (93%)]\tLoss: 339.207520\n",
      "====> Epoch: 287 Average train loss: 263.2057\n",
      "====> Epoch: 287 Average test loss: 946.0688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 288 [0/2589 (0%)]\tLoss: 441.250549\n",
      "Train Epoch: 288 [300/2589 (12%)]\tLoss: 318.855164\n",
      "Train Epoch: 288 [600/2589 (23%)]\tLoss: 234.560120\n",
      "Train Epoch: 288 [900/2589 (35%)]\tLoss: 288.727112\n",
      "Train Epoch: 288 [1200/2589 (46%)]\tLoss: 249.545700\n",
      "Train Epoch: 288 [1500/2589 (58%)]\tLoss: 366.298920\n",
      "Train Epoch: 288 [1800/2589 (70%)]\tLoss: 237.724579\n",
      "Train Epoch: 288 [2100/2589 (81%)]\tLoss: 304.012390\n",
      "Train Epoch: 288 [2400/2589 (93%)]\tLoss: 276.296692\n",
      "====> Epoch: 288 Average train loss: 269.5708\n",
      "====> Epoch: 288 Average test loss: 965.2894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 289 [0/2589 (0%)]\tLoss: 232.491669\n",
      "Train Epoch: 289 [300/2589 (12%)]\tLoss: 252.325302\n",
      "Train Epoch: 289 [600/2589 (23%)]\tLoss: 157.922913\n",
      "Train Epoch: 289 [900/2589 (35%)]\tLoss: 242.935257\n",
      "Train Epoch: 289 [1200/2589 (46%)]\tLoss: 187.334869\n",
      "Train Epoch: 289 [1500/2589 (58%)]\tLoss: 252.668610\n",
      "Train Epoch: 289 [1800/2589 (70%)]\tLoss: 223.685516\n",
      "Train Epoch: 289 [2100/2589 (81%)]\tLoss: 373.044647\n",
      "Train Epoch: 289 [2400/2589 (93%)]\tLoss: 291.825989\n",
      "====> Epoch: 289 Average train loss: 262.7905\n",
      "====> Epoch: 289 Average test loss: 948.3494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 290 [0/2589 (0%)]\tLoss: 294.165039\n",
      "Train Epoch: 290 [300/2589 (12%)]\tLoss: 234.105255\n",
      "Train Epoch: 290 [600/2589 (23%)]\tLoss: 250.731918\n",
      "Train Epoch: 290 [900/2589 (35%)]\tLoss: 229.852371\n",
      "Train Epoch: 290 [1200/2589 (46%)]\tLoss: 484.742615\n",
      "Train Epoch: 290 [1500/2589 (58%)]\tLoss: 232.190567\n",
      "Train Epoch: 290 [1800/2589 (70%)]\tLoss: 216.098892\n",
      "Train Epoch: 290 [2100/2589 (81%)]\tLoss: 291.156738\n",
      "Train Epoch: 290 [2400/2589 (93%)]\tLoss: 312.106873\n",
      "====> Epoch: 290 Average train loss: 265.4538\n",
      "====> Epoch: 290 Average test loss: 936.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 291 [0/2589 (0%)]\tLoss: 276.662079\n",
      "Train Epoch: 291 [300/2589 (12%)]\tLoss: 464.832947\n",
      "Train Epoch: 291 [600/2589 (23%)]\tLoss: 283.939392\n",
      "Train Epoch: 291 [900/2589 (35%)]\tLoss: 304.090698\n",
      "Train Epoch: 291 [1200/2589 (46%)]\tLoss: 318.949677\n",
      "Train Epoch: 291 [1500/2589 (58%)]\tLoss: 228.107025\n",
      "Train Epoch: 291 [1800/2589 (70%)]\tLoss: 240.134445\n",
      "Train Epoch: 291 [2100/2589 (81%)]\tLoss: 322.487122\n",
      "Train Epoch: 291 [2400/2589 (93%)]\tLoss: 278.802704\n",
      "====> Epoch: 291 Average train loss: 273.2462\n",
      "====> Epoch: 291 Average test loss: 956.8455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 292 [0/2589 (0%)]\tLoss: 238.805923\n",
      "Train Epoch: 292 [300/2589 (12%)]\tLoss: 263.349304\n",
      "Train Epoch: 292 [600/2589 (23%)]\tLoss: 252.448883\n",
      "Train Epoch: 292 [900/2589 (35%)]\tLoss: 191.507370\n",
      "Train Epoch: 292 [1200/2589 (46%)]\tLoss: 405.488159\n",
      "Train Epoch: 292 [1500/2589 (58%)]\tLoss: 243.716461\n",
      "Train Epoch: 292 [1800/2589 (70%)]\tLoss: 267.137726\n",
      "Train Epoch: 292 [2100/2589 (81%)]\tLoss: 208.406158\n",
      "Train Epoch: 292 [2400/2589 (93%)]\tLoss: 255.443817\n",
      "====> Epoch: 292 Average train loss: 261.7479\n",
      "====> Epoch: 292 Average test loss: 935.1797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 293 [0/2589 (0%)]\tLoss: 175.280090\n",
      "Train Epoch: 293 [300/2589 (12%)]\tLoss: 312.418274\n",
      "Train Epoch: 293 [600/2589 (23%)]\tLoss: 252.632645\n",
      "Train Epoch: 293 [900/2589 (35%)]\tLoss: 224.448105\n",
      "Train Epoch: 293 [1200/2589 (46%)]\tLoss: 272.844269\n",
      "Train Epoch: 293 [1500/2589 (58%)]\tLoss: 143.715027\n",
      "Train Epoch: 293 [1800/2589 (70%)]\tLoss: 212.146347\n",
      "Train Epoch: 293 [2100/2589 (81%)]\tLoss: 210.382782\n",
      "Train Epoch: 293 [2400/2589 (93%)]\tLoss: 286.486389\n",
      "====> Epoch: 293 Average train loss: 268.3186\n",
      "====> Epoch: 293 Average test loss: 945.0760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 294 [0/2589 (0%)]\tLoss: 202.488007\n",
      "Train Epoch: 294 [300/2589 (12%)]\tLoss: 297.489197\n",
      "Train Epoch: 294 [600/2589 (23%)]\tLoss: 215.661423\n",
      "Train Epoch: 294 [900/2589 (35%)]\tLoss: 247.322769\n",
      "Train Epoch: 294 [1200/2589 (46%)]\tLoss: 182.565933\n",
      "Train Epoch: 294 [1500/2589 (58%)]\tLoss: 244.889343\n",
      "Train Epoch: 294 [1800/2589 (70%)]\tLoss: 225.302490\n",
      "Train Epoch: 294 [2100/2589 (81%)]\tLoss: 278.745422\n",
      "Train Epoch: 294 [2400/2589 (93%)]\tLoss: 502.258331\n",
      "====> Epoch: 294 Average train loss: 277.9409\n",
      "====> Epoch: 294 Average test loss: 967.3154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 295 [0/2589 (0%)]\tLoss: 300.055115\n",
      "Train Epoch: 295 [300/2589 (12%)]\tLoss: 178.621735\n",
      "Train Epoch: 295 [600/2589 (23%)]\tLoss: 238.390335\n",
      "Train Epoch: 295 [900/2589 (35%)]\tLoss: 394.548859\n",
      "Train Epoch: 295 [1200/2589 (46%)]\tLoss: 270.325806\n",
      "Train Epoch: 295 [1500/2589 (58%)]\tLoss: 316.548767\n",
      "Train Epoch: 295 [1800/2589 (70%)]\tLoss: 442.004547\n",
      "Train Epoch: 295 [2100/2589 (81%)]\tLoss: 266.387848\n",
      "Train Epoch: 295 [2400/2589 (93%)]\tLoss: 238.829910\n",
      "====> Epoch: 295 Average train loss: 281.1856\n",
      "====> Epoch: 295 Average test loss: 945.3422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 296 [0/2589 (0%)]\tLoss: 163.242172\n",
      "Train Epoch: 296 [300/2589 (12%)]\tLoss: 448.872009\n",
      "Train Epoch: 296 [600/2589 (23%)]\tLoss: 260.761932\n",
      "Train Epoch: 296 [900/2589 (35%)]\tLoss: 220.661240\n",
      "Train Epoch: 296 [1200/2589 (46%)]\tLoss: 271.416565\n",
      "Train Epoch: 296 [1500/2589 (58%)]\tLoss: 334.821014\n",
      "Train Epoch: 296 [1800/2589 (70%)]\tLoss: 317.891296\n",
      "Train Epoch: 296 [2100/2589 (81%)]\tLoss: 207.614258\n",
      "Train Epoch: 296 [2400/2589 (93%)]\tLoss: 265.008850\n",
      "====> Epoch: 296 Average train loss: 267.5939\n",
      "====> Epoch: 296 Average test loss: 946.3652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 297 [0/2589 (0%)]\tLoss: 221.086380\n",
      "Train Epoch: 297 [300/2589 (12%)]\tLoss: 235.858994\n",
      "Train Epoch: 297 [600/2589 (23%)]\tLoss: 191.649429\n",
      "Train Epoch: 297 [900/2589 (35%)]\tLoss: 261.424713\n",
      "Train Epoch: 297 [1200/2589 (46%)]\tLoss: 327.839966\n",
      "Train Epoch: 297 [1500/2589 (58%)]\tLoss: 360.156891\n",
      "Train Epoch: 297 [1800/2589 (70%)]\tLoss: 408.746124\n",
      "Train Epoch: 297 [2100/2589 (81%)]\tLoss: 353.776794\n",
      "Train Epoch: 297 [2400/2589 (93%)]\tLoss: 244.410782\n",
      "====> Epoch: 297 Average train loss: 271.2309\n",
      "====> Epoch: 297 Average test loss: 944.8759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 298 [0/2589 (0%)]\tLoss: 279.171173\n",
      "Train Epoch: 298 [300/2589 (12%)]\tLoss: 313.528442\n",
      "Train Epoch: 298 [600/2589 (23%)]\tLoss: 223.231003\n",
      "Train Epoch: 298 [900/2589 (35%)]\tLoss: 305.428680\n",
      "Train Epoch: 298 [1200/2589 (46%)]\tLoss: 193.754776\n",
      "Train Epoch: 298 [1500/2589 (58%)]\tLoss: 251.414795\n",
      "Train Epoch: 298 [1800/2589 (70%)]\tLoss: 284.200378\n",
      "Train Epoch: 298 [2100/2589 (81%)]\tLoss: 291.696136\n",
      "Train Epoch: 298 [2400/2589 (93%)]\tLoss: 221.979568\n",
      "====> Epoch: 298 Average train loss: 272.0146\n",
      "====> Epoch: 298 Average test loss: 967.4447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 299 [0/2589 (0%)]\tLoss: 321.608856\n",
      "Train Epoch: 299 [300/2589 (12%)]\tLoss: 242.658859\n",
      "Train Epoch: 299 [600/2589 (23%)]\tLoss: 265.754425\n",
      "Train Epoch: 299 [900/2589 (35%)]\tLoss: 246.378601\n",
      "Train Epoch: 299 [1200/2589 (46%)]\tLoss: 293.714874\n",
      "Train Epoch: 299 [1500/2589 (58%)]\tLoss: 248.692780\n",
      "Train Epoch: 299 [1800/2589 (70%)]\tLoss: 432.947601\n",
      "Train Epoch: 299 [2100/2589 (81%)]\tLoss: 162.436234\n",
      "Train Epoch: 299 [2400/2589 (93%)]\tLoss: 245.364563\n",
      "====> Epoch: 299 Average train loss: 264.0948\n",
      "====> Epoch: 299 Average test loss: 953.7415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 300 [0/2589 (0%)]\tLoss: 254.570450\n",
      "Train Epoch: 300 [300/2589 (12%)]\tLoss: 387.399933\n",
      "Train Epoch: 300 [600/2589 (23%)]\tLoss: 358.679688\n",
      "Train Epoch: 300 [900/2589 (35%)]\tLoss: 225.940094\n",
      "Train Epoch: 300 [1200/2589 (46%)]\tLoss: 307.719696\n",
      "Train Epoch: 300 [1500/2589 (58%)]\tLoss: 397.856720\n",
      "Train Epoch: 300 [1800/2589 (70%)]\tLoss: 235.107376\n",
      "Train Epoch: 300 [2100/2589 (81%)]\tLoss: 254.176895\n",
      "Train Epoch: 300 [2400/2589 (93%)]\tLoss: 247.827942\n",
      "====> Epoch: 300 Average train loss: 261.3290\n",
      "====> Epoch: 300 Average test loss: 952.8093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 301 [0/2589 (0%)]\tLoss: 285.596619\n",
      "Train Epoch: 301 [300/2589 (12%)]\tLoss: 326.823364\n",
      "Train Epoch: 301 [600/2589 (23%)]\tLoss: 290.023438\n",
      "Train Epoch: 301 [900/2589 (35%)]\tLoss: 228.560928\n",
      "Train Epoch: 301 [1200/2589 (46%)]\tLoss: 298.259247\n",
      "Train Epoch: 301 [1500/2589 (58%)]\tLoss: 304.756714\n",
      "Train Epoch: 301 [1800/2589 (70%)]\tLoss: 233.602036\n",
      "Train Epoch: 301 [2100/2589 (81%)]\tLoss: 224.332993\n",
      "Train Epoch: 301 [2400/2589 (93%)]\tLoss: 220.329620\n",
      "====> Epoch: 301 Average train loss: 268.8899\n",
      "====> Epoch: 301 Average test loss: 939.1192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 302 [0/2589 (0%)]\tLoss: 334.599670\n",
      "Train Epoch: 302 [300/2589 (12%)]\tLoss: 299.239136\n",
      "Train Epoch: 302 [600/2589 (23%)]\tLoss: 207.500763\n",
      "Train Epoch: 302 [900/2589 (35%)]\tLoss: 235.170471\n",
      "Train Epoch: 302 [1200/2589 (46%)]\tLoss: 211.617615\n",
      "Train Epoch: 302 [1500/2589 (58%)]\tLoss: 290.511108\n",
      "Train Epoch: 302 [1800/2589 (70%)]\tLoss: 176.950653\n",
      "Train Epoch: 302 [2100/2589 (81%)]\tLoss: 270.049225\n",
      "Train Epoch: 302 [2400/2589 (93%)]\tLoss: 245.604996\n",
      "====> Epoch: 302 Average train loss: 262.5023\n",
      "====> Epoch: 302 Average test loss: 941.4927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 303 [0/2589 (0%)]\tLoss: 313.083771\n",
      "Train Epoch: 303 [300/2589 (12%)]\tLoss: 339.163513\n",
      "Train Epoch: 303 [600/2589 (23%)]\tLoss: 212.660873\n",
      "Train Epoch: 303 [900/2589 (35%)]\tLoss: 265.415466\n",
      "Train Epoch: 303 [1200/2589 (46%)]\tLoss: 349.063599\n",
      "Train Epoch: 303 [1500/2589 (58%)]\tLoss: 234.779984\n",
      "Train Epoch: 303 [1800/2589 (70%)]\tLoss: 369.389740\n",
      "Train Epoch: 303 [2100/2589 (81%)]\tLoss: 503.574921\n",
      "Train Epoch: 303 [2400/2589 (93%)]\tLoss: 245.232010\n",
      "====> Epoch: 303 Average train loss: 277.1310\n",
      "====> Epoch: 303 Average test loss: 949.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 304 [0/2589 (0%)]\tLoss: 206.443802\n",
      "Train Epoch: 304 [300/2589 (12%)]\tLoss: 296.411407\n",
      "Train Epoch: 304 [600/2589 (23%)]\tLoss: 372.045990\n",
      "Train Epoch: 304 [900/2589 (35%)]\tLoss: 245.587097\n",
      "Train Epoch: 304 [1200/2589 (46%)]\tLoss: 223.990936\n",
      "Train Epoch: 304 [1500/2589 (58%)]\tLoss: 254.534683\n",
      "Train Epoch: 304 [1800/2589 (70%)]\tLoss: 320.184052\n",
      "Train Epoch: 304 [2100/2589 (81%)]\tLoss: 213.316010\n",
      "Train Epoch: 304 [2400/2589 (93%)]\tLoss: 227.072922\n",
      "====> Epoch: 304 Average train loss: 266.9339\n",
      "====> Epoch: 304 Average test loss: 954.1442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 305 [0/2589 (0%)]\tLoss: 281.785767\n",
      "Train Epoch: 305 [300/2589 (12%)]\tLoss: 185.008530\n",
      "Train Epoch: 305 [600/2589 (23%)]\tLoss: 285.504700\n",
      "Train Epoch: 305 [900/2589 (35%)]\tLoss: 379.101349\n",
      "Train Epoch: 305 [1200/2589 (46%)]\tLoss: 191.445602\n",
      "Train Epoch: 305 [1500/2589 (58%)]\tLoss: 213.872238\n",
      "Train Epoch: 305 [1800/2589 (70%)]\tLoss: 175.254456\n",
      "Train Epoch: 305 [2100/2589 (81%)]\tLoss: 286.404846\n",
      "Train Epoch: 305 [2400/2589 (93%)]\tLoss: 301.976440\n",
      "====> Epoch: 305 Average train loss: 271.0514\n",
      "====> Epoch: 305 Average test loss: 955.8581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 306 [0/2589 (0%)]\tLoss: 217.915298\n",
      "Train Epoch: 306 [300/2589 (12%)]\tLoss: 194.961884\n",
      "Train Epoch: 306 [600/2589 (23%)]\tLoss: 295.069946\n",
      "Train Epoch: 306 [900/2589 (35%)]\tLoss: 246.467194\n",
      "Train Epoch: 306 [1200/2589 (46%)]\tLoss: 375.412262\n",
      "Train Epoch: 306 [1500/2589 (58%)]\tLoss: 209.328140\n",
      "Train Epoch: 306 [1800/2589 (70%)]\tLoss: 239.269318\n",
      "Train Epoch: 306 [2100/2589 (81%)]\tLoss: 287.133575\n",
      "Train Epoch: 306 [2400/2589 (93%)]\tLoss: 182.525131\n",
      "====> Epoch: 306 Average train loss: 262.4417\n",
      "====> Epoch: 306 Average test loss: 940.1801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 307 [0/2589 (0%)]\tLoss: 302.141571\n",
      "Train Epoch: 307 [300/2589 (12%)]\tLoss: 272.216522\n",
      "Train Epoch: 307 [600/2589 (23%)]\tLoss: 570.036560\n",
      "Train Epoch: 307 [900/2589 (35%)]\tLoss: 203.044907\n",
      "Train Epoch: 307 [1200/2589 (46%)]\tLoss: 330.150116\n",
      "Train Epoch: 307 [1500/2589 (58%)]\tLoss: 269.382904\n",
      "Train Epoch: 307 [1800/2589 (70%)]\tLoss: 311.288269\n",
      "Train Epoch: 307 [2100/2589 (81%)]\tLoss: 349.813843\n",
      "Train Epoch: 307 [2400/2589 (93%)]\tLoss: 245.892532\n",
      "====> Epoch: 307 Average train loss: 259.9726\n",
      "====> Epoch: 307 Average test loss: 951.3405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 308 [0/2589 (0%)]\tLoss: 405.060211\n",
      "Train Epoch: 308 [300/2589 (12%)]\tLoss: 345.814240\n",
      "Train Epoch: 308 [600/2589 (23%)]\tLoss: 325.103577\n",
      "Train Epoch: 308 [900/2589 (35%)]\tLoss: 211.580292\n",
      "Train Epoch: 308 [1200/2589 (46%)]\tLoss: 337.570435\n",
      "Train Epoch: 308 [1500/2589 (58%)]\tLoss: 386.139557\n",
      "Train Epoch: 308 [1800/2589 (70%)]\tLoss: 243.427261\n",
      "Train Epoch: 308 [2100/2589 (81%)]\tLoss: 205.161957\n",
      "Train Epoch: 308 [2400/2589 (93%)]\tLoss: 262.043671\n",
      "====> Epoch: 308 Average train loss: 266.1367\n",
      "====> Epoch: 308 Average test loss: 944.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 309 [0/2589 (0%)]\tLoss: 276.542511\n",
      "Train Epoch: 309 [300/2589 (12%)]\tLoss: 343.339722\n",
      "Train Epoch: 309 [600/2589 (23%)]\tLoss: 250.493439\n",
      "Train Epoch: 309 [900/2589 (35%)]\tLoss: 239.723389\n",
      "Train Epoch: 309 [1200/2589 (46%)]\tLoss: 253.964310\n",
      "Train Epoch: 309 [1500/2589 (58%)]\tLoss: 283.303589\n",
      "Train Epoch: 309 [1800/2589 (70%)]\tLoss: 210.053406\n",
      "Train Epoch: 309 [2100/2589 (81%)]\tLoss: 275.619415\n",
      "Train Epoch: 309 [2400/2589 (93%)]\tLoss: 245.724762\n",
      "====> Epoch: 309 Average train loss: 273.5811\n",
      "====> Epoch: 309 Average test loss: 952.0250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 310 [0/2589 (0%)]\tLoss: 215.022659\n",
      "Train Epoch: 310 [300/2589 (12%)]\tLoss: 327.990204\n",
      "Train Epoch: 310 [600/2589 (23%)]\tLoss: 253.480774\n",
      "Train Epoch: 310 [900/2589 (35%)]\tLoss: 260.084686\n",
      "Train Epoch: 310 [1200/2589 (46%)]\tLoss: 385.250793\n",
      "Train Epoch: 310 [1500/2589 (58%)]\tLoss: 288.428131\n",
      "Train Epoch: 310 [1800/2589 (70%)]\tLoss: 245.776581\n",
      "Train Epoch: 310 [2100/2589 (81%)]\tLoss: 194.939972\n",
      "Train Epoch: 310 [2400/2589 (93%)]\tLoss: 232.811951\n",
      "====> Epoch: 310 Average train loss: 256.9783\n",
      "====> Epoch: 310 Average test loss: 940.8093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 311 [0/2589 (0%)]\tLoss: 264.214935\n",
      "Train Epoch: 311 [300/2589 (12%)]\tLoss: 225.590561\n",
      "Train Epoch: 311 [600/2589 (23%)]\tLoss: 247.509354\n",
      "Train Epoch: 311 [900/2589 (35%)]\tLoss: 237.869141\n",
      "Train Epoch: 311 [1200/2589 (46%)]\tLoss: 265.593933\n",
      "Train Epoch: 311 [1500/2589 (58%)]\tLoss: 208.475525\n",
      "Train Epoch: 311 [1800/2589 (70%)]\tLoss: 345.942108\n",
      "Train Epoch: 311 [2100/2589 (81%)]\tLoss: 261.473083\n",
      "Train Epoch: 311 [2400/2589 (93%)]\tLoss: 171.706818\n",
      "====> Epoch: 311 Average train loss: 255.6692\n",
      "====> Epoch: 311 Average test loss: 972.2814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 312 [0/2589 (0%)]\tLoss: 300.790192\n",
      "Train Epoch: 312 [300/2589 (12%)]\tLoss: 325.384949\n",
      "Train Epoch: 312 [600/2589 (23%)]\tLoss: 315.487823\n",
      "Train Epoch: 312 [900/2589 (35%)]\tLoss: 219.858994\n",
      "Train Epoch: 312 [1200/2589 (46%)]\tLoss: 333.735443\n",
      "Train Epoch: 312 [1500/2589 (58%)]\tLoss: 270.851746\n",
      "Train Epoch: 312 [1800/2589 (70%)]\tLoss: 240.236008\n",
      "Train Epoch: 312 [2100/2589 (81%)]\tLoss: 392.169312\n",
      "Train Epoch: 312 [2400/2589 (93%)]\tLoss: 402.894623\n",
      "====> Epoch: 312 Average train loss: 269.1949\n",
      "====> Epoch: 312 Average test loss: 928.4889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 313 [0/2589 (0%)]\tLoss: 309.900024\n",
      "Train Epoch: 313 [300/2589 (12%)]\tLoss: 322.041351\n",
      "Train Epoch: 313 [600/2589 (23%)]\tLoss: 306.042694\n",
      "Train Epoch: 313 [900/2589 (35%)]\tLoss: 310.017303\n",
      "Train Epoch: 313 [1200/2589 (46%)]\tLoss: 215.568588\n",
      "Train Epoch: 313 [1500/2589 (58%)]\tLoss: 255.421356\n",
      "Train Epoch: 313 [1800/2589 (70%)]\tLoss: 206.935150\n",
      "Train Epoch: 313 [2100/2589 (81%)]\tLoss: 294.337769\n",
      "Train Epoch: 313 [2400/2589 (93%)]\tLoss: 213.381210\n",
      "====> Epoch: 313 Average train loss: 257.1447\n",
      "====> Epoch: 313 Average test loss: 938.5498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 314 [0/2589 (0%)]\tLoss: 211.883377\n",
      "Train Epoch: 314 [300/2589 (12%)]\tLoss: 191.652969\n",
      "Train Epoch: 314 [600/2589 (23%)]\tLoss: 271.885559\n",
      "Train Epoch: 314 [900/2589 (35%)]\tLoss: 146.561722\n",
      "Train Epoch: 314 [1200/2589 (46%)]\tLoss: 275.492706\n",
      "Train Epoch: 314 [1500/2589 (58%)]\tLoss: 236.598221\n",
      "Train Epoch: 314 [1800/2589 (70%)]\tLoss: 267.797485\n",
      "Train Epoch: 314 [2100/2589 (81%)]\tLoss: 221.463196\n",
      "Train Epoch: 314 [2400/2589 (93%)]\tLoss: 249.374695\n",
      "====> Epoch: 314 Average train loss: 265.3014\n",
      "====> Epoch: 314 Average test loss: 942.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 315 [0/2589 (0%)]\tLoss: 366.413605\n",
      "Train Epoch: 315 [300/2589 (12%)]\tLoss: 289.983398\n",
      "Train Epoch: 315 [600/2589 (23%)]\tLoss: 277.613678\n",
      "Train Epoch: 315 [900/2589 (35%)]\tLoss: 300.278137\n",
      "Train Epoch: 315 [1200/2589 (46%)]\tLoss: 208.690979\n",
      "Train Epoch: 315 [1500/2589 (58%)]\tLoss: 234.969681\n",
      "Train Epoch: 315 [1800/2589 (70%)]\tLoss: 245.473404\n",
      "Train Epoch: 315 [2100/2589 (81%)]\tLoss: 274.098267\n",
      "Train Epoch: 315 [2400/2589 (93%)]\tLoss: 384.600555\n",
      "====> Epoch: 315 Average train loss: 269.3150\n",
      "====> Epoch: 315 Average test loss: 933.4404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 316 [0/2589 (0%)]\tLoss: 278.325256\n",
      "Train Epoch: 316 [300/2589 (12%)]\tLoss: 294.433868\n",
      "Train Epoch: 316 [600/2589 (23%)]\tLoss: 187.725128\n",
      "Train Epoch: 316 [900/2589 (35%)]\tLoss: 149.157333\n",
      "Train Epoch: 316 [1200/2589 (46%)]\tLoss: 185.686386\n",
      "Train Epoch: 316 [1500/2589 (58%)]\tLoss: 305.711975\n",
      "Train Epoch: 316 [1800/2589 (70%)]\tLoss: 212.769470\n",
      "Train Epoch: 316 [2100/2589 (81%)]\tLoss: 189.913330\n",
      "Train Epoch: 316 [2400/2589 (93%)]\tLoss: 223.433350\n",
      "====> Epoch: 316 Average train loss: 257.7905\n",
      "====> Epoch: 316 Average test loss: 932.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 317 [0/2589 (0%)]\tLoss: 213.623367\n",
      "Train Epoch: 317 [300/2589 (12%)]\tLoss: 247.876633\n",
      "Train Epoch: 317 [600/2589 (23%)]\tLoss: 191.012848\n",
      "Train Epoch: 317 [900/2589 (35%)]\tLoss: 211.932693\n",
      "Train Epoch: 317 [1200/2589 (46%)]\tLoss: 407.792694\n",
      "Train Epoch: 317 [1500/2589 (58%)]\tLoss: 293.362610\n",
      "Train Epoch: 317 [1800/2589 (70%)]\tLoss: 256.184326\n",
      "Train Epoch: 317 [2100/2589 (81%)]\tLoss: 363.324280\n",
      "Train Epoch: 317 [2400/2589 (93%)]\tLoss: 203.063461\n",
      "====> Epoch: 317 Average train loss: 261.5942\n",
      "====> Epoch: 317 Average test loss: 943.2633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 318 [0/2589 (0%)]\tLoss: 188.919983\n",
      "Train Epoch: 318 [300/2589 (12%)]\tLoss: 252.595566\n",
      "Train Epoch: 318 [600/2589 (23%)]\tLoss: 284.345978\n",
      "Train Epoch: 318 [900/2589 (35%)]\tLoss: 222.784164\n",
      "Train Epoch: 318 [1200/2589 (46%)]\tLoss: 262.367279\n",
      "Train Epoch: 318 [1500/2589 (58%)]\tLoss: 388.046600\n",
      "Train Epoch: 318 [1800/2589 (70%)]\tLoss: 259.700470\n",
      "Train Epoch: 318 [2100/2589 (81%)]\tLoss: 256.785065\n",
      "Train Epoch: 318 [2400/2589 (93%)]\tLoss: 270.049286\n",
      "====> Epoch: 318 Average train loss: 261.8507\n",
      "====> Epoch: 318 Average test loss: 937.0328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 319 [0/2589 (0%)]\tLoss: 256.292206\n",
      "Train Epoch: 319 [300/2589 (12%)]\tLoss: 320.854675\n",
      "Train Epoch: 319 [600/2589 (23%)]\tLoss: 196.075134\n",
      "Train Epoch: 319 [900/2589 (35%)]\tLoss: 149.049362\n",
      "Train Epoch: 319 [1200/2589 (46%)]\tLoss: 214.594818\n",
      "Train Epoch: 319 [1500/2589 (58%)]\tLoss: 209.720352\n",
      "Train Epoch: 319 [1800/2589 (70%)]\tLoss: 335.349304\n",
      "Train Epoch: 319 [2100/2589 (81%)]\tLoss: 255.839798\n",
      "Train Epoch: 319 [2400/2589 (93%)]\tLoss: 282.031525\n",
      "====> Epoch: 319 Average train loss: 254.5281\n",
      "====> Epoch: 319 Average test loss: 942.2435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 320 [0/2589 (0%)]\tLoss: 249.759384\n",
      "Train Epoch: 320 [300/2589 (12%)]\tLoss: 334.446930\n",
      "Train Epoch: 320 [600/2589 (23%)]\tLoss: 280.289093\n",
      "Train Epoch: 320 [900/2589 (35%)]\tLoss: 378.700500\n",
      "Train Epoch: 320 [1200/2589 (46%)]\tLoss: 213.094147\n",
      "Train Epoch: 320 [1500/2589 (58%)]\tLoss: 198.872101\n",
      "Train Epoch: 320 [1800/2589 (70%)]\tLoss: 232.195587\n",
      "Train Epoch: 320 [2100/2589 (81%)]\tLoss: 196.086212\n",
      "Train Epoch: 320 [2400/2589 (93%)]\tLoss: 264.788727\n",
      "====> Epoch: 320 Average train loss: 262.8053\n",
      "====> Epoch: 320 Average test loss: 948.6943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 321 [0/2589 (0%)]\tLoss: 206.391739\n",
      "Train Epoch: 321 [300/2589 (12%)]\tLoss: 193.859116\n",
      "Train Epoch: 321 [600/2589 (23%)]\tLoss: 217.167282\n",
      "Train Epoch: 321 [900/2589 (35%)]\tLoss: 252.286423\n",
      "Train Epoch: 321 [1200/2589 (46%)]\tLoss: 187.486328\n",
      "Train Epoch: 321 [1500/2589 (58%)]\tLoss: 285.463501\n",
      "Train Epoch: 321 [1800/2589 (70%)]\tLoss: 155.048691\n",
      "Train Epoch: 321 [2100/2589 (81%)]\tLoss: 178.458435\n",
      "Train Epoch: 321 [2400/2589 (93%)]\tLoss: 228.589218\n",
      "====> Epoch: 321 Average train loss: 255.9441\n",
      "====> Epoch: 321 Average test loss: 923.1171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 322 [0/2589 (0%)]\tLoss: 227.417130\n",
      "Train Epoch: 322 [300/2589 (12%)]\tLoss: 276.923706\n",
      "Train Epoch: 322 [600/2589 (23%)]\tLoss: 302.982513\n",
      "Train Epoch: 322 [900/2589 (35%)]\tLoss: 241.930161\n",
      "Train Epoch: 322 [1200/2589 (46%)]\tLoss: 254.856644\n",
      "Train Epoch: 322 [1500/2589 (58%)]\tLoss: 294.172699\n",
      "Train Epoch: 322 [1800/2589 (70%)]\tLoss: 319.065308\n",
      "Train Epoch: 322 [2100/2589 (81%)]\tLoss: 243.042587\n",
      "Train Epoch: 322 [2400/2589 (93%)]\tLoss: 448.457123\n",
      "====> Epoch: 322 Average train loss: 261.3504\n",
      "====> Epoch: 322 Average test loss: 937.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 323 [0/2589 (0%)]\tLoss: 331.837982\n",
      "Train Epoch: 323 [300/2589 (12%)]\tLoss: 212.365509\n",
      "Train Epoch: 323 [600/2589 (23%)]\tLoss: 247.627945\n",
      "Train Epoch: 323 [900/2589 (35%)]\tLoss: 316.536285\n",
      "Train Epoch: 323 [1200/2589 (46%)]\tLoss: 243.717529\n",
      "Train Epoch: 323 [1500/2589 (58%)]\tLoss: 279.751831\n",
      "Train Epoch: 323 [1800/2589 (70%)]\tLoss: 199.817947\n",
      "Train Epoch: 323 [2100/2589 (81%)]\tLoss: 225.339325\n",
      "Train Epoch: 323 [2400/2589 (93%)]\tLoss: 249.307861\n",
      "====> Epoch: 323 Average train loss: 261.7910\n",
      "====> Epoch: 323 Average test loss: 946.7642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 324 [0/2589 (0%)]\tLoss: 319.745636\n",
      "Train Epoch: 324 [300/2589 (12%)]\tLoss: 324.001343\n",
      "Train Epoch: 324 [600/2589 (23%)]\tLoss: 251.675735\n",
      "Train Epoch: 324 [900/2589 (35%)]\tLoss: 237.450104\n",
      "Train Epoch: 324 [1200/2589 (46%)]\tLoss: 282.022888\n",
      "Train Epoch: 324 [1500/2589 (58%)]\tLoss: 251.175049\n",
      "Train Epoch: 324 [1800/2589 (70%)]\tLoss: 191.932755\n",
      "Train Epoch: 324 [2100/2589 (81%)]\tLoss: 209.974380\n",
      "Train Epoch: 324 [2400/2589 (93%)]\tLoss: 241.224594\n",
      "====> Epoch: 324 Average train loss: 263.3947\n",
      "====> Epoch: 324 Average test loss: 947.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 325 [0/2589 (0%)]\tLoss: 254.186661\n",
      "Train Epoch: 325 [300/2589 (12%)]\tLoss: 247.728577\n",
      "Train Epoch: 325 [600/2589 (23%)]\tLoss: 298.922943\n",
      "Train Epoch: 325 [900/2589 (35%)]\tLoss: 297.784271\n",
      "Train Epoch: 325 [1200/2589 (46%)]\tLoss: 330.712036\n",
      "Train Epoch: 325 [1500/2589 (58%)]\tLoss: 266.662079\n",
      "Train Epoch: 325 [1800/2589 (70%)]\tLoss: 219.917038\n",
      "Train Epoch: 325 [2100/2589 (81%)]\tLoss: 220.430176\n",
      "Train Epoch: 325 [2400/2589 (93%)]\tLoss: 240.987900\n",
      "====> Epoch: 325 Average train loss: 249.5544\n",
      "====> Epoch: 325 Average test loss: 937.4764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 326 [0/2589 (0%)]\tLoss: 154.421661\n",
      "Train Epoch: 326 [300/2589 (12%)]\tLoss: 194.097382\n",
      "Train Epoch: 326 [600/2589 (23%)]\tLoss: 241.958252\n",
      "Train Epoch: 326 [900/2589 (35%)]\tLoss: 237.946045\n",
      "Train Epoch: 326 [1200/2589 (46%)]\tLoss: 238.596054\n",
      "Train Epoch: 326 [1500/2589 (58%)]\tLoss: 228.912277\n",
      "Train Epoch: 326 [1800/2589 (70%)]\tLoss: 227.911880\n",
      "Train Epoch: 326 [2100/2589 (81%)]\tLoss: 317.116211\n",
      "Train Epoch: 326 [2400/2589 (93%)]\tLoss: 191.842865\n",
      "====> Epoch: 326 Average train loss: 262.2332\n",
      "====> Epoch: 326 Average test loss: 934.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 327 [0/2589 (0%)]\tLoss: 203.300018\n",
      "Train Epoch: 327 [300/2589 (12%)]\tLoss: 187.428329\n",
      "Train Epoch: 327 [600/2589 (23%)]\tLoss: 211.769577\n",
      "Train Epoch: 327 [900/2589 (35%)]\tLoss: 356.637421\n",
      "Train Epoch: 327 [1200/2589 (46%)]\tLoss: 247.556213\n",
      "Train Epoch: 327 [1500/2589 (58%)]\tLoss: 221.484482\n",
      "Train Epoch: 327 [1800/2589 (70%)]\tLoss: 239.007828\n",
      "Train Epoch: 327 [2100/2589 (81%)]\tLoss: 228.591766\n",
      "Train Epoch: 327 [2400/2589 (93%)]\tLoss: 195.424088\n",
      "====> Epoch: 327 Average train loss: 262.3908\n",
      "====> Epoch: 327 Average test loss: 948.2976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 328 [0/2589 (0%)]\tLoss: 194.336288\n",
      "Train Epoch: 328 [300/2589 (12%)]\tLoss: 269.564117\n",
      "Train Epoch: 328 [600/2589 (23%)]\tLoss: 265.316803\n",
      "Train Epoch: 328 [900/2589 (35%)]\tLoss: 202.301407\n",
      "Train Epoch: 328 [1200/2589 (46%)]\tLoss: 319.885651\n",
      "Train Epoch: 328 [1500/2589 (58%)]\tLoss: 253.430313\n",
      "Train Epoch: 328 [1800/2589 (70%)]\tLoss: 331.694000\n",
      "Train Epoch: 328 [2100/2589 (81%)]\tLoss: 190.687485\n",
      "Train Epoch: 328 [2400/2589 (93%)]\tLoss: 246.171844\n",
      "====> Epoch: 328 Average train loss: 260.5096\n",
      "====> Epoch: 328 Average test loss: 947.8442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 329 [0/2589 (0%)]\tLoss: 219.048996\n",
      "Train Epoch: 329 [300/2589 (12%)]\tLoss: 256.500397\n",
      "Train Epoch: 329 [600/2589 (23%)]\tLoss: 268.427521\n",
      "Train Epoch: 329 [900/2589 (35%)]\tLoss: 240.103317\n",
      "Train Epoch: 329 [1200/2589 (46%)]\tLoss: 380.186249\n",
      "Train Epoch: 329 [1500/2589 (58%)]\tLoss: 268.972351\n",
      "Train Epoch: 329 [1800/2589 (70%)]\tLoss: 343.101868\n",
      "Train Epoch: 329 [2100/2589 (81%)]\tLoss: 322.888733\n",
      "Train Epoch: 329 [2400/2589 (93%)]\tLoss: 233.965118\n",
      "====> Epoch: 329 Average train loss: 260.6546\n",
      "====> Epoch: 329 Average test loss: 941.6453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 330 [0/2589 (0%)]\tLoss: 221.512390\n",
      "Train Epoch: 330 [300/2589 (12%)]\tLoss: 307.727173\n",
      "Train Epoch: 330 [600/2589 (23%)]\tLoss: 399.201019\n",
      "Train Epoch: 330 [900/2589 (35%)]\tLoss: 259.270050\n",
      "Train Epoch: 330 [1200/2589 (46%)]\tLoss: 235.750870\n",
      "Train Epoch: 330 [1500/2589 (58%)]\tLoss: 268.917328\n",
      "Train Epoch: 330 [1800/2589 (70%)]\tLoss: 226.509628\n",
      "Train Epoch: 330 [2100/2589 (81%)]\tLoss: 260.031616\n",
      "Train Epoch: 330 [2400/2589 (93%)]\tLoss: 239.600815\n",
      "====> Epoch: 330 Average train loss: 260.5555\n",
      "====> Epoch: 330 Average test loss: 944.3398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 331 [0/2589 (0%)]\tLoss: 194.327362\n",
      "Train Epoch: 331 [300/2589 (12%)]\tLoss: 279.281219\n",
      "Train Epoch: 331 [600/2589 (23%)]\tLoss: 191.025101\n",
      "Train Epoch: 331 [900/2589 (35%)]\tLoss: 243.510193\n",
      "Train Epoch: 331 [1200/2589 (46%)]\tLoss: 255.548935\n",
      "Train Epoch: 331 [1500/2589 (58%)]\tLoss: 206.667511\n",
      "Train Epoch: 331 [1800/2589 (70%)]\tLoss: 261.585419\n",
      "Train Epoch: 331 [2100/2589 (81%)]\tLoss: 377.758820\n",
      "Train Epoch: 331 [2400/2589 (93%)]\tLoss: 211.424942\n",
      "====> Epoch: 331 Average train loss: 253.5587\n",
      "====> Epoch: 331 Average test loss: 941.9277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 332 [0/2589 (0%)]\tLoss: 232.969940\n",
      "Train Epoch: 332 [300/2589 (12%)]\tLoss: 275.731720\n",
      "Train Epoch: 332 [600/2589 (23%)]\tLoss: 273.025482\n",
      "Train Epoch: 332 [900/2589 (35%)]\tLoss: 331.748901\n",
      "Train Epoch: 332 [1200/2589 (46%)]\tLoss: 212.212097\n",
      "Train Epoch: 332 [1500/2589 (58%)]\tLoss: 212.710281\n",
      "Train Epoch: 332 [1800/2589 (70%)]\tLoss: 329.525024\n",
      "Train Epoch: 332 [2100/2589 (81%)]\tLoss: 314.621704\n",
      "Train Epoch: 332 [2400/2589 (93%)]\tLoss: 308.892395\n",
      "====> Epoch: 332 Average train loss: 259.3448\n",
      "====> Epoch: 332 Average test loss: 959.4010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 333 [0/2589 (0%)]\tLoss: 158.493103\n",
      "Train Epoch: 333 [300/2589 (12%)]\tLoss: 239.355408\n",
      "Train Epoch: 333 [600/2589 (23%)]\tLoss: 261.838837\n",
      "Train Epoch: 333 [900/2589 (35%)]\tLoss: 264.772400\n",
      "Train Epoch: 333 [1200/2589 (46%)]\tLoss: 282.568481\n",
      "Train Epoch: 333 [1500/2589 (58%)]\tLoss: 336.680847\n",
      "Train Epoch: 333 [1800/2589 (70%)]\tLoss: 312.723450\n",
      "Train Epoch: 333 [2100/2589 (81%)]\tLoss: 171.291809\n",
      "Train Epoch: 333 [2400/2589 (93%)]\tLoss: 228.838699\n",
      "====> Epoch: 333 Average train loss: 261.0243\n",
      "====> Epoch: 333 Average test loss: 936.1480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 334 [0/2589 (0%)]\tLoss: 281.165314\n",
      "Train Epoch: 334 [300/2589 (12%)]\tLoss: 280.030304\n",
      "Train Epoch: 334 [600/2589 (23%)]\tLoss: 272.883759\n",
      "Train Epoch: 334 [900/2589 (35%)]\tLoss: 380.536835\n",
      "Train Epoch: 334 [1200/2589 (46%)]\tLoss: 204.745895\n",
      "Train Epoch: 334 [1500/2589 (58%)]\tLoss: 206.739807\n",
      "Train Epoch: 334 [1800/2589 (70%)]\tLoss: 269.300873\n",
      "Train Epoch: 334 [2100/2589 (81%)]\tLoss: 249.684845\n",
      "Train Epoch: 334 [2400/2589 (93%)]\tLoss: 320.290802\n",
      "====> Epoch: 334 Average train loss: 254.6252\n",
      "====> Epoch: 334 Average test loss: 964.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 335 [0/2589 (0%)]\tLoss: 542.213684\n",
      "Train Epoch: 335 [300/2589 (12%)]\tLoss: 190.083527\n",
      "Train Epoch: 335 [600/2589 (23%)]\tLoss: 247.859467\n",
      "Train Epoch: 335 [900/2589 (35%)]\tLoss: 319.929169\n",
      "Train Epoch: 335 [1200/2589 (46%)]\tLoss: 262.764038\n",
      "Train Epoch: 335 [1500/2589 (58%)]\tLoss: 224.432892\n",
      "Train Epoch: 335 [1800/2589 (70%)]\tLoss: 219.614639\n",
      "Train Epoch: 335 [2100/2589 (81%)]\tLoss: 293.658356\n",
      "Train Epoch: 335 [2400/2589 (93%)]\tLoss: 292.570831\n",
      "====> Epoch: 335 Average train loss: 261.0443\n",
      "====> Epoch: 335 Average test loss: 933.9248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 336 [0/2589 (0%)]\tLoss: 238.313232\n",
      "Train Epoch: 336 [300/2589 (12%)]\tLoss: 229.237625\n",
      "Train Epoch: 336 [600/2589 (23%)]\tLoss: 189.995605\n",
      "Train Epoch: 336 [900/2589 (35%)]\tLoss: 293.837372\n",
      "Train Epoch: 336 [1200/2589 (46%)]\tLoss: 315.745270\n",
      "Train Epoch: 336 [1500/2589 (58%)]\tLoss: 351.162994\n",
      "Train Epoch: 336 [1800/2589 (70%)]\tLoss: 215.289062\n",
      "Train Epoch: 336 [2100/2589 (81%)]\tLoss: 227.843582\n",
      "Train Epoch: 336 [2400/2589 (93%)]\tLoss: 272.994080\n",
      "====> Epoch: 336 Average train loss: 260.5739\n",
      "====> Epoch: 336 Average test loss: 926.1443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 337 [0/2589 (0%)]\tLoss: 196.490036\n",
      "Train Epoch: 337 [300/2589 (12%)]\tLoss: 208.404953\n",
      "Train Epoch: 337 [600/2589 (23%)]\tLoss: 436.386047\n",
      "Train Epoch: 337 [900/2589 (35%)]\tLoss: 205.040390\n",
      "Train Epoch: 337 [1200/2589 (46%)]\tLoss: 181.353622\n",
      "Train Epoch: 337 [1500/2589 (58%)]\tLoss: 297.162720\n",
      "Train Epoch: 337 [1800/2589 (70%)]\tLoss: 253.178513\n",
      "Train Epoch: 337 [2100/2589 (81%)]\tLoss: 361.626892\n",
      "Train Epoch: 337 [2400/2589 (93%)]\tLoss: 296.249298\n",
      "====> Epoch: 337 Average train loss: 255.9836\n",
      "====> Epoch: 337 Average test loss: 924.0224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 338 [0/2589 (0%)]\tLoss: 217.979080\n",
      "Train Epoch: 338 [300/2589 (12%)]\tLoss: 165.697464\n",
      "Train Epoch: 338 [600/2589 (23%)]\tLoss: 248.452621\n",
      "Train Epoch: 338 [900/2589 (35%)]\tLoss: 265.978973\n",
      "Train Epoch: 338 [1200/2589 (46%)]\tLoss: 286.140350\n",
      "Train Epoch: 338 [1500/2589 (58%)]\tLoss: 410.066010\n",
      "Train Epoch: 338 [1800/2589 (70%)]\tLoss: 220.144623\n",
      "Train Epoch: 338 [2100/2589 (81%)]\tLoss: 186.472427\n",
      "Train Epoch: 338 [2400/2589 (93%)]\tLoss: 307.013794\n",
      "====> Epoch: 338 Average train loss: 264.8444\n",
      "====> Epoch: 338 Average test loss: 937.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 339 [0/2589 (0%)]\tLoss: 239.486893\n",
      "Train Epoch: 339 [300/2589 (12%)]\tLoss: 238.584091\n",
      "Train Epoch: 339 [600/2589 (23%)]\tLoss: 224.577881\n",
      "Train Epoch: 339 [900/2589 (35%)]\tLoss: 247.824768\n",
      "Train Epoch: 339 [1200/2589 (46%)]\tLoss: 297.226074\n",
      "Train Epoch: 339 [1500/2589 (58%)]\tLoss: 219.648453\n",
      "Train Epoch: 339 [1800/2589 (70%)]\tLoss: 282.070374\n",
      "Train Epoch: 339 [2100/2589 (81%)]\tLoss: 275.051056\n",
      "Train Epoch: 339 [2400/2589 (93%)]\tLoss: 192.436066\n",
      "====> Epoch: 339 Average train loss: 270.0186\n",
      "====> Epoch: 339 Average test loss: 947.1173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 340 [0/2589 (0%)]\tLoss: 219.171158\n",
      "Train Epoch: 340 [300/2589 (12%)]\tLoss: 219.824402\n",
      "Train Epoch: 340 [600/2589 (23%)]\tLoss: 212.919983\n",
      "Train Epoch: 340 [900/2589 (35%)]\tLoss: 269.672882\n",
      "Train Epoch: 340 [1200/2589 (46%)]\tLoss: 164.546875\n",
      "Train Epoch: 340 [1500/2589 (58%)]\tLoss: 200.981506\n",
      "Train Epoch: 340 [1800/2589 (70%)]\tLoss: 235.301102\n",
      "Train Epoch: 340 [2100/2589 (81%)]\tLoss: 229.832565\n",
      "Train Epoch: 340 [2400/2589 (93%)]\tLoss: 232.154602\n",
      "====> Epoch: 340 Average train loss: 264.1271\n",
      "====> Epoch: 340 Average test loss: 958.1835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 341 [0/2589 (0%)]\tLoss: 284.308502\n",
      "Train Epoch: 341 [300/2589 (12%)]\tLoss: 302.076965\n",
      "Train Epoch: 341 [600/2589 (23%)]\tLoss: 211.670670\n",
      "Train Epoch: 341 [900/2589 (35%)]\tLoss: 283.500946\n",
      "Train Epoch: 341 [1200/2589 (46%)]\tLoss: 174.247940\n",
      "Train Epoch: 341 [1500/2589 (58%)]\tLoss: 157.118637\n",
      "Train Epoch: 341 [1800/2589 (70%)]\tLoss: 307.682587\n",
      "Train Epoch: 341 [2100/2589 (81%)]\tLoss: 471.154938\n",
      "Train Epoch: 341 [2400/2589 (93%)]\tLoss: 317.807465\n",
      "====> Epoch: 341 Average train loss: 256.6861\n",
      "====> Epoch: 341 Average test loss: 968.2186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 342 [0/2589 (0%)]\tLoss: 217.435516\n",
      "Train Epoch: 342 [300/2589 (12%)]\tLoss: 227.214539\n",
      "Train Epoch: 342 [600/2589 (23%)]\tLoss: 232.239304\n",
      "Train Epoch: 342 [900/2589 (35%)]\tLoss: 257.612732\n",
      "Train Epoch: 342 [1200/2589 (46%)]\tLoss: 287.973267\n",
      "Train Epoch: 342 [1500/2589 (58%)]\tLoss: 236.184219\n",
      "Train Epoch: 342 [1800/2589 (70%)]\tLoss: 291.267059\n",
      "Train Epoch: 342 [2100/2589 (81%)]\tLoss: 239.982681\n",
      "Train Epoch: 342 [2400/2589 (93%)]\tLoss: 367.624481\n",
      "====> Epoch: 342 Average train loss: 266.5034\n",
      "====> Epoch: 342 Average test loss: 954.0414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 343 [0/2589 (0%)]\tLoss: 254.297562\n",
      "Train Epoch: 343 [300/2589 (12%)]\tLoss: 310.573181\n",
      "Train Epoch: 343 [600/2589 (23%)]\tLoss: 353.531189\n",
      "Train Epoch: 343 [900/2589 (35%)]\tLoss: 291.460663\n",
      "Train Epoch: 343 [1200/2589 (46%)]\tLoss: 215.676422\n",
      "Train Epoch: 343 [1500/2589 (58%)]\tLoss: 200.021225\n",
      "Train Epoch: 343 [1800/2589 (70%)]\tLoss: 213.613922\n",
      "Train Epoch: 343 [2100/2589 (81%)]\tLoss: 210.637848\n",
      "Train Epoch: 343 [2400/2589 (93%)]\tLoss: 382.737732\n",
      "====> Epoch: 343 Average train loss: 254.3696\n",
      "====> Epoch: 343 Average test loss: 941.5994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 344 [0/2589 (0%)]\tLoss: 164.724472\n",
      "Train Epoch: 344 [300/2589 (12%)]\tLoss: 218.619919\n",
      "Train Epoch: 344 [600/2589 (23%)]\tLoss: 235.191086\n",
      "Train Epoch: 344 [900/2589 (35%)]\tLoss: 331.703766\n",
      "Train Epoch: 344 [1200/2589 (46%)]\tLoss: 208.077911\n",
      "Train Epoch: 344 [1500/2589 (58%)]\tLoss: 298.188263\n",
      "Train Epoch: 344 [1800/2589 (70%)]\tLoss: 231.894608\n",
      "Train Epoch: 344 [2100/2589 (81%)]\tLoss: 287.616730\n",
      "Train Epoch: 344 [2400/2589 (93%)]\tLoss: 236.122101\n",
      "====> Epoch: 344 Average train loss: 252.8084\n",
      "====> Epoch: 344 Average test loss: 950.0778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 345 [0/2589 (0%)]\tLoss: 221.539062\n",
      "Train Epoch: 345 [300/2589 (12%)]\tLoss: 220.861084\n",
      "Train Epoch: 345 [600/2589 (23%)]\tLoss: 337.196228\n",
      "Train Epoch: 345 [900/2589 (35%)]\tLoss: 402.056976\n",
      "Train Epoch: 345 [1200/2589 (46%)]\tLoss: 346.921600\n",
      "Train Epoch: 345 [1500/2589 (58%)]\tLoss: 285.850189\n",
      "Train Epoch: 345 [1800/2589 (70%)]\tLoss: 278.080688\n",
      "Train Epoch: 345 [2100/2589 (81%)]\tLoss: 265.565521\n",
      "Train Epoch: 345 [2400/2589 (93%)]\tLoss: 331.408173\n",
      "====> Epoch: 345 Average train loss: 264.8466\n",
      "====> Epoch: 345 Average test loss: 942.0285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 346 [0/2589 (0%)]\tLoss: 217.689407\n",
      "Train Epoch: 346 [300/2589 (12%)]\tLoss: 390.591156\n",
      "Train Epoch: 346 [600/2589 (23%)]\tLoss: 189.776550\n",
      "Train Epoch: 346 [900/2589 (35%)]\tLoss: 247.170975\n",
      "Train Epoch: 346 [1200/2589 (46%)]\tLoss: 237.202698\n",
      "Train Epoch: 346 [1500/2589 (58%)]\tLoss: 176.104874\n",
      "Train Epoch: 346 [1800/2589 (70%)]\tLoss: 338.708069\n",
      "Train Epoch: 346 [2100/2589 (81%)]\tLoss: 182.086029\n",
      "Train Epoch: 346 [2400/2589 (93%)]\tLoss: 247.310638\n",
      "====> Epoch: 346 Average train loss: 263.2365\n",
      "====> Epoch: 346 Average test loss: 945.1237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 347 [0/2589 (0%)]\tLoss: 336.916687\n",
      "Train Epoch: 347 [300/2589 (12%)]\tLoss: 266.183075\n",
      "Train Epoch: 347 [600/2589 (23%)]\tLoss: 169.468170\n",
      "Train Epoch: 347 [900/2589 (35%)]\tLoss: 157.081009\n",
      "Train Epoch: 347 [1200/2589 (46%)]\tLoss: 293.678864\n",
      "Train Epoch: 347 [1500/2589 (58%)]\tLoss: 275.645660\n",
      "Train Epoch: 347 [1800/2589 (70%)]\tLoss: 233.985138\n",
      "Train Epoch: 347 [2100/2589 (81%)]\tLoss: 209.237106\n",
      "Train Epoch: 347 [2400/2589 (93%)]\tLoss: 259.789734\n",
      "====> Epoch: 347 Average train loss: 250.7006\n",
      "====> Epoch: 347 Average test loss: 950.7366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 348 [0/2589 (0%)]\tLoss: 354.613922\n",
      "Train Epoch: 348 [300/2589 (12%)]\tLoss: 248.439651\n",
      "Train Epoch: 348 [600/2589 (23%)]\tLoss: 291.602509\n",
      "Train Epoch: 348 [900/2589 (35%)]\tLoss: 266.362854\n",
      "Train Epoch: 348 [1200/2589 (46%)]\tLoss: 381.486542\n",
      "Train Epoch: 348 [1500/2589 (58%)]\tLoss: 453.669312\n",
      "Train Epoch: 348 [1800/2589 (70%)]\tLoss: 263.515900\n",
      "Train Epoch: 348 [2100/2589 (81%)]\tLoss: 204.817474\n",
      "Train Epoch: 348 [2400/2589 (93%)]\tLoss: 268.438141\n",
      "====> Epoch: 348 Average train loss: 271.3756\n",
      "====> Epoch: 348 Average test loss: 961.0988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 349 [0/2589 (0%)]\tLoss: 185.650864\n",
      "Train Epoch: 349 [300/2589 (12%)]\tLoss: 253.677704\n",
      "Train Epoch: 349 [600/2589 (23%)]\tLoss: 169.140915\n",
      "Train Epoch: 349 [900/2589 (35%)]\tLoss: 382.147003\n",
      "Train Epoch: 349 [1200/2589 (46%)]\tLoss: 210.829758\n",
      "Train Epoch: 349 [1500/2589 (58%)]\tLoss: 290.132904\n",
      "Train Epoch: 349 [1800/2589 (70%)]\tLoss: 204.488251\n",
      "Train Epoch: 349 [2100/2589 (81%)]\tLoss: 254.082672\n",
      "Train Epoch: 349 [2400/2589 (93%)]\tLoss: 277.758209\n",
      "====> Epoch: 349 Average train loss: 262.4128\n",
      "====> Epoch: 349 Average test loss: 956.6597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 350 [0/2589 (0%)]\tLoss: 209.453812\n",
      "Train Epoch: 350 [300/2589 (12%)]\tLoss: 236.718307\n",
      "Train Epoch: 350 [600/2589 (23%)]\tLoss: 215.739685\n",
      "Train Epoch: 350 [900/2589 (35%)]\tLoss: 311.067261\n",
      "Train Epoch: 350 [1200/2589 (46%)]\tLoss: 200.161575\n",
      "Train Epoch: 350 [1500/2589 (58%)]\tLoss: 207.904648\n",
      "Train Epoch: 350 [1800/2589 (70%)]\tLoss: 197.783554\n",
      "Train Epoch: 350 [2100/2589 (81%)]\tLoss: 313.650787\n",
      "Train Epoch: 350 [2400/2589 (93%)]\tLoss: 266.496674\n",
      "====> Epoch: 350 Average train loss: 259.3699\n",
      "====> Epoch: 350 Average test loss: 927.8883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 351 [0/2589 (0%)]\tLoss: 362.379974\n",
      "Train Epoch: 351 [300/2589 (12%)]\tLoss: 141.281006\n",
      "Train Epoch: 351 [600/2589 (23%)]\tLoss: 258.543121\n",
      "Train Epoch: 351 [900/2589 (35%)]\tLoss: 152.748322\n",
      "Train Epoch: 351 [1200/2589 (46%)]\tLoss: 170.642166\n",
      "Train Epoch: 351 [1500/2589 (58%)]\tLoss: 264.287628\n",
      "Train Epoch: 351 [1800/2589 (70%)]\tLoss: 187.588348\n",
      "Train Epoch: 351 [2100/2589 (81%)]\tLoss: 293.484070\n",
      "Train Epoch: 351 [2400/2589 (93%)]\tLoss: 392.996002\n",
      "====> Epoch: 351 Average train loss: 256.2318\n",
      "====> Epoch: 351 Average test loss: 944.4013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 352 [0/2589 (0%)]\tLoss: 166.007904\n",
      "Train Epoch: 352 [300/2589 (12%)]\tLoss: 159.886719\n",
      "Train Epoch: 352 [600/2589 (23%)]\tLoss: 221.948730\n",
      "Train Epoch: 352 [900/2589 (35%)]\tLoss: 404.871704\n",
      "Train Epoch: 352 [1200/2589 (46%)]\tLoss: 330.837769\n",
      "Train Epoch: 352 [1500/2589 (58%)]\tLoss: 254.361160\n",
      "Train Epoch: 352 [1800/2589 (70%)]\tLoss: 286.453339\n",
      "Train Epoch: 352 [2100/2589 (81%)]\tLoss: 217.613983\n",
      "Train Epoch: 352 [2400/2589 (93%)]\tLoss: 242.596100\n",
      "====> Epoch: 352 Average train loss: 265.4568\n",
      "====> Epoch: 352 Average test loss: 974.4774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 353 [0/2589 (0%)]\tLoss: 164.435608\n",
      "Train Epoch: 353 [300/2589 (12%)]\tLoss: 268.442444\n",
      "Train Epoch: 353 [600/2589 (23%)]\tLoss: 200.898972\n",
      "Train Epoch: 353 [900/2589 (35%)]\tLoss: 213.494339\n",
      "Train Epoch: 353 [1200/2589 (46%)]\tLoss: 222.602615\n",
      "Train Epoch: 353 [1500/2589 (58%)]\tLoss: 208.999557\n",
      "Train Epoch: 353 [1800/2589 (70%)]\tLoss: 239.697540\n",
      "Train Epoch: 353 [2100/2589 (81%)]\tLoss: 281.537994\n",
      "Train Epoch: 353 [2400/2589 (93%)]\tLoss: 242.520248\n",
      "====> Epoch: 353 Average train loss: 253.6762\n",
      "====> Epoch: 353 Average test loss: 959.7214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 354 [0/2589 (0%)]\tLoss: 313.387817\n",
      "Train Epoch: 354 [300/2589 (12%)]\tLoss: 252.489273\n",
      "Train Epoch: 354 [600/2589 (23%)]\tLoss: 183.216599\n",
      "Train Epoch: 354 [900/2589 (35%)]\tLoss: 195.393555\n",
      "Train Epoch: 354 [1200/2589 (46%)]\tLoss: 355.404144\n",
      "Train Epoch: 354 [1500/2589 (58%)]\tLoss: 203.293060\n",
      "Train Epoch: 354 [1800/2589 (70%)]\tLoss: 270.208496\n",
      "Train Epoch: 354 [2100/2589 (81%)]\tLoss: 320.701599\n",
      "Train Epoch: 354 [2400/2589 (93%)]\tLoss: 207.684219\n",
      "====> Epoch: 354 Average train loss: 260.1967\n",
      "====> Epoch: 354 Average test loss: 946.2910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 355 [0/2589 (0%)]\tLoss: 253.620224\n",
      "Train Epoch: 355 [300/2589 (12%)]\tLoss: 140.446457\n",
      "Train Epoch: 355 [600/2589 (23%)]\tLoss: 240.810226\n",
      "Train Epoch: 355 [900/2589 (35%)]\tLoss: 314.010315\n",
      "Train Epoch: 355 [1200/2589 (46%)]\tLoss: 186.514755\n",
      "Train Epoch: 355 [1500/2589 (58%)]\tLoss: 206.369553\n",
      "Train Epoch: 355 [1800/2589 (70%)]\tLoss: 212.525909\n",
      "Train Epoch: 355 [2100/2589 (81%)]\tLoss: 232.797012\n",
      "Train Epoch: 355 [2400/2589 (93%)]\tLoss: 358.665863\n",
      "====> Epoch: 355 Average train loss: 265.4736\n",
      "====> Epoch: 355 Average test loss: 937.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 356 [0/2589 (0%)]\tLoss: 218.950760\n",
      "Train Epoch: 356 [300/2589 (12%)]\tLoss: 243.163239\n",
      "Train Epoch: 356 [600/2589 (23%)]\tLoss: 238.161667\n",
      "Train Epoch: 356 [900/2589 (35%)]\tLoss: 213.324905\n",
      "Train Epoch: 356 [1200/2589 (46%)]\tLoss: 221.304001\n",
      "Train Epoch: 356 [1500/2589 (58%)]\tLoss: 334.078430\n",
      "Train Epoch: 356 [1800/2589 (70%)]\tLoss: 231.939743\n",
      "Train Epoch: 356 [2100/2589 (81%)]\tLoss: 290.886505\n",
      "Train Epoch: 356 [2400/2589 (93%)]\tLoss: 225.325333\n",
      "====> Epoch: 356 Average train loss: 253.4973\n",
      "====> Epoch: 356 Average test loss: 936.0545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 357 [0/2589 (0%)]\tLoss: 221.936005\n",
      "Train Epoch: 357 [300/2589 (12%)]\tLoss: 261.805878\n",
      "Train Epoch: 357 [600/2589 (23%)]\tLoss: 196.028992\n",
      "Train Epoch: 357 [900/2589 (35%)]\tLoss: 287.870575\n",
      "Train Epoch: 357 [1200/2589 (46%)]\tLoss: 233.643845\n",
      "Train Epoch: 357 [1500/2589 (58%)]\tLoss: 284.528168\n",
      "Train Epoch: 357 [1800/2589 (70%)]\tLoss: 288.671356\n",
      "Train Epoch: 357 [2100/2589 (81%)]\tLoss: 237.687653\n",
      "Train Epoch: 357 [2400/2589 (93%)]\tLoss: 252.206924\n",
      "====> Epoch: 357 Average train loss: 243.2253\n",
      "====> Epoch: 357 Average test loss: 948.6334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 358 [0/2589 (0%)]\tLoss: 402.940735\n",
      "Train Epoch: 358 [300/2589 (12%)]\tLoss: 235.459930\n",
      "Train Epoch: 358 [600/2589 (23%)]\tLoss: 286.989899\n",
      "Train Epoch: 358 [900/2589 (35%)]\tLoss: 202.368683\n",
      "Train Epoch: 358 [1200/2589 (46%)]\tLoss: 320.007050\n",
      "Train Epoch: 358 [1500/2589 (58%)]\tLoss: 329.867310\n",
      "Train Epoch: 358 [1800/2589 (70%)]\tLoss: 307.400696\n",
      "Train Epoch: 358 [2100/2589 (81%)]\tLoss: 306.086609\n",
      "Train Epoch: 358 [2400/2589 (93%)]\tLoss: 189.233200\n",
      "====> Epoch: 358 Average train loss: 263.6834\n",
      "====> Epoch: 358 Average test loss: 929.8859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 359 [0/2589 (0%)]\tLoss: 248.234116\n",
      "Train Epoch: 359 [300/2589 (12%)]\tLoss: 171.006577\n",
      "Train Epoch: 359 [600/2589 (23%)]\tLoss: 174.849091\n",
      "Train Epoch: 359 [900/2589 (35%)]\tLoss: 185.528870\n",
      "Train Epoch: 359 [1200/2589 (46%)]\tLoss: 198.673050\n",
      "Train Epoch: 359 [1500/2589 (58%)]\tLoss: 181.639572\n",
      "Train Epoch: 359 [1800/2589 (70%)]\tLoss: 304.331085\n",
      "Train Epoch: 359 [2100/2589 (81%)]\tLoss: 202.970367\n",
      "Train Epoch: 359 [2400/2589 (93%)]\tLoss: 196.813812\n",
      "====> Epoch: 359 Average train loss: 246.8792\n",
      "====> Epoch: 359 Average test loss: 955.8262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 360 [0/2589 (0%)]\tLoss: 219.823883\n",
      "Train Epoch: 360 [300/2589 (12%)]\tLoss: 305.827728\n",
      "Train Epoch: 360 [600/2589 (23%)]\tLoss: 320.840485\n",
      "Train Epoch: 360 [900/2589 (35%)]\tLoss: 270.036407\n",
      "Train Epoch: 360 [1200/2589 (46%)]\tLoss: 306.980316\n",
      "Train Epoch: 360 [1500/2589 (58%)]\tLoss: 183.100540\n",
      "Train Epoch: 360 [1800/2589 (70%)]\tLoss: 240.769150\n",
      "Train Epoch: 360 [2100/2589 (81%)]\tLoss: 310.538055\n",
      "Train Epoch: 360 [2400/2589 (93%)]\tLoss: 180.973663\n",
      "====> Epoch: 360 Average train loss: 263.9293\n",
      "====> Epoch: 360 Average test loss: 937.1301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 361 [0/2589 (0%)]\tLoss: 244.498215\n",
      "Train Epoch: 361 [300/2589 (12%)]\tLoss: 448.055786\n",
      "Train Epoch: 361 [600/2589 (23%)]\tLoss: 289.296570\n",
      "Train Epoch: 361 [900/2589 (35%)]\tLoss: 239.837723\n",
      "Train Epoch: 361 [1200/2589 (46%)]\tLoss: 176.704269\n",
      "Train Epoch: 361 [1500/2589 (58%)]\tLoss: 183.482620\n",
      "Train Epoch: 361 [1800/2589 (70%)]\tLoss: 226.535461\n",
      "Train Epoch: 361 [2100/2589 (81%)]\tLoss: 248.062805\n",
      "Train Epoch: 361 [2400/2589 (93%)]\tLoss: 219.267899\n",
      "====> Epoch: 361 Average train loss: 258.2462\n",
      "====> Epoch: 361 Average test loss: 936.5776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 362 [0/2589 (0%)]\tLoss: 138.480316\n",
      "Train Epoch: 362 [300/2589 (12%)]\tLoss: 306.478363\n",
      "Train Epoch: 362 [600/2589 (23%)]\tLoss: 187.258163\n",
      "Train Epoch: 362 [900/2589 (35%)]\tLoss: 217.048889\n",
      "Train Epoch: 362 [1200/2589 (46%)]\tLoss: 235.330032\n",
      "Train Epoch: 362 [1500/2589 (58%)]\tLoss: 228.714874\n",
      "Train Epoch: 362 [1800/2589 (70%)]\tLoss: 389.810089\n",
      "Train Epoch: 362 [2100/2589 (81%)]\tLoss: 306.004120\n",
      "Train Epoch: 362 [2400/2589 (93%)]\tLoss: 317.051971\n",
      "====> Epoch: 362 Average train loss: 247.2429\n",
      "====> Epoch: 362 Average test loss: 953.4880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 363 [0/2589 (0%)]\tLoss: 292.805298\n",
      "Train Epoch: 363 [300/2589 (12%)]\tLoss: 193.947586\n",
      "Train Epoch: 363 [600/2589 (23%)]\tLoss: 209.883255\n",
      "Train Epoch: 363 [900/2589 (35%)]\tLoss: 233.219971\n",
      "Train Epoch: 363 [1200/2589 (46%)]\tLoss: 250.868103\n",
      "Train Epoch: 363 [1500/2589 (58%)]\tLoss: 299.713348\n",
      "Train Epoch: 363 [1800/2589 (70%)]\tLoss: 302.847534\n",
      "Train Epoch: 363 [2100/2589 (81%)]\tLoss: 251.470978\n",
      "Train Epoch: 363 [2400/2589 (93%)]\tLoss: 215.636627\n",
      "====> Epoch: 363 Average train loss: 264.2370\n",
      "====> Epoch: 363 Average test loss: 930.0495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 364 [0/2589 (0%)]\tLoss: 281.292175\n",
      "Train Epoch: 364 [300/2589 (12%)]\tLoss: 199.482239\n",
      "Train Epoch: 364 [600/2589 (23%)]\tLoss: 194.015625\n",
      "Train Epoch: 364 [900/2589 (35%)]\tLoss: 270.741730\n",
      "Train Epoch: 364 [1200/2589 (46%)]\tLoss: 238.478226\n",
      "Train Epoch: 364 [1500/2589 (58%)]\tLoss: 255.955276\n",
      "Train Epoch: 364 [1800/2589 (70%)]\tLoss: 172.544922\n",
      "Train Epoch: 364 [2100/2589 (81%)]\tLoss: 244.800674\n",
      "Train Epoch: 364 [2400/2589 (93%)]\tLoss: 245.959244\n",
      "====> Epoch: 364 Average train loss: 264.2267\n",
      "====> Epoch: 364 Average test loss: 935.4619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 365 [0/2589 (0%)]\tLoss: 197.271881\n",
      "Train Epoch: 365 [300/2589 (12%)]\tLoss: 261.125519\n",
      "Train Epoch: 365 [600/2589 (23%)]\tLoss: 296.344177\n",
      "Train Epoch: 365 [900/2589 (35%)]\tLoss: 216.577133\n",
      "Train Epoch: 365 [1200/2589 (46%)]\tLoss: 493.636383\n",
      "Train Epoch: 365 [1500/2589 (58%)]\tLoss: 397.377991\n",
      "Train Epoch: 365 [1800/2589 (70%)]\tLoss: 274.675903\n",
      "Train Epoch: 365 [2100/2589 (81%)]\tLoss: 406.837616\n",
      "Train Epoch: 365 [2400/2589 (93%)]\tLoss: 206.723160\n",
      "====> Epoch: 365 Average train loss: 254.0549\n",
      "====> Epoch: 365 Average test loss: 945.0838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 366 [0/2589 (0%)]\tLoss: 239.087158\n",
      "Train Epoch: 366 [300/2589 (12%)]\tLoss: 273.386536\n",
      "Train Epoch: 366 [600/2589 (23%)]\tLoss: 323.308289\n",
      "Train Epoch: 366 [900/2589 (35%)]\tLoss: 221.330399\n",
      "Train Epoch: 366 [1200/2589 (46%)]\tLoss: 198.336929\n",
      "Train Epoch: 366 [1500/2589 (58%)]\tLoss: 196.882034\n",
      "Train Epoch: 366 [1800/2589 (70%)]\tLoss: 252.319473\n",
      "Train Epoch: 366 [2100/2589 (81%)]\tLoss: 439.087585\n",
      "Train Epoch: 366 [2400/2589 (93%)]\tLoss: 215.278030\n",
      "====> Epoch: 366 Average train loss: 249.0074\n",
      "====> Epoch: 366 Average test loss: 934.4811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 367 [0/2589 (0%)]\tLoss: 269.220673\n",
      "Train Epoch: 367 [300/2589 (12%)]\tLoss: 262.975555\n",
      "Train Epoch: 367 [600/2589 (23%)]\tLoss: 268.424866\n",
      "Train Epoch: 367 [900/2589 (35%)]\tLoss: 261.701538\n",
      "Train Epoch: 367 [1200/2589 (46%)]\tLoss: 381.750153\n",
      "Train Epoch: 367 [1500/2589 (58%)]\tLoss: 305.686340\n",
      "Train Epoch: 367 [1800/2589 (70%)]\tLoss: 294.036041\n",
      "Train Epoch: 367 [2100/2589 (81%)]\tLoss: 314.597260\n",
      "Train Epoch: 367 [2400/2589 (93%)]\tLoss: 218.581940\n",
      "====> Epoch: 367 Average train loss: 263.6609\n",
      "====> Epoch: 367 Average test loss: 953.8215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 368 [0/2589 (0%)]\tLoss: 283.932800\n",
      "Train Epoch: 368 [300/2589 (12%)]\tLoss: 169.323257\n",
      "Train Epoch: 368 [600/2589 (23%)]\tLoss: 240.098450\n",
      "Train Epoch: 368 [900/2589 (35%)]\tLoss: 218.989578\n",
      "Train Epoch: 368 [1200/2589 (46%)]\tLoss: 459.905273\n",
      "Train Epoch: 368 [1500/2589 (58%)]\tLoss: 260.544830\n",
      "Train Epoch: 368 [1800/2589 (70%)]\tLoss: 238.010574\n",
      "Train Epoch: 368 [2100/2589 (81%)]\tLoss: 106.866646\n",
      "Train Epoch: 368 [2400/2589 (93%)]\tLoss: 323.139282\n",
      "====> Epoch: 368 Average train loss: 246.3014\n",
      "====> Epoch: 368 Average test loss: 935.7025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 369 [0/2589 (0%)]\tLoss: 280.970825\n",
      "Train Epoch: 369 [300/2589 (12%)]\tLoss: 165.324875\n",
      "Train Epoch: 369 [600/2589 (23%)]\tLoss: 329.741821\n",
      "Train Epoch: 369 [900/2589 (35%)]\tLoss: 250.533035\n",
      "Train Epoch: 369 [1200/2589 (46%)]\tLoss: 225.082321\n",
      "Train Epoch: 369 [1500/2589 (58%)]\tLoss: 244.471100\n",
      "Train Epoch: 369 [1800/2589 (70%)]\tLoss: 228.405106\n",
      "Train Epoch: 369 [2100/2589 (81%)]\tLoss: 258.020691\n",
      "Train Epoch: 369 [2400/2589 (93%)]\tLoss: 147.301086\n",
      "====> Epoch: 369 Average train loss: 255.2820\n",
      "====> Epoch: 369 Average test loss: 944.5346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 370 [0/2589 (0%)]\tLoss: 251.602142\n",
      "Train Epoch: 370 [300/2589 (12%)]\tLoss: 282.066467\n",
      "Train Epoch: 370 [600/2589 (23%)]\tLoss: 418.403412\n",
      "Train Epoch: 370 [900/2589 (35%)]\tLoss: 302.785370\n",
      "Train Epoch: 370 [1200/2589 (46%)]\tLoss: 240.631027\n",
      "Train Epoch: 370 [1500/2589 (58%)]\tLoss: 273.792786\n",
      "Train Epoch: 370 [1800/2589 (70%)]\tLoss: 243.333893\n",
      "Train Epoch: 370 [2100/2589 (81%)]\tLoss: 209.474655\n",
      "Train Epoch: 370 [2400/2589 (93%)]\tLoss: 284.656860\n",
      "====> Epoch: 370 Average train loss: 260.7522\n",
      "====> Epoch: 370 Average test loss: 945.7510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 371 [0/2589 (0%)]\tLoss: 249.111633\n",
      "Train Epoch: 371 [300/2589 (12%)]\tLoss: 275.861908\n",
      "Train Epoch: 371 [600/2589 (23%)]\tLoss: 227.886963\n",
      "Train Epoch: 371 [900/2589 (35%)]\tLoss: 171.717453\n",
      "Train Epoch: 371 [1200/2589 (46%)]\tLoss: 343.352814\n",
      "Train Epoch: 371 [1500/2589 (58%)]\tLoss: 312.362610\n",
      "Train Epoch: 371 [1800/2589 (70%)]\tLoss: 257.917358\n",
      "Train Epoch: 371 [2100/2589 (81%)]\tLoss: 247.864075\n",
      "Train Epoch: 371 [2400/2589 (93%)]\tLoss: 309.485352\n",
      "====> Epoch: 371 Average train loss: 256.9789\n",
      "====> Epoch: 371 Average test loss: 939.1662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 372 [0/2589 (0%)]\tLoss: 315.369659\n",
      "Train Epoch: 372 [300/2589 (12%)]\tLoss: 231.147385\n",
      "Train Epoch: 372 [600/2589 (23%)]\tLoss: 185.164200\n",
      "Train Epoch: 372 [900/2589 (35%)]\tLoss: 281.882751\n",
      "Train Epoch: 372 [1200/2589 (46%)]\tLoss: 277.878143\n",
      "Train Epoch: 372 [1500/2589 (58%)]\tLoss: 388.429779\n",
      "Train Epoch: 372 [1800/2589 (70%)]\tLoss: 215.551270\n",
      "Train Epoch: 372 [2100/2589 (81%)]\tLoss: 294.543060\n",
      "Train Epoch: 372 [2400/2589 (93%)]\tLoss: 274.218048\n",
      "====> Epoch: 372 Average train loss: 266.1878\n",
      "====> Epoch: 372 Average test loss: 954.9326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 373 [0/2589 (0%)]\tLoss: 300.705597\n",
      "Train Epoch: 373 [300/2589 (12%)]\tLoss: 232.181152\n",
      "Train Epoch: 373 [600/2589 (23%)]\tLoss: 155.750793\n",
      "Train Epoch: 373 [900/2589 (35%)]\tLoss: 216.580338\n",
      "Train Epoch: 373 [1200/2589 (46%)]\tLoss: 267.684143\n",
      "Train Epoch: 373 [1500/2589 (58%)]\tLoss: 203.957016\n",
      "Train Epoch: 373 [1800/2589 (70%)]\tLoss: 229.213867\n",
      "Train Epoch: 373 [2100/2589 (81%)]\tLoss: 314.163422\n",
      "Train Epoch: 373 [2400/2589 (93%)]\tLoss: 236.135971\n",
      "====> Epoch: 373 Average train loss: 249.4835\n",
      "====> Epoch: 373 Average test loss: 951.4661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 374 [0/2589 (0%)]\tLoss: 280.317993\n",
      "Train Epoch: 374 [300/2589 (12%)]\tLoss: 228.932480\n",
      "Train Epoch: 374 [600/2589 (23%)]\tLoss: 269.956696\n",
      "Train Epoch: 374 [900/2589 (35%)]\tLoss: 344.743103\n",
      "Train Epoch: 374 [1200/2589 (46%)]\tLoss: 237.096283\n",
      "Train Epoch: 374 [1500/2589 (58%)]\tLoss: 204.093735\n",
      "Train Epoch: 374 [1800/2589 (70%)]\tLoss: 209.851593\n",
      "Train Epoch: 374 [2100/2589 (81%)]\tLoss: 312.744476\n",
      "Train Epoch: 374 [2400/2589 (93%)]\tLoss: 316.878998\n",
      "====> Epoch: 374 Average train loss: 260.0376\n",
      "====> Epoch: 374 Average test loss: 945.7491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 375 [0/2589 (0%)]\tLoss: 232.107025\n",
      "Train Epoch: 375 [300/2589 (12%)]\tLoss: 252.725555\n",
      "Train Epoch: 375 [600/2589 (23%)]\tLoss: 222.988632\n",
      "Train Epoch: 375 [900/2589 (35%)]\tLoss: 224.895279\n",
      "Train Epoch: 375 [1200/2589 (46%)]\tLoss: 230.277771\n",
      "Train Epoch: 375 [1500/2589 (58%)]\tLoss: 207.531586\n",
      "Train Epoch: 375 [1800/2589 (70%)]\tLoss: 267.463074\n",
      "Train Epoch: 375 [2100/2589 (81%)]\tLoss: 173.963593\n",
      "Train Epoch: 375 [2400/2589 (93%)]\tLoss: 220.338715\n",
      "====> Epoch: 375 Average train loss: 249.9332\n",
      "====> Epoch: 375 Average test loss: 920.1699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 376 [0/2589 (0%)]\tLoss: 215.366898\n",
      "Train Epoch: 376 [300/2589 (12%)]\tLoss: 321.032593\n",
      "Train Epoch: 376 [600/2589 (23%)]\tLoss: 284.090363\n",
      "Train Epoch: 376 [900/2589 (35%)]\tLoss: 303.409241\n",
      "Train Epoch: 376 [1200/2589 (46%)]\tLoss: 186.916367\n",
      "Train Epoch: 376 [1500/2589 (58%)]\tLoss: 240.663895\n",
      "Train Epoch: 376 [1800/2589 (70%)]\tLoss: 271.187897\n",
      "Train Epoch: 376 [2100/2589 (81%)]\tLoss: 272.673096\n",
      "Train Epoch: 376 [2400/2589 (93%)]\tLoss: 226.269669\n",
      "====> Epoch: 376 Average train loss: 251.5891\n",
      "====> Epoch: 376 Average test loss: 959.1415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 377 [0/2589 (0%)]\tLoss: 224.642441\n",
      "Train Epoch: 377 [300/2589 (12%)]\tLoss: 239.054794\n",
      "Train Epoch: 377 [600/2589 (23%)]\tLoss: 224.535797\n",
      "Train Epoch: 377 [900/2589 (35%)]\tLoss: 261.532379\n",
      "Train Epoch: 377 [1200/2589 (46%)]\tLoss: 287.045441\n",
      "Train Epoch: 377 [1500/2589 (58%)]\tLoss: 255.255722\n",
      "Train Epoch: 377 [1800/2589 (70%)]\tLoss: 323.792755\n",
      "Train Epoch: 377 [2100/2589 (81%)]\tLoss: 193.711594\n",
      "Train Epoch: 377 [2400/2589 (93%)]\tLoss: 248.045502\n",
      "====> Epoch: 377 Average train loss: 254.4917\n",
      "====> Epoch: 377 Average test loss: 937.5497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 378 [0/2589 (0%)]\tLoss: 314.950836\n",
      "Train Epoch: 378 [300/2589 (12%)]\tLoss: 665.476013\n",
      "Train Epoch: 378 [600/2589 (23%)]\tLoss: 272.499603\n",
      "Train Epoch: 378 [900/2589 (35%)]\tLoss: 153.417145\n",
      "Train Epoch: 378 [1200/2589 (46%)]\tLoss: 302.589844\n",
      "Train Epoch: 378 [1500/2589 (58%)]\tLoss: 299.492218\n",
      "Train Epoch: 378 [1800/2589 (70%)]\tLoss: 231.761002\n",
      "Train Epoch: 378 [2100/2589 (81%)]\tLoss: 275.847595\n",
      "Train Epoch: 378 [2400/2589 (93%)]\tLoss: 198.126816\n",
      "====> Epoch: 378 Average train loss: 255.3538\n",
      "====> Epoch: 378 Average test loss: 940.1991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 379 [0/2589 (0%)]\tLoss: 210.749512\n",
      "Train Epoch: 379 [300/2589 (12%)]\tLoss: 281.220886\n",
      "Train Epoch: 379 [600/2589 (23%)]\tLoss: 264.220428\n",
      "Train Epoch: 379 [900/2589 (35%)]\tLoss: 192.478714\n",
      "Train Epoch: 379 [1200/2589 (46%)]\tLoss: 273.083557\n",
      "Train Epoch: 379 [1500/2589 (58%)]\tLoss: 274.984039\n",
      "Train Epoch: 379 [1800/2589 (70%)]\tLoss: 273.469727\n",
      "Train Epoch: 379 [2100/2589 (81%)]\tLoss: 263.600220\n",
      "Train Epoch: 379 [2400/2589 (93%)]\tLoss: 236.622330\n",
      "====> Epoch: 379 Average train loss: 261.4786\n",
      "====> Epoch: 379 Average test loss: 944.0287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 380 [0/2589 (0%)]\tLoss: 209.036926\n",
      "Train Epoch: 380 [300/2589 (12%)]\tLoss: 220.916702\n",
      "Train Epoch: 380 [600/2589 (23%)]\tLoss: 284.089081\n",
      "Train Epoch: 380 [900/2589 (35%)]\tLoss: 184.609909\n",
      "Train Epoch: 380 [1200/2589 (46%)]\tLoss: 316.978302\n",
      "Train Epoch: 380 [1500/2589 (58%)]\tLoss: 254.058105\n",
      "Train Epoch: 380 [1800/2589 (70%)]\tLoss: 222.224442\n",
      "Train Epoch: 380 [2100/2589 (81%)]\tLoss: 199.767517\n",
      "Train Epoch: 380 [2400/2589 (93%)]\tLoss: 233.783371\n",
      "====> Epoch: 380 Average train loss: 258.8616\n",
      "====> Epoch: 380 Average test loss: 962.0023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 381 [0/2589 (0%)]\tLoss: 240.485184\n",
      "Train Epoch: 381 [300/2589 (12%)]\tLoss: 261.773407\n",
      "Train Epoch: 381 [600/2589 (23%)]\tLoss: 220.639359\n",
      "Train Epoch: 381 [900/2589 (35%)]\tLoss: 213.977890\n",
      "Train Epoch: 381 [1200/2589 (46%)]\tLoss: 283.313202\n",
      "Train Epoch: 381 [1500/2589 (58%)]\tLoss: 349.688599\n",
      "Train Epoch: 381 [1800/2589 (70%)]\tLoss: 280.948334\n",
      "Train Epoch: 381 [2100/2589 (81%)]\tLoss: 268.267151\n",
      "Train Epoch: 381 [2400/2589 (93%)]\tLoss: 260.214600\n",
      "====> Epoch: 381 Average train loss: 263.2006\n",
      "====> Epoch: 381 Average test loss: 939.7959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 382 [0/2589 (0%)]\tLoss: 247.558746\n",
      "Train Epoch: 382 [300/2589 (12%)]\tLoss: 307.180237\n",
      "Train Epoch: 382 [600/2589 (23%)]\tLoss: 267.085846\n",
      "Train Epoch: 382 [900/2589 (35%)]\tLoss: 421.244995\n",
      "Train Epoch: 382 [1200/2589 (46%)]\tLoss: 186.687790\n",
      "Train Epoch: 382 [1500/2589 (58%)]\tLoss: 286.465637\n",
      "Train Epoch: 382 [1800/2589 (70%)]\tLoss: 218.316711\n",
      "Train Epoch: 382 [2100/2589 (81%)]\tLoss: 197.685806\n",
      "Train Epoch: 382 [2400/2589 (93%)]\tLoss: 170.559921\n",
      "====> Epoch: 382 Average train loss: 247.2971\n",
      "====> Epoch: 382 Average test loss: 958.1138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 383 [0/2589 (0%)]\tLoss: 216.863708\n",
      "Train Epoch: 383 [300/2589 (12%)]\tLoss: 203.998856\n",
      "Train Epoch: 383 [600/2589 (23%)]\tLoss: 210.652084\n",
      "Train Epoch: 383 [900/2589 (35%)]\tLoss: 260.648315\n",
      "Train Epoch: 383 [1200/2589 (46%)]\tLoss: 309.906158\n",
      "Train Epoch: 383 [1500/2589 (58%)]\tLoss: 246.219452\n",
      "Train Epoch: 383 [1800/2589 (70%)]\tLoss: 230.208588\n",
      "Train Epoch: 383 [2100/2589 (81%)]\tLoss: 283.611206\n",
      "Train Epoch: 383 [2400/2589 (93%)]\tLoss: 169.558655\n",
      "====> Epoch: 383 Average train loss: 251.4205\n",
      "====> Epoch: 383 Average test loss: 939.3318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 384 [0/2589 (0%)]\tLoss: 223.110596\n",
      "Train Epoch: 384 [300/2589 (12%)]\tLoss: 195.707275\n",
      "Train Epoch: 384 [600/2589 (23%)]\tLoss: 199.938919\n",
      "Train Epoch: 384 [900/2589 (35%)]\tLoss: 268.494690\n",
      "Train Epoch: 384 [1200/2589 (46%)]\tLoss: 253.470917\n",
      "Train Epoch: 384 [1500/2589 (58%)]\tLoss: 257.880219\n",
      "Train Epoch: 384 [1800/2589 (70%)]\tLoss: 173.252197\n",
      "Train Epoch: 384 [2100/2589 (81%)]\tLoss: 162.703201\n",
      "Train Epoch: 384 [2400/2589 (93%)]\tLoss: 156.108429\n",
      "====> Epoch: 384 Average train loss: 266.7634\n",
      "====> Epoch: 384 Average test loss: 931.5944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 385 [0/2589 (0%)]\tLoss: 267.297852\n",
      "Train Epoch: 385 [300/2589 (12%)]\tLoss: 245.289902\n",
      "Train Epoch: 385 [600/2589 (23%)]\tLoss: 284.792267\n",
      "Train Epoch: 385 [900/2589 (35%)]\tLoss: 298.715485\n",
      "Train Epoch: 385 [1200/2589 (46%)]\tLoss: 297.748901\n",
      "Train Epoch: 385 [1500/2589 (58%)]\tLoss: 177.349777\n",
      "Train Epoch: 385 [1800/2589 (70%)]\tLoss: 350.725555\n",
      "Train Epoch: 385 [2100/2589 (81%)]\tLoss: 221.216446\n",
      "Train Epoch: 385 [2400/2589 (93%)]\tLoss: 178.667496\n",
      "====> Epoch: 385 Average train loss: 264.7143\n",
      "====> Epoch: 385 Average test loss: 928.8928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 386 [0/2589 (0%)]\tLoss: 254.624451\n",
      "Train Epoch: 386 [300/2589 (12%)]\tLoss: 249.282639\n",
      "Train Epoch: 386 [600/2589 (23%)]\tLoss: 235.630219\n",
      "Train Epoch: 386 [900/2589 (35%)]\tLoss: 207.816620\n",
      "Train Epoch: 386 [1200/2589 (46%)]\tLoss: 237.869736\n",
      "Train Epoch: 386 [1500/2589 (58%)]\tLoss: 192.724625\n",
      "Train Epoch: 386 [1800/2589 (70%)]\tLoss: 219.968857\n",
      "Train Epoch: 386 [2100/2589 (81%)]\tLoss: 197.189148\n",
      "Train Epoch: 386 [2400/2589 (93%)]\tLoss: 313.685059\n",
      "====> Epoch: 386 Average train loss: 252.4182\n",
      "====> Epoch: 386 Average test loss: 949.6311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 387 [0/2589 (0%)]\tLoss: 202.845505\n",
      "Train Epoch: 387 [300/2589 (12%)]\tLoss: 187.758408\n",
      "Train Epoch: 387 [600/2589 (23%)]\tLoss: 307.995117\n",
      "Train Epoch: 387 [900/2589 (35%)]\tLoss: 199.743256\n",
      "Train Epoch: 387 [1200/2589 (46%)]\tLoss: 268.084839\n",
      "Train Epoch: 387 [1500/2589 (58%)]\tLoss: 219.972183\n",
      "Train Epoch: 387 [1800/2589 (70%)]\tLoss: 261.338684\n",
      "Train Epoch: 387 [2100/2589 (81%)]\tLoss: 233.199844\n",
      "Train Epoch: 387 [2400/2589 (93%)]\tLoss: 247.152313\n",
      "====> Epoch: 387 Average train loss: 244.5802\n",
      "====> Epoch: 387 Average test loss: 935.8424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 388 [0/2589 (0%)]\tLoss: 231.780731\n",
      "Train Epoch: 388 [300/2589 (12%)]\tLoss: 247.509460\n",
      "Train Epoch: 388 [600/2589 (23%)]\tLoss: 246.893066\n",
      "Train Epoch: 388 [900/2589 (35%)]\tLoss: 245.680450\n",
      "Train Epoch: 388 [1200/2589 (46%)]\tLoss: 234.475723\n",
      "Train Epoch: 388 [1500/2589 (58%)]\tLoss: 195.062302\n",
      "Train Epoch: 388 [1800/2589 (70%)]\tLoss: 510.532715\n",
      "Train Epoch: 388 [2100/2589 (81%)]\tLoss: 271.305695\n",
      "Train Epoch: 388 [2400/2589 (93%)]\tLoss: 301.109833\n",
      "====> Epoch: 388 Average train loss: 251.2036\n",
      "====> Epoch: 388 Average test loss: 939.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 389 [0/2589 (0%)]\tLoss: 183.047287\n",
      "Train Epoch: 389 [300/2589 (12%)]\tLoss: 217.309921\n",
      "Train Epoch: 389 [600/2589 (23%)]\tLoss: 297.004272\n",
      "Train Epoch: 389 [900/2589 (35%)]\tLoss: 424.085327\n",
      "Train Epoch: 389 [1200/2589 (46%)]\tLoss: 311.598724\n",
      "Train Epoch: 389 [1500/2589 (58%)]\tLoss: 267.240479\n",
      "Train Epoch: 389 [1800/2589 (70%)]\tLoss: 235.315002\n",
      "Train Epoch: 389 [2100/2589 (81%)]\tLoss: 219.040359\n",
      "Train Epoch: 389 [2400/2589 (93%)]\tLoss: 234.454788\n",
      "====> Epoch: 389 Average train loss: 254.1225\n",
      "====> Epoch: 389 Average test loss: 947.2115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 390 [0/2589 (0%)]\tLoss: 211.216492\n",
      "Train Epoch: 390 [300/2589 (12%)]\tLoss: 238.121445\n",
      "Train Epoch: 390 [600/2589 (23%)]\tLoss: 248.482162\n",
      "Train Epoch: 390 [900/2589 (35%)]\tLoss: 245.317383\n",
      "Train Epoch: 390 [1200/2589 (46%)]\tLoss: 203.977859\n",
      "Train Epoch: 390 [1500/2589 (58%)]\tLoss: 238.562424\n",
      "Train Epoch: 390 [1800/2589 (70%)]\tLoss: 256.800720\n",
      "Train Epoch: 390 [2100/2589 (81%)]\tLoss: 196.353668\n",
      "Train Epoch: 390 [2400/2589 (93%)]\tLoss: 211.208206\n",
      "====> Epoch: 390 Average train loss: 252.3188\n",
      "====> Epoch: 390 Average test loss: 945.7823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 391 [0/2589 (0%)]\tLoss: 244.767410\n",
      "Train Epoch: 391 [300/2589 (12%)]\tLoss: 274.363770\n",
      "Train Epoch: 391 [600/2589 (23%)]\tLoss: 242.487076\n",
      "Train Epoch: 391 [900/2589 (35%)]\tLoss: 216.358124\n",
      "Train Epoch: 391 [1200/2589 (46%)]\tLoss: 215.467590\n",
      "Train Epoch: 391 [1500/2589 (58%)]\tLoss: 198.905853\n",
      "Train Epoch: 391 [1800/2589 (70%)]\tLoss: 260.756500\n",
      "Train Epoch: 391 [2100/2589 (81%)]\tLoss: 357.689758\n",
      "Train Epoch: 391 [2400/2589 (93%)]\tLoss: 162.181366\n",
      "====> Epoch: 391 Average train loss: 248.7729\n",
      "====> Epoch: 391 Average test loss: 925.3140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 392 [0/2589 (0%)]\tLoss: 208.171463\n",
      "Train Epoch: 392 [300/2589 (12%)]\tLoss: 174.721329\n",
      "Train Epoch: 392 [600/2589 (23%)]\tLoss: 245.187897\n",
      "Train Epoch: 392 [900/2589 (35%)]\tLoss: 223.059387\n",
      "Train Epoch: 392 [1200/2589 (46%)]\tLoss: 216.879257\n",
      "Train Epoch: 392 [1500/2589 (58%)]\tLoss: 252.025940\n",
      "Train Epoch: 392 [1800/2589 (70%)]\tLoss: 295.888763\n",
      "Train Epoch: 392 [2100/2589 (81%)]\tLoss: 259.774994\n",
      "Train Epoch: 392 [2400/2589 (93%)]\tLoss: 404.828217\n",
      "====> Epoch: 392 Average train loss: 260.7106\n",
      "====> Epoch: 392 Average test loss: 927.3264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 393 [0/2589 (0%)]\tLoss: 199.763214\n",
      "Train Epoch: 393 [300/2589 (12%)]\tLoss: 311.492371\n",
      "Train Epoch: 393 [600/2589 (23%)]\tLoss: 198.907059\n",
      "Train Epoch: 393 [900/2589 (35%)]\tLoss: 190.672882\n",
      "Train Epoch: 393 [1200/2589 (46%)]\tLoss: 271.176819\n",
      "Train Epoch: 393 [1500/2589 (58%)]\tLoss: 450.114410\n",
      "Train Epoch: 393 [1800/2589 (70%)]\tLoss: 209.536652\n",
      "Train Epoch: 393 [2100/2589 (81%)]\tLoss: 292.182495\n",
      "Train Epoch: 393 [2400/2589 (93%)]\tLoss: 228.734131\n",
      "====> Epoch: 393 Average train loss: 260.4640\n",
      "====> Epoch: 393 Average test loss: 926.0548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 394 [0/2589 (0%)]\tLoss: 212.165192\n",
      "Train Epoch: 394 [300/2589 (12%)]\tLoss: 142.433685\n",
      "Train Epoch: 394 [600/2589 (23%)]\tLoss: 247.071609\n",
      "Train Epoch: 394 [900/2589 (35%)]\tLoss: 280.852631\n",
      "Train Epoch: 394 [1200/2589 (46%)]\tLoss: 187.520416\n",
      "Train Epoch: 394 [1500/2589 (58%)]\tLoss: 274.126984\n",
      "Train Epoch: 394 [1800/2589 (70%)]\tLoss: 180.556808\n",
      "Train Epoch: 394 [2100/2589 (81%)]\tLoss: 227.113358\n",
      "Train Epoch: 394 [2400/2589 (93%)]\tLoss: 210.651184\n",
      "====> Epoch: 394 Average train loss: 249.8428\n",
      "====> Epoch: 394 Average test loss: 915.4385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 395 [0/2589 (0%)]\tLoss: 216.877106\n",
      "Train Epoch: 395 [300/2589 (12%)]\tLoss: 212.558807\n",
      "Train Epoch: 395 [600/2589 (23%)]\tLoss: 222.997055\n",
      "Train Epoch: 395 [900/2589 (35%)]\tLoss: 191.176590\n",
      "Train Epoch: 395 [1200/2589 (46%)]\tLoss: 262.137268\n",
      "Train Epoch: 395 [1500/2589 (58%)]\tLoss: 307.141418\n",
      "Train Epoch: 395 [1800/2589 (70%)]\tLoss: 177.440216\n",
      "Train Epoch: 395 [2100/2589 (81%)]\tLoss: 240.178482\n",
      "Train Epoch: 395 [2400/2589 (93%)]\tLoss: 233.538162\n",
      "====> Epoch: 395 Average train loss: 259.1407\n",
      "====> Epoch: 395 Average test loss: 921.6974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 396 [0/2589 (0%)]\tLoss: 193.997971\n",
      "Train Epoch: 396 [300/2589 (12%)]\tLoss: 210.992371\n",
      "Train Epoch: 396 [600/2589 (23%)]\tLoss: 321.169434\n",
      "Train Epoch: 396 [900/2589 (35%)]\tLoss: 299.616547\n",
      "Train Epoch: 396 [1200/2589 (46%)]\tLoss: 254.835938\n",
      "Train Epoch: 396 [1500/2589 (58%)]\tLoss: 198.804001\n",
      "Train Epoch: 396 [1800/2589 (70%)]\tLoss: 207.662445\n",
      "Train Epoch: 396 [2100/2589 (81%)]\tLoss: 302.636871\n",
      "Train Epoch: 396 [2400/2589 (93%)]\tLoss: 357.522583\n",
      "====> Epoch: 396 Average train loss: 251.2978\n",
      "====> Epoch: 396 Average test loss: 956.8038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 397 [0/2589 (0%)]\tLoss: 253.839310\n",
      "Train Epoch: 397 [300/2589 (12%)]\tLoss: 247.924698\n",
      "Train Epoch: 397 [600/2589 (23%)]\tLoss: 202.410614\n",
      "Train Epoch: 397 [900/2589 (35%)]\tLoss: 191.639587\n",
      "Train Epoch: 397 [1200/2589 (46%)]\tLoss: 236.904083\n",
      "Train Epoch: 397 [1500/2589 (58%)]\tLoss: 250.051819\n",
      "Train Epoch: 397 [1800/2589 (70%)]\tLoss: 217.025238\n",
      "Train Epoch: 397 [2100/2589 (81%)]\tLoss: 213.856293\n",
      "Train Epoch: 397 [2400/2589 (93%)]\tLoss: 322.961395\n",
      "====> Epoch: 397 Average train loss: 251.9208\n",
      "====> Epoch: 397 Average test loss: 960.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 398 [0/2589 (0%)]\tLoss: 222.948914\n",
      "Train Epoch: 398 [300/2589 (12%)]\tLoss: 304.671417\n",
      "Train Epoch: 398 [600/2589 (23%)]\tLoss: 210.720215\n",
      "Train Epoch: 398 [900/2589 (35%)]\tLoss: 189.240128\n",
      "Train Epoch: 398 [1200/2589 (46%)]\tLoss: 303.432739\n",
      "Train Epoch: 398 [1500/2589 (58%)]\tLoss: 188.387039\n",
      "Train Epoch: 398 [1800/2589 (70%)]\tLoss: 202.599518\n",
      "Train Epoch: 398 [2100/2589 (81%)]\tLoss: 221.277283\n",
      "Train Epoch: 398 [2400/2589 (93%)]\tLoss: 193.628510\n",
      "====> Epoch: 398 Average train loss: 236.6460\n",
      "====> Epoch: 398 Average test loss: 952.6353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 399 [0/2589 (0%)]\tLoss: 278.859589\n",
      "Train Epoch: 399 [300/2589 (12%)]\tLoss: 201.032166\n",
      "Train Epoch: 399 [600/2589 (23%)]\tLoss: 281.577240\n",
      "Train Epoch: 399 [900/2589 (35%)]\tLoss: 238.602142\n",
      "Train Epoch: 399 [1200/2589 (46%)]\tLoss: 188.779953\n",
      "Train Epoch: 399 [1500/2589 (58%)]\tLoss: 373.828400\n",
      "Train Epoch: 399 [1800/2589 (70%)]\tLoss: 226.569107\n",
      "Train Epoch: 399 [2100/2589 (81%)]\tLoss: 255.627365\n",
      "Train Epoch: 399 [2400/2589 (93%)]\tLoss: 295.097961\n",
      "====> Epoch: 399 Average train loss: 247.9621\n",
      "====> Epoch: 399 Average test loss: 932.2720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 400 [0/2589 (0%)]\tLoss: 345.275208\n",
      "Train Epoch: 400 [300/2589 (12%)]\tLoss: 188.865982\n",
      "Train Epoch: 400 [600/2589 (23%)]\tLoss: 245.478729\n",
      "Train Epoch: 400 [900/2589 (35%)]\tLoss: 267.609650\n",
      "Train Epoch: 400 [1200/2589 (46%)]\tLoss: 234.076599\n",
      "Train Epoch: 400 [1500/2589 (58%)]\tLoss: 232.227509\n",
      "Train Epoch: 400 [1800/2589 (70%)]\tLoss: 207.041061\n",
      "Train Epoch: 400 [2100/2589 (81%)]\tLoss: 189.465668\n",
      "Train Epoch: 400 [2400/2589 (93%)]\tLoss: 263.673706\n",
      "====> Epoch: 400 Average train loss: 251.2146\n",
      "====> Epoch: 400 Average test loss: 953.0095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 401 [0/2589 (0%)]\tLoss: 205.116180\n",
      "Train Epoch: 401 [300/2589 (12%)]\tLoss: 248.865768\n",
      "Train Epoch: 401 [600/2589 (23%)]\tLoss: 209.090012\n",
      "Train Epoch: 401 [900/2589 (35%)]\tLoss: 427.007385\n",
      "Train Epoch: 401 [1200/2589 (46%)]\tLoss: 212.798813\n",
      "Train Epoch: 401 [1500/2589 (58%)]\tLoss: 341.717224\n",
      "Train Epoch: 401 [1800/2589 (70%)]\tLoss: 221.377838\n",
      "Train Epoch: 401 [2100/2589 (81%)]\tLoss: 166.245453\n",
      "Train Epoch: 401 [2400/2589 (93%)]\tLoss: 194.902405\n",
      "====> Epoch: 401 Average train loss: 246.9460\n",
      "====> Epoch: 401 Average test loss: 934.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 402 [0/2589 (0%)]\tLoss: 368.393219\n",
      "Train Epoch: 402 [300/2589 (12%)]\tLoss: 278.380646\n",
      "Train Epoch: 402 [600/2589 (23%)]\tLoss: 443.679688\n",
      "Train Epoch: 402 [900/2589 (35%)]\tLoss: 324.400238\n",
      "Train Epoch: 402 [1200/2589 (46%)]\tLoss: 226.317047\n",
      "Train Epoch: 402 [1500/2589 (58%)]\tLoss: 200.127213\n",
      "Train Epoch: 402 [1800/2589 (70%)]\tLoss: 175.463577\n",
      "Train Epoch: 402 [2100/2589 (81%)]\tLoss: 266.002228\n",
      "Train Epoch: 402 [2400/2589 (93%)]\tLoss: 228.923737\n",
      "====> Epoch: 402 Average train loss: 264.9139\n",
      "====> Epoch: 402 Average test loss: 934.2823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 403 [0/2589 (0%)]\tLoss: 254.689423\n",
      "Train Epoch: 403 [300/2589 (12%)]\tLoss: 182.477859\n",
      "Train Epoch: 403 [600/2589 (23%)]\tLoss: 439.245056\n",
      "Train Epoch: 403 [900/2589 (35%)]\tLoss: 180.881851\n",
      "Train Epoch: 403 [1200/2589 (46%)]\tLoss: 230.174545\n",
      "Train Epoch: 403 [1500/2589 (58%)]\tLoss: 206.124710\n",
      "Train Epoch: 403 [1800/2589 (70%)]\tLoss: 225.688828\n",
      "Train Epoch: 403 [2100/2589 (81%)]\tLoss: 197.364456\n",
      "Train Epoch: 403 [2400/2589 (93%)]\tLoss: 272.841461\n",
      "====> Epoch: 403 Average train loss: 246.1090\n",
      "====> Epoch: 403 Average test loss: 939.6639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 404 [0/2589 (0%)]\tLoss: 512.956970\n",
      "Train Epoch: 404 [300/2589 (12%)]\tLoss: 172.836929\n",
      "Train Epoch: 404 [600/2589 (23%)]\tLoss: 177.685028\n",
      "Train Epoch: 404 [900/2589 (35%)]\tLoss: 220.272598\n",
      "Train Epoch: 404 [1200/2589 (46%)]\tLoss: 302.587891\n",
      "Train Epoch: 404 [1500/2589 (58%)]\tLoss: 196.898117\n",
      "Train Epoch: 404 [1800/2589 (70%)]\tLoss: 231.785492\n",
      "Train Epoch: 404 [2100/2589 (81%)]\tLoss: 293.246155\n",
      "Train Epoch: 404 [2400/2589 (93%)]\tLoss: 230.323776\n",
      "====> Epoch: 404 Average train loss: 254.5652\n",
      "====> Epoch: 404 Average test loss: 962.0424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 405 [0/2589 (0%)]\tLoss: 212.291595\n",
      "Train Epoch: 405 [300/2589 (12%)]\tLoss: 228.499176\n",
      "Train Epoch: 405 [600/2589 (23%)]\tLoss: 291.212311\n",
      "Train Epoch: 405 [900/2589 (35%)]\tLoss: 275.819336\n",
      "Train Epoch: 405 [1200/2589 (46%)]\tLoss: 283.664276\n",
      "Train Epoch: 405 [1500/2589 (58%)]\tLoss: 257.617798\n",
      "Train Epoch: 405 [1800/2589 (70%)]\tLoss: 213.619919\n",
      "Train Epoch: 405 [2100/2589 (81%)]\tLoss: 239.271805\n",
      "Train Epoch: 405 [2400/2589 (93%)]\tLoss: 265.426636\n",
      "====> Epoch: 405 Average train loss: 242.9148\n",
      "====> Epoch: 405 Average test loss: 937.6823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 406 [0/2589 (0%)]\tLoss: 204.709488\n",
      "Train Epoch: 406 [300/2589 (12%)]\tLoss: 192.995590\n",
      "Train Epoch: 406 [600/2589 (23%)]\tLoss: 160.124161\n",
      "Train Epoch: 406 [900/2589 (35%)]\tLoss: 393.787170\n",
      "Train Epoch: 406 [1200/2589 (46%)]\tLoss: 240.370529\n",
      "Train Epoch: 406 [1500/2589 (58%)]\tLoss: 183.922531\n",
      "Train Epoch: 406 [1800/2589 (70%)]\tLoss: 283.120880\n",
      "Train Epoch: 406 [2100/2589 (81%)]\tLoss: 287.814453\n",
      "Train Epoch: 406 [2400/2589 (93%)]\tLoss: 333.913757\n",
      "====> Epoch: 406 Average train loss: 246.9130\n",
      "====> Epoch: 406 Average test loss: 952.0463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 407 [0/2589 (0%)]\tLoss: 176.499130\n",
      "Train Epoch: 407 [300/2589 (12%)]\tLoss: 199.292908\n",
      "Train Epoch: 407 [600/2589 (23%)]\tLoss: 244.035583\n",
      "Train Epoch: 407 [900/2589 (35%)]\tLoss: 275.520355\n",
      "Train Epoch: 407 [1200/2589 (46%)]\tLoss: 223.823547\n",
      "Train Epoch: 407 [1500/2589 (58%)]\tLoss: 216.952713\n",
      "Train Epoch: 407 [1800/2589 (70%)]\tLoss: 270.695038\n",
      "Train Epoch: 407 [2100/2589 (81%)]\tLoss: 178.633560\n",
      "Train Epoch: 407 [2400/2589 (93%)]\tLoss: 302.136414\n",
      "====> Epoch: 407 Average train loss: 251.8750\n",
      "====> Epoch: 407 Average test loss: 929.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 408 [0/2589 (0%)]\tLoss: 223.145859\n",
      "Train Epoch: 408 [300/2589 (12%)]\tLoss: 230.654617\n",
      "Train Epoch: 408 [600/2589 (23%)]\tLoss: 179.936615\n",
      "Train Epoch: 408 [900/2589 (35%)]\tLoss: 198.404495\n",
      "Train Epoch: 408 [1200/2589 (46%)]\tLoss: 277.625610\n",
      "Train Epoch: 408 [1500/2589 (58%)]\tLoss: 227.970566\n",
      "Train Epoch: 408 [1800/2589 (70%)]\tLoss: 232.931213\n",
      "Train Epoch: 408 [2100/2589 (81%)]\tLoss: 348.081146\n",
      "Train Epoch: 408 [2400/2589 (93%)]\tLoss: 276.284637\n",
      "====> Epoch: 408 Average train loss: 260.6438\n",
      "====> Epoch: 408 Average test loss: 928.3941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 409 [0/2589 (0%)]\tLoss: 380.887634\n",
      "Train Epoch: 409 [300/2589 (12%)]\tLoss: 226.666824\n",
      "Train Epoch: 409 [600/2589 (23%)]\tLoss: 261.885590\n",
      "Train Epoch: 409 [900/2589 (35%)]\tLoss: 339.356049\n",
      "Train Epoch: 409 [1200/2589 (46%)]\tLoss: 345.989594\n",
      "Train Epoch: 409 [1500/2589 (58%)]\tLoss: 199.514832\n",
      "Train Epoch: 409 [1800/2589 (70%)]\tLoss: 293.235443\n",
      "Train Epoch: 409 [2100/2589 (81%)]\tLoss: 195.389709\n",
      "Train Epoch: 409 [2400/2589 (93%)]\tLoss: 258.474670\n",
      "====> Epoch: 409 Average train loss: 258.1627\n",
      "====> Epoch: 409 Average test loss: 952.4744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 410 [0/2589 (0%)]\tLoss: 297.837616\n",
      "Train Epoch: 410 [300/2589 (12%)]\tLoss: 270.025421\n",
      "Train Epoch: 410 [600/2589 (23%)]\tLoss: 204.795670\n",
      "Train Epoch: 410 [900/2589 (35%)]\tLoss: 209.321640\n",
      "Train Epoch: 410 [1200/2589 (46%)]\tLoss: 195.752609\n",
      "Train Epoch: 410 [1500/2589 (58%)]\tLoss: 199.396866\n",
      "Train Epoch: 410 [1800/2589 (70%)]\tLoss: 237.767365\n",
      "Train Epoch: 410 [2100/2589 (81%)]\tLoss: 168.723114\n",
      "Train Epoch: 410 [2400/2589 (93%)]\tLoss: 281.768463\n",
      "====> Epoch: 410 Average train loss: 245.6702\n",
      "====> Epoch: 410 Average test loss: 943.4377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 411 [0/2589 (0%)]\tLoss: 183.649872\n",
      "Train Epoch: 411 [300/2589 (12%)]\tLoss: 273.042419\n",
      "Train Epoch: 411 [600/2589 (23%)]\tLoss: 296.622223\n",
      "Train Epoch: 411 [900/2589 (35%)]\tLoss: 138.282303\n",
      "Train Epoch: 411 [1200/2589 (46%)]\tLoss: 292.639801\n",
      "Train Epoch: 411 [1500/2589 (58%)]\tLoss: 249.076675\n",
      "Train Epoch: 411 [1800/2589 (70%)]\tLoss: 197.640366\n",
      "Train Epoch: 411 [2100/2589 (81%)]\tLoss: 289.982605\n",
      "Train Epoch: 411 [2400/2589 (93%)]\tLoss: 221.089401\n",
      "====> Epoch: 411 Average train loss: 243.3591\n",
      "====> Epoch: 411 Average test loss: 934.0870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 412 [0/2589 (0%)]\tLoss: 209.930740\n",
      "Train Epoch: 412 [300/2589 (12%)]\tLoss: 233.624161\n",
      "Train Epoch: 412 [600/2589 (23%)]\tLoss: 199.115814\n",
      "Train Epoch: 412 [900/2589 (35%)]\tLoss: 209.346329\n",
      "Train Epoch: 412 [1200/2589 (46%)]\tLoss: 329.933502\n",
      "Train Epoch: 412 [1500/2589 (58%)]\tLoss: 238.388519\n",
      "Train Epoch: 412 [1800/2589 (70%)]\tLoss: 222.198792\n",
      "Train Epoch: 412 [2100/2589 (81%)]\tLoss: 218.046890\n",
      "Train Epoch: 412 [2400/2589 (93%)]\tLoss: 330.591858\n",
      "====> Epoch: 412 Average train loss: 245.2986\n",
      "====> Epoch: 412 Average test loss: 940.5776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 413 [0/2589 (0%)]\tLoss: 249.585297\n",
      "Train Epoch: 413 [300/2589 (12%)]\tLoss: 224.441833\n",
      "Train Epoch: 413 [600/2589 (23%)]\tLoss: 240.425644\n",
      "Train Epoch: 413 [900/2589 (35%)]\tLoss: 205.249649\n",
      "Train Epoch: 413 [1200/2589 (46%)]\tLoss: 226.068268\n",
      "Train Epoch: 413 [1500/2589 (58%)]\tLoss: 393.605621\n",
      "Train Epoch: 413 [1800/2589 (70%)]\tLoss: 210.304153\n",
      "Train Epoch: 413 [2100/2589 (81%)]\tLoss: 212.831955\n",
      "Train Epoch: 413 [2400/2589 (93%)]\tLoss: 272.273438\n",
      "====> Epoch: 413 Average train loss: 253.3809\n",
      "====> Epoch: 413 Average test loss: 928.3470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 414 [0/2589 (0%)]\tLoss: 430.979034\n",
      "Train Epoch: 414 [300/2589 (12%)]\tLoss: 386.919159\n",
      "Train Epoch: 414 [600/2589 (23%)]\tLoss: 237.160049\n",
      "Train Epoch: 414 [900/2589 (35%)]\tLoss: 176.641220\n",
      "Train Epoch: 414 [1200/2589 (46%)]\tLoss: 210.380554\n",
      "Train Epoch: 414 [1500/2589 (58%)]\tLoss: 248.815903\n",
      "Train Epoch: 414 [1800/2589 (70%)]\tLoss: 198.925385\n",
      "Train Epoch: 414 [2100/2589 (81%)]\tLoss: 250.313904\n",
      "Train Epoch: 414 [2400/2589 (93%)]\tLoss: 221.931061\n",
      "====> Epoch: 414 Average train loss: 261.9082\n",
      "====> Epoch: 414 Average test loss: 922.6257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 415 [0/2589 (0%)]\tLoss: 203.931854\n",
      "Train Epoch: 415 [300/2589 (12%)]\tLoss: 186.132416\n",
      "Train Epoch: 415 [600/2589 (23%)]\tLoss: 226.497467\n",
      "Train Epoch: 415 [900/2589 (35%)]\tLoss: 271.365448\n",
      "Train Epoch: 415 [1200/2589 (46%)]\tLoss: 379.995789\n",
      "Train Epoch: 415 [1500/2589 (58%)]\tLoss: 210.039734\n",
      "Train Epoch: 415 [1800/2589 (70%)]\tLoss: 213.615326\n",
      "Train Epoch: 415 [2100/2589 (81%)]\tLoss: 218.616379\n",
      "Train Epoch: 415 [2400/2589 (93%)]\tLoss: 252.507858\n",
      "====> Epoch: 415 Average train loss: 256.0601\n",
      "====> Epoch: 415 Average test loss: 948.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 416 [0/2589 (0%)]\tLoss: 236.132782\n",
      "Train Epoch: 416 [300/2589 (12%)]\tLoss: 233.341766\n",
      "Train Epoch: 416 [600/2589 (23%)]\tLoss: 255.616867\n",
      "Train Epoch: 416 [900/2589 (35%)]\tLoss: 174.694275\n",
      "Train Epoch: 416 [1200/2589 (46%)]\tLoss: 279.970764\n",
      "Train Epoch: 416 [1500/2589 (58%)]\tLoss: 212.935806\n",
      "Train Epoch: 416 [1800/2589 (70%)]\tLoss: 198.454178\n",
      "Train Epoch: 416 [2100/2589 (81%)]\tLoss: 299.116547\n",
      "Train Epoch: 416 [2400/2589 (93%)]\tLoss: 395.073395\n",
      "====> Epoch: 416 Average train loss: 259.4940\n",
      "====> Epoch: 416 Average test loss: 941.6132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 417 [0/2589 (0%)]\tLoss: 202.774551\n",
      "Train Epoch: 417 [300/2589 (12%)]\tLoss: 254.775208\n",
      "Train Epoch: 417 [600/2589 (23%)]\tLoss: 168.598038\n",
      "Train Epoch: 417 [900/2589 (35%)]\tLoss: 281.087128\n",
      "Train Epoch: 417 [1200/2589 (46%)]\tLoss: 327.281250\n",
      "Train Epoch: 417 [1500/2589 (58%)]\tLoss: 233.492157\n",
      "Train Epoch: 417 [1800/2589 (70%)]\tLoss: 225.669891\n",
      "Train Epoch: 417 [2100/2589 (81%)]\tLoss: 313.961426\n",
      "Train Epoch: 417 [2400/2589 (93%)]\tLoss: 258.516907\n",
      "====> Epoch: 417 Average train loss: 254.7074\n",
      "====> Epoch: 417 Average test loss: 927.8553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 418 [0/2589 (0%)]\tLoss: 185.612305\n",
      "Train Epoch: 418 [300/2589 (12%)]\tLoss: 249.030472\n",
      "Train Epoch: 418 [600/2589 (23%)]\tLoss: 228.814316\n",
      "Train Epoch: 418 [900/2589 (35%)]\tLoss: 172.286758\n",
      "Train Epoch: 418 [1200/2589 (46%)]\tLoss: 198.695160\n",
      "Train Epoch: 418 [1500/2589 (58%)]\tLoss: 251.069839\n",
      "Train Epoch: 418 [1800/2589 (70%)]\tLoss: 206.995255\n",
      "Train Epoch: 418 [2100/2589 (81%)]\tLoss: 236.101669\n",
      "Train Epoch: 418 [2400/2589 (93%)]\tLoss: 210.903641\n",
      "====> Epoch: 418 Average train loss: 238.4677\n",
      "====> Epoch: 418 Average test loss: 931.7001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 419 [0/2589 (0%)]\tLoss: 297.424133\n",
      "Train Epoch: 419 [300/2589 (12%)]\tLoss: 283.872131\n",
      "Train Epoch: 419 [600/2589 (23%)]\tLoss: 310.176147\n",
      "Train Epoch: 419 [900/2589 (35%)]\tLoss: 278.188599\n",
      "Train Epoch: 419 [1200/2589 (46%)]\tLoss: 178.944077\n",
      "Train Epoch: 419 [1500/2589 (58%)]\tLoss: 214.290726\n",
      "Train Epoch: 419 [1800/2589 (70%)]\tLoss: 300.436646\n",
      "Train Epoch: 419 [2100/2589 (81%)]\tLoss: 309.704407\n",
      "Train Epoch: 419 [2400/2589 (93%)]\tLoss: 381.299622\n",
      "====> Epoch: 419 Average train loss: 253.9382\n",
      "====> Epoch: 419 Average test loss: 941.9567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 420 [0/2589 (0%)]\tLoss: 230.969147\n",
      "Train Epoch: 420 [300/2589 (12%)]\tLoss: 471.627167\n",
      "Train Epoch: 420 [600/2589 (23%)]\tLoss: 241.817673\n",
      "Train Epoch: 420 [900/2589 (35%)]\tLoss: 315.895081\n",
      "Train Epoch: 420 [1200/2589 (46%)]\tLoss: 256.195953\n",
      "Train Epoch: 420 [1500/2589 (58%)]\tLoss: 241.377991\n",
      "Train Epoch: 420 [1800/2589 (70%)]\tLoss: 245.641220\n",
      "Train Epoch: 420 [2100/2589 (81%)]\tLoss: 287.106964\n",
      "Train Epoch: 420 [2400/2589 (93%)]\tLoss: 315.889374\n",
      "====> Epoch: 420 Average train loss: 242.0989\n",
      "====> Epoch: 420 Average test loss: 956.1702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 421 [0/2589 (0%)]\tLoss: 274.042511\n",
      "Train Epoch: 421 [300/2589 (12%)]\tLoss: 210.466629\n",
      "Train Epoch: 421 [600/2589 (23%)]\tLoss: 285.976440\n",
      "Train Epoch: 421 [900/2589 (35%)]\tLoss: 193.742676\n",
      "Train Epoch: 421 [1200/2589 (46%)]\tLoss: 277.496094\n",
      "Train Epoch: 421 [1500/2589 (58%)]\tLoss: 271.670105\n",
      "Train Epoch: 421 [1800/2589 (70%)]\tLoss: 181.972809\n",
      "Train Epoch: 421 [2100/2589 (81%)]\tLoss: 189.976654\n",
      "Train Epoch: 421 [2400/2589 (93%)]\tLoss: 154.004532\n",
      "====> Epoch: 421 Average train loss: 244.7791\n",
      "====> Epoch: 421 Average test loss: 935.7040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 422 [0/2589 (0%)]\tLoss: 184.202057\n",
      "Train Epoch: 422 [300/2589 (12%)]\tLoss: 245.080460\n",
      "Train Epoch: 422 [600/2589 (23%)]\tLoss: 259.194397\n",
      "Train Epoch: 422 [900/2589 (35%)]\tLoss: 252.237518\n",
      "Train Epoch: 422 [1200/2589 (46%)]\tLoss: 253.238510\n",
      "Train Epoch: 422 [1500/2589 (58%)]\tLoss: 258.185638\n",
      "Train Epoch: 422 [1800/2589 (70%)]\tLoss: 217.882553\n",
      "Train Epoch: 422 [2100/2589 (81%)]\tLoss: 327.773407\n",
      "Train Epoch: 422 [2400/2589 (93%)]\tLoss: 236.422455\n",
      "====> Epoch: 422 Average train loss: 247.0449\n",
      "====> Epoch: 422 Average test loss: 937.7954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 423 [0/2589 (0%)]\tLoss: 354.127747\n",
      "Train Epoch: 423 [300/2589 (12%)]\tLoss: 295.933990\n",
      "Train Epoch: 423 [600/2589 (23%)]\tLoss: 254.115753\n",
      "Train Epoch: 423 [900/2589 (35%)]\tLoss: 180.022018\n",
      "Train Epoch: 423 [1200/2589 (46%)]\tLoss: 273.340454\n",
      "Train Epoch: 423 [1500/2589 (58%)]\tLoss: 196.240128\n",
      "Train Epoch: 423 [1800/2589 (70%)]\tLoss: 206.140106\n",
      "Train Epoch: 423 [2100/2589 (81%)]\tLoss: 194.917343\n",
      "Train Epoch: 423 [2400/2589 (93%)]\tLoss: 305.262695\n",
      "====> Epoch: 423 Average train loss: 259.6731\n",
      "====> Epoch: 423 Average test loss: 931.5181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 424 [0/2589 (0%)]\tLoss: 187.150681\n",
      "Train Epoch: 424 [300/2589 (12%)]\tLoss: 259.111023\n",
      "Train Epoch: 424 [600/2589 (23%)]\tLoss: 198.938751\n",
      "Train Epoch: 424 [900/2589 (35%)]\tLoss: 296.453217\n",
      "Train Epoch: 424 [1200/2589 (46%)]\tLoss: 237.481583\n",
      "Train Epoch: 424 [1500/2589 (58%)]\tLoss: 218.160904\n",
      "Train Epoch: 424 [1800/2589 (70%)]\tLoss: 256.741882\n",
      "Train Epoch: 424 [2100/2589 (81%)]\tLoss: 204.354828\n",
      "Train Epoch: 424 [2400/2589 (93%)]\tLoss: 190.895508\n",
      "====> Epoch: 424 Average train loss: 265.2580\n",
      "====> Epoch: 424 Average test loss: 924.2442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 425 [0/2589 (0%)]\tLoss: 149.215179\n",
      "Train Epoch: 425 [300/2589 (12%)]\tLoss: 264.263245\n",
      "Train Epoch: 425 [600/2589 (23%)]\tLoss: 190.276672\n",
      "Train Epoch: 425 [900/2589 (35%)]\tLoss: 191.272141\n",
      "Train Epoch: 425 [1200/2589 (46%)]\tLoss: 314.520203\n",
      "Train Epoch: 425 [1500/2589 (58%)]\tLoss: 235.983459\n",
      "Train Epoch: 425 [1800/2589 (70%)]\tLoss: 240.924149\n",
      "Train Epoch: 425 [2100/2589 (81%)]\tLoss: 248.339828\n",
      "Train Epoch: 425 [2400/2589 (93%)]\tLoss: 244.834213\n",
      "====> Epoch: 425 Average train loss: 259.0190\n",
      "====> Epoch: 425 Average test loss: 966.7729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 426 [0/2589 (0%)]\tLoss: 206.137756\n",
      "Train Epoch: 426 [300/2589 (12%)]\tLoss: 221.251266\n",
      "Train Epoch: 426 [600/2589 (23%)]\tLoss: 265.601776\n",
      "Train Epoch: 426 [900/2589 (35%)]\tLoss: 166.372299\n",
      "Train Epoch: 426 [1200/2589 (46%)]\tLoss: 229.416733\n",
      "Train Epoch: 426 [1500/2589 (58%)]\tLoss: 241.206787\n",
      "Train Epoch: 426 [1800/2589 (70%)]\tLoss: 173.656555\n",
      "Train Epoch: 426 [2100/2589 (81%)]\tLoss: 220.595047\n",
      "Train Epoch: 426 [2400/2589 (93%)]\tLoss: 389.505188\n",
      "====> Epoch: 426 Average train loss: 245.3721\n",
      "====> Epoch: 426 Average test loss: 923.1602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 427 [0/2589 (0%)]\tLoss: 237.564346\n",
      "Train Epoch: 427 [300/2589 (12%)]\tLoss: 150.031631\n",
      "Train Epoch: 427 [600/2589 (23%)]\tLoss: 324.781891\n",
      "Train Epoch: 427 [900/2589 (35%)]\tLoss: 200.188293\n",
      "Train Epoch: 427 [1200/2589 (46%)]\tLoss: 262.837952\n",
      "Train Epoch: 427 [1500/2589 (58%)]\tLoss: 288.880524\n",
      "Train Epoch: 427 [1800/2589 (70%)]\tLoss: 224.523361\n",
      "Train Epoch: 427 [2100/2589 (81%)]\tLoss: 352.920898\n",
      "Train Epoch: 427 [2400/2589 (93%)]\tLoss: 226.122375\n",
      "====> Epoch: 427 Average train loss: 245.1305\n",
      "====> Epoch: 427 Average test loss: 937.6133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 428 [0/2589 (0%)]\tLoss: 200.970215\n",
      "Train Epoch: 428 [300/2589 (12%)]\tLoss: 227.993790\n",
      "Train Epoch: 428 [600/2589 (23%)]\tLoss: 162.511551\n",
      "Train Epoch: 428 [900/2589 (35%)]\tLoss: 273.667877\n",
      "Train Epoch: 428 [1200/2589 (46%)]\tLoss: 168.634537\n",
      "Train Epoch: 428 [1500/2589 (58%)]\tLoss: 290.457245\n",
      "Train Epoch: 428 [1800/2589 (70%)]\tLoss: 156.550690\n",
      "Train Epoch: 428 [2100/2589 (81%)]\tLoss: 183.605225\n",
      "Train Epoch: 428 [2400/2589 (93%)]\tLoss: 248.056870\n",
      "====> Epoch: 428 Average train loss: 249.7812\n",
      "====> Epoch: 428 Average test loss: 928.4556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 429 [0/2589 (0%)]\tLoss: 313.618713\n",
      "Train Epoch: 429 [300/2589 (12%)]\tLoss: 255.512985\n",
      "Train Epoch: 429 [600/2589 (23%)]\tLoss: 167.461517\n",
      "Train Epoch: 429 [900/2589 (35%)]\tLoss: 334.925140\n",
      "Train Epoch: 429 [1200/2589 (46%)]\tLoss: 306.476227\n",
      "Train Epoch: 429 [1500/2589 (58%)]\tLoss: 178.216141\n",
      "Train Epoch: 429 [1800/2589 (70%)]\tLoss: 315.709412\n",
      "Train Epoch: 429 [2100/2589 (81%)]\tLoss: 232.948990\n",
      "Train Epoch: 429 [2400/2589 (93%)]\tLoss: 425.143616\n",
      "====> Epoch: 429 Average train loss: 245.3071\n",
      "====> Epoch: 429 Average test loss: 957.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 430 [0/2589 (0%)]\tLoss: 353.855652\n",
      "Train Epoch: 430 [300/2589 (12%)]\tLoss: 287.250214\n",
      "Train Epoch: 430 [600/2589 (23%)]\tLoss: 343.843109\n",
      "Train Epoch: 430 [900/2589 (35%)]\tLoss: 212.009567\n",
      "Train Epoch: 430 [1200/2589 (46%)]\tLoss: 174.346100\n",
      "Train Epoch: 430 [1500/2589 (58%)]\tLoss: 231.865723\n",
      "Train Epoch: 430 [1800/2589 (70%)]\tLoss: 171.117767\n",
      "Train Epoch: 430 [2100/2589 (81%)]\tLoss: 152.181931\n",
      "Train Epoch: 430 [2400/2589 (93%)]\tLoss: 198.253082\n",
      "====> Epoch: 430 Average train loss: 244.3102\n",
      "====> Epoch: 430 Average test loss: 939.3787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 431 [0/2589 (0%)]\tLoss: 191.895447\n",
      "Train Epoch: 431 [300/2589 (12%)]\tLoss: 192.645233\n",
      "Train Epoch: 431 [600/2589 (23%)]\tLoss: 229.599792\n",
      "Train Epoch: 431 [900/2589 (35%)]\tLoss: 304.138611\n",
      "Train Epoch: 431 [1200/2589 (46%)]\tLoss: 191.015945\n",
      "Train Epoch: 431 [1500/2589 (58%)]\tLoss: 194.267563\n",
      "Train Epoch: 431 [1800/2589 (70%)]\tLoss: 238.785553\n",
      "Train Epoch: 431 [2100/2589 (81%)]\tLoss: 235.597977\n",
      "Train Epoch: 431 [2400/2589 (93%)]\tLoss: 205.662277\n",
      "====> Epoch: 431 Average train loss: 238.7695\n",
      "====> Epoch: 431 Average test loss: 942.4780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 432 [0/2589 (0%)]\tLoss: 187.248932\n",
      "Train Epoch: 432 [300/2589 (12%)]\tLoss: 173.604431\n",
      "Train Epoch: 432 [600/2589 (23%)]\tLoss: 421.310272\n",
      "Train Epoch: 432 [900/2589 (35%)]\tLoss: 212.657578\n",
      "Train Epoch: 432 [1200/2589 (46%)]\tLoss: 196.389557\n",
      "Train Epoch: 432 [1500/2589 (58%)]\tLoss: 258.288666\n",
      "Train Epoch: 432 [1800/2589 (70%)]\tLoss: 322.468445\n",
      "Train Epoch: 432 [2100/2589 (81%)]\tLoss: 231.554993\n",
      "Train Epoch: 432 [2400/2589 (93%)]\tLoss: 259.965698\n",
      "====> Epoch: 432 Average train loss: 254.6409\n",
      "====> Epoch: 432 Average test loss: 927.1711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 433 [0/2589 (0%)]\tLoss: 263.448425\n",
      "Train Epoch: 433 [300/2589 (12%)]\tLoss: 216.782089\n",
      "Train Epoch: 433 [600/2589 (23%)]\tLoss: 205.638351\n",
      "Train Epoch: 433 [900/2589 (35%)]\tLoss: 308.016998\n",
      "Train Epoch: 433 [1200/2589 (46%)]\tLoss: 256.257843\n",
      "Train Epoch: 433 [1500/2589 (58%)]\tLoss: 257.723755\n",
      "Train Epoch: 433 [1800/2589 (70%)]\tLoss: 289.348785\n",
      "Train Epoch: 433 [2100/2589 (81%)]\tLoss: 304.413849\n",
      "Train Epoch: 433 [2400/2589 (93%)]\tLoss: 269.695160\n",
      "====> Epoch: 433 Average train loss: 259.5370\n",
      "====> Epoch: 433 Average test loss: 959.7018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 434 [0/2589 (0%)]\tLoss: 231.361267\n",
      "Train Epoch: 434 [300/2589 (12%)]\tLoss: 302.131836\n",
      "Train Epoch: 434 [600/2589 (23%)]\tLoss: 262.166382\n",
      "Train Epoch: 434 [900/2589 (35%)]\tLoss: 295.164154\n",
      "Train Epoch: 434 [1200/2589 (46%)]\tLoss: 205.422653\n",
      "Train Epoch: 434 [1500/2589 (58%)]\tLoss: 240.797119\n",
      "Train Epoch: 434 [1800/2589 (70%)]\tLoss: 159.998825\n",
      "Train Epoch: 434 [2100/2589 (81%)]\tLoss: 352.375702\n",
      "Train Epoch: 434 [2400/2589 (93%)]\tLoss: 349.338928\n",
      "====> Epoch: 434 Average train loss: 251.1289\n",
      "====> Epoch: 434 Average test loss: 952.3669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 435 [0/2589 (0%)]\tLoss: 272.227631\n",
      "Train Epoch: 435 [300/2589 (12%)]\tLoss: 338.642151\n",
      "Train Epoch: 435 [600/2589 (23%)]\tLoss: 214.080032\n",
      "Train Epoch: 435 [900/2589 (35%)]\tLoss: 161.702179\n",
      "Train Epoch: 435 [1200/2589 (46%)]\tLoss: 264.207184\n",
      "Train Epoch: 435 [1500/2589 (58%)]\tLoss: 153.689621\n",
      "Train Epoch: 435 [1800/2589 (70%)]\tLoss: 196.205322\n",
      "Train Epoch: 435 [2100/2589 (81%)]\tLoss: 258.156372\n",
      "Train Epoch: 435 [2400/2589 (93%)]\tLoss: 264.308777\n",
      "====> Epoch: 435 Average train loss: 262.3973\n",
      "====> Epoch: 435 Average test loss: 940.2126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 436 [0/2589 (0%)]\tLoss: 160.659012\n",
      "Train Epoch: 436 [300/2589 (12%)]\tLoss: 238.095718\n",
      "Train Epoch: 436 [600/2589 (23%)]\tLoss: 214.918594\n",
      "Train Epoch: 436 [900/2589 (35%)]\tLoss: 212.271057\n",
      "Train Epoch: 436 [1200/2589 (46%)]\tLoss: 238.139435\n",
      "Train Epoch: 436 [1500/2589 (58%)]\tLoss: 167.915695\n",
      "Train Epoch: 436 [1800/2589 (70%)]\tLoss: 259.970398\n",
      "Train Epoch: 436 [2100/2589 (81%)]\tLoss: 309.839508\n",
      "Train Epoch: 436 [2400/2589 (93%)]\tLoss: 272.010376\n",
      "====> Epoch: 436 Average train loss: 241.9433\n",
      "====> Epoch: 436 Average test loss: 937.1937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 437 [0/2589 (0%)]\tLoss: 277.364380\n",
      "Train Epoch: 437 [300/2589 (12%)]\tLoss: 246.021530\n",
      "Train Epoch: 437 [600/2589 (23%)]\tLoss: 174.198334\n",
      "Train Epoch: 437 [900/2589 (35%)]\tLoss: 256.284943\n",
      "Train Epoch: 437 [1200/2589 (46%)]\tLoss: 382.443573\n",
      "Train Epoch: 437 [1500/2589 (58%)]\tLoss: 221.532318\n",
      "Train Epoch: 437 [1800/2589 (70%)]\tLoss: 242.310379\n",
      "Train Epoch: 437 [2100/2589 (81%)]\tLoss: 232.366013\n",
      "Train Epoch: 437 [2400/2589 (93%)]\tLoss: 229.879715\n",
      "====> Epoch: 437 Average train loss: 244.6232\n",
      "====> Epoch: 437 Average test loss: 931.0627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 438 [0/2589 (0%)]\tLoss: 182.302155\n",
      "Train Epoch: 438 [300/2589 (12%)]\tLoss: 485.035553\n",
      "Train Epoch: 438 [600/2589 (23%)]\tLoss: 203.803894\n",
      "Train Epoch: 438 [900/2589 (35%)]\tLoss: 224.787262\n",
      "Train Epoch: 438 [1200/2589 (46%)]\tLoss: 148.262650\n",
      "Train Epoch: 438 [1500/2589 (58%)]\tLoss: 188.155350\n",
      "Train Epoch: 438 [1800/2589 (70%)]\tLoss: 192.029785\n",
      "Train Epoch: 438 [2100/2589 (81%)]\tLoss: 178.382950\n",
      "Train Epoch: 438 [2400/2589 (93%)]\tLoss: 198.523575\n",
      "====> Epoch: 438 Average train loss: 251.7345\n",
      "====> Epoch: 438 Average test loss: 927.6356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 439 [0/2589 (0%)]\tLoss: 363.301819\n",
      "Train Epoch: 439 [300/2589 (12%)]\tLoss: 265.102997\n",
      "Train Epoch: 439 [600/2589 (23%)]\tLoss: 223.705002\n",
      "Train Epoch: 439 [900/2589 (35%)]\tLoss: 196.363922\n",
      "Train Epoch: 439 [1200/2589 (46%)]\tLoss: 230.251678\n",
      "Train Epoch: 439 [1500/2589 (58%)]\tLoss: 279.290680\n",
      "Train Epoch: 439 [1800/2589 (70%)]\tLoss: 198.266281\n",
      "Train Epoch: 439 [2100/2589 (81%)]\tLoss: 161.977341\n",
      "Train Epoch: 439 [2400/2589 (93%)]\tLoss: 250.098831\n",
      "====> Epoch: 439 Average train loss: 242.4645\n",
      "====> Epoch: 439 Average test loss: 932.3303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 440 [0/2589 (0%)]\tLoss: 153.783447\n",
      "Train Epoch: 440 [300/2589 (12%)]\tLoss: 328.423248\n",
      "Train Epoch: 440 [600/2589 (23%)]\tLoss: 222.421326\n",
      "Train Epoch: 440 [900/2589 (35%)]\tLoss: 305.942505\n",
      "Train Epoch: 440 [1200/2589 (46%)]\tLoss: 201.592575\n",
      "Train Epoch: 440 [1500/2589 (58%)]\tLoss: 290.704620\n",
      "Train Epoch: 440 [1800/2589 (70%)]\tLoss: 168.457581\n",
      "Train Epoch: 440 [2100/2589 (81%)]\tLoss: 248.013443\n",
      "Train Epoch: 440 [2400/2589 (93%)]\tLoss: 201.382294\n",
      "====> Epoch: 440 Average train loss: 239.1361\n",
      "====> Epoch: 440 Average test loss: 926.0422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 441 [0/2589 (0%)]\tLoss: 214.028183\n",
      "Train Epoch: 441 [300/2589 (12%)]\tLoss: 181.707672\n",
      "Train Epoch: 441 [600/2589 (23%)]\tLoss: 296.546112\n",
      "Train Epoch: 441 [900/2589 (35%)]\tLoss: 235.229630\n",
      "Train Epoch: 441 [1200/2589 (46%)]\tLoss: 199.736282\n",
      "Train Epoch: 441 [1500/2589 (58%)]\tLoss: 222.615631\n",
      "Train Epoch: 441 [1800/2589 (70%)]\tLoss: 249.324448\n",
      "Train Epoch: 441 [2100/2589 (81%)]\tLoss: 215.216034\n",
      "Train Epoch: 441 [2400/2589 (93%)]\tLoss: 312.462799\n",
      "====> Epoch: 441 Average train loss: 259.7952\n",
      "====> Epoch: 441 Average test loss: 930.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 442 [0/2589 (0%)]\tLoss: 337.309570\n",
      "Train Epoch: 442 [300/2589 (12%)]\tLoss: 301.688538\n",
      "Train Epoch: 442 [600/2589 (23%)]\tLoss: 259.571686\n",
      "Train Epoch: 442 [900/2589 (35%)]\tLoss: 237.707214\n",
      "Train Epoch: 442 [1200/2589 (46%)]\tLoss: 242.174286\n",
      "Train Epoch: 442 [1500/2589 (58%)]\tLoss: 212.379730\n",
      "Train Epoch: 442 [1800/2589 (70%)]\tLoss: 312.610138\n",
      "Train Epoch: 442 [2100/2589 (81%)]\tLoss: 272.870331\n",
      "Train Epoch: 442 [2400/2589 (93%)]\tLoss: 251.323563\n",
      "====> Epoch: 442 Average train loss: 252.7437\n",
      "====> Epoch: 442 Average test loss: 918.1342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 443 [0/2589 (0%)]\tLoss: 468.235748\n",
      "Train Epoch: 443 [300/2589 (12%)]\tLoss: 393.564636\n",
      "Train Epoch: 443 [600/2589 (23%)]\tLoss: 316.715637\n",
      "Train Epoch: 443 [900/2589 (35%)]\tLoss: 221.524582\n",
      "Train Epoch: 443 [1200/2589 (46%)]\tLoss: 188.071777\n",
      "Train Epoch: 443 [1500/2589 (58%)]\tLoss: 165.279526\n",
      "Train Epoch: 443 [1800/2589 (70%)]\tLoss: 293.426300\n",
      "Train Epoch: 443 [2100/2589 (81%)]\tLoss: 262.094360\n",
      "Train Epoch: 443 [2400/2589 (93%)]\tLoss: 213.706863\n",
      "====> Epoch: 443 Average train loss: 252.4684\n",
      "====> Epoch: 443 Average test loss: 916.7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 444 [0/2589 (0%)]\tLoss: 185.567795\n",
      "Train Epoch: 444 [300/2589 (12%)]\tLoss: 217.638702\n",
      "Train Epoch: 444 [600/2589 (23%)]\tLoss: 214.208939\n",
      "Train Epoch: 444 [900/2589 (35%)]\tLoss: 288.388977\n",
      "Train Epoch: 444 [1200/2589 (46%)]\tLoss: 300.095612\n",
      "Train Epoch: 444 [1500/2589 (58%)]\tLoss: 141.227737\n",
      "Train Epoch: 444 [1800/2589 (70%)]\tLoss: 203.621063\n",
      "Train Epoch: 444 [2100/2589 (81%)]\tLoss: 211.944138\n",
      "Train Epoch: 444 [2400/2589 (93%)]\tLoss: 309.629333\n",
      "====> Epoch: 444 Average train loss: 253.6311\n",
      "====> Epoch: 444 Average test loss: 938.7849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 445 [0/2589 (0%)]\tLoss: 269.042297\n",
      "Train Epoch: 445 [300/2589 (12%)]\tLoss: 188.715530\n",
      "Train Epoch: 445 [600/2589 (23%)]\tLoss: 376.986237\n",
      "Train Epoch: 445 [900/2589 (35%)]\tLoss: 270.468750\n",
      "Train Epoch: 445 [1200/2589 (46%)]\tLoss: 196.156906\n",
      "Train Epoch: 445 [1500/2589 (58%)]\tLoss: 331.624878\n",
      "Train Epoch: 445 [1800/2589 (70%)]\tLoss: 184.241516\n",
      "Train Epoch: 445 [2100/2589 (81%)]\tLoss: 263.190704\n",
      "Train Epoch: 445 [2400/2589 (93%)]\tLoss: 426.217377\n",
      "====> Epoch: 445 Average train loss: 242.5079\n",
      "====> Epoch: 445 Average test loss: 930.3281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 446 [0/2589 (0%)]\tLoss: 438.346893\n",
      "Train Epoch: 446 [300/2589 (12%)]\tLoss: 242.678787\n",
      "Train Epoch: 446 [600/2589 (23%)]\tLoss: 185.249771\n",
      "Train Epoch: 446 [900/2589 (35%)]\tLoss: 220.861420\n",
      "Train Epoch: 446 [1200/2589 (46%)]\tLoss: 221.866180\n",
      "Train Epoch: 446 [1500/2589 (58%)]\tLoss: 213.941177\n",
      "Train Epoch: 446 [1800/2589 (70%)]\tLoss: 298.867126\n",
      "Train Epoch: 446 [2100/2589 (81%)]\tLoss: 284.932404\n",
      "Train Epoch: 446 [2400/2589 (93%)]\tLoss: 191.642715\n",
      "====> Epoch: 446 Average train loss: 237.4073\n",
      "====> Epoch: 446 Average test loss: 935.8356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 447 [0/2589 (0%)]\tLoss: 245.784653\n",
      "Train Epoch: 447 [300/2589 (12%)]\tLoss: 263.134796\n",
      "Train Epoch: 447 [600/2589 (23%)]\tLoss: 245.046967\n",
      "Train Epoch: 447 [900/2589 (35%)]\tLoss: 216.335510\n",
      "Train Epoch: 447 [1200/2589 (46%)]\tLoss: 236.713089\n",
      "Train Epoch: 447 [1500/2589 (58%)]\tLoss: 204.485489\n",
      "Train Epoch: 447 [1800/2589 (70%)]\tLoss: 190.140228\n",
      "Train Epoch: 447 [2100/2589 (81%)]\tLoss: 222.840302\n",
      "Train Epoch: 447 [2400/2589 (93%)]\tLoss: 180.307281\n",
      "====> Epoch: 447 Average train loss: 253.3616\n",
      "====> Epoch: 447 Average test loss: 948.6080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 448 [0/2589 (0%)]\tLoss: 219.823685\n",
      "Train Epoch: 448 [300/2589 (12%)]\tLoss: 239.876236\n",
      "Train Epoch: 448 [600/2589 (23%)]\tLoss: 197.104263\n",
      "Train Epoch: 448 [900/2589 (35%)]\tLoss: 292.868652\n",
      "Train Epoch: 448 [1200/2589 (46%)]\tLoss: 296.405396\n",
      "Train Epoch: 448 [1500/2589 (58%)]\tLoss: 290.282593\n",
      "Train Epoch: 448 [1800/2589 (70%)]\tLoss: 223.072556\n",
      "Train Epoch: 448 [2100/2589 (81%)]\tLoss: 256.425446\n",
      "Train Epoch: 448 [2400/2589 (93%)]\tLoss: 267.103668\n",
      "====> Epoch: 448 Average train loss: 250.6991\n",
      "====> Epoch: 448 Average test loss: 932.3400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 449 [0/2589 (0%)]\tLoss: 221.518387\n",
      "Train Epoch: 449 [300/2589 (12%)]\tLoss: 232.314438\n",
      "Train Epoch: 449 [600/2589 (23%)]\tLoss: 254.336761\n",
      "Train Epoch: 449 [900/2589 (35%)]\tLoss: 177.829407\n",
      "Train Epoch: 449 [1200/2589 (46%)]\tLoss: 202.033890\n",
      "Train Epoch: 449 [1500/2589 (58%)]\tLoss: 390.074799\n",
      "Train Epoch: 449 [1800/2589 (70%)]\tLoss: 220.126801\n",
      "Train Epoch: 449 [2100/2589 (81%)]\tLoss: 224.399109\n",
      "Train Epoch: 449 [2400/2589 (93%)]\tLoss: 203.843491\n",
      "====> Epoch: 449 Average train loss: 251.3369\n",
      "====> Epoch: 449 Average test loss: 924.5502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 450 [0/2589 (0%)]\tLoss: 200.428040\n",
      "Train Epoch: 450 [300/2589 (12%)]\tLoss: 238.223846\n",
      "Train Epoch: 450 [600/2589 (23%)]\tLoss: 290.225098\n",
      "Train Epoch: 450 [900/2589 (35%)]\tLoss: 202.836380\n",
      "Train Epoch: 450 [1200/2589 (46%)]\tLoss: 210.139954\n",
      "Train Epoch: 450 [1500/2589 (58%)]\tLoss: 227.109634\n",
      "Train Epoch: 450 [1800/2589 (70%)]\tLoss: 189.565918\n",
      "Train Epoch: 450 [2100/2589 (81%)]\tLoss: 207.931610\n",
      "Train Epoch: 450 [2400/2589 (93%)]\tLoss: 312.641998\n",
      "====> Epoch: 450 Average train loss: 251.6906\n",
      "====> Epoch: 450 Average test loss: 935.0670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 451 [0/2589 (0%)]\tLoss: 182.137253\n",
      "Train Epoch: 451 [300/2589 (12%)]\tLoss: 174.124573\n",
      "Train Epoch: 451 [600/2589 (23%)]\tLoss: 222.578873\n",
      "Train Epoch: 451 [900/2589 (35%)]\tLoss: 286.787292\n",
      "Train Epoch: 451 [1200/2589 (46%)]\tLoss: 184.956772\n",
      "Train Epoch: 451 [1500/2589 (58%)]\tLoss: 329.838013\n",
      "Train Epoch: 451 [1800/2589 (70%)]\tLoss: 389.980164\n",
      "Train Epoch: 451 [2100/2589 (81%)]\tLoss: 151.575150\n",
      "Train Epoch: 451 [2400/2589 (93%)]\tLoss: 339.529999\n",
      "====> Epoch: 451 Average train loss: 243.8013\n",
      "====> Epoch: 451 Average test loss: 934.8045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 452 [0/2589 (0%)]\tLoss: 154.474838\n",
      "Train Epoch: 452 [300/2589 (12%)]\tLoss: 218.269806\n",
      "Train Epoch: 452 [600/2589 (23%)]\tLoss: 217.644394\n",
      "Train Epoch: 452 [900/2589 (35%)]\tLoss: 238.021027\n",
      "Train Epoch: 452 [1200/2589 (46%)]\tLoss: 263.387207\n",
      "Train Epoch: 452 [1500/2589 (58%)]\tLoss: 210.408646\n",
      "Train Epoch: 452 [1800/2589 (70%)]\tLoss: 230.772354\n",
      "Train Epoch: 452 [2100/2589 (81%)]\tLoss: 253.429749\n",
      "Train Epoch: 452 [2400/2589 (93%)]\tLoss: 198.783752\n",
      "====> Epoch: 452 Average train loss: 245.2820\n",
      "====> Epoch: 452 Average test loss: 919.0958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 453 [0/2589 (0%)]\tLoss: 185.344330\n",
      "Train Epoch: 453 [300/2589 (12%)]\tLoss: 188.604874\n",
      "Train Epoch: 453 [600/2589 (23%)]\tLoss: 223.181992\n",
      "Train Epoch: 453 [900/2589 (35%)]\tLoss: 310.524811\n",
      "Train Epoch: 453 [1200/2589 (46%)]\tLoss: 233.707458\n",
      "Train Epoch: 453 [1500/2589 (58%)]\tLoss: 212.930450\n",
      "Train Epoch: 453 [1800/2589 (70%)]\tLoss: 190.016266\n",
      "Train Epoch: 453 [2100/2589 (81%)]\tLoss: 267.556946\n",
      "Train Epoch: 453 [2400/2589 (93%)]\tLoss: 230.648911\n",
      "====> Epoch: 453 Average train loss: 241.7199\n",
      "====> Epoch: 453 Average test loss: 924.6835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 454 [0/2589 (0%)]\tLoss: 365.602234\n",
      "Train Epoch: 454 [300/2589 (12%)]\tLoss: 224.115280\n",
      "Train Epoch: 454 [600/2589 (23%)]\tLoss: 321.347534\n",
      "Train Epoch: 454 [900/2589 (35%)]\tLoss: 233.998383\n",
      "Train Epoch: 454 [1200/2589 (46%)]\tLoss: 264.115448\n",
      "Train Epoch: 454 [1500/2589 (58%)]\tLoss: 198.302032\n",
      "Train Epoch: 454 [1800/2589 (70%)]\tLoss: 267.557373\n",
      "Train Epoch: 454 [2100/2589 (81%)]\tLoss: 390.998627\n",
      "Train Epoch: 454 [2400/2589 (93%)]\tLoss: 318.985565\n",
      "====> Epoch: 454 Average train loss: 251.7260\n",
      "====> Epoch: 454 Average test loss: 935.7169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 455 [0/2589 (0%)]\tLoss: 269.695435\n",
      "Train Epoch: 455 [300/2589 (12%)]\tLoss: 213.338562\n",
      "Train Epoch: 455 [600/2589 (23%)]\tLoss: 281.435699\n",
      "Train Epoch: 455 [900/2589 (35%)]\tLoss: 193.625549\n",
      "Train Epoch: 455 [1200/2589 (46%)]\tLoss: 171.999069\n",
      "Train Epoch: 455 [1500/2589 (58%)]\tLoss: 285.261719\n",
      "Train Epoch: 455 [1800/2589 (70%)]\tLoss: 220.767181\n",
      "Train Epoch: 455 [2100/2589 (81%)]\tLoss: 347.056427\n",
      "Train Epoch: 455 [2400/2589 (93%)]\tLoss: 222.620102\n",
      "====> Epoch: 455 Average train loss: 255.7019\n",
      "====> Epoch: 455 Average test loss: 934.0847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 456 [0/2589 (0%)]\tLoss: 223.842331\n",
      "Train Epoch: 456 [300/2589 (12%)]\tLoss: 219.884415\n",
      "Train Epoch: 456 [600/2589 (23%)]\tLoss: 235.432999\n",
      "Train Epoch: 456 [900/2589 (35%)]\tLoss: 209.202469\n",
      "Train Epoch: 456 [1200/2589 (46%)]\tLoss: 164.910950\n",
      "Train Epoch: 456 [1500/2589 (58%)]\tLoss: 419.191925\n",
      "Train Epoch: 456 [1800/2589 (70%)]\tLoss: 215.961899\n",
      "Train Epoch: 456 [2100/2589 (81%)]\tLoss: 200.223816\n",
      "Train Epoch: 456 [2400/2589 (93%)]\tLoss: 268.498627\n",
      "====> Epoch: 456 Average train loss: 248.2960\n",
      "====> Epoch: 456 Average test loss: 937.5534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 457 [0/2589 (0%)]\tLoss: 186.119171\n",
      "Train Epoch: 457 [300/2589 (12%)]\tLoss: 216.542862\n",
      "Train Epoch: 457 [600/2589 (23%)]\tLoss: 271.345123\n",
      "Train Epoch: 457 [900/2589 (35%)]\tLoss: 315.666565\n",
      "Train Epoch: 457 [1200/2589 (46%)]\tLoss: 260.000336\n",
      "Train Epoch: 457 [1500/2589 (58%)]\tLoss: 290.028748\n",
      "Train Epoch: 457 [1800/2589 (70%)]\tLoss: 199.860123\n",
      "Train Epoch: 457 [2100/2589 (81%)]\tLoss: 216.429108\n",
      "Train Epoch: 457 [2400/2589 (93%)]\tLoss: 336.241302\n",
      "====> Epoch: 457 Average train loss: 253.4710\n",
      "====> Epoch: 457 Average test loss: 923.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 458 [0/2589 (0%)]\tLoss: 280.413422\n",
      "Train Epoch: 458 [300/2589 (12%)]\tLoss: 247.879929\n",
      "Train Epoch: 458 [600/2589 (23%)]\tLoss: 236.091934\n",
      "Train Epoch: 458 [900/2589 (35%)]\tLoss: 280.363495\n",
      "Train Epoch: 458 [1200/2589 (46%)]\tLoss: 278.948059\n",
      "Train Epoch: 458 [1500/2589 (58%)]\tLoss: 377.982758\n",
      "Train Epoch: 458 [1800/2589 (70%)]\tLoss: 252.235214\n",
      "Train Epoch: 458 [2100/2589 (81%)]\tLoss: 222.989227\n",
      "Train Epoch: 458 [2400/2589 (93%)]\tLoss: 171.654694\n",
      "====> Epoch: 458 Average train loss: 245.7833\n",
      "====> Epoch: 458 Average test loss: 964.6569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 459 [0/2589 (0%)]\tLoss: 328.086761\n",
      "Train Epoch: 459 [300/2589 (12%)]\tLoss: 251.105637\n",
      "Train Epoch: 459 [600/2589 (23%)]\tLoss: 209.233429\n",
      "Train Epoch: 459 [900/2589 (35%)]\tLoss: 263.565338\n",
      "Train Epoch: 459 [1200/2589 (46%)]\tLoss: 222.543167\n",
      "Train Epoch: 459 [1500/2589 (58%)]\tLoss: 243.416016\n",
      "Train Epoch: 459 [1800/2589 (70%)]\tLoss: 231.847565\n",
      "Train Epoch: 459 [2100/2589 (81%)]\tLoss: 194.023224\n",
      "Train Epoch: 459 [2400/2589 (93%)]\tLoss: 265.007538\n",
      "====> Epoch: 459 Average train loss: 255.6560\n",
      "====> Epoch: 459 Average test loss: 935.6890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 460 [0/2589 (0%)]\tLoss: 224.237198\n",
      "Train Epoch: 460 [300/2589 (12%)]\tLoss: 252.772766\n",
      "Train Epoch: 460 [600/2589 (23%)]\tLoss: 289.795685\n",
      "Train Epoch: 460 [900/2589 (35%)]\tLoss: 292.794434\n",
      "Train Epoch: 460 [1200/2589 (46%)]\tLoss: 211.506821\n",
      "Train Epoch: 460 [1500/2589 (58%)]\tLoss: 309.204529\n",
      "Train Epoch: 460 [1800/2589 (70%)]\tLoss: 214.059357\n",
      "Train Epoch: 460 [2100/2589 (81%)]\tLoss: 260.504639\n",
      "Train Epoch: 460 [2400/2589 (93%)]\tLoss: 277.777313\n",
      "====> Epoch: 460 Average train loss: 255.5204\n",
      "====> Epoch: 460 Average test loss: 924.3417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 461 [0/2589 (0%)]\tLoss: 269.697083\n",
      "Train Epoch: 461 [300/2589 (12%)]\tLoss: 332.272949\n",
      "Train Epoch: 461 [600/2589 (23%)]\tLoss: 247.151993\n",
      "Train Epoch: 461 [900/2589 (35%)]\tLoss: 376.282898\n",
      "Train Epoch: 461 [1200/2589 (46%)]\tLoss: 465.566498\n",
      "Train Epoch: 461 [1500/2589 (58%)]\tLoss: 247.288406\n",
      "Train Epoch: 461 [1800/2589 (70%)]\tLoss: 316.357971\n",
      "Train Epoch: 461 [2100/2589 (81%)]\tLoss: 187.607361\n",
      "Train Epoch: 461 [2400/2589 (93%)]\tLoss: 304.916199\n",
      "====> Epoch: 461 Average train loss: 248.8930\n",
      "====> Epoch: 461 Average test loss: 930.8351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 462 [0/2589 (0%)]\tLoss: 205.698914\n",
      "Train Epoch: 462 [300/2589 (12%)]\tLoss: 262.091095\n",
      "Train Epoch: 462 [600/2589 (23%)]\tLoss: 189.698227\n",
      "Train Epoch: 462 [900/2589 (35%)]\tLoss: 193.964767\n",
      "Train Epoch: 462 [1200/2589 (46%)]\tLoss: 215.460403\n",
      "Train Epoch: 462 [1500/2589 (58%)]\tLoss: 209.822525\n",
      "Train Epoch: 462 [1800/2589 (70%)]\tLoss: 264.642700\n",
      "Train Epoch: 462 [2100/2589 (81%)]\tLoss: 216.690002\n",
      "Train Epoch: 462 [2400/2589 (93%)]\tLoss: 204.437500\n",
      "====> Epoch: 462 Average train loss: 239.6320\n",
      "====> Epoch: 462 Average test loss: 925.8163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 463 [0/2589 (0%)]\tLoss: 286.606995\n",
      "Train Epoch: 463 [300/2589 (12%)]\tLoss: 199.010254\n",
      "Train Epoch: 463 [600/2589 (23%)]\tLoss: 279.276489\n",
      "Train Epoch: 463 [900/2589 (35%)]\tLoss: 260.390259\n",
      "Train Epoch: 463 [1200/2589 (46%)]\tLoss: 196.952011\n",
      "Train Epoch: 463 [1500/2589 (58%)]\tLoss: 248.565262\n",
      "Train Epoch: 463 [1800/2589 (70%)]\tLoss: 266.982391\n",
      "Train Epoch: 463 [2100/2589 (81%)]\tLoss: 162.012527\n",
      "Train Epoch: 463 [2400/2589 (93%)]\tLoss: 208.869049\n",
      "====> Epoch: 463 Average train loss: 252.2079\n",
      "====> Epoch: 463 Average test loss: 931.5884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 464 [0/2589 (0%)]\tLoss: 392.044037\n",
      "Train Epoch: 464 [300/2589 (12%)]\tLoss: 266.028870\n",
      "Train Epoch: 464 [600/2589 (23%)]\tLoss: 219.464645\n",
      "Train Epoch: 464 [900/2589 (35%)]\tLoss: 384.087616\n",
      "Train Epoch: 464 [1200/2589 (46%)]\tLoss: 177.986008\n",
      "Train Epoch: 464 [1500/2589 (58%)]\tLoss: 223.256897\n",
      "Train Epoch: 464 [1800/2589 (70%)]\tLoss: 428.012115\n",
      "Train Epoch: 464 [2100/2589 (81%)]\tLoss: 434.930328\n",
      "Train Epoch: 464 [2400/2589 (93%)]\tLoss: 195.236481\n",
      "====> Epoch: 464 Average train loss: 254.0908\n",
      "====> Epoch: 464 Average test loss: 923.8907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 465 [0/2589 (0%)]\tLoss: 276.897614\n",
      "Train Epoch: 465 [300/2589 (12%)]\tLoss: 238.120514\n",
      "Train Epoch: 465 [600/2589 (23%)]\tLoss: 227.960632\n",
      "Train Epoch: 465 [900/2589 (35%)]\tLoss: 300.732056\n",
      "Train Epoch: 465 [1200/2589 (46%)]\tLoss: 207.696609\n",
      "Train Epoch: 465 [1500/2589 (58%)]\tLoss: 164.361557\n",
      "Train Epoch: 465 [1800/2589 (70%)]\tLoss: 193.614838\n",
      "Train Epoch: 465 [2100/2589 (81%)]\tLoss: 234.040268\n",
      "Train Epoch: 465 [2400/2589 (93%)]\tLoss: 338.406799\n",
      "====> Epoch: 465 Average train loss: 240.5749\n",
      "====> Epoch: 465 Average test loss: 927.0194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 466 [0/2589 (0%)]\tLoss: 209.332916\n",
      "Train Epoch: 466 [300/2589 (12%)]\tLoss: 259.515320\n",
      "Train Epoch: 466 [600/2589 (23%)]\tLoss: 262.403381\n",
      "Train Epoch: 466 [900/2589 (35%)]\tLoss: 260.294464\n",
      "Train Epoch: 466 [1200/2589 (46%)]\tLoss: 193.569031\n",
      "Train Epoch: 466 [1500/2589 (58%)]\tLoss: 228.032928\n",
      "Train Epoch: 466 [1800/2589 (70%)]\tLoss: 235.484406\n",
      "Train Epoch: 466 [2100/2589 (81%)]\tLoss: 329.124451\n",
      "Train Epoch: 466 [2400/2589 (93%)]\tLoss: 282.685089\n",
      "====> Epoch: 466 Average train loss: 248.8971\n",
      "====> Epoch: 466 Average test loss: 938.2167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 467 [0/2589 (0%)]\tLoss: 191.367325\n",
      "Train Epoch: 467 [300/2589 (12%)]\tLoss: 324.033630\n",
      "Train Epoch: 467 [600/2589 (23%)]\tLoss: 413.467194\n",
      "Train Epoch: 467 [900/2589 (35%)]\tLoss: 182.973007\n",
      "Train Epoch: 467 [1200/2589 (46%)]\tLoss: 315.191437\n",
      "Train Epoch: 467 [1500/2589 (58%)]\tLoss: 248.277985\n",
      "Train Epoch: 467 [1800/2589 (70%)]\tLoss: 209.206528\n",
      "Train Epoch: 467 [2100/2589 (81%)]\tLoss: 244.962051\n",
      "Train Epoch: 467 [2400/2589 (93%)]\tLoss: 300.544281\n",
      "====> Epoch: 467 Average train loss: 253.6609\n",
      "====> Epoch: 467 Average test loss: 940.6816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 468 [0/2589 (0%)]\tLoss: 278.528839\n",
      "Train Epoch: 468 [300/2589 (12%)]\tLoss: 545.607666\n",
      "Train Epoch: 468 [600/2589 (23%)]\tLoss: 193.908264\n",
      "Train Epoch: 468 [900/2589 (35%)]\tLoss: 290.110657\n",
      "Train Epoch: 468 [1200/2589 (46%)]\tLoss: 232.391693\n",
      "Train Epoch: 468 [1500/2589 (58%)]\tLoss: 133.318558\n",
      "Train Epoch: 468 [1800/2589 (70%)]\tLoss: 328.334198\n",
      "Train Epoch: 468 [2100/2589 (81%)]\tLoss: 181.975784\n",
      "Train Epoch: 468 [2400/2589 (93%)]\tLoss: 315.434052\n",
      "====> Epoch: 468 Average train loss: 253.4308\n",
      "====> Epoch: 468 Average test loss: 938.9866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 469 [0/2589 (0%)]\tLoss: 182.748337\n",
      "Train Epoch: 469 [300/2589 (12%)]\tLoss: 197.448578\n",
      "Train Epoch: 469 [600/2589 (23%)]\tLoss: 272.626740\n",
      "Train Epoch: 469 [900/2589 (35%)]\tLoss: 423.024017\n",
      "Train Epoch: 469 [1200/2589 (46%)]\tLoss: 246.800735\n",
      "Train Epoch: 469 [1500/2589 (58%)]\tLoss: 449.923035\n",
      "Train Epoch: 469 [1800/2589 (70%)]\tLoss: 258.640106\n",
      "Train Epoch: 469 [2100/2589 (81%)]\tLoss: 217.906693\n",
      "Train Epoch: 469 [2400/2589 (93%)]\tLoss: 189.032700\n",
      "====> Epoch: 469 Average train loss: 249.4446\n",
      "====> Epoch: 469 Average test loss: 932.0867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 470 [0/2589 (0%)]\tLoss: 174.167389\n",
      "Train Epoch: 470 [300/2589 (12%)]\tLoss: 301.989471\n",
      "Train Epoch: 470 [600/2589 (23%)]\tLoss: 461.371643\n",
      "Train Epoch: 470 [900/2589 (35%)]\tLoss: 198.839981\n",
      "Train Epoch: 470 [1200/2589 (46%)]\tLoss: 176.703217\n",
      "Train Epoch: 470 [1500/2589 (58%)]\tLoss: 229.361099\n",
      "Train Epoch: 470 [1800/2589 (70%)]\tLoss: 207.813034\n",
      "Train Epoch: 470 [2100/2589 (81%)]\tLoss: 221.615372\n",
      "Train Epoch: 470 [2400/2589 (93%)]\tLoss: 144.166016\n",
      "====> Epoch: 470 Average train loss: 247.6641\n",
      "====> Epoch: 470 Average test loss: 931.6561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 471 [0/2589 (0%)]\tLoss: 283.767517\n",
      "Train Epoch: 471 [300/2589 (12%)]\tLoss: 193.335281\n",
      "Train Epoch: 471 [600/2589 (23%)]\tLoss: 184.771835\n",
      "Train Epoch: 471 [900/2589 (35%)]\tLoss: 166.782440\n",
      "Train Epoch: 471 [1200/2589 (46%)]\tLoss: 337.508575\n",
      "Train Epoch: 471 [1500/2589 (58%)]\tLoss: 348.222443\n",
      "Train Epoch: 471 [1800/2589 (70%)]\tLoss: 177.252304\n",
      "Train Epoch: 471 [2100/2589 (81%)]\tLoss: 241.156906\n",
      "Train Epoch: 471 [2400/2589 (93%)]\tLoss: 275.705017\n",
      "====> Epoch: 471 Average train loss: 237.2007\n",
      "====> Epoch: 471 Average test loss: 917.7784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 472 [0/2589 (0%)]\tLoss: 202.501236\n",
      "Train Epoch: 472 [300/2589 (12%)]\tLoss: 191.057480\n",
      "Train Epoch: 472 [600/2589 (23%)]\tLoss: 180.046921\n",
      "Train Epoch: 472 [900/2589 (35%)]\tLoss: 215.408203\n",
      "Train Epoch: 472 [1200/2589 (46%)]\tLoss: 290.384308\n",
      "Train Epoch: 472 [1500/2589 (58%)]\tLoss: 251.577881\n",
      "Train Epoch: 472 [1800/2589 (70%)]\tLoss: 212.773926\n",
      "Train Epoch: 472 [2100/2589 (81%)]\tLoss: 252.350128\n",
      "Train Epoch: 472 [2400/2589 (93%)]\tLoss: 317.538391\n",
      "====> Epoch: 472 Average train loss: 243.3851\n",
      "====> Epoch: 472 Average test loss: 941.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 473 [0/2589 (0%)]\tLoss: 223.402481\n",
      "Train Epoch: 473 [300/2589 (12%)]\tLoss: 196.550995\n",
      "Train Epoch: 473 [600/2589 (23%)]\tLoss: 179.140717\n",
      "Train Epoch: 473 [900/2589 (35%)]\tLoss: 205.049881\n",
      "Train Epoch: 473 [1200/2589 (46%)]\tLoss: 186.646545\n",
      "Train Epoch: 473 [1500/2589 (58%)]\tLoss: 232.407364\n",
      "Train Epoch: 473 [1800/2589 (70%)]\tLoss: 219.169144\n",
      "Train Epoch: 473 [2100/2589 (81%)]\tLoss: 278.877380\n",
      "Train Epoch: 473 [2400/2589 (93%)]\tLoss: 220.034225\n",
      "====> Epoch: 473 Average train loss: 243.1538\n",
      "====> Epoch: 473 Average test loss: 946.1533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 474 [0/2589 (0%)]\tLoss: 334.152649\n",
      "Train Epoch: 474 [300/2589 (12%)]\tLoss: 276.942780\n",
      "Train Epoch: 474 [600/2589 (23%)]\tLoss: 189.543304\n",
      "Train Epoch: 474 [900/2589 (35%)]\tLoss: 215.934738\n",
      "Train Epoch: 474 [1200/2589 (46%)]\tLoss: 191.448700\n",
      "Train Epoch: 474 [1500/2589 (58%)]\tLoss: 266.740997\n",
      "Train Epoch: 474 [1800/2589 (70%)]\tLoss: 217.191422\n",
      "Train Epoch: 474 [2100/2589 (81%)]\tLoss: 155.024124\n",
      "Train Epoch: 474 [2400/2589 (93%)]\tLoss: 378.265045\n",
      "====> Epoch: 474 Average train loss: 252.7428\n",
      "====> Epoch: 474 Average test loss: 938.9654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 475 [0/2589 (0%)]\tLoss: 201.646957\n",
      "Train Epoch: 475 [300/2589 (12%)]\tLoss: 204.804062\n",
      "Train Epoch: 475 [600/2589 (23%)]\tLoss: 292.590363\n",
      "Train Epoch: 475 [900/2589 (35%)]\tLoss: 377.899628\n",
      "Train Epoch: 475 [1200/2589 (46%)]\tLoss: 272.458374\n",
      "Train Epoch: 475 [1500/2589 (58%)]\tLoss: 149.697174\n",
      "Train Epoch: 475 [1800/2589 (70%)]\tLoss: 179.182480\n",
      "Train Epoch: 475 [2100/2589 (81%)]\tLoss: 255.875992\n",
      "Train Epoch: 475 [2400/2589 (93%)]\tLoss: 412.686981\n",
      "====> Epoch: 475 Average train loss: 254.4669\n",
      "====> Epoch: 475 Average test loss: 931.1589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 476 [0/2589 (0%)]\tLoss: 275.636322\n",
      "Train Epoch: 476 [300/2589 (12%)]\tLoss: 263.547394\n",
      "Train Epoch: 476 [600/2589 (23%)]\tLoss: 242.682816\n",
      "Train Epoch: 476 [900/2589 (35%)]\tLoss: 212.502701\n",
      "Train Epoch: 476 [1200/2589 (46%)]\tLoss: 208.147125\n",
      "Train Epoch: 476 [1500/2589 (58%)]\tLoss: 255.802841\n",
      "Train Epoch: 476 [1800/2589 (70%)]\tLoss: 224.739700\n",
      "Train Epoch: 476 [2100/2589 (81%)]\tLoss: 259.697540\n",
      "Train Epoch: 476 [2400/2589 (93%)]\tLoss: 449.258789\n",
      "====> Epoch: 476 Average train loss: 247.5217\n",
      "====> Epoch: 476 Average test loss: 930.3965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 477 [0/2589 (0%)]\tLoss: 285.399750\n",
      "Train Epoch: 477 [300/2589 (12%)]\tLoss: 262.735596\n",
      "Train Epoch: 477 [600/2589 (23%)]\tLoss: 208.680405\n",
      "Train Epoch: 477 [900/2589 (35%)]\tLoss: 251.078339\n",
      "Train Epoch: 477 [1200/2589 (46%)]\tLoss: 236.256775\n",
      "Train Epoch: 477 [1500/2589 (58%)]\tLoss: 215.871445\n",
      "Train Epoch: 477 [1800/2589 (70%)]\tLoss: 173.118744\n",
      "Train Epoch: 477 [2100/2589 (81%)]\tLoss: 201.116959\n",
      "Train Epoch: 477 [2400/2589 (93%)]\tLoss: 305.304016\n",
      "====> Epoch: 477 Average train loss: 240.0033\n",
      "====> Epoch: 477 Average test loss: 926.3947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 478 [0/2589 (0%)]\tLoss: 219.377197\n",
      "Train Epoch: 478 [300/2589 (12%)]\tLoss: 203.208145\n",
      "Train Epoch: 478 [600/2589 (23%)]\tLoss: 128.451004\n",
      "Train Epoch: 478 [900/2589 (35%)]\tLoss: 182.934113\n",
      "Train Epoch: 478 [1200/2589 (46%)]\tLoss: 244.603973\n",
      "Train Epoch: 478 [1500/2589 (58%)]\tLoss: 172.155624\n",
      "Train Epoch: 478 [1800/2589 (70%)]\tLoss: 323.532135\n",
      "Train Epoch: 478 [2100/2589 (81%)]\tLoss: 308.421448\n",
      "Train Epoch: 478 [2400/2589 (93%)]\tLoss: 218.005219\n",
      "====> Epoch: 478 Average train loss: 251.1639\n",
      "====> Epoch: 478 Average test loss: 935.1523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 479 [0/2589 (0%)]\tLoss: 281.698181\n",
      "Train Epoch: 479 [300/2589 (12%)]\tLoss: 242.727692\n",
      "Train Epoch: 479 [600/2589 (23%)]\tLoss: 236.961395\n",
      "Train Epoch: 479 [900/2589 (35%)]\tLoss: 409.837219\n",
      "Train Epoch: 479 [1200/2589 (46%)]\tLoss: 200.853180\n",
      "Train Epoch: 479 [1500/2589 (58%)]\tLoss: 259.797913\n",
      "Train Epoch: 479 [1800/2589 (70%)]\tLoss: 238.609055\n",
      "Train Epoch: 479 [2100/2589 (81%)]\tLoss: 259.098633\n",
      "Train Epoch: 479 [2400/2589 (93%)]\tLoss: 242.936493\n",
      "====> Epoch: 479 Average train loss: 242.0840\n",
      "====> Epoch: 479 Average test loss: 929.9018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 480 [0/2589 (0%)]\tLoss: 204.439301\n",
      "Train Epoch: 480 [300/2589 (12%)]\tLoss: 251.787918\n",
      "Train Epoch: 480 [600/2589 (23%)]\tLoss: 289.093262\n",
      "Train Epoch: 480 [900/2589 (35%)]\tLoss: 187.663742\n",
      "Train Epoch: 480 [1200/2589 (46%)]\tLoss: 307.007263\n",
      "Train Epoch: 480 [1500/2589 (58%)]\tLoss: 198.014099\n",
      "Train Epoch: 480 [1800/2589 (70%)]\tLoss: 253.746979\n",
      "Train Epoch: 480 [2100/2589 (81%)]\tLoss: 209.436188\n",
      "Train Epoch: 480 [2400/2589 (93%)]\tLoss: 215.406265\n",
      "====> Epoch: 480 Average train loss: 242.2089\n",
      "====> Epoch: 480 Average test loss: 936.2805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 481 [0/2589 (0%)]\tLoss: 227.904922\n",
      "Train Epoch: 481 [300/2589 (12%)]\tLoss: 299.712463\n",
      "Train Epoch: 481 [600/2589 (23%)]\tLoss: 258.343842\n",
      "Train Epoch: 481 [900/2589 (35%)]\tLoss: 340.257019\n",
      "Train Epoch: 481 [1200/2589 (46%)]\tLoss: 437.649933\n",
      "Train Epoch: 481 [1500/2589 (58%)]\tLoss: 308.324768\n",
      "Train Epoch: 481 [1800/2589 (70%)]\tLoss: 282.638031\n",
      "Train Epoch: 481 [2100/2589 (81%)]\tLoss: 221.721039\n",
      "Train Epoch: 481 [2400/2589 (93%)]\tLoss: 256.329285\n",
      "====> Epoch: 481 Average train loss: 241.6668\n",
      "====> Epoch: 481 Average test loss: 939.3630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 482 [0/2589 (0%)]\tLoss: 259.907349\n",
      "Train Epoch: 482 [300/2589 (12%)]\tLoss: 265.323181\n",
      "Train Epoch: 482 [600/2589 (23%)]\tLoss: 325.884827\n",
      "Train Epoch: 482 [900/2589 (35%)]\tLoss: 237.122589\n",
      "Train Epoch: 482 [1200/2589 (46%)]\tLoss: 315.887146\n",
      "Train Epoch: 482 [1500/2589 (58%)]\tLoss: 220.289230\n",
      "Train Epoch: 482 [1800/2589 (70%)]\tLoss: 203.963470\n",
      "Train Epoch: 482 [2100/2589 (81%)]\tLoss: 337.735321\n",
      "Train Epoch: 482 [2400/2589 (93%)]\tLoss: 199.469376\n",
      "====> Epoch: 482 Average train loss: 256.7135\n",
      "====> Epoch: 482 Average test loss: 935.1829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 483 [0/2589 (0%)]\tLoss: 250.904816\n",
      "Train Epoch: 483 [300/2589 (12%)]\tLoss: 236.976166\n",
      "Train Epoch: 483 [600/2589 (23%)]\tLoss: 238.726212\n",
      "Train Epoch: 483 [900/2589 (35%)]\tLoss: 223.587128\n",
      "Train Epoch: 483 [1200/2589 (46%)]\tLoss: 238.486160\n",
      "Train Epoch: 483 [1500/2589 (58%)]\tLoss: 220.304520\n",
      "Train Epoch: 483 [1800/2589 (70%)]\tLoss: 206.875641\n",
      "Train Epoch: 483 [2100/2589 (81%)]\tLoss: 183.541489\n",
      "Train Epoch: 483 [2400/2589 (93%)]\tLoss: 199.335648\n",
      "====> Epoch: 483 Average train loss: 234.9377\n",
      "====> Epoch: 483 Average test loss: 923.8475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 484 [0/2589 (0%)]\tLoss: 214.503738\n",
      "Train Epoch: 484 [300/2589 (12%)]\tLoss: 247.624481\n",
      "Train Epoch: 484 [600/2589 (23%)]\tLoss: 221.944778\n",
      "Train Epoch: 484 [900/2589 (35%)]\tLoss: 216.875305\n",
      "Train Epoch: 484 [1200/2589 (46%)]\tLoss: 317.819275\n",
      "Train Epoch: 484 [1500/2589 (58%)]\tLoss: 193.291077\n",
      "Train Epoch: 484 [1800/2589 (70%)]\tLoss: 176.499771\n",
      "Train Epoch: 484 [2100/2589 (81%)]\tLoss: 233.110626\n",
      "Train Epoch: 484 [2400/2589 (93%)]\tLoss: 231.423965\n",
      "====> Epoch: 484 Average train loss: 240.2570\n",
      "====> Epoch: 484 Average test loss: 923.1832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 485 [0/2589 (0%)]\tLoss: 242.373749\n",
      "Train Epoch: 485 [300/2589 (12%)]\tLoss: 353.687775\n",
      "Train Epoch: 485 [600/2589 (23%)]\tLoss: 216.114426\n",
      "Train Epoch: 485 [900/2589 (35%)]\tLoss: 333.371429\n",
      "Train Epoch: 485 [1200/2589 (46%)]\tLoss: 211.985687\n",
      "Train Epoch: 485 [1500/2589 (58%)]\tLoss: 182.961182\n",
      "Train Epoch: 485 [1800/2589 (70%)]\tLoss: 172.850479\n",
      "Train Epoch: 485 [2100/2589 (81%)]\tLoss: 180.554886\n",
      "Train Epoch: 485 [2400/2589 (93%)]\tLoss: 216.539551\n",
      "====> Epoch: 485 Average train loss: 240.6596\n",
      "====> Epoch: 485 Average test loss: 941.3409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 486 [0/2589 (0%)]\tLoss: 303.678375\n",
      "Train Epoch: 486 [300/2589 (12%)]\tLoss: 283.834351\n",
      "Train Epoch: 486 [600/2589 (23%)]\tLoss: 308.221039\n",
      "Train Epoch: 486 [900/2589 (35%)]\tLoss: 137.968063\n",
      "Train Epoch: 486 [1200/2589 (46%)]\tLoss: 265.822510\n",
      "Train Epoch: 486 [1500/2589 (58%)]\tLoss: 237.375259\n",
      "Train Epoch: 486 [1800/2589 (70%)]\tLoss: 283.872772\n",
      "Train Epoch: 486 [2100/2589 (81%)]\tLoss: 205.679382\n",
      "Train Epoch: 486 [2400/2589 (93%)]\tLoss: 198.511551\n",
      "====> Epoch: 486 Average train loss: 250.2430\n",
      "====> Epoch: 486 Average test loss: 924.7115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 487 [0/2589 (0%)]\tLoss: 298.795105\n",
      "Train Epoch: 487 [300/2589 (12%)]\tLoss: 187.752670\n",
      "Train Epoch: 487 [600/2589 (23%)]\tLoss: 195.246780\n",
      "Train Epoch: 487 [900/2589 (35%)]\tLoss: 342.740936\n",
      "Train Epoch: 487 [1200/2589 (46%)]\tLoss: 213.638245\n",
      "Train Epoch: 487 [1500/2589 (58%)]\tLoss: 162.399216\n",
      "Train Epoch: 487 [1800/2589 (70%)]\tLoss: 202.525940\n",
      "Train Epoch: 487 [2100/2589 (81%)]\tLoss: 191.001511\n",
      "Train Epoch: 487 [2400/2589 (93%)]\tLoss: 269.103729\n",
      "====> Epoch: 487 Average train loss: 245.0170\n",
      "====> Epoch: 487 Average test loss: 930.5221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 488 [0/2589 (0%)]\tLoss: 229.111954\n",
      "Train Epoch: 488 [300/2589 (12%)]\tLoss: 365.590668\n",
      "Train Epoch: 488 [600/2589 (23%)]\tLoss: 213.119400\n",
      "Train Epoch: 488 [900/2589 (35%)]\tLoss: 258.122345\n",
      "Train Epoch: 488 [1200/2589 (46%)]\tLoss: 235.254166\n",
      "Train Epoch: 488 [1500/2589 (58%)]\tLoss: 337.429169\n",
      "Train Epoch: 488 [1800/2589 (70%)]\tLoss: 187.954208\n",
      "Train Epoch: 488 [2100/2589 (81%)]\tLoss: 230.994446\n",
      "Train Epoch: 488 [2400/2589 (93%)]\tLoss: 275.414612\n",
      "====> Epoch: 488 Average train loss: 237.9884\n",
      "====> Epoch: 488 Average test loss: 926.3790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 489 [0/2589 (0%)]\tLoss: 167.157166\n",
      "Train Epoch: 489 [300/2589 (12%)]\tLoss: 230.071182\n",
      "Train Epoch: 489 [600/2589 (23%)]\tLoss: 263.166016\n",
      "Train Epoch: 489 [900/2589 (35%)]\tLoss: 194.784363\n",
      "Train Epoch: 489 [1200/2589 (46%)]\tLoss: 229.323502\n",
      "Train Epoch: 489 [1500/2589 (58%)]\tLoss: 208.011261\n",
      "Train Epoch: 489 [1800/2589 (70%)]\tLoss: 222.502930\n",
      "Train Epoch: 489 [2100/2589 (81%)]\tLoss: 341.375092\n",
      "Train Epoch: 489 [2400/2589 (93%)]\tLoss: 166.356552\n",
      "====> Epoch: 489 Average train loss: 251.1101\n",
      "====> Epoch: 489 Average test loss: 939.9407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 490 [0/2589 (0%)]\tLoss: 232.321396\n",
      "Train Epoch: 490 [300/2589 (12%)]\tLoss: 288.081665\n",
      "Train Epoch: 490 [600/2589 (23%)]\tLoss: 261.067780\n",
      "Train Epoch: 490 [900/2589 (35%)]\tLoss: 220.720413\n",
      "Train Epoch: 490 [1200/2589 (46%)]\tLoss: 198.671371\n",
      "Train Epoch: 490 [1500/2589 (58%)]\tLoss: 205.974823\n",
      "Train Epoch: 490 [1800/2589 (70%)]\tLoss: 172.396027\n",
      "Train Epoch: 490 [2100/2589 (81%)]\tLoss: 242.055069\n",
      "Train Epoch: 490 [2400/2589 (93%)]\tLoss: 274.116486\n",
      "====> Epoch: 490 Average train loss: 246.4343\n",
      "====> Epoch: 490 Average test loss: 936.4825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 491 [0/2589 (0%)]\tLoss: 176.035751\n",
      "Train Epoch: 491 [300/2589 (12%)]\tLoss: 260.200287\n",
      "Train Epoch: 491 [600/2589 (23%)]\tLoss: 168.281769\n",
      "Train Epoch: 491 [900/2589 (35%)]\tLoss: 231.425964\n",
      "Train Epoch: 491 [1200/2589 (46%)]\tLoss: 189.406326\n",
      "Train Epoch: 491 [1500/2589 (58%)]\tLoss: 251.264420\n",
      "Train Epoch: 491 [1800/2589 (70%)]\tLoss: 249.503448\n",
      "Train Epoch: 491 [2100/2589 (81%)]\tLoss: 246.327744\n",
      "Train Epoch: 491 [2400/2589 (93%)]\tLoss: 222.199661\n",
      "====> Epoch: 491 Average train loss: 252.6730\n",
      "====> Epoch: 491 Average test loss: 940.6419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 492 [0/2589 (0%)]\tLoss: 233.282166\n",
      "Train Epoch: 492 [300/2589 (12%)]\tLoss: 286.974274\n",
      "Train Epoch: 492 [600/2589 (23%)]\tLoss: 370.415527\n",
      "Train Epoch: 492 [900/2589 (35%)]\tLoss: 205.146912\n",
      "Train Epoch: 492 [1200/2589 (46%)]\tLoss: 228.688126\n",
      "Train Epoch: 492 [1500/2589 (58%)]\tLoss: 390.611450\n",
      "Train Epoch: 492 [1800/2589 (70%)]\tLoss: 198.635712\n",
      "Train Epoch: 492 [2100/2589 (81%)]\tLoss: 224.671631\n",
      "Train Epoch: 492 [2400/2589 (93%)]\tLoss: 183.028595\n",
      "====> Epoch: 492 Average train loss: 245.7295\n",
      "====> Epoch: 492 Average test loss: 936.7296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 493 [0/2589 (0%)]\tLoss: 294.478241\n",
      "Train Epoch: 493 [300/2589 (12%)]\tLoss: 213.567703\n",
      "Train Epoch: 493 [600/2589 (23%)]\tLoss: 158.524796\n",
      "Train Epoch: 493 [900/2589 (35%)]\tLoss: 213.049118\n",
      "Train Epoch: 493 [1200/2589 (46%)]\tLoss: 226.428513\n",
      "Train Epoch: 493 [1500/2589 (58%)]\tLoss: 191.725266\n",
      "Train Epoch: 493 [1800/2589 (70%)]\tLoss: 203.225098\n",
      "Train Epoch: 493 [2100/2589 (81%)]\tLoss: 249.726105\n",
      "Train Epoch: 493 [2400/2589 (93%)]\tLoss: 165.700272\n",
      "====> Epoch: 493 Average train loss: 237.3346\n",
      "====> Epoch: 493 Average test loss: 926.8521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 494 [0/2589 (0%)]\tLoss: 195.510025\n",
      "Train Epoch: 494 [300/2589 (12%)]\tLoss: 235.635574\n",
      "Train Epoch: 494 [600/2589 (23%)]\tLoss: 242.779877\n",
      "Train Epoch: 494 [900/2589 (35%)]\tLoss: 286.815460\n",
      "Train Epoch: 494 [1200/2589 (46%)]\tLoss: 228.707230\n",
      "Train Epoch: 494 [1500/2589 (58%)]\tLoss: 211.561966\n",
      "Train Epoch: 494 [1800/2589 (70%)]\tLoss: 206.196365\n",
      "Train Epoch: 494 [2100/2589 (81%)]\tLoss: 227.721619\n",
      "Train Epoch: 494 [2400/2589 (93%)]\tLoss: 319.880402\n",
      "====> Epoch: 494 Average train loss: 260.5996\n",
      "====> Epoch: 494 Average test loss: 931.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 495 [0/2589 (0%)]\tLoss: 324.391235\n",
      "Train Epoch: 495 [300/2589 (12%)]\tLoss: 256.292755\n",
      "Train Epoch: 495 [600/2589 (23%)]\tLoss: 203.090439\n",
      "Train Epoch: 495 [900/2589 (35%)]\tLoss: 277.749451\n",
      "Train Epoch: 495 [1200/2589 (46%)]\tLoss: 193.961533\n",
      "Train Epoch: 495 [1500/2589 (58%)]\tLoss: 270.548737\n",
      "Train Epoch: 495 [1800/2589 (70%)]\tLoss: 227.106094\n",
      "Train Epoch: 495 [2100/2589 (81%)]\tLoss: 217.131195\n",
      "Train Epoch: 495 [2400/2589 (93%)]\tLoss: 208.164841\n",
      "====> Epoch: 495 Average train loss: 246.2388\n",
      "====> Epoch: 495 Average test loss: 940.1923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 496 [0/2589 (0%)]\tLoss: 278.598694\n",
      "Train Epoch: 496 [300/2589 (12%)]\tLoss: 194.504822\n",
      "Train Epoch: 496 [600/2589 (23%)]\tLoss: 140.079971\n",
      "Train Epoch: 496 [900/2589 (35%)]\tLoss: 192.962402\n",
      "Train Epoch: 496 [1200/2589 (46%)]\tLoss: 243.967438\n",
      "Train Epoch: 496 [1500/2589 (58%)]\tLoss: 212.695084\n",
      "Train Epoch: 496 [1800/2589 (70%)]\tLoss: 134.147049\n",
      "Train Epoch: 496 [2100/2589 (81%)]\tLoss: 202.129593\n",
      "Train Epoch: 496 [2400/2589 (93%)]\tLoss: 320.960480\n",
      "====> Epoch: 496 Average train loss: 235.2095\n",
      "====> Epoch: 496 Average test loss: 930.4241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 497 [0/2589 (0%)]\tLoss: 211.166885\n",
      "Train Epoch: 497 [300/2589 (12%)]\tLoss: 192.520325\n",
      "Train Epoch: 497 [600/2589 (23%)]\tLoss: 154.304245\n",
      "Train Epoch: 497 [900/2589 (35%)]\tLoss: 216.911911\n",
      "Train Epoch: 497 [1200/2589 (46%)]\tLoss: 160.650787\n",
      "Train Epoch: 497 [1500/2589 (58%)]\tLoss: 265.909149\n",
      "Train Epoch: 497 [1800/2589 (70%)]\tLoss: 263.727081\n",
      "Train Epoch: 497 [2100/2589 (81%)]\tLoss: 402.394836\n",
      "Train Epoch: 497 [2400/2589 (93%)]\tLoss: 164.073563\n",
      "====> Epoch: 497 Average train loss: 240.7064\n",
      "====> Epoch: 497 Average test loss: 934.5732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 498 [0/2589 (0%)]\tLoss: 203.553558\n",
      "Train Epoch: 498 [300/2589 (12%)]\tLoss: 258.882172\n",
      "Train Epoch: 498 [600/2589 (23%)]\tLoss: 187.461075\n",
      "Train Epoch: 498 [900/2589 (35%)]\tLoss: 209.030869\n",
      "Train Epoch: 498 [1200/2589 (46%)]\tLoss: 225.378265\n",
      "Train Epoch: 498 [1500/2589 (58%)]\tLoss: 245.503021\n",
      "Train Epoch: 498 [1800/2589 (70%)]\tLoss: 532.886963\n",
      "Train Epoch: 498 [2100/2589 (81%)]\tLoss: 233.652206\n",
      "Train Epoch: 498 [2400/2589 (93%)]\tLoss: 217.613907\n",
      "====> Epoch: 498 Average train loss: 236.6842\n",
      "====> Epoch: 498 Average test loss: 930.3523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 499 [0/2589 (0%)]\tLoss: 223.936981\n",
      "Train Epoch: 499 [300/2589 (12%)]\tLoss: 190.000305\n",
      "Train Epoch: 499 [600/2589 (23%)]\tLoss: 363.208771\n",
      "Train Epoch: 499 [900/2589 (35%)]\tLoss: 195.617249\n",
      "Train Epoch: 499 [1200/2589 (46%)]\tLoss: 511.521851\n",
      "Train Epoch: 499 [1500/2589 (58%)]\tLoss: 243.231110\n",
      "Train Epoch: 499 [1800/2589 (70%)]\tLoss: 237.787491\n",
      "Train Epoch: 499 [2100/2589 (81%)]\tLoss: 197.482742\n",
      "Train Epoch: 499 [2400/2589 (93%)]\tLoss: 254.537704\n",
      "====> Epoch: 499 Average train loss: 254.0616\n",
      "====> Epoch: 499 Average test loss: 922.6622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 500 [0/2589 (0%)]\tLoss: 308.834045\n",
      "Train Epoch: 500 [300/2589 (12%)]\tLoss: 205.239410\n",
      "Train Epoch: 500 [600/2589 (23%)]\tLoss: 261.113007\n",
      "Train Epoch: 500 [900/2589 (35%)]\tLoss: 251.289001\n",
      "Train Epoch: 500 [1200/2589 (46%)]\tLoss: 176.593201\n",
      "Train Epoch: 500 [1500/2589 (58%)]\tLoss: 287.758728\n",
      "Train Epoch: 500 [1800/2589 (70%)]\tLoss: 255.764023\n",
      "Train Epoch: 500 [2100/2589 (81%)]\tLoss: 187.006439\n",
      "Train Epoch: 500 [2400/2589 (93%)]\tLoss: 258.139496\n",
      "====> Epoch: 500 Average train loss: 250.7685\n",
      "====> Epoch: 500 Average test loss: 920.4973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 501 [0/2589 (0%)]\tLoss: 192.976501\n",
      "Train Epoch: 501 [300/2589 (12%)]\tLoss: 224.905533\n",
      "Train Epoch: 501 [600/2589 (23%)]\tLoss: 171.487076\n",
      "Train Epoch: 501 [900/2589 (35%)]\tLoss: 137.597168\n",
      "Train Epoch: 501 [1200/2589 (46%)]\tLoss: 300.103180\n",
      "Train Epoch: 501 [1500/2589 (58%)]\tLoss: 287.823792\n",
      "Train Epoch: 501 [1800/2589 (70%)]\tLoss: 259.929718\n",
      "Train Epoch: 501 [2100/2589 (81%)]\tLoss: 266.728058\n",
      "Train Epoch: 501 [2400/2589 (93%)]\tLoss: 268.936127\n",
      "====> Epoch: 501 Average train loss: 249.1462\n",
      "====> Epoch: 501 Average test loss: 940.8166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 502 [0/2589 (0%)]\tLoss: 178.750031\n",
      "Train Epoch: 502 [300/2589 (12%)]\tLoss: 196.433411\n",
      "Train Epoch: 502 [600/2589 (23%)]\tLoss: 265.991760\n",
      "Train Epoch: 502 [900/2589 (35%)]\tLoss: 209.435379\n",
      "Train Epoch: 502 [1200/2589 (46%)]\tLoss: 190.835724\n",
      "Train Epoch: 502 [1500/2589 (58%)]\tLoss: 257.659058\n",
      "Train Epoch: 502 [1800/2589 (70%)]\tLoss: 355.967468\n",
      "Train Epoch: 502 [2100/2589 (81%)]\tLoss: 253.766388\n",
      "Train Epoch: 502 [2400/2589 (93%)]\tLoss: 209.617279\n",
      "====> Epoch: 502 Average train loss: 239.2224\n",
      "====> Epoch: 502 Average test loss: 944.4431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 503 [0/2589 (0%)]\tLoss: 273.784454\n",
      "Train Epoch: 503 [300/2589 (12%)]\tLoss: 277.832672\n",
      "Train Epoch: 503 [600/2589 (23%)]\tLoss: 206.536469\n",
      "Train Epoch: 503 [900/2589 (35%)]\tLoss: 209.938629\n",
      "Train Epoch: 503 [1200/2589 (46%)]\tLoss: 272.737701\n",
      "Train Epoch: 503 [1500/2589 (58%)]\tLoss: 240.224380\n",
      "Train Epoch: 503 [1800/2589 (70%)]\tLoss: 248.459900\n",
      "Train Epoch: 503 [2100/2589 (81%)]\tLoss: 208.812363\n",
      "Train Epoch: 503 [2400/2589 (93%)]\tLoss: 202.202805\n",
      "====> Epoch: 503 Average train loss: 239.4711\n",
      "====> Epoch: 503 Average test loss: 910.0509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 504 [0/2589 (0%)]\tLoss: 273.171570\n",
      "Train Epoch: 504 [300/2589 (12%)]\tLoss: 294.103149\n",
      "Train Epoch: 504 [600/2589 (23%)]\tLoss: 255.520981\n",
      "Train Epoch: 504 [900/2589 (35%)]\tLoss: 208.619949\n",
      "Train Epoch: 504 [1200/2589 (46%)]\tLoss: 221.256699\n",
      "Train Epoch: 504 [1500/2589 (58%)]\tLoss: 147.094635\n",
      "Train Epoch: 504 [1800/2589 (70%)]\tLoss: 342.477844\n",
      "Train Epoch: 504 [2100/2589 (81%)]\tLoss: 180.606430\n",
      "Train Epoch: 504 [2400/2589 (93%)]\tLoss: 201.291473\n",
      "====> Epoch: 504 Average train loss: 244.8916\n",
      "====> Epoch: 504 Average test loss: 928.5480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 505 [0/2589 (0%)]\tLoss: 221.675537\n",
      "Train Epoch: 505 [300/2589 (12%)]\tLoss: 219.654388\n",
      "Train Epoch: 505 [600/2589 (23%)]\tLoss: 197.742188\n",
      "Train Epoch: 505 [900/2589 (35%)]\tLoss: 137.668427\n",
      "Train Epoch: 505 [1200/2589 (46%)]\tLoss: 202.471161\n",
      "Train Epoch: 505 [1500/2589 (58%)]\tLoss: 219.700684\n",
      "Train Epoch: 505 [1800/2589 (70%)]\tLoss: 250.518417\n",
      "Train Epoch: 505 [2100/2589 (81%)]\tLoss: 199.944275\n",
      "Train Epoch: 505 [2400/2589 (93%)]\tLoss: 235.026871\n",
      "====> Epoch: 505 Average train loss: 243.4945\n",
      "====> Epoch: 505 Average test loss: 935.1415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 506 [0/2589 (0%)]\tLoss: 161.969711\n",
      "Train Epoch: 506 [300/2589 (12%)]\tLoss: 295.105560\n",
      "Train Epoch: 506 [600/2589 (23%)]\tLoss: 129.950089\n",
      "Train Epoch: 506 [900/2589 (35%)]\tLoss: 259.290436\n",
      "Train Epoch: 506 [1200/2589 (46%)]\tLoss: 243.679016\n",
      "Train Epoch: 506 [1500/2589 (58%)]\tLoss: 263.086029\n",
      "Train Epoch: 506 [1800/2589 (70%)]\tLoss: 270.831604\n",
      "Train Epoch: 506 [2100/2589 (81%)]\tLoss: 230.681625\n",
      "Train Epoch: 506 [2400/2589 (93%)]\tLoss: 214.772522\n",
      "====> Epoch: 506 Average train loss: 244.2153\n",
      "====> Epoch: 506 Average test loss: 936.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 507 [0/2589 (0%)]\tLoss: 183.856628\n",
      "Train Epoch: 507 [300/2589 (12%)]\tLoss: 219.857971\n",
      "Train Epoch: 507 [600/2589 (23%)]\tLoss: 208.656281\n",
      "Train Epoch: 507 [900/2589 (35%)]\tLoss: 197.415573\n",
      "Train Epoch: 507 [1200/2589 (46%)]\tLoss: 178.961197\n",
      "Train Epoch: 507 [1500/2589 (58%)]\tLoss: 194.057419\n",
      "Train Epoch: 507 [1800/2589 (70%)]\tLoss: 155.466415\n",
      "Train Epoch: 507 [2100/2589 (81%)]\tLoss: 231.009140\n",
      "Train Epoch: 507 [2400/2589 (93%)]\tLoss: 274.475769\n",
      "====> Epoch: 507 Average train loss: 243.6999\n",
      "====> Epoch: 507 Average test loss: 934.3226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 508 [0/2589 (0%)]\tLoss: 254.270752\n",
      "Train Epoch: 508 [300/2589 (12%)]\tLoss: 328.808960\n",
      "Train Epoch: 508 [600/2589 (23%)]\tLoss: 260.192291\n",
      "Train Epoch: 508 [900/2589 (35%)]\tLoss: 226.832535\n",
      "Train Epoch: 508 [1200/2589 (46%)]\tLoss: 139.754257\n",
      "Train Epoch: 508 [1500/2589 (58%)]\tLoss: 189.288513\n",
      "Train Epoch: 508 [1800/2589 (70%)]\tLoss: 203.605667\n",
      "Train Epoch: 508 [2100/2589 (81%)]\tLoss: 183.700912\n",
      "Train Epoch: 508 [2400/2589 (93%)]\tLoss: 208.813629\n",
      "====> Epoch: 508 Average train loss: 242.5503\n",
      "====> Epoch: 508 Average test loss: 913.0699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 509 [0/2589 (0%)]\tLoss: 229.629074\n",
      "Train Epoch: 509 [300/2589 (12%)]\tLoss: 194.114777\n",
      "Train Epoch: 509 [600/2589 (23%)]\tLoss: 215.655670\n",
      "Train Epoch: 509 [900/2589 (35%)]\tLoss: 267.667725\n",
      "Train Epoch: 509 [1200/2589 (46%)]\tLoss: 225.187576\n",
      "Train Epoch: 509 [1500/2589 (58%)]\tLoss: 213.744400\n",
      "Train Epoch: 509 [1800/2589 (70%)]\tLoss: 223.831131\n",
      "Train Epoch: 509 [2100/2589 (81%)]\tLoss: 230.655426\n",
      "Train Epoch: 509 [2400/2589 (93%)]\tLoss: 253.506897\n",
      "====> Epoch: 509 Average train loss: 244.2812\n",
      "====> Epoch: 509 Average test loss: 947.3771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 510 [0/2589 (0%)]\tLoss: 216.493103\n",
      "Train Epoch: 510 [300/2589 (12%)]\tLoss: 255.863861\n",
      "Train Epoch: 510 [600/2589 (23%)]\tLoss: 276.993042\n",
      "Train Epoch: 510 [900/2589 (35%)]\tLoss: 198.594254\n",
      "Train Epoch: 510 [1200/2589 (46%)]\tLoss: 342.597107\n",
      "Train Epoch: 510 [1500/2589 (58%)]\tLoss: 347.812012\n",
      "Train Epoch: 510 [1800/2589 (70%)]\tLoss: 213.764023\n",
      "Train Epoch: 510 [2100/2589 (81%)]\tLoss: 230.097885\n",
      "Train Epoch: 510 [2400/2589 (93%)]\tLoss: 306.264160\n",
      "====> Epoch: 510 Average train loss: 243.2507\n",
      "====> Epoch: 510 Average test loss: 942.2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 511 [0/2589 (0%)]\tLoss: 337.629852\n",
      "Train Epoch: 511 [300/2589 (12%)]\tLoss: 218.623077\n",
      "Train Epoch: 511 [600/2589 (23%)]\tLoss: 273.178375\n",
      "Train Epoch: 511 [900/2589 (35%)]\tLoss: 227.243927\n",
      "Train Epoch: 511 [1200/2589 (46%)]\tLoss: 226.651428\n",
      "Train Epoch: 511 [1500/2589 (58%)]\tLoss: 293.640778\n",
      "Train Epoch: 511 [1800/2589 (70%)]\tLoss: 178.818817\n",
      "Train Epoch: 511 [2100/2589 (81%)]\tLoss: 292.946625\n",
      "Train Epoch: 511 [2400/2589 (93%)]\tLoss: 190.731613\n",
      "====> Epoch: 511 Average train loss: 248.3609\n",
      "====> Epoch: 511 Average test loss: 926.8101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 512 [0/2589 (0%)]\tLoss: 227.708710\n",
      "Train Epoch: 512 [300/2589 (12%)]\tLoss: 292.346741\n",
      "Train Epoch: 512 [600/2589 (23%)]\tLoss: 254.753952\n",
      "Train Epoch: 512 [900/2589 (35%)]\tLoss: 165.533203\n",
      "Train Epoch: 512 [1200/2589 (46%)]\tLoss: 252.636566\n",
      "Train Epoch: 512 [1500/2589 (58%)]\tLoss: 205.960800\n",
      "Train Epoch: 512 [1800/2589 (70%)]\tLoss: 237.767273\n",
      "Train Epoch: 512 [2100/2589 (81%)]\tLoss: 245.482391\n",
      "Train Epoch: 512 [2400/2589 (93%)]\tLoss: 222.033829\n",
      "====> Epoch: 512 Average train loss: 250.6253\n",
      "====> Epoch: 512 Average test loss: 911.0735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 513 [0/2589 (0%)]\tLoss: 210.511902\n",
      "Train Epoch: 513 [300/2589 (12%)]\tLoss: 256.653809\n",
      "Train Epoch: 513 [600/2589 (23%)]\tLoss: 297.869965\n",
      "Train Epoch: 513 [900/2589 (35%)]\tLoss: 163.548370\n",
      "Train Epoch: 513 [1200/2589 (46%)]\tLoss: 276.827240\n",
      "Train Epoch: 513 [1500/2589 (58%)]\tLoss: 316.324738\n",
      "Train Epoch: 513 [1800/2589 (70%)]\tLoss: 282.114716\n",
      "Train Epoch: 513 [2100/2589 (81%)]\tLoss: 310.009583\n",
      "Train Epoch: 513 [2400/2589 (93%)]\tLoss: 230.060989\n",
      "====> Epoch: 513 Average train loss: 243.3961\n",
      "====> Epoch: 513 Average test loss: 939.3077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 514 [0/2589 (0%)]\tLoss: 359.394501\n",
      "Train Epoch: 514 [300/2589 (12%)]\tLoss: 217.814941\n",
      "Train Epoch: 514 [600/2589 (23%)]\tLoss: 234.050262\n",
      "Train Epoch: 514 [900/2589 (35%)]\tLoss: 199.129745\n",
      "Train Epoch: 514 [1200/2589 (46%)]\tLoss: 239.955872\n",
      "Train Epoch: 514 [1500/2589 (58%)]\tLoss: 169.659668\n",
      "Train Epoch: 514 [1800/2589 (70%)]\tLoss: 221.361557\n",
      "Train Epoch: 514 [2100/2589 (81%)]\tLoss: 214.524704\n",
      "Train Epoch: 514 [2400/2589 (93%)]\tLoss: 157.502731\n",
      "====> Epoch: 514 Average train loss: 251.3676\n",
      "====> Epoch: 514 Average test loss: 927.6556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 515 [0/2589 (0%)]\tLoss: 189.443161\n",
      "Train Epoch: 515 [300/2589 (12%)]\tLoss: 330.470154\n",
      "Train Epoch: 515 [600/2589 (23%)]\tLoss: 156.113251\n",
      "Train Epoch: 515 [900/2589 (35%)]\tLoss: 158.747864\n",
      "Train Epoch: 515 [1200/2589 (46%)]\tLoss: 217.708237\n",
      "Train Epoch: 515 [1500/2589 (58%)]\tLoss: 286.120270\n",
      "Train Epoch: 515 [1800/2589 (70%)]\tLoss: 273.653320\n",
      "Train Epoch: 515 [2100/2589 (81%)]\tLoss: 356.013000\n",
      "Train Epoch: 515 [2400/2589 (93%)]\tLoss: 181.753098\n",
      "====> Epoch: 515 Average train loss: 250.3963\n",
      "====> Epoch: 515 Average test loss: 928.3296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 516 [0/2589 (0%)]\tLoss: 182.801620\n",
      "Train Epoch: 516 [300/2589 (12%)]\tLoss: 269.033447\n",
      "Train Epoch: 516 [600/2589 (23%)]\tLoss: 345.518280\n",
      "Train Epoch: 516 [900/2589 (35%)]\tLoss: 221.097458\n",
      "Train Epoch: 516 [1200/2589 (46%)]\tLoss: 204.497177\n",
      "Train Epoch: 516 [1500/2589 (58%)]\tLoss: 195.082291\n",
      "Train Epoch: 516 [1800/2589 (70%)]\tLoss: 214.271164\n",
      "Train Epoch: 516 [2100/2589 (81%)]\tLoss: 210.229309\n",
      "Train Epoch: 516 [2400/2589 (93%)]\tLoss: 218.357040\n",
      "====> Epoch: 516 Average train loss: 245.6911\n",
      "====> Epoch: 516 Average test loss: 931.1663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 517 [0/2589 (0%)]\tLoss: 298.521088\n",
      "Train Epoch: 517 [300/2589 (12%)]\tLoss: 252.433685\n",
      "Train Epoch: 517 [600/2589 (23%)]\tLoss: 190.162399\n",
      "Train Epoch: 517 [900/2589 (35%)]\tLoss: 211.510468\n",
      "Train Epoch: 517 [1200/2589 (46%)]\tLoss: 206.514420\n",
      "Train Epoch: 517 [1500/2589 (58%)]\tLoss: 294.570831\n",
      "Train Epoch: 517 [1800/2589 (70%)]\tLoss: 297.211853\n",
      "Train Epoch: 517 [2100/2589 (81%)]\tLoss: 227.045364\n",
      "Train Epoch: 517 [2400/2589 (93%)]\tLoss: 197.417084\n",
      "====> Epoch: 517 Average train loss: 247.2485\n",
      "====> Epoch: 517 Average test loss: 941.6323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 518 [0/2589 (0%)]\tLoss: 214.904556\n",
      "Train Epoch: 518 [300/2589 (12%)]\tLoss: 231.800400\n",
      "Train Epoch: 518 [600/2589 (23%)]\tLoss: 263.243683\n",
      "Train Epoch: 518 [900/2589 (35%)]\tLoss: 234.671295\n",
      "Train Epoch: 518 [1200/2589 (46%)]\tLoss: 205.081436\n",
      "Train Epoch: 518 [1500/2589 (58%)]\tLoss: 329.918121\n",
      "Train Epoch: 518 [1800/2589 (70%)]\tLoss: 240.878143\n",
      "Train Epoch: 518 [2100/2589 (81%)]\tLoss: 207.520340\n",
      "Train Epoch: 518 [2400/2589 (93%)]\tLoss: 251.457901\n",
      "====> Epoch: 518 Average train loss: 252.6849\n",
      "====> Epoch: 518 Average test loss: 925.8502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 519 [0/2589 (0%)]\tLoss: 191.246292\n",
      "Train Epoch: 519 [300/2589 (12%)]\tLoss: 170.300842\n",
      "Train Epoch: 519 [600/2589 (23%)]\tLoss: 192.445450\n",
      "Train Epoch: 519 [900/2589 (35%)]\tLoss: 161.008575\n",
      "Train Epoch: 519 [1200/2589 (46%)]\tLoss: 241.728775\n",
      "Train Epoch: 519 [1500/2589 (58%)]\tLoss: 179.533203\n",
      "Train Epoch: 519 [1800/2589 (70%)]\tLoss: 201.490555\n",
      "Train Epoch: 519 [2100/2589 (81%)]\tLoss: 217.190659\n",
      "Train Epoch: 519 [2400/2589 (93%)]\tLoss: 232.049026\n",
      "====> Epoch: 519 Average train loss: 242.5823\n",
      "====> Epoch: 519 Average test loss: 952.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 520 [0/2589 (0%)]\tLoss: 270.629333\n",
      "Train Epoch: 520 [300/2589 (12%)]\tLoss: 245.645660\n",
      "Train Epoch: 520 [600/2589 (23%)]\tLoss: 332.593628\n",
      "Train Epoch: 520 [900/2589 (35%)]\tLoss: 186.139664\n",
      "Train Epoch: 520 [1200/2589 (46%)]\tLoss: 224.603210\n",
      "Train Epoch: 520 [1500/2589 (58%)]\tLoss: 160.696869\n",
      "Train Epoch: 520 [1800/2589 (70%)]\tLoss: 234.760071\n",
      "Train Epoch: 520 [2100/2589 (81%)]\tLoss: 271.704041\n",
      "Train Epoch: 520 [2400/2589 (93%)]\tLoss: 222.411575\n",
      "====> Epoch: 520 Average train loss: 241.1835\n",
      "====> Epoch: 520 Average test loss: 931.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 521 [0/2589 (0%)]\tLoss: 221.971725\n",
      "Train Epoch: 521 [300/2589 (12%)]\tLoss: 234.566208\n",
      "Train Epoch: 521 [600/2589 (23%)]\tLoss: 204.649231\n",
      "Train Epoch: 521 [900/2589 (35%)]\tLoss: 167.572830\n",
      "Train Epoch: 521 [1200/2589 (46%)]\tLoss: 184.783615\n",
      "Train Epoch: 521 [1500/2589 (58%)]\tLoss: 256.282074\n",
      "Train Epoch: 521 [1800/2589 (70%)]\tLoss: 222.619278\n",
      "Train Epoch: 521 [2100/2589 (81%)]\tLoss: 231.220520\n",
      "Train Epoch: 521 [2400/2589 (93%)]\tLoss: 179.781708\n",
      "====> Epoch: 521 Average train loss: 248.3247\n",
      "====> Epoch: 521 Average test loss: 927.3158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 522 [0/2589 (0%)]\tLoss: 210.083389\n",
      "Train Epoch: 522 [300/2589 (12%)]\tLoss: 338.504456\n",
      "Train Epoch: 522 [600/2589 (23%)]\tLoss: 297.464661\n",
      "Train Epoch: 522 [900/2589 (35%)]\tLoss: 178.828842\n",
      "Train Epoch: 522 [1200/2589 (46%)]\tLoss: 214.123581\n",
      "Train Epoch: 522 [1500/2589 (58%)]\tLoss: 397.618866\n",
      "Train Epoch: 522 [1800/2589 (70%)]\tLoss: 356.851929\n",
      "Train Epoch: 522 [2100/2589 (81%)]\tLoss: 202.182068\n",
      "Train Epoch: 522 [2400/2589 (93%)]\tLoss: 195.926834\n",
      "====> Epoch: 522 Average train loss: 235.5629\n",
      "====> Epoch: 522 Average test loss: 923.4256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 523 [0/2589 (0%)]\tLoss: 167.150574\n",
      "Train Epoch: 523 [300/2589 (12%)]\tLoss: 235.864563\n",
      "Train Epoch: 523 [600/2589 (23%)]\tLoss: 304.709076\n",
      "Train Epoch: 523 [900/2589 (35%)]\tLoss: 192.108002\n",
      "Train Epoch: 523 [1200/2589 (46%)]\tLoss: 274.667206\n",
      "Train Epoch: 523 [1500/2589 (58%)]\tLoss: 246.160248\n",
      "Train Epoch: 523 [1800/2589 (70%)]\tLoss: 266.606812\n",
      "Train Epoch: 523 [2100/2589 (81%)]\tLoss: 188.959137\n",
      "Train Epoch: 523 [2400/2589 (93%)]\tLoss: 225.527527\n",
      "====> Epoch: 523 Average train loss: 235.4341\n",
      "====> Epoch: 523 Average test loss: 932.1808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 524 [0/2589 (0%)]\tLoss: 196.368454\n",
      "Train Epoch: 524 [300/2589 (12%)]\tLoss: 263.794983\n",
      "Train Epoch: 524 [600/2589 (23%)]\tLoss: 289.125061\n",
      "Train Epoch: 524 [900/2589 (35%)]\tLoss: 189.147034\n",
      "Train Epoch: 524 [1200/2589 (46%)]\tLoss: 465.869537\n",
      "Train Epoch: 524 [1500/2589 (58%)]\tLoss: 241.367325\n",
      "Train Epoch: 524 [1800/2589 (70%)]\tLoss: 214.796677\n",
      "Train Epoch: 524 [2100/2589 (81%)]\tLoss: 309.374298\n",
      "Train Epoch: 524 [2400/2589 (93%)]\tLoss: 210.025299\n",
      "====> Epoch: 524 Average train loss: 256.4477\n",
      "====> Epoch: 524 Average test loss: 926.6059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 525 [0/2589 (0%)]\tLoss: 217.339600\n",
      "Train Epoch: 525 [300/2589 (12%)]\tLoss: 261.177002\n",
      "Train Epoch: 525 [600/2589 (23%)]\tLoss: 487.559143\n",
      "Train Epoch: 525 [900/2589 (35%)]\tLoss: 261.451263\n",
      "Train Epoch: 525 [1200/2589 (46%)]\tLoss: 313.398468\n",
      "Train Epoch: 525 [1500/2589 (58%)]\tLoss: 281.524536\n",
      "Train Epoch: 525 [1800/2589 (70%)]\tLoss: 210.222916\n",
      "Train Epoch: 525 [2100/2589 (81%)]\tLoss: 235.715576\n",
      "Train Epoch: 525 [2400/2589 (93%)]\tLoss: 181.300674\n",
      "====> Epoch: 525 Average train loss: 248.8141\n",
      "====> Epoch: 525 Average test loss: 918.5244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 526 [0/2589 (0%)]\tLoss: 284.634735\n",
      "Train Epoch: 526 [300/2589 (12%)]\tLoss: 276.977417\n",
      "Train Epoch: 526 [600/2589 (23%)]\tLoss: 220.547455\n",
      "Train Epoch: 526 [900/2589 (35%)]\tLoss: 218.577454\n",
      "Train Epoch: 526 [1200/2589 (46%)]\tLoss: 219.376602\n",
      "Train Epoch: 526 [1500/2589 (58%)]\tLoss: 167.869766\n",
      "Train Epoch: 526 [1800/2589 (70%)]\tLoss: 182.397720\n",
      "Train Epoch: 526 [2100/2589 (81%)]\tLoss: 177.247620\n",
      "Train Epoch: 526 [2400/2589 (93%)]\tLoss: 173.113022\n",
      "====> Epoch: 526 Average train loss: 240.3763\n",
      "====> Epoch: 526 Average test loss: 928.2099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 527 [0/2589 (0%)]\tLoss: 229.738113\n",
      "Train Epoch: 527 [300/2589 (12%)]\tLoss: 196.356384\n",
      "Train Epoch: 527 [600/2589 (23%)]\tLoss: 209.528381\n",
      "Train Epoch: 527 [900/2589 (35%)]\tLoss: 178.816269\n",
      "Train Epoch: 527 [1200/2589 (46%)]\tLoss: 228.324524\n",
      "Train Epoch: 527 [1500/2589 (58%)]\tLoss: 210.757416\n",
      "Train Epoch: 527 [1800/2589 (70%)]\tLoss: 221.282959\n",
      "Train Epoch: 527 [2100/2589 (81%)]\tLoss: 199.386032\n",
      "Train Epoch: 527 [2400/2589 (93%)]\tLoss: 228.307632\n",
      "====> Epoch: 527 Average train loss: 246.0258\n",
      "====> Epoch: 527 Average test loss: 922.0280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 528 [0/2589 (0%)]\tLoss: 175.345612\n",
      "Train Epoch: 528 [300/2589 (12%)]\tLoss: 192.462814\n",
      "Train Epoch: 528 [600/2589 (23%)]\tLoss: 234.651413\n",
      "Train Epoch: 528 [900/2589 (35%)]\tLoss: 225.012268\n",
      "Train Epoch: 528 [1200/2589 (46%)]\tLoss: 133.067642\n",
      "Train Epoch: 528 [1500/2589 (58%)]\tLoss: 279.521362\n",
      "Train Epoch: 528 [1800/2589 (70%)]\tLoss: 258.343018\n",
      "Train Epoch: 528 [2100/2589 (81%)]\tLoss: 168.099121\n",
      "Train Epoch: 528 [2400/2589 (93%)]\tLoss: 221.063934\n",
      "====> Epoch: 528 Average train loss: 246.5504\n",
      "====> Epoch: 528 Average test loss: 911.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 529 [0/2589 (0%)]\tLoss: 232.776199\n",
      "Train Epoch: 529 [300/2589 (12%)]\tLoss: 218.629898\n",
      "Train Epoch: 529 [600/2589 (23%)]\tLoss: 245.879807\n",
      "Train Epoch: 529 [900/2589 (35%)]\tLoss: 278.245117\n",
      "Train Epoch: 529 [1200/2589 (46%)]\tLoss: 285.770294\n",
      "Train Epoch: 529 [1500/2589 (58%)]\tLoss: 194.314148\n",
      "Train Epoch: 529 [1800/2589 (70%)]\tLoss: 243.739777\n",
      "Train Epoch: 529 [2100/2589 (81%)]\tLoss: 264.830750\n",
      "Train Epoch: 529 [2400/2589 (93%)]\tLoss: 252.819855\n",
      "====> Epoch: 529 Average train loss: 237.9051\n",
      "====> Epoch: 529 Average test loss: 923.4440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 530 [0/2589 (0%)]\tLoss: 306.907532\n",
      "Train Epoch: 530 [300/2589 (12%)]\tLoss: 242.937698\n",
      "Train Epoch: 530 [600/2589 (23%)]\tLoss: 266.387299\n",
      "Train Epoch: 530 [900/2589 (35%)]\tLoss: 211.953705\n",
      "Train Epoch: 530 [1200/2589 (46%)]\tLoss: 366.668823\n",
      "Train Epoch: 530 [1500/2589 (58%)]\tLoss: 165.508011\n",
      "Train Epoch: 530 [1800/2589 (70%)]\tLoss: 184.701096\n",
      "Train Epoch: 530 [2100/2589 (81%)]\tLoss: 197.434830\n",
      "Train Epoch: 530 [2400/2589 (93%)]\tLoss: 186.710220\n",
      "====> Epoch: 530 Average train loss: 234.0200\n",
      "====> Epoch: 530 Average test loss: 941.5137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 531 [0/2589 (0%)]\tLoss: 278.682129\n",
      "Train Epoch: 531 [300/2589 (12%)]\tLoss: 220.350922\n",
      "Train Epoch: 531 [600/2589 (23%)]\tLoss: 214.863754\n",
      "Train Epoch: 531 [900/2589 (35%)]\tLoss: 248.687225\n",
      "Train Epoch: 531 [1200/2589 (46%)]\tLoss: 164.340363\n",
      "Train Epoch: 531 [1500/2589 (58%)]\tLoss: 237.132584\n",
      "Train Epoch: 531 [1800/2589 (70%)]\tLoss: 219.617691\n",
      "Train Epoch: 531 [2100/2589 (81%)]\tLoss: 289.543549\n",
      "Train Epoch: 531 [2400/2589 (93%)]\tLoss: 163.367340\n",
      "====> Epoch: 531 Average train loss: 245.1615\n",
      "====> Epoch: 531 Average test loss: 934.8530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 532 [0/2589 (0%)]\tLoss: 219.038925\n",
      "Train Epoch: 532 [300/2589 (12%)]\tLoss: 194.468613\n",
      "Train Epoch: 532 [600/2589 (23%)]\tLoss: 203.920334\n",
      "Train Epoch: 532 [900/2589 (35%)]\tLoss: 264.955475\n",
      "Train Epoch: 532 [1200/2589 (46%)]\tLoss: 218.679535\n",
      "Train Epoch: 532 [1500/2589 (58%)]\tLoss: 164.851425\n",
      "Train Epoch: 532 [1800/2589 (70%)]\tLoss: 136.494415\n",
      "Train Epoch: 532 [2100/2589 (81%)]\tLoss: 203.991501\n",
      "Train Epoch: 532 [2400/2589 (93%)]\tLoss: 240.900620\n",
      "====> Epoch: 532 Average train loss: 244.8327\n",
      "====> Epoch: 532 Average test loss: 921.5090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 533 [0/2589 (0%)]\tLoss: 143.927444\n",
      "Train Epoch: 533 [300/2589 (12%)]\tLoss: 274.349731\n",
      "Train Epoch: 533 [600/2589 (23%)]\tLoss: 231.148254\n",
      "Train Epoch: 533 [900/2589 (35%)]\tLoss: 351.399078\n",
      "Train Epoch: 533 [1200/2589 (46%)]\tLoss: 164.421860\n",
      "Train Epoch: 533 [1500/2589 (58%)]\tLoss: 215.392502\n",
      "Train Epoch: 533 [1800/2589 (70%)]\tLoss: 264.717072\n",
      "Train Epoch: 533 [2100/2589 (81%)]\tLoss: 206.680771\n",
      "Train Epoch: 533 [2400/2589 (93%)]\tLoss: 187.218979\n",
      "====> Epoch: 533 Average train loss: 239.6877\n",
      "====> Epoch: 533 Average test loss: 939.0224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 534 [0/2589 (0%)]\tLoss: 240.334793\n",
      "Train Epoch: 534 [300/2589 (12%)]\tLoss: 204.433655\n",
      "Train Epoch: 534 [600/2589 (23%)]\tLoss: 267.942230\n",
      "Train Epoch: 534 [900/2589 (35%)]\tLoss: 220.571442\n",
      "Train Epoch: 534 [1200/2589 (46%)]\tLoss: 251.893234\n",
      "Train Epoch: 534 [1500/2589 (58%)]\tLoss: 196.394211\n",
      "Train Epoch: 534 [1800/2589 (70%)]\tLoss: 208.692322\n",
      "Train Epoch: 534 [2100/2589 (81%)]\tLoss: 159.185837\n",
      "Train Epoch: 534 [2400/2589 (93%)]\tLoss: 210.905334\n",
      "====> Epoch: 534 Average train loss: 236.9677\n",
      "====> Epoch: 534 Average test loss: 936.4269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 535 [0/2589 (0%)]\tLoss: 188.838104\n",
      "Train Epoch: 535 [300/2589 (12%)]\tLoss: 221.832230\n",
      "Train Epoch: 535 [600/2589 (23%)]\tLoss: 591.809875\n",
      "Train Epoch: 535 [900/2589 (35%)]\tLoss: 243.156647\n",
      "Train Epoch: 535 [1200/2589 (46%)]\tLoss: 239.747879\n",
      "Train Epoch: 535 [1500/2589 (58%)]\tLoss: 190.496140\n",
      "Train Epoch: 535 [1800/2589 (70%)]\tLoss: 187.042007\n",
      "Train Epoch: 535 [2100/2589 (81%)]\tLoss: 175.087540\n",
      "Train Epoch: 535 [2400/2589 (93%)]\tLoss: 163.268845\n",
      "====> Epoch: 535 Average train loss: 241.8819\n",
      "====> Epoch: 535 Average test loss: 924.6982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 536 [0/2589 (0%)]\tLoss: 233.298767\n",
      "Train Epoch: 536 [300/2589 (12%)]\tLoss: 273.006836\n",
      "Train Epoch: 536 [600/2589 (23%)]\tLoss: 172.504242\n",
      "Train Epoch: 536 [900/2589 (35%)]\tLoss: 298.189850\n",
      "Train Epoch: 536 [1200/2589 (46%)]\tLoss: 456.820099\n",
      "Train Epoch: 536 [1500/2589 (58%)]\tLoss: 251.200089\n",
      "Train Epoch: 536 [1800/2589 (70%)]\tLoss: 204.251602\n",
      "Train Epoch: 536 [2100/2589 (81%)]\tLoss: 282.799774\n",
      "Train Epoch: 536 [2400/2589 (93%)]\tLoss: 210.931213\n",
      "====> Epoch: 536 Average train loss: 243.8327\n",
      "====> Epoch: 536 Average test loss: 930.7568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 537 [0/2589 (0%)]\tLoss: 295.753571\n",
      "Train Epoch: 537 [300/2589 (12%)]\tLoss: 265.680481\n",
      "Train Epoch: 537 [600/2589 (23%)]\tLoss: 320.866119\n",
      "Train Epoch: 537 [900/2589 (35%)]\tLoss: 186.453033\n",
      "Train Epoch: 537 [1200/2589 (46%)]\tLoss: 220.823151\n",
      "Train Epoch: 537 [1500/2589 (58%)]\tLoss: 172.876038\n",
      "Train Epoch: 537 [1800/2589 (70%)]\tLoss: 186.708221\n",
      "Train Epoch: 537 [2100/2589 (81%)]\tLoss: 159.723465\n",
      "Train Epoch: 537 [2400/2589 (93%)]\tLoss: 193.985825\n",
      "====> Epoch: 537 Average train loss: 242.7125\n",
      "====> Epoch: 537 Average test loss: 937.4135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 538 [0/2589 (0%)]\tLoss: 247.593887\n",
      "Train Epoch: 538 [300/2589 (12%)]\tLoss: 225.787323\n",
      "Train Epoch: 538 [600/2589 (23%)]\tLoss: 292.995972\n",
      "Train Epoch: 538 [900/2589 (35%)]\tLoss: 353.004517\n",
      "Train Epoch: 538 [1200/2589 (46%)]\tLoss: 333.073700\n",
      "Train Epoch: 538 [1500/2589 (58%)]\tLoss: 166.930069\n",
      "Train Epoch: 538 [1800/2589 (70%)]\tLoss: 468.342468\n",
      "Train Epoch: 538 [2100/2589 (81%)]\tLoss: 220.971024\n",
      "Train Epoch: 538 [2400/2589 (93%)]\tLoss: 346.148132\n",
      "====> Epoch: 538 Average train loss: 258.8522\n",
      "====> Epoch: 538 Average test loss: 931.7278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 539 [0/2589 (0%)]\tLoss: 213.377838\n",
      "Train Epoch: 539 [300/2589 (12%)]\tLoss: 282.354156\n",
      "Train Epoch: 539 [600/2589 (23%)]\tLoss: 233.207748\n",
      "Train Epoch: 539 [900/2589 (35%)]\tLoss: 204.122177\n",
      "Train Epoch: 539 [1200/2589 (46%)]\tLoss: 242.170319\n",
      "Train Epoch: 539 [1500/2589 (58%)]\tLoss: 297.676056\n",
      "Train Epoch: 539 [1800/2589 (70%)]\tLoss: 248.210587\n",
      "Train Epoch: 539 [2100/2589 (81%)]\tLoss: 202.935715\n",
      "Train Epoch: 539 [2400/2589 (93%)]\tLoss: 245.198715\n",
      "====> Epoch: 539 Average train loss: 243.7859\n",
      "====> Epoch: 539 Average test loss: 917.7772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 540 [0/2589 (0%)]\tLoss: 252.158951\n",
      "Train Epoch: 540 [300/2589 (12%)]\tLoss: 486.964386\n",
      "Train Epoch: 540 [600/2589 (23%)]\tLoss: 249.821945\n",
      "Train Epoch: 540 [900/2589 (35%)]\tLoss: 297.018463\n",
      "Train Epoch: 540 [1200/2589 (46%)]\tLoss: 245.039841\n",
      "Train Epoch: 540 [1500/2589 (58%)]\tLoss: 386.301361\n",
      "Train Epoch: 540 [1800/2589 (70%)]\tLoss: 226.330093\n",
      "Train Epoch: 540 [2100/2589 (81%)]\tLoss: 211.965912\n",
      "Train Epoch: 540 [2400/2589 (93%)]\tLoss: 254.714310\n",
      "====> Epoch: 540 Average train loss: 246.1393\n",
      "====> Epoch: 540 Average test loss: 936.6194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 541 [0/2589 (0%)]\tLoss: 148.451248\n",
      "Train Epoch: 541 [300/2589 (12%)]\tLoss: 271.781067\n",
      "Train Epoch: 541 [600/2589 (23%)]\tLoss: 366.401276\n",
      "Train Epoch: 541 [900/2589 (35%)]\tLoss: 341.416412\n",
      "Train Epoch: 541 [1200/2589 (46%)]\tLoss: 199.891357\n",
      "Train Epoch: 541 [1500/2589 (58%)]\tLoss: 340.988983\n",
      "Train Epoch: 541 [1800/2589 (70%)]\tLoss: 224.465103\n",
      "Train Epoch: 541 [2100/2589 (81%)]\tLoss: 293.188812\n",
      "Train Epoch: 541 [2400/2589 (93%)]\tLoss: 235.358292\n",
      "====> Epoch: 541 Average train loss: 247.1363\n",
      "====> Epoch: 541 Average test loss: 921.2215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 542 [0/2589 (0%)]\tLoss: 256.100739\n",
      "Train Epoch: 542 [300/2589 (12%)]\tLoss: 263.537231\n",
      "Train Epoch: 542 [600/2589 (23%)]\tLoss: 177.814041\n",
      "Train Epoch: 542 [900/2589 (35%)]\tLoss: 281.333069\n",
      "Train Epoch: 542 [1200/2589 (46%)]\tLoss: 174.672668\n",
      "Train Epoch: 542 [1500/2589 (58%)]\tLoss: 210.032364\n",
      "Train Epoch: 542 [1800/2589 (70%)]\tLoss: 253.724030\n",
      "Train Epoch: 542 [2100/2589 (81%)]\tLoss: 240.723007\n",
      "Train Epoch: 542 [2400/2589 (93%)]\tLoss: 213.939316\n",
      "====> Epoch: 542 Average train loss: 239.7455\n",
      "====> Epoch: 542 Average test loss: 929.4408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 543 [0/2589 (0%)]\tLoss: 316.677094\n",
      "Train Epoch: 543 [300/2589 (12%)]\tLoss: 225.667343\n",
      "Train Epoch: 543 [600/2589 (23%)]\tLoss: 155.718414\n",
      "Train Epoch: 543 [900/2589 (35%)]\tLoss: 194.743942\n",
      "Train Epoch: 543 [1200/2589 (46%)]\tLoss: 233.147446\n",
      "Train Epoch: 543 [1500/2589 (58%)]\tLoss: 220.033829\n",
      "Train Epoch: 543 [1800/2589 (70%)]\tLoss: 175.588440\n",
      "Train Epoch: 543 [2100/2589 (81%)]\tLoss: 394.499573\n",
      "Train Epoch: 543 [2400/2589 (93%)]\tLoss: 263.985138\n",
      "====> Epoch: 543 Average train loss: 245.9104\n",
      "====> Epoch: 543 Average test loss: 963.1053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 544 [0/2589 (0%)]\tLoss: 147.464264\n",
      "Train Epoch: 544 [300/2589 (12%)]\tLoss: 289.069031\n",
      "Train Epoch: 544 [600/2589 (23%)]\tLoss: 201.552628\n",
      "Train Epoch: 544 [900/2589 (35%)]\tLoss: 236.547852\n",
      "Train Epoch: 544 [1200/2589 (46%)]\tLoss: 210.682678\n",
      "Train Epoch: 544 [1500/2589 (58%)]\tLoss: 197.613083\n",
      "Train Epoch: 544 [1800/2589 (70%)]\tLoss: 280.833496\n",
      "Train Epoch: 544 [2100/2589 (81%)]\tLoss: 239.872742\n",
      "Train Epoch: 544 [2400/2589 (93%)]\tLoss: 326.786194\n",
      "====> Epoch: 544 Average train loss: 235.4888\n",
      "====> Epoch: 544 Average test loss: 916.0204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 545 [0/2589 (0%)]\tLoss: 165.683731\n",
      "Train Epoch: 545 [300/2589 (12%)]\tLoss: 202.659073\n",
      "Train Epoch: 545 [600/2589 (23%)]\tLoss: 192.141769\n",
      "Train Epoch: 545 [900/2589 (35%)]\tLoss: 211.237854\n",
      "Train Epoch: 545 [1200/2589 (46%)]\tLoss: 167.680740\n",
      "Train Epoch: 545 [1500/2589 (58%)]\tLoss: 190.836594\n",
      "Train Epoch: 545 [1800/2589 (70%)]\tLoss: 209.136642\n",
      "Train Epoch: 545 [2100/2589 (81%)]\tLoss: 234.826172\n",
      "Train Epoch: 545 [2400/2589 (93%)]\tLoss: 201.743973\n",
      "====> Epoch: 545 Average train loss: 239.5051\n",
      "====> Epoch: 545 Average test loss: 919.0586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 546 [0/2589 (0%)]\tLoss: 246.469879\n",
      "Train Epoch: 546 [300/2589 (12%)]\tLoss: 307.932800\n",
      "Train Epoch: 546 [600/2589 (23%)]\tLoss: 141.053986\n",
      "Train Epoch: 546 [900/2589 (35%)]\tLoss: 230.918320\n",
      "Train Epoch: 546 [1200/2589 (46%)]\tLoss: 153.841995\n",
      "Train Epoch: 546 [1500/2589 (58%)]\tLoss: 195.901154\n",
      "Train Epoch: 546 [1800/2589 (70%)]\tLoss: 161.518616\n",
      "Train Epoch: 546 [2100/2589 (81%)]\tLoss: 153.731552\n",
      "Train Epoch: 546 [2400/2589 (93%)]\tLoss: 190.296478\n",
      "====> Epoch: 546 Average train loss: 238.5642\n",
      "====> Epoch: 546 Average test loss: 933.4476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 547 [0/2589 (0%)]\tLoss: 174.316864\n",
      "Train Epoch: 547 [300/2589 (12%)]\tLoss: 230.688477\n",
      "Train Epoch: 547 [600/2589 (23%)]\tLoss: 151.341080\n",
      "Train Epoch: 547 [900/2589 (35%)]\tLoss: 237.390244\n",
      "Train Epoch: 547 [1200/2589 (46%)]\tLoss: 261.821228\n",
      "Train Epoch: 547 [1500/2589 (58%)]\tLoss: 248.842102\n",
      "Train Epoch: 547 [1800/2589 (70%)]\tLoss: 202.181168\n",
      "Train Epoch: 547 [2100/2589 (81%)]\tLoss: 235.101456\n",
      "Train Epoch: 547 [2400/2589 (93%)]\tLoss: 265.392029\n",
      "====> Epoch: 547 Average train loss: 240.7671\n",
      "====> Epoch: 547 Average test loss: 927.3614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 548 [0/2589 (0%)]\tLoss: 220.972229\n",
      "Train Epoch: 548 [300/2589 (12%)]\tLoss: 287.117615\n",
      "Train Epoch: 548 [600/2589 (23%)]\tLoss: 275.926697\n",
      "Train Epoch: 548 [900/2589 (35%)]\tLoss: 213.736877\n",
      "Train Epoch: 548 [1200/2589 (46%)]\tLoss: 282.008240\n",
      "Train Epoch: 548 [1500/2589 (58%)]\tLoss: 191.823914\n",
      "Train Epoch: 548 [1800/2589 (70%)]\tLoss: 161.396393\n",
      "Train Epoch: 548 [2100/2589 (81%)]\tLoss: 210.618546\n",
      "Train Epoch: 548 [2400/2589 (93%)]\tLoss: 198.432190\n",
      "====> Epoch: 548 Average train loss: 241.7249\n",
      "====> Epoch: 548 Average test loss: 917.7051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 549 [0/2589 (0%)]\tLoss: 149.905548\n",
      "Train Epoch: 549 [300/2589 (12%)]\tLoss: 389.677917\n",
      "Train Epoch: 549 [600/2589 (23%)]\tLoss: 186.826706\n",
      "Train Epoch: 549 [900/2589 (35%)]\tLoss: 229.183273\n",
      "Train Epoch: 549 [1200/2589 (46%)]\tLoss: 329.186035\n",
      "Train Epoch: 549 [1500/2589 (58%)]\tLoss: 284.228821\n",
      "Train Epoch: 549 [1800/2589 (70%)]\tLoss: 203.928635\n",
      "Train Epoch: 549 [2100/2589 (81%)]\tLoss: 212.052750\n",
      "Train Epoch: 549 [2400/2589 (93%)]\tLoss: 195.813187\n",
      "====> Epoch: 549 Average train loss: 237.0999\n",
      "====> Epoch: 549 Average test loss: 934.9672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 550 [0/2589 (0%)]\tLoss: 354.487305\n",
      "Train Epoch: 550 [300/2589 (12%)]\tLoss: 221.657562\n",
      "Train Epoch: 550 [600/2589 (23%)]\tLoss: 237.737991\n",
      "Train Epoch: 550 [900/2589 (35%)]\tLoss: 193.350037\n",
      "Train Epoch: 550 [1200/2589 (46%)]\tLoss: 199.528717\n",
      "Train Epoch: 550 [1500/2589 (58%)]\tLoss: 252.218948\n",
      "Train Epoch: 550 [1800/2589 (70%)]\tLoss: 219.447678\n",
      "Train Epoch: 550 [2100/2589 (81%)]\tLoss: 328.114594\n",
      "Train Epoch: 550 [2400/2589 (93%)]\tLoss: 207.508102\n",
      "====> Epoch: 550 Average train loss: 238.5684\n",
      "====> Epoch: 550 Average test loss: 929.4916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 551 [0/2589 (0%)]\tLoss: 165.133652\n",
      "Train Epoch: 551 [300/2589 (12%)]\tLoss: 329.730438\n",
      "Train Epoch: 551 [600/2589 (23%)]\tLoss: 277.053162\n",
      "Train Epoch: 551 [900/2589 (35%)]\tLoss: 220.740677\n",
      "Train Epoch: 551 [1200/2589 (46%)]\tLoss: 287.711731\n",
      "Train Epoch: 551 [1500/2589 (58%)]\tLoss: 252.184143\n",
      "Train Epoch: 551 [1800/2589 (70%)]\tLoss: 239.617172\n",
      "Train Epoch: 551 [2100/2589 (81%)]\tLoss: 236.715302\n",
      "Train Epoch: 551 [2400/2589 (93%)]\tLoss: 259.618866\n",
      "====> Epoch: 551 Average train loss: 237.3170\n",
      "====> Epoch: 551 Average test loss: 929.7668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 552 [0/2589 (0%)]\tLoss: 258.493469\n",
      "Train Epoch: 552 [300/2589 (12%)]\tLoss: 256.843292\n",
      "Train Epoch: 552 [600/2589 (23%)]\tLoss: 257.001068\n",
      "Train Epoch: 552 [900/2589 (35%)]\tLoss: 191.561264\n",
      "Train Epoch: 552 [1200/2589 (46%)]\tLoss: 329.869080\n",
      "Train Epoch: 552 [1500/2589 (58%)]\tLoss: 398.731476\n",
      "Train Epoch: 552 [1800/2589 (70%)]\tLoss: 246.832977\n",
      "Train Epoch: 552 [2100/2589 (81%)]\tLoss: 264.181580\n",
      "Train Epoch: 552 [2400/2589 (93%)]\tLoss: 280.477936\n",
      "====> Epoch: 552 Average train loss: 243.3650\n",
      "====> Epoch: 552 Average test loss: 940.8876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 553 [0/2589 (0%)]\tLoss: 237.163925\n",
      "Train Epoch: 553 [300/2589 (12%)]\tLoss: 149.059753\n",
      "Train Epoch: 553 [600/2589 (23%)]\tLoss: 211.482651\n",
      "Train Epoch: 553 [900/2589 (35%)]\tLoss: 201.212051\n",
      "Train Epoch: 553 [1200/2589 (46%)]\tLoss: 409.404266\n",
      "Train Epoch: 553 [1500/2589 (58%)]\tLoss: 214.056732\n",
      "Train Epoch: 553 [1800/2589 (70%)]\tLoss: 287.068939\n",
      "Train Epoch: 553 [2100/2589 (81%)]\tLoss: 160.861755\n",
      "Train Epoch: 553 [2400/2589 (93%)]\tLoss: 182.268280\n",
      "====> Epoch: 553 Average train loss: 243.2249\n",
      "====> Epoch: 553 Average test loss: 930.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 554 [0/2589 (0%)]\tLoss: 168.270538\n",
      "Train Epoch: 554 [300/2589 (12%)]\tLoss: 234.720917\n",
      "Train Epoch: 554 [600/2589 (23%)]\tLoss: 225.277115\n",
      "Train Epoch: 554 [900/2589 (35%)]\tLoss: 191.793365\n",
      "Train Epoch: 554 [1200/2589 (46%)]\tLoss: 291.147461\n",
      "Train Epoch: 554 [1500/2589 (58%)]\tLoss: 190.169220\n",
      "Train Epoch: 554 [1800/2589 (70%)]\tLoss: 306.534515\n",
      "Train Epoch: 554 [2100/2589 (81%)]\tLoss: 327.700836\n",
      "Train Epoch: 554 [2400/2589 (93%)]\tLoss: 297.441589\n",
      "====> Epoch: 554 Average train loss: 247.6744\n",
      "====> Epoch: 554 Average test loss: 931.5707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 555 [0/2589 (0%)]\tLoss: 211.817413\n",
      "Train Epoch: 555 [300/2589 (12%)]\tLoss: 418.536530\n",
      "Train Epoch: 555 [600/2589 (23%)]\tLoss: 242.047592\n",
      "Train Epoch: 555 [900/2589 (35%)]\tLoss: 257.910126\n",
      "Train Epoch: 555 [1200/2589 (46%)]\tLoss: 254.085831\n",
      "Train Epoch: 555 [1500/2589 (58%)]\tLoss: 245.534531\n",
      "Train Epoch: 555 [1800/2589 (70%)]\tLoss: 292.730316\n",
      "Train Epoch: 555 [2100/2589 (81%)]\tLoss: 195.168900\n",
      "Train Epoch: 555 [2400/2589 (93%)]\tLoss: 257.533600\n",
      "====> Epoch: 555 Average train loss: 239.1896\n",
      "====> Epoch: 555 Average test loss: 947.1853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 556 [0/2589 (0%)]\tLoss: 258.187225\n",
      "Train Epoch: 556 [300/2589 (12%)]\tLoss: 387.410278\n",
      "Train Epoch: 556 [600/2589 (23%)]\tLoss: 156.542526\n",
      "Train Epoch: 556 [900/2589 (35%)]\tLoss: 509.042511\n",
      "Train Epoch: 556 [1200/2589 (46%)]\tLoss: 136.513443\n",
      "Train Epoch: 556 [1500/2589 (58%)]\tLoss: 224.963135\n",
      "Train Epoch: 556 [1800/2589 (70%)]\tLoss: 296.245392\n",
      "Train Epoch: 556 [2100/2589 (81%)]\tLoss: 218.304108\n",
      "Train Epoch: 556 [2400/2589 (93%)]\tLoss: 195.278076\n",
      "====> Epoch: 556 Average train loss: 244.6760\n",
      "====> Epoch: 556 Average test loss: 939.0759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 557 [0/2589 (0%)]\tLoss: 177.617477\n",
      "Train Epoch: 557 [300/2589 (12%)]\tLoss: 226.364578\n",
      "Train Epoch: 557 [600/2589 (23%)]\tLoss: 192.890182\n",
      "Train Epoch: 557 [900/2589 (35%)]\tLoss: 211.443848\n",
      "Train Epoch: 557 [1200/2589 (46%)]\tLoss: 229.513199\n",
      "Train Epoch: 557 [1500/2589 (58%)]\tLoss: 224.033188\n",
      "Train Epoch: 557 [1800/2589 (70%)]\tLoss: 239.325943\n",
      "Train Epoch: 557 [2100/2589 (81%)]\tLoss: 252.731094\n",
      "Train Epoch: 557 [2400/2589 (93%)]\tLoss: 161.668610\n",
      "====> Epoch: 557 Average train loss: 241.7477\n",
      "====> Epoch: 557 Average test loss: 934.5980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 558 [0/2589 (0%)]\tLoss: 168.826096\n",
      "Train Epoch: 558 [300/2589 (12%)]\tLoss: 155.040955\n",
      "Train Epoch: 558 [600/2589 (23%)]\tLoss: 217.534454\n",
      "Train Epoch: 558 [900/2589 (35%)]\tLoss: 340.702118\n",
      "Train Epoch: 558 [1200/2589 (46%)]\tLoss: 241.261490\n",
      "Train Epoch: 558 [1500/2589 (58%)]\tLoss: 169.276337\n",
      "Train Epoch: 558 [1800/2589 (70%)]\tLoss: 203.095230\n",
      "Train Epoch: 558 [2100/2589 (81%)]\tLoss: 171.889099\n",
      "Train Epoch: 558 [2400/2589 (93%)]\tLoss: 222.519135\n",
      "====> Epoch: 558 Average train loss: 233.1744\n",
      "====> Epoch: 558 Average test loss: 926.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 559 [0/2589 (0%)]\tLoss: 226.913635\n",
      "Train Epoch: 559 [300/2589 (12%)]\tLoss: 230.530701\n",
      "Train Epoch: 559 [600/2589 (23%)]\tLoss: 239.226212\n",
      "Train Epoch: 559 [900/2589 (35%)]\tLoss: 380.372437\n",
      "Train Epoch: 559 [1200/2589 (46%)]\tLoss: 257.187134\n",
      "Train Epoch: 559 [1500/2589 (58%)]\tLoss: 254.042755\n",
      "Train Epoch: 559 [1800/2589 (70%)]\tLoss: 189.365326\n",
      "Train Epoch: 559 [2100/2589 (81%)]\tLoss: 237.396576\n",
      "Train Epoch: 559 [2400/2589 (93%)]\tLoss: 261.730865\n",
      "====> Epoch: 559 Average train loss: 251.0783\n",
      "====> Epoch: 559 Average test loss: 925.3830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 560 [0/2589 (0%)]\tLoss: 294.991364\n",
      "Train Epoch: 560 [300/2589 (12%)]\tLoss: 197.245163\n",
      "Train Epoch: 560 [600/2589 (23%)]\tLoss: 462.903198\n",
      "Train Epoch: 560 [900/2589 (35%)]\tLoss: 279.972229\n",
      "Train Epoch: 560 [1200/2589 (46%)]\tLoss: 186.912277\n",
      "Train Epoch: 560 [1500/2589 (58%)]\tLoss: 250.098602\n",
      "Train Epoch: 560 [1800/2589 (70%)]\tLoss: 151.940170\n",
      "Train Epoch: 560 [2100/2589 (81%)]\tLoss: 213.217056\n",
      "Train Epoch: 560 [2400/2589 (93%)]\tLoss: 190.638733\n",
      "====> Epoch: 560 Average train loss: 230.2210\n",
      "====> Epoch: 560 Average test loss: 924.7430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 561 [0/2589 (0%)]\tLoss: 229.098984\n",
      "Train Epoch: 561 [300/2589 (12%)]\tLoss: 271.282135\n",
      "Train Epoch: 561 [600/2589 (23%)]\tLoss: 268.721222\n",
      "Train Epoch: 561 [900/2589 (35%)]\tLoss: 211.819748\n",
      "Train Epoch: 561 [1200/2589 (46%)]\tLoss: 510.636688\n",
      "Train Epoch: 561 [1500/2589 (58%)]\tLoss: 250.281418\n",
      "Train Epoch: 561 [1800/2589 (70%)]\tLoss: 178.106400\n",
      "Train Epoch: 561 [2100/2589 (81%)]\tLoss: 375.557709\n",
      "Train Epoch: 561 [2400/2589 (93%)]\tLoss: 169.136398\n",
      "====> Epoch: 561 Average train loss: 243.0366\n",
      "====> Epoch: 561 Average test loss: 919.0704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 562 [0/2589 (0%)]\tLoss: 302.986328\n",
      "Train Epoch: 562 [300/2589 (12%)]\tLoss: 245.340973\n",
      "Train Epoch: 562 [600/2589 (23%)]\tLoss: 239.027023\n",
      "Train Epoch: 562 [900/2589 (35%)]\tLoss: 195.650833\n",
      "Train Epoch: 562 [1200/2589 (46%)]\tLoss: 202.414337\n",
      "Train Epoch: 562 [1500/2589 (58%)]\tLoss: 154.618088\n",
      "Train Epoch: 562 [1800/2589 (70%)]\tLoss: 259.813599\n",
      "Train Epoch: 562 [2100/2589 (81%)]\tLoss: 260.007263\n",
      "Train Epoch: 562 [2400/2589 (93%)]\tLoss: 348.473419\n",
      "====> Epoch: 562 Average train loss: 227.9159\n",
      "====> Epoch: 562 Average test loss: 922.0945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 563 [0/2589 (0%)]\tLoss: 196.008011\n",
      "Train Epoch: 563 [300/2589 (12%)]\tLoss: 224.481384\n",
      "Train Epoch: 563 [600/2589 (23%)]\tLoss: 351.680634\n",
      "Train Epoch: 563 [900/2589 (35%)]\tLoss: 198.660538\n",
      "Train Epoch: 563 [1200/2589 (46%)]\tLoss: 209.223053\n",
      "Train Epoch: 563 [1500/2589 (58%)]\tLoss: 198.976456\n",
      "Train Epoch: 563 [1800/2589 (70%)]\tLoss: 174.570755\n",
      "Train Epoch: 563 [2100/2589 (81%)]\tLoss: 261.432556\n",
      "Train Epoch: 563 [2400/2589 (93%)]\tLoss: 227.488754\n",
      "====> Epoch: 563 Average train loss: 240.7139\n",
      "====> Epoch: 563 Average test loss: 922.6110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 564 [0/2589 (0%)]\tLoss: 240.636475\n",
      "Train Epoch: 564 [300/2589 (12%)]\tLoss: 233.325729\n",
      "Train Epoch: 564 [600/2589 (23%)]\tLoss: 185.108994\n",
      "Train Epoch: 564 [900/2589 (35%)]\tLoss: 187.255676\n",
      "Train Epoch: 564 [1200/2589 (46%)]\tLoss: 192.540955\n",
      "Train Epoch: 564 [1500/2589 (58%)]\tLoss: 266.026581\n",
      "Train Epoch: 564 [1800/2589 (70%)]\tLoss: 165.135971\n",
      "Train Epoch: 564 [2100/2589 (81%)]\tLoss: 205.453369\n",
      "Train Epoch: 564 [2400/2589 (93%)]\tLoss: 219.267227\n",
      "====> Epoch: 564 Average train loss: 236.7265\n",
      "====> Epoch: 564 Average test loss: 926.1212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 565 [0/2589 (0%)]\tLoss: 229.756088\n",
      "Train Epoch: 565 [300/2589 (12%)]\tLoss: 225.473557\n",
      "Train Epoch: 565 [600/2589 (23%)]\tLoss: 194.983688\n",
      "Train Epoch: 565 [900/2589 (35%)]\tLoss: 222.140518\n",
      "Train Epoch: 565 [1200/2589 (46%)]\tLoss: 198.678680\n",
      "Train Epoch: 565 [1500/2589 (58%)]\tLoss: 242.395554\n",
      "Train Epoch: 565 [1800/2589 (70%)]\tLoss: 211.977310\n",
      "Train Epoch: 565 [2100/2589 (81%)]\tLoss: 220.399887\n",
      "Train Epoch: 565 [2400/2589 (93%)]\tLoss: 193.278793\n",
      "====> Epoch: 565 Average train loss: 234.5316\n",
      "====> Epoch: 565 Average test loss: 929.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 566 [0/2589 (0%)]\tLoss: 198.181381\n",
      "Train Epoch: 566 [300/2589 (12%)]\tLoss: 288.560059\n",
      "Train Epoch: 566 [600/2589 (23%)]\tLoss: 276.834290\n",
      "Train Epoch: 566 [900/2589 (35%)]\tLoss: 406.992523\n",
      "Train Epoch: 566 [1200/2589 (46%)]\tLoss: 240.614609\n",
      "Train Epoch: 566 [1500/2589 (58%)]\tLoss: 195.091934\n",
      "Train Epoch: 566 [1800/2589 (70%)]\tLoss: 245.586288\n",
      "Train Epoch: 566 [2100/2589 (81%)]\tLoss: 216.080429\n",
      "Train Epoch: 566 [2400/2589 (93%)]\tLoss: 299.480774\n",
      "====> Epoch: 566 Average train loss: 242.8483\n",
      "====> Epoch: 566 Average test loss: 933.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 567 [0/2589 (0%)]\tLoss: 155.166824\n",
      "Train Epoch: 567 [300/2589 (12%)]\tLoss: 279.346497\n",
      "Train Epoch: 567 [600/2589 (23%)]\tLoss: 240.774384\n",
      "Train Epoch: 567 [900/2589 (35%)]\tLoss: 211.921326\n",
      "Train Epoch: 567 [1200/2589 (46%)]\tLoss: 235.819427\n",
      "Train Epoch: 567 [1500/2589 (58%)]\tLoss: 224.272705\n",
      "Train Epoch: 567 [1800/2589 (70%)]\tLoss: 222.976562\n",
      "Train Epoch: 567 [2100/2589 (81%)]\tLoss: 206.760574\n",
      "Train Epoch: 567 [2400/2589 (93%)]\tLoss: 243.838348\n",
      "====> Epoch: 567 Average train loss: 238.7727\n",
      "====> Epoch: 567 Average test loss: 930.3434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 568 [0/2589 (0%)]\tLoss: 400.856445\n",
      "Train Epoch: 568 [300/2589 (12%)]\tLoss: 244.872910\n",
      "Train Epoch: 568 [600/2589 (23%)]\tLoss: 179.183762\n",
      "Train Epoch: 568 [900/2589 (35%)]\tLoss: 165.945480\n",
      "Train Epoch: 568 [1200/2589 (46%)]\tLoss: 240.564301\n",
      "Train Epoch: 568 [1500/2589 (58%)]\tLoss: 155.344070\n",
      "Train Epoch: 568 [1800/2589 (70%)]\tLoss: 200.716614\n",
      "Train Epoch: 568 [2100/2589 (81%)]\tLoss: 207.872971\n",
      "Train Epoch: 568 [2400/2589 (93%)]\tLoss: 255.886246\n",
      "====> Epoch: 568 Average train loss: 245.8701\n",
      "====> Epoch: 568 Average test loss: 939.4676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 569 [0/2589 (0%)]\tLoss: 211.923889\n",
      "Train Epoch: 569 [300/2589 (12%)]\tLoss: 150.007095\n",
      "Train Epoch: 569 [600/2589 (23%)]\tLoss: 137.694138\n",
      "Train Epoch: 569 [900/2589 (35%)]\tLoss: 326.698883\n",
      "Train Epoch: 569 [1200/2589 (46%)]\tLoss: 233.598236\n",
      "Train Epoch: 569 [1500/2589 (58%)]\tLoss: 363.925293\n",
      "Train Epoch: 569 [1800/2589 (70%)]\tLoss: 233.092422\n",
      "Train Epoch: 569 [2100/2589 (81%)]\tLoss: 262.742340\n",
      "Train Epoch: 569 [2400/2589 (93%)]\tLoss: 183.081223\n",
      "====> Epoch: 569 Average train loss: 237.3093\n",
      "====> Epoch: 569 Average test loss: 930.2797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 570 [0/2589 (0%)]\tLoss: 208.408112\n",
      "Train Epoch: 570 [300/2589 (12%)]\tLoss: 259.808258\n",
      "Train Epoch: 570 [600/2589 (23%)]\tLoss: 295.650818\n",
      "Train Epoch: 570 [900/2589 (35%)]\tLoss: 208.985809\n",
      "Train Epoch: 570 [1200/2589 (46%)]\tLoss: 257.787872\n",
      "Train Epoch: 570 [1500/2589 (58%)]\tLoss: 228.295471\n",
      "Train Epoch: 570 [1800/2589 (70%)]\tLoss: 333.384644\n",
      "Train Epoch: 570 [2100/2589 (81%)]\tLoss: 473.595917\n",
      "Train Epoch: 570 [2400/2589 (93%)]\tLoss: 342.672638\n",
      "====> Epoch: 570 Average train loss: 246.3151\n",
      "====> Epoch: 570 Average test loss: 924.2963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 571 [0/2589 (0%)]\tLoss: 217.548050\n",
      "Train Epoch: 571 [300/2589 (12%)]\tLoss: 285.816345\n",
      "Train Epoch: 571 [600/2589 (23%)]\tLoss: 380.335938\n",
      "Train Epoch: 571 [900/2589 (35%)]\tLoss: 210.818466\n",
      "Train Epoch: 571 [1200/2589 (46%)]\tLoss: 274.597382\n",
      "Train Epoch: 571 [1500/2589 (58%)]\tLoss: 248.606995\n",
      "Train Epoch: 571 [1800/2589 (70%)]\tLoss: 285.580078\n",
      "Train Epoch: 571 [2100/2589 (81%)]\tLoss: 292.866089\n",
      "Train Epoch: 571 [2400/2589 (93%)]\tLoss: 268.614532\n",
      "====> Epoch: 571 Average train loss: 237.0359\n",
      "====> Epoch: 571 Average test loss: 932.4213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 572 [0/2589 (0%)]\tLoss: 176.297073\n",
      "Train Epoch: 572 [300/2589 (12%)]\tLoss: 193.217422\n",
      "Train Epoch: 572 [600/2589 (23%)]\tLoss: 182.831833\n",
      "Train Epoch: 572 [900/2589 (35%)]\tLoss: 236.248840\n",
      "Train Epoch: 572 [1200/2589 (46%)]\tLoss: 278.428986\n",
      "Train Epoch: 572 [1500/2589 (58%)]\tLoss: 396.925232\n",
      "Train Epoch: 572 [1800/2589 (70%)]\tLoss: 278.874084\n",
      "Train Epoch: 572 [2100/2589 (81%)]\tLoss: 313.771790\n",
      "Train Epoch: 572 [2400/2589 (93%)]\tLoss: 265.809753\n",
      "====> Epoch: 572 Average train loss: 244.2743\n",
      "====> Epoch: 572 Average test loss: 901.8179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 573 [0/2589 (0%)]\tLoss: 198.626114\n",
      "Train Epoch: 573 [300/2589 (12%)]\tLoss: 226.668976\n",
      "Train Epoch: 573 [600/2589 (23%)]\tLoss: 233.482773\n",
      "Train Epoch: 573 [900/2589 (35%)]\tLoss: 209.669586\n",
      "Train Epoch: 573 [1200/2589 (46%)]\tLoss: 425.290497\n",
      "Train Epoch: 573 [1500/2589 (58%)]\tLoss: 280.913849\n",
      "Train Epoch: 573 [1800/2589 (70%)]\tLoss: 297.811340\n",
      "Train Epoch: 573 [2100/2589 (81%)]\tLoss: 165.948212\n",
      "Train Epoch: 573 [2400/2589 (93%)]\tLoss: 203.926483\n",
      "====> Epoch: 573 Average train loss: 249.3867\n",
      "====> Epoch: 573 Average test loss: 931.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 574 [0/2589 (0%)]\tLoss: 231.209534\n",
      "Train Epoch: 574 [300/2589 (12%)]\tLoss: 176.526947\n",
      "Train Epoch: 574 [600/2589 (23%)]\tLoss: 342.462433\n",
      "Train Epoch: 574 [900/2589 (35%)]\tLoss: 161.316574\n",
      "Train Epoch: 574 [1200/2589 (46%)]\tLoss: 235.137863\n",
      "Train Epoch: 574 [1500/2589 (58%)]\tLoss: 247.773407\n",
      "Train Epoch: 574 [1800/2589 (70%)]\tLoss: 174.171677\n",
      "Train Epoch: 574 [2100/2589 (81%)]\tLoss: 164.102890\n",
      "Train Epoch: 574 [2400/2589 (93%)]\tLoss: 269.799896\n",
      "====> Epoch: 574 Average train loss: 240.8351\n",
      "====> Epoch: 574 Average test loss: 920.7397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 575 [0/2589 (0%)]\tLoss: 190.854309\n",
      "Train Epoch: 575 [300/2589 (12%)]\tLoss: 264.654816\n",
      "Train Epoch: 575 [600/2589 (23%)]\tLoss: 281.139313\n",
      "Train Epoch: 575 [900/2589 (35%)]\tLoss: 182.208206\n",
      "Train Epoch: 575 [1200/2589 (46%)]\tLoss: 248.557922\n",
      "Train Epoch: 575 [1500/2589 (58%)]\tLoss: 235.104401\n",
      "Train Epoch: 575 [1800/2589 (70%)]\tLoss: 221.881775\n",
      "Train Epoch: 575 [2100/2589 (81%)]\tLoss: 318.059967\n",
      "Train Epoch: 575 [2400/2589 (93%)]\tLoss: 297.957367\n",
      "====> Epoch: 575 Average train loss: 246.8351\n",
      "====> Epoch: 575 Average test loss: 926.4070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 576 [0/2589 (0%)]\tLoss: 238.543884\n",
      "Train Epoch: 576 [300/2589 (12%)]\tLoss: 236.414734\n",
      "Train Epoch: 576 [600/2589 (23%)]\tLoss: 187.876404\n",
      "Train Epoch: 576 [900/2589 (35%)]\tLoss: 194.253464\n",
      "Train Epoch: 576 [1200/2589 (46%)]\tLoss: 253.142517\n",
      "Train Epoch: 576 [1500/2589 (58%)]\tLoss: 151.009659\n",
      "Train Epoch: 576 [1800/2589 (70%)]\tLoss: 256.962708\n",
      "Train Epoch: 576 [2100/2589 (81%)]\tLoss: 297.898376\n",
      "Train Epoch: 576 [2400/2589 (93%)]\tLoss: 194.144775\n",
      "====> Epoch: 576 Average train loss: 238.7292\n",
      "====> Epoch: 576 Average test loss: 934.0757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 577 [0/2589 (0%)]\tLoss: 218.705948\n",
      "Train Epoch: 577 [300/2589 (12%)]\tLoss: 200.659729\n",
      "Train Epoch: 577 [600/2589 (23%)]\tLoss: 186.989029\n",
      "Train Epoch: 577 [900/2589 (35%)]\tLoss: 263.173798\n",
      "Train Epoch: 577 [1200/2589 (46%)]\tLoss: 264.276764\n",
      "Train Epoch: 577 [1500/2589 (58%)]\tLoss: 209.837067\n",
      "Train Epoch: 577 [1800/2589 (70%)]\tLoss: 226.590012\n",
      "Train Epoch: 577 [2100/2589 (81%)]\tLoss: 264.158234\n",
      "Train Epoch: 577 [2400/2589 (93%)]\tLoss: 211.251770\n",
      "====> Epoch: 577 Average train loss: 243.4553\n",
      "====> Epoch: 577 Average test loss: 936.7154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 578 [0/2589 (0%)]\tLoss: 149.707550\n",
      "Train Epoch: 578 [300/2589 (12%)]\tLoss: 249.955826\n",
      "Train Epoch: 578 [600/2589 (23%)]\tLoss: 201.644455\n",
      "Train Epoch: 578 [900/2589 (35%)]\tLoss: 239.335754\n",
      "Train Epoch: 578 [1200/2589 (46%)]\tLoss: 226.137970\n",
      "Train Epoch: 578 [1500/2589 (58%)]\tLoss: 179.385574\n",
      "Train Epoch: 578 [1800/2589 (70%)]\tLoss: 396.915192\n",
      "Train Epoch: 578 [2100/2589 (81%)]\tLoss: 233.773102\n",
      "Train Epoch: 578 [2400/2589 (93%)]\tLoss: 325.668030\n",
      "====> Epoch: 578 Average train loss: 247.8955\n",
      "====> Epoch: 578 Average test loss: 932.1933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 579 [0/2589 (0%)]\tLoss: 285.085785\n",
      "Train Epoch: 579 [300/2589 (12%)]\tLoss: 212.392761\n",
      "Train Epoch: 579 [600/2589 (23%)]\tLoss: 334.464874\n",
      "Train Epoch: 579 [900/2589 (35%)]\tLoss: 256.465698\n",
      "Train Epoch: 579 [1200/2589 (46%)]\tLoss: 238.117386\n",
      "Train Epoch: 579 [1500/2589 (58%)]\tLoss: 329.872742\n",
      "Train Epoch: 579 [1800/2589 (70%)]\tLoss: 246.091736\n",
      "Train Epoch: 579 [2100/2589 (81%)]\tLoss: 244.331299\n",
      "Train Epoch: 579 [2400/2589 (93%)]\tLoss: 211.732132\n",
      "====> Epoch: 579 Average train loss: 238.4412\n",
      "====> Epoch: 579 Average test loss: 936.5897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 580 [0/2589 (0%)]\tLoss: 153.026077\n",
      "Train Epoch: 580 [300/2589 (12%)]\tLoss: 243.751465\n",
      "Train Epoch: 580 [600/2589 (23%)]\tLoss: 196.299988\n",
      "Train Epoch: 580 [900/2589 (35%)]\tLoss: 202.882294\n",
      "Train Epoch: 580 [1200/2589 (46%)]\tLoss: 327.378937\n",
      "Train Epoch: 580 [1500/2589 (58%)]\tLoss: 127.707550\n",
      "Train Epoch: 580 [1800/2589 (70%)]\tLoss: 207.898575\n",
      "Train Epoch: 580 [2100/2589 (81%)]\tLoss: 230.463104\n",
      "Train Epoch: 580 [2400/2589 (93%)]\tLoss: 186.731888\n",
      "====> Epoch: 580 Average train loss: 225.0676\n",
      "====> Epoch: 580 Average test loss: 920.6909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 581 [0/2589 (0%)]\tLoss: 397.444153\n",
      "Train Epoch: 581 [300/2589 (12%)]\tLoss: 169.851349\n",
      "Train Epoch: 581 [600/2589 (23%)]\tLoss: 244.810135\n",
      "Train Epoch: 581 [900/2589 (35%)]\tLoss: 302.375031\n",
      "Train Epoch: 581 [1200/2589 (46%)]\tLoss: 220.543533\n",
      "Train Epoch: 581 [1500/2589 (58%)]\tLoss: 233.487106\n",
      "Train Epoch: 581 [1800/2589 (70%)]\tLoss: 231.895935\n",
      "Train Epoch: 581 [2100/2589 (81%)]\tLoss: 209.916473\n",
      "Train Epoch: 581 [2400/2589 (93%)]\tLoss: 196.551926\n",
      "====> Epoch: 581 Average train loss: 239.8007\n",
      "====> Epoch: 581 Average test loss: 908.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 582 [0/2589 (0%)]\tLoss: 248.811279\n",
      "Train Epoch: 582 [300/2589 (12%)]\tLoss: 168.340775\n",
      "Train Epoch: 582 [600/2589 (23%)]\tLoss: 229.386826\n",
      "Train Epoch: 582 [900/2589 (35%)]\tLoss: 219.204834\n",
      "Train Epoch: 582 [1200/2589 (46%)]\tLoss: 350.997711\n",
      "Train Epoch: 582 [1500/2589 (58%)]\tLoss: 273.247925\n",
      "Train Epoch: 582 [1800/2589 (70%)]\tLoss: 160.888123\n",
      "Train Epoch: 582 [2100/2589 (81%)]\tLoss: 203.976898\n",
      "Train Epoch: 582 [2400/2589 (93%)]\tLoss: 236.032364\n",
      "====> Epoch: 582 Average train loss: 246.7793\n",
      "====> Epoch: 582 Average test loss: 938.1541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 583 [0/2589 (0%)]\tLoss: 244.841034\n",
      "Train Epoch: 583 [300/2589 (12%)]\tLoss: 180.191101\n",
      "Train Epoch: 583 [600/2589 (23%)]\tLoss: 170.687439\n",
      "Train Epoch: 583 [900/2589 (35%)]\tLoss: 263.862000\n",
      "Train Epoch: 583 [1200/2589 (46%)]\tLoss: 194.765396\n",
      "Train Epoch: 583 [1500/2589 (58%)]\tLoss: 259.728607\n",
      "Train Epoch: 583 [1800/2589 (70%)]\tLoss: 246.765335\n",
      "Train Epoch: 583 [2100/2589 (81%)]\tLoss: 163.160507\n",
      "Train Epoch: 583 [2400/2589 (93%)]\tLoss: 351.629669\n",
      "====> Epoch: 583 Average train loss: 239.2654\n",
      "====> Epoch: 583 Average test loss: 910.7672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 584 [0/2589 (0%)]\tLoss: 301.786926\n",
      "Train Epoch: 584 [300/2589 (12%)]\tLoss: 212.661652\n",
      "Train Epoch: 584 [600/2589 (23%)]\tLoss: 206.686447\n",
      "Train Epoch: 584 [900/2589 (35%)]\tLoss: 179.196014\n",
      "Train Epoch: 584 [1200/2589 (46%)]\tLoss: 158.731873\n",
      "Train Epoch: 584 [1500/2589 (58%)]\tLoss: 169.975693\n",
      "Train Epoch: 584 [1800/2589 (70%)]\tLoss: 177.529572\n",
      "Train Epoch: 584 [2100/2589 (81%)]\tLoss: 191.628525\n",
      "Train Epoch: 584 [2400/2589 (93%)]\tLoss: 236.121063\n",
      "====> Epoch: 584 Average train loss: 241.5978\n",
      "====> Epoch: 584 Average test loss: 936.6904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 585 [0/2589 (0%)]\tLoss: 186.739716\n",
      "Train Epoch: 585 [300/2589 (12%)]\tLoss: 176.046387\n",
      "Train Epoch: 585 [600/2589 (23%)]\tLoss: 192.382904\n",
      "Train Epoch: 585 [900/2589 (35%)]\tLoss: 201.016266\n",
      "Train Epoch: 585 [1200/2589 (46%)]\tLoss: 217.077988\n",
      "Train Epoch: 585 [1500/2589 (58%)]\tLoss: 247.746857\n",
      "Train Epoch: 585 [1800/2589 (70%)]\tLoss: 249.394485\n",
      "Train Epoch: 585 [2100/2589 (81%)]\tLoss: 182.810822\n",
      "Train Epoch: 585 [2400/2589 (93%)]\tLoss: 206.150162\n",
      "====> Epoch: 585 Average train loss: 239.3089\n",
      "====> Epoch: 585 Average test loss: 920.4712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 586 [0/2589 (0%)]\tLoss: 200.680832\n",
      "Train Epoch: 586 [300/2589 (12%)]\tLoss: 209.330994\n",
      "Train Epoch: 586 [600/2589 (23%)]\tLoss: 246.388947\n",
      "Train Epoch: 586 [900/2589 (35%)]\tLoss: 325.846283\n",
      "Train Epoch: 586 [1200/2589 (46%)]\tLoss: 176.186172\n",
      "Train Epoch: 586 [1500/2589 (58%)]\tLoss: 248.463943\n",
      "Train Epoch: 586 [1800/2589 (70%)]\tLoss: 233.960007\n",
      "Train Epoch: 586 [2100/2589 (81%)]\tLoss: 240.591568\n",
      "Train Epoch: 586 [2400/2589 (93%)]\tLoss: 389.914459\n",
      "====> Epoch: 586 Average train loss: 245.5014\n",
      "====> Epoch: 586 Average test loss: 927.7599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 587 [0/2589 (0%)]\tLoss: 245.770752\n",
      "Train Epoch: 587 [300/2589 (12%)]\tLoss: 207.706329\n",
      "Train Epoch: 587 [600/2589 (23%)]\tLoss: 301.979614\n",
      "Train Epoch: 587 [900/2589 (35%)]\tLoss: 156.612244\n",
      "Train Epoch: 587 [1200/2589 (46%)]\tLoss: 266.672333\n",
      "Train Epoch: 587 [1500/2589 (58%)]\tLoss: 433.262909\n",
      "Train Epoch: 587 [1800/2589 (70%)]\tLoss: 168.447784\n",
      "Train Epoch: 587 [2100/2589 (81%)]\tLoss: 197.315628\n",
      "Train Epoch: 587 [2400/2589 (93%)]\tLoss: 356.620758\n",
      "====> Epoch: 587 Average train loss: 239.3958\n",
      "====> Epoch: 587 Average test loss: 932.7542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 588 [0/2589 (0%)]\tLoss: 332.687225\n",
      "Train Epoch: 588 [300/2589 (12%)]\tLoss: 295.150360\n",
      "Train Epoch: 588 [600/2589 (23%)]\tLoss: 257.588074\n",
      "Train Epoch: 588 [900/2589 (35%)]\tLoss: 258.526825\n",
      "Train Epoch: 588 [1200/2589 (46%)]\tLoss: 240.557053\n",
      "Train Epoch: 588 [1500/2589 (58%)]\tLoss: 153.256271\n",
      "Train Epoch: 588 [1800/2589 (70%)]\tLoss: 193.228485\n",
      "Train Epoch: 588 [2100/2589 (81%)]\tLoss: 192.816254\n",
      "Train Epoch: 588 [2400/2589 (93%)]\tLoss: 345.277405\n",
      "====> Epoch: 588 Average train loss: 235.8076\n",
      "====> Epoch: 588 Average test loss: 928.1514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 589 [0/2589 (0%)]\tLoss: 316.593079\n",
      "Train Epoch: 589 [300/2589 (12%)]\tLoss: 223.864792\n",
      "Train Epoch: 589 [600/2589 (23%)]\tLoss: 174.267929\n",
      "Train Epoch: 589 [900/2589 (35%)]\tLoss: 260.742798\n",
      "Train Epoch: 589 [1200/2589 (46%)]\tLoss: 204.180374\n",
      "Train Epoch: 589 [1500/2589 (58%)]\tLoss: 212.012070\n",
      "Train Epoch: 589 [1800/2589 (70%)]\tLoss: 242.562576\n",
      "Train Epoch: 589 [2100/2589 (81%)]\tLoss: 268.675537\n",
      "Train Epoch: 589 [2400/2589 (93%)]\tLoss: 211.940247\n",
      "====> Epoch: 589 Average train loss: 237.9236\n",
      "====> Epoch: 589 Average test loss: 938.3593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 590 [0/2589 (0%)]\tLoss: 142.563065\n",
      "Train Epoch: 590 [300/2589 (12%)]\tLoss: 195.757019\n",
      "Train Epoch: 590 [600/2589 (23%)]\tLoss: 279.290588\n",
      "Train Epoch: 590 [900/2589 (35%)]\tLoss: 193.544174\n",
      "Train Epoch: 590 [1200/2589 (46%)]\tLoss: 263.193787\n",
      "Train Epoch: 590 [1500/2589 (58%)]\tLoss: 256.719666\n",
      "Train Epoch: 590 [1800/2589 (70%)]\tLoss: 192.397476\n",
      "Train Epoch: 590 [2100/2589 (81%)]\tLoss: 249.050003\n",
      "Train Epoch: 590 [2400/2589 (93%)]\tLoss: 176.003021\n",
      "====> Epoch: 590 Average train loss: 231.3588\n",
      "====> Epoch: 590 Average test loss: 913.5266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 591 [0/2589 (0%)]\tLoss: 225.960358\n",
      "Train Epoch: 591 [300/2589 (12%)]\tLoss: 194.626495\n",
      "Train Epoch: 591 [600/2589 (23%)]\tLoss: 222.374512\n",
      "Train Epoch: 591 [900/2589 (35%)]\tLoss: 272.636505\n",
      "Train Epoch: 591 [1200/2589 (46%)]\tLoss: 228.528015\n",
      "Train Epoch: 591 [1500/2589 (58%)]\tLoss: 177.791992\n",
      "Train Epoch: 591 [1800/2589 (70%)]\tLoss: 195.418030\n",
      "Train Epoch: 591 [2100/2589 (81%)]\tLoss: 213.657318\n",
      "Train Epoch: 591 [2400/2589 (93%)]\tLoss: 230.828079\n",
      "====> Epoch: 591 Average train loss: 240.5139\n",
      "====> Epoch: 591 Average test loss: 917.8865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 592 [0/2589 (0%)]\tLoss: 376.471954\n",
      "Train Epoch: 592 [300/2589 (12%)]\tLoss: 237.843704\n",
      "Train Epoch: 592 [600/2589 (23%)]\tLoss: 212.675705\n",
      "Train Epoch: 592 [900/2589 (35%)]\tLoss: 189.685577\n",
      "Train Epoch: 592 [1200/2589 (46%)]\tLoss: 367.877289\n",
      "Train Epoch: 592 [1500/2589 (58%)]\tLoss: 300.600555\n",
      "Train Epoch: 592 [1800/2589 (70%)]\tLoss: 180.139679\n",
      "Train Epoch: 592 [2100/2589 (81%)]\tLoss: 213.242874\n",
      "Train Epoch: 592 [2400/2589 (93%)]\tLoss: 221.890656\n",
      "====> Epoch: 592 Average train loss: 233.7299\n",
      "====> Epoch: 592 Average test loss: 924.6027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 593 [0/2589 (0%)]\tLoss: 178.470673\n",
      "Train Epoch: 593 [300/2589 (12%)]\tLoss: 225.634567\n",
      "Train Epoch: 593 [600/2589 (23%)]\tLoss: 251.960892\n",
      "Train Epoch: 593 [900/2589 (35%)]\tLoss: 156.831741\n",
      "Train Epoch: 593 [1200/2589 (46%)]\tLoss: 172.377029\n",
      "Train Epoch: 593 [1500/2589 (58%)]\tLoss: 174.018997\n",
      "Train Epoch: 593 [1800/2589 (70%)]\tLoss: 130.176651\n",
      "Train Epoch: 593 [2100/2589 (81%)]\tLoss: 266.155975\n",
      "Train Epoch: 593 [2400/2589 (93%)]\tLoss: 190.202713\n",
      "====> Epoch: 593 Average train loss: 245.7135\n",
      "====> Epoch: 593 Average test loss: 943.1447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 594 [0/2589 (0%)]\tLoss: 195.111359\n",
      "Train Epoch: 594 [300/2589 (12%)]\tLoss: 164.601532\n",
      "Train Epoch: 594 [600/2589 (23%)]\tLoss: 220.837616\n",
      "Train Epoch: 594 [900/2589 (35%)]\tLoss: 334.009613\n",
      "Train Epoch: 594 [1200/2589 (46%)]\tLoss: 341.713104\n",
      "Train Epoch: 594 [1500/2589 (58%)]\tLoss: 158.972641\n",
      "Train Epoch: 594 [1800/2589 (70%)]\tLoss: 210.438614\n",
      "Train Epoch: 594 [2100/2589 (81%)]\tLoss: 224.445740\n",
      "Train Epoch: 594 [2400/2589 (93%)]\tLoss: 278.790894\n",
      "====> Epoch: 594 Average train loss: 237.4198\n",
      "====> Epoch: 594 Average test loss: 938.6334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 595 [0/2589 (0%)]\tLoss: 162.487885\n",
      "Train Epoch: 595 [300/2589 (12%)]\tLoss: 212.600357\n",
      "Train Epoch: 595 [600/2589 (23%)]\tLoss: 294.915802\n",
      "Train Epoch: 595 [900/2589 (35%)]\tLoss: 214.381943\n",
      "Train Epoch: 595 [1200/2589 (46%)]\tLoss: 155.423584\n",
      "Train Epoch: 595 [1500/2589 (58%)]\tLoss: 160.241669\n",
      "Train Epoch: 595 [1800/2589 (70%)]\tLoss: 192.740067\n",
      "Train Epoch: 595 [2100/2589 (81%)]\tLoss: 186.830048\n",
      "Train Epoch: 595 [2400/2589 (93%)]\tLoss: 195.154449\n",
      "====> Epoch: 595 Average train loss: 234.5304\n",
      "====> Epoch: 595 Average test loss: 923.0322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 596 [0/2589 (0%)]\tLoss: 292.464661\n",
      "Train Epoch: 596 [300/2589 (12%)]\tLoss: 241.441803\n",
      "Train Epoch: 596 [600/2589 (23%)]\tLoss: 243.664597\n",
      "Train Epoch: 596 [900/2589 (35%)]\tLoss: 288.005676\n",
      "Train Epoch: 596 [1200/2589 (46%)]\tLoss: 166.633163\n",
      "Train Epoch: 596 [1500/2589 (58%)]\tLoss: 235.915802\n",
      "Train Epoch: 596 [1800/2589 (70%)]\tLoss: 420.541962\n",
      "Train Epoch: 596 [2100/2589 (81%)]\tLoss: 251.671036\n",
      "Train Epoch: 596 [2400/2589 (93%)]\tLoss: 257.146606\n",
      "====> Epoch: 596 Average train loss: 235.3619\n",
      "====> Epoch: 596 Average test loss: 923.2069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 597 [0/2589 (0%)]\tLoss: 210.441437\n",
      "Train Epoch: 597 [300/2589 (12%)]\tLoss: 210.427780\n",
      "Train Epoch: 597 [600/2589 (23%)]\tLoss: 223.234787\n",
      "Train Epoch: 597 [900/2589 (35%)]\tLoss: 222.696228\n",
      "Train Epoch: 597 [1200/2589 (46%)]\tLoss: 294.312164\n",
      "Train Epoch: 597 [1500/2589 (58%)]\tLoss: 353.735138\n",
      "Train Epoch: 597 [1800/2589 (70%)]\tLoss: 159.061218\n",
      "Train Epoch: 597 [2100/2589 (81%)]\tLoss: 262.239288\n",
      "Train Epoch: 597 [2400/2589 (93%)]\tLoss: 223.825790\n",
      "====> Epoch: 597 Average train loss: 230.9718\n",
      "====> Epoch: 597 Average test loss: 927.0799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 598 [0/2589 (0%)]\tLoss: 187.720001\n",
      "Train Epoch: 598 [300/2589 (12%)]\tLoss: 214.537323\n",
      "Train Epoch: 598 [600/2589 (23%)]\tLoss: 177.509079\n",
      "Train Epoch: 598 [900/2589 (35%)]\tLoss: 206.576630\n",
      "Train Epoch: 598 [1200/2589 (46%)]\tLoss: 184.223465\n",
      "Train Epoch: 598 [1500/2589 (58%)]\tLoss: 273.244507\n",
      "Train Epoch: 598 [1800/2589 (70%)]\tLoss: 193.657578\n",
      "Train Epoch: 598 [2100/2589 (81%)]\tLoss: 245.121521\n",
      "Train Epoch: 598 [2400/2589 (93%)]\tLoss: 416.853027\n",
      "====> Epoch: 598 Average train loss: 235.8881\n",
      "====> Epoch: 598 Average test loss: 926.8281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 599 [0/2589 (0%)]\tLoss: 265.526062\n",
      "Train Epoch: 599 [300/2589 (12%)]\tLoss: 303.814056\n",
      "Train Epoch: 599 [600/2589 (23%)]\tLoss: 249.944199\n",
      "Train Epoch: 599 [900/2589 (35%)]\tLoss: 197.752121\n",
      "Train Epoch: 599 [1200/2589 (46%)]\tLoss: 202.665802\n",
      "Train Epoch: 599 [1500/2589 (58%)]\tLoss: 175.804199\n",
      "Train Epoch: 599 [1800/2589 (70%)]\tLoss: 201.296677\n",
      "Train Epoch: 599 [2100/2589 (81%)]\tLoss: 257.694794\n",
      "Train Epoch: 599 [2400/2589 (93%)]\tLoss: 168.985382\n",
      "====> Epoch: 599 Average train loss: 229.1633\n",
      "====> Epoch: 599 Average test loss: 927.0479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 600 [0/2589 (0%)]\tLoss: 198.813019\n",
      "Train Epoch: 600 [300/2589 (12%)]\tLoss: 277.746582\n",
      "Train Epoch: 600 [600/2589 (23%)]\tLoss: 192.969894\n",
      "Train Epoch: 600 [900/2589 (35%)]\tLoss: 314.253387\n",
      "Train Epoch: 600 [1200/2589 (46%)]\tLoss: 176.204163\n",
      "Train Epoch: 600 [1500/2589 (58%)]\tLoss: 211.558487\n",
      "Train Epoch: 600 [1800/2589 (70%)]\tLoss: 174.833435\n",
      "Train Epoch: 600 [2100/2589 (81%)]\tLoss: 249.511322\n",
      "Train Epoch: 600 [2400/2589 (93%)]\tLoss: 195.580719\n",
      "====> Epoch: 600 Average train loss: 240.7432\n",
      "====> Epoch: 600 Average test loss: 913.7824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 601 [0/2589 (0%)]\tLoss: 245.096970\n",
      "Train Epoch: 601 [300/2589 (12%)]\tLoss: 626.028442\n",
      "Train Epoch: 601 [600/2589 (23%)]\tLoss: 187.535492\n",
      "Train Epoch: 601 [900/2589 (35%)]\tLoss: 226.392410\n",
      "Train Epoch: 601 [1200/2589 (46%)]\tLoss: 245.142792\n",
      "Train Epoch: 601 [1500/2589 (58%)]\tLoss: 277.553986\n",
      "Train Epoch: 601 [1800/2589 (70%)]\tLoss: 177.582428\n",
      "Train Epoch: 601 [2100/2589 (81%)]\tLoss: 189.389862\n",
      "Train Epoch: 601 [2400/2589 (93%)]\tLoss: 285.263885\n",
      "====> Epoch: 601 Average train loss: 230.5992\n",
      "====> Epoch: 601 Average test loss: 923.0145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 602 [0/2589 (0%)]\tLoss: 302.322266\n",
      "Train Epoch: 602 [300/2589 (12%)]\tLoss: 191.733856\n",
      "Train Epoch: 602 [600/2589 (23%)]\tLoss: 312.359070\n",
      "Train Epoch: 602 [900/2589 (35%)]\tLoss: 146.389252\n",
      "Train Epoch: 602 [1200/2589 (46%)]\tLoss: 150.511520\n",
      "Train Epoch: 602 [1500/2589 (58%)]\tLoss: 202.750763\n",
      "Train Epoch: 602 [1800/2589 (70%)]\tLoss: 195.767715\n",
      "Train Epoch: 602 [2100/2589 (81%)]\tLoss: 254.186462\n",
      "Train Epoch: 602 [2400/2589 (93%)]\tLoss: 202.058777\n",
      "====> Epoch: 602 Average train loss: 234.3300\n",
      "====> Epoch: 602 Average test loss: 933.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 603 [0/2589 (0%)]\tLoss: 233.333633\n",
      "Train Epoch: 603 [300/2589 (12%)]\tLoss: 162.783279\n",
      "Train Epoch: 603 [600/2589 (23%)]\tLoss: 220.812927\n",
      "Train Epoch: 603 [900/2589 (35%)]\tLoss: 187.980301\n",
      "Train Epoch: 603 [1200/2589 (46%)]\tLoss: 164.964172\n",
      "Train Epoch: 603 [1500/2589 (58%)]\tLoss: 219.020355\n",
      "Train Epoch: 603 [1800/2589 (70%)]\tLoss: 279.689362\n",
      "Train Epoch: 603 [2100/2589 (81%)]\tLoss: 208.007660\n",
      "Train Epoch: 603 [2400/2589 (93%)]\tLoss: 195.337784\n",
      "====> Epoch: 603 Average train loss: 230.6464\n",
      "====> Epoch: 603 Average test loss: 940.3978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 604 [0/2589 (0%)]\tLoss: 294.027740\n",
      "Train Epoch: 604 [300/2589 (12%)]\tLoss: 201.451767\n",
      "Train Epoch: 604 [600/2589 (23%)]\tLoss: 177.958633\n",
      "Train Epoch: 604 [900/2589 (35%)]\tLoss: 258.271851\n",
      "Train Epoch: 604 [1200/2589 (46%)]\tLoss: 194.744797\n",
      "Train Epoch: 604 [1500/2589 (58%)]\tLoss: 171.138153\n",
      "Train Epoch: 604 [1800/2589 (70%)]\tLoss: 187.781479\n",
      "Train Epoch: 604 [2100/2589 (81%)]\tLoss: 196.062302\n",
      "Train Epoch: 604 [2400/2589 (93%)]\tLoss: 286.624725\n",
      "====> Epoch: 604 Average train loss: 242.2828\n",
      "====> Epoch: 604 Average test loss: 922.5609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 605 [0/2589 (0%)]\tLoss: 204.209091\n",
      "Train Epoch: 605 [300/2589 (12%)]\tLoss: 246.097351\n",
      "Train Epoch: 605 [600/2589 (23%)]\tLoss: 191.671173\n",
      "Train Epoch: 605 [900/2589 (35%)]\tLoss: 207.512375\n",
      "Train Epoch: 605 [1200/2589 (46%)]\tLoss: 198.721420\n",
      "Train Epoch: 605 [1500/2589 (58%)]\tLoss: 195.096786\n",
      "Train Epoch: 605 [1800/2589 (70%)]\tLoss: 211.098236\n",
      "Train Epoch: 605 [2100/2589 (81%)]\tLoss: 195.844482\n",
      "Train Epoch: 605 [2400/2589 (93%)]\tLoss: 313.640747\n",
      "====> Epoch: 605 Average train loss: 240.8461\n",
      "====> Epoch: 605 Average test loss: 919.2299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 606 [0/2589 (0%)]\tLoss: 229.421783\n",
      "Train Epoch: 606 [300/2589 (12%)]\tLoss: 275.209503\n",
      "Train Epoch: 606 [600/2589 (23%)]\tLoss: 188.188416\n",
      "Train Epoch: 606 [900/2589 (35%)]\tLoss: 219.184296\n",
      "Train Epoch: 606 [1200/2589 (46%)]\tLoss: 187.903305\n",
      "Train Epoch: 606 [1500/2589 (58%)]\tLoss: 196.674896\n",
      "Train Epoch: 606 [1800/2589 (70%)]\tLoss: 379.226044\n",
      "Train Epoch: 606 [2100/2589 (81%)]\tLoss: 257.735046\n",
      "Train Epoch: 606 [2400/2589 (93%)]\tLoss: 241.398865\n",
      "====> Epoch: 606 Average train loss: 224.7763\n",
      "====> Epoch: 606 Average test loss: 934.6016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 607 [0/2589 (0%)]\tLoss: 225.803925\n",
      "Train Epoch: 607 [300/2589 (12%)]\tLoss: 333.772919\n",
      "Train Epoch: 607 [600/2589 (23%)]\tLoss: 235.901810\n",
      "Train Epoch: 607 [900/2589 (35%)]\tLoss: 374.770874\n",
      "Train Epoch: 607 [1200/2589 (46%)]\tLoss: 142.210846\n",
      "Train Epoch: 607 [1500/2589 (58%)]\tLoss: 235.759476\n",
      "Train Epoch: 607 [1800/2589 (70%)]\tLoss: 168.188995\n",
      "Train Epoch: 607 [2100/2589 (81%)]\tLoss: 165.529266\n",
      "Train Epoch: 607 [2400/2589 (93%)]\tLoss: 204.727570\n",
      "====> Epoch: 607 Average train loss: 242.0032\n",
      "====> Epoch: 607 Average test loss: 938.0877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 608 [0/2589 (0%)]\tLoss: 232.484894\n",
      "Train Epoch: 608 [300/2589 (12%)]\tLoss: 252.831024\n",
      "Train Epoch: 608 [600/2589 (23%)]\tLoss: 183.844147\n",
      "Train Epoch: 608 [900/2589 (35%)]\tLoss: 284.271515\n",
      "Train Epoch: 608 [1200/2589 (46%)]\tLoss: 225.776840\n",
      "Train Epoch: 608 [1500/2589 (58%)]\tLoss: 191.061981\n",
      "Train Epoch: 608 [1800/2589 (70%)]\tLoss: 197.225937\n",
      "Train Epoch: 608 [2100/2589 (81%)]\tLoss: 219.137253\n",
      "Train Epoch: 608 [2400/2589 (93%)]\tLoss: 204.225098\n",
      "====> Epoch: 608 Average train loss: 242.3699\n",
      "====> Epoch: 608 Average test loss: 939.0529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 609 [0/2589 (0%)]\tLoss: 286.572906\n",
      "Train Epoch: 609 [300/2589 (12%)]\tLoss: 133.513519\n",
      "Train Epoch: 609 [600/2589 (23%)]\tLoss: 298.328003\n",
      "Train Epoch: 609 [900/2589 (35%)]\tLoss: 232.058578\n",
      "Train Epoch: 609 [1200/2589 (46%)]\tLoss: 291.228394\n",
      "Train Epoch: 609 [1500/2589 (58%)]\tLoss: 318.445129\n",
      "Train Epoch: 609 [1800/2589 (70%)]\tLoss: 253.020035\n",
      "Train Epoch: 609 [2100/2589 (81%)]\tLoss: 384.778046\n",
      "Train Epoch: 609 [2400/2589 (93%)]\tLoss: 236.792908\n",
      "====> Epoch: 609 Average train loss: 251.2114\n",
      "====> Epoch: 609 Average test loss: 918.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 610 [0/2589 (0%)]\tLoss: 233.079941\n",
      "Train Epoch: 610 [300/2589 (12%)]\tLoss: 206.118683\n",
      "Train Epoch: 610 [600/2589 (23%)]\tLoss: 203.831879\n",
      "Train Epoch: 610 [900/2589 (35%)]\tLoss: 215.628418\n",
      "Train Epoch: 610 [1200/2589 (46%)]\tLoss: 203.413803\n",
      "Train Epoch: 610 [1500/2589 (58%)]\tLoss: 200.422623\n",
      "Train Epoch: 610 [1800/2589 (70%)]\tLoss: 277.637787\n",
      "Train Epoch: 610 [2100/2589 (81%)]\tLoss: 194.775146\n",
      "Train Epoch: 610 [2400/2589 (93%)]\tLoss: 194.383942\n",
      "====> Epoch: 610 Average train loss: 240.9875\n",
      "====> Epoch: 610 Average test loss: 937.0707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 611 [0/2589 (0%)]\tLoss: 162.955338\n",
      "Train Epoch: 611 [300/2589 (12%)]\tLoss: 185.062256\n",
      "Train Epoch: 611 [600/2589 (23%)]\tLoss: 256.294617\n",
      "Train Epoch: 611 [900/2589 (35%)]\tLoss: 172.490677\n",
      "Train Epoch: 611 [1200/2589 (46%)]\tLoss: 188.439697\n",
      "Train Epoch: 611 [1500/2589 (58%)]\tLoss: 190.123825\n",
      "Train Epoch: 611 [1800/2589 (70%)]\tLoss: 312.608612\n",
      "Train Epoch: 611 [2100/2589 (81%)]\tLoss: 216.396698\n",
      "Train Epoch: 611 [2400/2589 (93%)]\tLoss: 191.252640\n",
      "====> Epoch: 611 Average train loss: 231.7695\n",
      "====> Epoch: 611 Average test loss: 909.1709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 612 [0/2589 (0%)]\tLoss: 320.478455\n",
      "Train Epoch: 612 [300/2589 (12%)]\tLoss: 265.381134\n",
      "Train Epoch: 612 [600/2589 (23%)]\tLoss: 193.381210\n",
      "Train Epoch: 612 [900/2589 (35%)]\tLoss: 249.607590\n",
      "Train Epoch: 612 [1200/2589 (46%)]\tLoss: 317.943695\n",
      "Train Epoch: 612 [1500/2589 (58%)]\tLoss: 345.981079\n",
      "Train Epoch: 612 [1800/2589 (70%)]\tLoss: 183.726288\n",
      "Train Epoch: 612 [2100/2589 (81%)]\tLoss: 417.714447\n",
      "Train Epoch: 612 [2400/2589 (93%)]\tLoss: 156.968765\n",
      "====> Epoch: 612 Average train loss: 240.0668\n",
      "====> Epoch: 612 Average test loss: 926.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 613 [0/2589 (0%)]\tLoss: 188.374222\n",
      "Train Epoch: 613 [300/2589 (12%)]\tLoss: 200.217453\n",
      "Train Epoch: 613 [600/2589 (23%)]\tLoss: 218.190979\n",
      "Train Epoch: 613 [900/2589 (35%)]\tLoss: 203.005280\n",
      "Train Epoch: 613 [1200/2589 (46%)]\tLoss: 277.603180\n",
      "Train Epoch: 613 [1500/2589 (58%)]\tLoss: 304.888702\n",
      "Train Epoch: 613 [1800/2589 (70%)]\tLoss: 194.220856\n",
      "Train Epoch: 613 [2100/2589 (81%)]\tLoss: 184.196518\n",
      "Train Epoch: 613 [2400/2589 (93%)]\tLoss: 317.656647\n",
      "====> Epoch: 613 Average train loss: 238.7027\n",
      "====> Epoch: 613 Average test loss: 926.0804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 614 [0/2589 (0%)]\tLoss: 229.921356\n",
      "Train Epoch: 614 [300/2589 (12%)]\tLoss: 368.644531\n",
      "Train Epoch: 614 [600/2589 (23%)]\tLoss: 221.775558\n",
      "Train Epoch: 614 [900/2589 (35%)]\tLoss: 233.590775\n",
      "Train Epoch: 614 [1200/2589 (46%)]\tLoss: 224.977676\n",
      "Train Epoch: 614 [1500/2589 (58%)]\tLoss: 236.046631\n",
      "Train Epoch: 614 [1800/2589 (70%)]\tLoss: 253.097580\n",
      "Train Epoch: 614 [2100/2589 (81%)]\tLoss: 203.941162\n",
      "Train Epoch: 614 [2400/2589 (93%)]\tLoss: 226.172668\n",
      "====> Epoch: 614 Average train loss: 244.4123\n",
      "====> Epoch: 614 Average test loss: 937.4459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 615 [0/2589 (0%)]\tLoss: 184.117264\n",
      "Train Epoch: 615 [300/2589 (12%)]\tLoss: 355.842163\n",
      "Train Epoch: 615 [600/2589 (23%)]\tLoss: 212.161530\n",
      "Train Epoch: 615 [900/2589 (35%)]\tLoss: 215.212296\n",
      "Train Epoch: 615 [1200/2589 (46%)]\tLoss: 134.553131\n",
      "Train Epoch: 615 [1500/2589 (58%)]\tLoss: 241.229950\n",
      "Train Epoch: 615 [1800/2589 (70%)]\tLoss: 174.606094\n",
      "Train Epoch: 615 [2100/2589 (81%)]\tLoss: 172.495407\n",
      "Train Epoch: 615 [2400/2589 (93%)]\tLoss: 182.812317\n",
      "====> Epoch: 615 Average train loss: 239.0265\n",
      "====> Epoch: 615 Average test loss: 923.0535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 616 [0/2589 (0%)]\tLoss: 269.822388\n",
      "Train Epoch: 616 [300/2589 (12%)]\tLoss: 281.005402\n",
      "Train Epoch: 616 [600/2589 (23%)]\tLoss: 179.478592\n",
      "Train Epoch: 616 [900/2589 (35%)]\tLoss: 371.496277\n",
      "Train Epoch: 616 [1200/2589 (46%)]\tLoss: 175.281296\n",
      "Train Epoch: 616 [1500/2589 (58%)]\tLoss: 210.759323\n",
      "Train Epoch: 616 [1800/2589 (70%)]\tLoss: 144.098053\n",
      "Train Epoch: 616 [2100/2589 (81%)]\tLoss: 289.089325\n",
      "Train Epoch: 616 [2400/2589 (93%)]\tLoss: 299.709564\n",
      "====> Epoch: 616 Average train loss: 237.3321\n",
      "====> Epoch: 616 Average test loss: 941.6080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 617 [0/2589 (0%)]\tLoss: 200.924530\n",
      "Train Epoch: 617 [300/2589 (12%)]\tLoss: 263.311676\n",
      "Train Epoch: 617 [600/2589 (23%)]\tLoss: 270.089081\n",
      "Train Epoch: 617 [900/2589 (35%)]\tLoss: 203.711914\n",
      "Train Epoch: 617 [1200/2589 (46%)]\tLoss: 295.459503\n",
      "Train Epoch: 617 [1500/2589 (58%)]\tLoss: 156.738586\n",
      "Train Epoch: 617 [1800/2589 (70%)]\tLoss: 184.467987\n",
      "Train Epoch: 617 [2100/2589 (81%)]\tLoss: 212.122238\n",
      "Train Epoch: 617 [2400/2589 (93%)]\tLoss: 288.172028\n",
      "====> Epoch: 617 Average train loss: 236.4250\n",
      "====> Epoch: 617 Average test loss: 922.3795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 618 [0/2589 (0%)]\tLoss: 263.607880\n",
      "Train Epoch: 618 [300/2589 (12%)]\tLoss: 239.478073\n",
      "Train Epoch: 618 [600/2589 (23%)]\tLoss: 325.792297\n",
      "Train Epoch: 618 [900/2589 (35%)]\tLoss: 194.768250\n",
      "Train Epoch: 618 [1200/2589 (46%)]\tLoss: 206.006790\n",
      "Train Epoch: 618 [1500/2589 (58%)]\tLoss: 247.575989\n",
      "Train Epoch: 618 [1800/2589 (70%)]\tLoss: 186.327087\n",
      "Train Epoch: 618 [2100/2589 (81%)]\tLoss: 270.564178\n",
      "Train Epoch: 618 [2400/2589 (93%)]\tLoss: 268.252350\n",
      "====> Epoch: 618 Average train loss: 235.9618\n",
      "====> Epoch: 618 Average test loss: 918.8068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 619 [0/2589 (0%)]\tLoss: 198.547333\n",
      "Train Epoch: 619 [300/2589 (12%)]\tLoss: 327.100861\n",
      "Train Epoch: 619 [600/2589 (23%)]\tLoss: 242.784760\n",
      "Train Epoch: 619 [900/2589 (35%)]\tLoss: 328.248016\n",
      "Train Epoch: 619 [1200/2589 (46%)]\tLoss: 134.518250\n",
      "Train Epoch: 619 [1500/2589 (58%)]\tLoss: 324.604034\n",
      "Train Epoch: 619 [1800/2589 (70%)]\tLoss: 411.619141\n",
      "Train Epoch: 619 [2100/2589 (81%)]\tLoss: 201.518661\n",
      "Train Epoch: 619 [2400/2589 (93%)]\tLoss: 186.148056\n",
      "====> Epoch: 619 Average train loss: 230.0205\n",
      "====> Epoch: 619 Average test loss: 929.7872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 620 [0/2589 (0%)]\tLoss: 290.735931\n",
      "Train Epoch: 620 [300/2589 (12%)]\tLoss: 266.267365\n",
      "Train Epoch: 620 [600/2589 (23%)]\tLoss: 262.757812\n",
      "Train Epoch: 620 [900/2589 (35%)]\tLoss: 176.780518\n",
      "Train Epoch: 620 [1200/2589 (46%)]\tLoss: 170.466736\n",
      "Train Epoch: 620 [1500/2589 (58%)]\tLoss: 196.657974\n",
      "Train Epoch: 620 [1800/2589 (70%)]\tLoss: 193.153763\n",
      "Train Epoch: 620 [2100/2589 (81%)]\tLoss: 243.351913\n",
      "Train Epoch: 620 [2400/2589 (93%)]\tLoss: 170.593033\n",
      "====> Epoch: 620 Average train loss: 225.6427\n",
      "====> Epoch: 620 Average test loss: 934.5082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 621 [0/2589 (0%)]\tLoss: 184.589188\n",
      "Train Epoch: 621 [300/2589 (12%)]\tLoss: 268.080414\n",
      "Train Epoch: 621 [600/2589 (23%)]\tLoss: 190.402435\n",
      "Train Epoch: 621 [900/2589 (35%)]\tLoss: 205.447037\n",
      "Train Epoch: 621 [1200/2589 (46%)]\tLoss: 208.992447\n",
      "Train Epoch: 621 [1500/2589 (58%)]\tLoss: 218.626663\n",
      "Train Epoch: 621 [1800/2589 (70%)]\tLoss: 223.084625\n",
      "Train Epoch: 621 [2100/2589 (81%)]\tLoss: 264.410767\n",
      "Train Epoch: 621 [2400/2589 (93%)]\tLoss: 266.046661\n",
      "====> Epoch: 621 Average train loss: 241.8837\n",
      "====> Epoch: 621 Average test loss: 917.2831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 622 [0/2589 (0%)]\tLoss: 325.144104\n",
      "Train Epoch: 622 [300/2589 (12%)]\tLoss: 215.248825\n",
      "Train Epoch: 622 [600/2589 (23%)]\tLoss: 216.084305\n",
      "Train Epoch: 622 [900/2589 (35%)]\tLoss: 177.918396\n",
      "Train Epoch: 622 [1200/2589 (46%)]\tLoss: 225.703400\n",
      "Train Epoch: 622 [1500/2589 (58%)]\tLoss: 156.759903\n",
      "Train Epoch: 622 [1800/2589 (70%)]\tLoss: 177.586578\n",
      "Train Epoch: 622 [2100/2589 (81%)]\tLoss: 295.525970\n",
      "Train Epoch: 622 [2400/2589 (93%)]\tLoss: 198.415695\n",
      "====> Epoch: 622 Average train loss: 234.5181\n",
      "====> Epoch: 622 Average test loss: 916.5603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 623 [0/2589 (0%)]\tLoss: 329.267700\n",
      "Train Epoch: 623 [300/2589 (12%)]\tLoss: 320.921417\n",
      "Train Epoch: 623 [600/2589 (23%)]\tLoss: 185.134140\n",
      "Train Epoch: 623 [900/2589 (35%)]\tLoss: 172.117386\n",
      "Train Epoch: 623 [1200/2589 (46%)]\tLoss: 232.888504\n",
      "Train Epoch: 623 [1500/2589 (58%)]\tLoss: 184.837494\n",
      "Train Epoch: 623 [1800/2589 (70%)]\tLoss: 207.228226\n",
      "Train Epoch: 623 [2100/2589 (81%)]\tLoss: 283.726135\n",
      "Train Epoch: 623 [2400/2589 (93%)]\tLoss: 189.821762\n",
      "====> Epoch: 623 Average train loss: 228.6425\n",
      "====> Epoch: 623 Average test loss: 919.1269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 624 [0/2589 (0%)]\tLoss: 119.801956\n",
      "Train Epoch: 624 [300/2589 (12%)]\tLoss: 221.311050\n",
      "Train Epoch: 624 [600/2589 (23%)]\tLoss: 255.266068\n",
      "Train Epoch: 624 [900/2589 (35%)]\tLoss: 257.622162\n",
      "Train Epoch: 624 [1200/2589 (46%)]\tLoss: 192.113937\n",
      "Train Epoch: 624 [1500/2589 (58%)]\tLoss: 265.163818\n",
      "Train Epoch: 624 [1800/2589 (70%)]\tLoss: 188.213287\n",
      "Train Epoch: 624 [2100/2589 (81%)]\tLoss: 269.248444\n",
      "Train Epoch: 624 [2400/2589 (93%)]\tLoss: 167.842010\n",
      "====> Epoch: 624 Average train loss: 231.3240\n",
      "====> Epoch: 624 Average test loss: 914.2858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 625 [0/2589 (0%)]\tLoss: 196.408920\n",
      "Train Epoch: 625 [300/2589 (12%)]\tLoss: 416.520172\n",
      "Train Epoch: 625 [600/2589 (23%)]\tLoss: 188.576141\n",
      "Train Epoch: 625 [900/2589 (35%)]\tLoss: 203.742401\n",
      "Train Epoch: 625 [1200/2589 (46%)]\tLoss: 242.313416\n",
      "Train Epoch: 625 [1500/2589 (58%)]\tLoss: 273.006683\n",
      "Train Epoch: 625 [1800/2589 (70%)]\tLoss: 258.380768\n",
      "Train Epoch: 625 [2100/2589 (81%)]\tLoss: 270.862152\n",
      "Train Epoch: 625 [2400/2589 (93%)]\tLoss: 155.687347\n",
      "====> Epoch: 625 Average train loss: 236.5581\n",
      "====> Epoch: 625 Average test loss: 927.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 626 [0/2589 (0%)]\tLoss: 342.108337\n",
      "Train Epoch: 626 [300/2589 (12%)]\tLoss: 398.541290\n",
      "Train Epoch: 626 [600/2589 (23%)]\tLoss: 210.781830\n",
      "Train Epoch: 626 [900/2589 (35%)]\tLoss: 288.579468\n",
      "Train Epoch: 626 [1200/2589 (46%)]\tLoss: 190.471268\n",
      "Train Epoch: 626 [1500/2589 (58%)]\tLoss: 161.886169\n",
      "Train Epoch: 626 [1800/2589 (70%)]\tLoss: 169.764938\n",
      "Train Epoch: 626 [2100/2589 (81%)]\tLoss: 195.032883\n",
      "Train Epoch: 626 [2400/2589 (93%)]\tLoss: 177.098602\n",
      "====> Epoch: 626 Average train loss: 237.4917\n",
      "====> Epoch: 626 Average test loss: 928.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 627 [0/2589 (0%)]\tLoss: 194.002411\n",
      "Train Epoch: 627 [300/2589 (12%)]\tLoss: 251.921906\n",
      "Train Epoch: 627 [600/2589 (23%)]\tLoss: 182.429108\n",
      "Train Epoch: 627 [900/2589 (35%)]\tLoss: 229.956894\n",
      "Train Epoch: 627 [1200/2589 (46%)]\tLoss: 290.268433\n",
      "Train Epoch: 627 [1500/2589 (58%)]\tLoss: 316.051208\n",
      "Train Epoch: 627 [1800/2589 (70%)]\tLoss: 175.660004\n",
      "Train Epoch: 627 [2100/2589 (81%)]\tLoss: 144.193985\n",
      "Train Epoch: 627 [2400/2589 (93%)]\tLoss: 185.850632\n",
      "====> Epoch: 627 Average train loss: 228.8573\n",
      "====> Epoch: 627 Average test loss: 919.5530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 628 [0/2589 (0%)]\tLoss: 160.720322\n",
      "Train Epoch: 628 [300/2589 (12%)]\tLoss: 186.974701\n",
      "Train Epoch: 628 [600/2589 (23%)]\tLoss: 358.160492\n",
      "Train Epoch: 628 [900/2589 (35%)]\tLoss: 250.330383\n",
      "Train Epoch: 628 [1200/2589 (46%)]\tLoss: 220.083282\n",
      "Train Epoch: 628 [1500/2589 (58%)]\tLoss: 392.714142\n",
      "Train Epoch: 628 [1800/2589 (70%)]\tLoss: 230.129913\n",
      "Train Epoch: 628 [2100/2589 (81%)]\tLoss: 220.271942\n",
      "Train Epoch: 628 [2400/2589 (93%)]\tLoss: 330.412659\n",
      "====> Epoch: 628 Average train loss: 238.5007\n",
      "====> Epoch: 628 Average test loss: 925.6245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 629 [0/2589 (0%)]\tLoss: 170.770584\n",
      "Train Epoch: 629 [300/2589 (12%)]\tLoss: 264.475067\n",
      "Train Epoch: 629 [600/2589 (23%)]\tLoss: 194.487595\n",
      "Train Epoch: 629 [900/2589 (35%)]\tLoss: 231.153046\n",
      "Train Epoch: 629 [1200/2589 (46%)]\tLoss: 257.818817\n",
      "Train Epoch: 629 [1500/2589 (58%)]\tLoss: 157.720673\n",
      "Train Epoch: 629 [1800/2589 (70%)]\tLoss: 147.270859\n",
      "Train Epoch: 629 [2100/2589 (81%)]\tLoss: 215.214325\n",
      "Train Epoch: 629 [2400/2589 (93%)]\tLoss: 204.320526\n",
      "====> Epoch: 629 Average train loss: 223.1703\n",
      "====> Epoch: 629 Average test loss: 935.2125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 630 [0/2589 (0%)]\tLoss: 146.108215\n",
      "Train Epoch: 630 [300/2589 (12%)]\tLoss: 165.573990\n",
      "Train Epoch: 630 [600/2589 (23%)]\tLoss: 141.920624\n",
      "Train Epoch: 630 [900/2589 (35%)]\tLoss: 196.465317\n",
      "Train Epoch: 630 [1200/2589 (46%)]\tLoss: 259.138580\n",
      "Train Epoch: 630 [1500/2589 (58%)]\tLoss: 239.357391\n",
      "Train Epoch: 630 [1800/2589 (70%)]\tLoss: 214.551697\n",
      "Train Epoch: 630 [2100/2589 (81%)]\tLoss: 286.392944\n",
      "Train Epoch: 630 [2400/2589 (93%)]\tLoss: 320.038666\n",
      "====> Epoch: 630 Average train loss: 238.7441\n",
      "====> Epoch: 630 Average test loss: 928.4946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 631 [0/2589 (0%)]\tLoss: 241.741409\n",
      "Train Epoch: 631 [300/2589 (12%)]\tLoss: 204.740540\n",
      "Train Epoch: 631 [600/2589 (23%)]\tLoss: 160.040634\n",
      "Train Epoch: 631 [900/2589 (35%)]\tLoss: 277.892365\n",
      "Train Epoch: 631 [1200/2589 (46%)]\tLoss: 151.402267\n",
      "Train Epoch: 631 [1500/2589 (58%)]\tLoss: 321.513031\n",
      "Train Epoch: 631 [1800/2589 (70%)]\tLoss: 403.416290\n",
      "Train Epoch: 631 [2100/2589 (81%)]\tLoss: 257.801422\n",
      "Train Epoch: 631 [2400/2589 (93%)]\tLoss: 104.609657\n",
      "====> Epoch: 631 Average train loss: 247.7958\n",
      "====> Epoch: 631 Average test loss: 932.4271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 632 [0/2589 (0%)]\tLoss: 224.220963\n",
      "Train Epoch: 632 [300/2589 (12%)]\tLoss: 209.931671\n",
      "Train Epoch: 632 [600/2589 (23%)]\tLoss: 244.266953\n",
      "Train Epoch: 632 [900/2589 (35%)]\tLoss: 148.767548\n",
      "Train Epoch: 632 [1200/2589 (46%)]\tLoss: 164.150681\n",
      "Train Epoch: 632 [1500/2589 (58%)]\tLoss: 283.920807\n",
      "Train Epoch: 632 [1800/2589 (70%)]\tLoss: 337.688416\n",
      "Train Epoch: 632 [2100/2589 (81%)]\tLoss: 509.703766\n",
      "Train Epoch: 632 [2400/2589 (93%)]\tLoss: 221.790100\n",
      "====> Epoch: 632 Average train loss: 245.3412\n",
      "====> Epoch: 632 Average test loss: 914.5854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 633 [0/2589 (0%)]\tLoss: 176.177658\n",
      "Train Epoch: 633 [300/2589 (12%)]\tLoss: 138.673401\n",
      "Train Epoch: 633 [600/2589 (23%)]\tLoss: 199.018097\n",
      "Train Epoch: 633 [900/2589 (35%)]\tLoss: 186.880814\n",
      "Train Epoch: 633 [1200/2589 (46%)]\tLoss: 180.699600\n",
      "Train Epoch: 633 [1500/2589 (58%)]\tLoss: 237.758728\n",
      "Train Epoch: 633 [1800/2589 (70%)]\tLoss: 184.775146\n",
      "Train Epoch: 633 [2100/2589 (81%)]\tLoss: 238.227798\n",
      "Train Epoch: 633 [2400/2589 (93%)]\tLoss: 313.065643\n",
      "====> Epoch: 633 Average train loss: 225.7942\n",
      "====> Epoch: 633 Average test loss: 929.7153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 634 [0/2589 (0%)]\tLoss: 170.903488\n",
      "Train Epoch: 634 [300/2589 (12%)]\tLoss: 192.965088\n",
      "Train Epoch: 634 [600/2589 (23%)]\tLoss: 120.516312\n",
      "Train Epoch: 634 [900/2589 (35%)]\tLoss: 139.352463\n",
      "Train Epoch: 634 [1200/2589 (46%)]\tLoss: 280.696838\n",
      "Train Epoch: 634 [1500/2589 (58%)]\tLoss: 224.353455\n",
      "Train Epoch: 634 [1800/2589 (70%)]\tLoss: 271.959015\n",
      "Train Epoch: 634 [2100/2589 (81%)]\tLoss: 373.150299\n",
      "Train Epoch: 634 [2400/2589 (93%)]\tLoss: 301.986206\n",
      "====> Epoch: 634 Average train loss: 240.5994\n",
      "====> Epoch: 634 Average test loss: 924.1290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 635 [0/2589 (0%)]\tLoss: 217.272797\n",
      "Train Epoch: 635 [300/2589 (12%)]\tLoss: 222.300919\n",
      "Train Epoch: 635 [600/2589 (23%)]\tLoss: 194.588959\n",
      "Train Epoch: 635 [900/2589 (35%)]\tLoss: 212.210587\n",
      "Train Epoch: 635 [1200/2589 (46%)]\tLoss: 192.925110\n",
      "Train Epoch: 635 [1500/2589 (58%)]\tLoss: 297.611389\n",
      "Train Epoch: 635 [1800/2589 (70%)]\tLoss: 195.324249\n",
      "Train Epoch: 635 [2100/2589 (81%)]\tLoss: 192.909088\n",
      "Train Epoch: 635 [2400/2589 (93%)]\tLoss: 165.963562\n",
      "====> Epoch: 635 Average train loss: 238.1458\n",
      "====> Epoch: 635 Average test loss: 928.4870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 636 [0/2589 (0%)]\tLoss: 171.765976\n",
      "Train Epoch: 636 [300/2589 (12%)]\tLoss: 224.712830\n",
      "Train Epoch: 636 [600/2589 (23%)]\tLoss: 249.623474\n",
      "Train Epoch: 636 [900/2589 (35%)]\tLoss: 156.850098\n",
      "Train Epoch: 636 [1200/2589 (46%)]\tLoss: 182.745132\n",
      "Train Epoch: 636 [1500/2589 (58%)]\tLoss: 226.225693\n",
      "Train Epoch: 636 [1800/2589 (70%)]\tLoss: 161.264023\n",
      "Train Epoch: 636 [2100/2589 (81%)]\tLoss: 198.267319\n",
      "Train Epoch: 636 [2400/2589 (93%)]\tLoss: 209.502670\n",
      "====> Epoch: 636 Average train loss: 243.5566\n",
      "====> Epoch: 636 Average test loss: 932.8662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 637 [0/2589 (0%)]\tLoss: 221.023956\n",
      "Train Epoch: 637 [300/2589 (12%)]\tLoss: 278.388367\n",
      "Train Epoch: 637 [600/2589 (23%)]\tLoss: 304.570435\n",
      "Train Epoch: 637 [900/2589 (35%)]\tLoss: 160.643387\n",
      "Train Epoch: 637 [1200/2589 (46%)]\tLoss: 207.236877\n",
      "Train Epoch: 637 [1500/2589 (58%)]\tLoss: 283.076447\n",
      "Train Epoch: 637 [1800/2589 (70%)]\tLoss: 324.203064\n",
      "Train Epoch: 637 [2100/2589 (81%)]\tLoss: 262.016907\n",
      "Train Epoch: 637 [2400/2589 (93%)]\tLoss: 210.906723\n",
      "====> Epoch: 637 Average train loss: 233.4448\n",
      "====> Epoch: 637 Average test loss: 940.1219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 638 [0/2589 (0%)]\tLoss: 229.341293\n",
      "Train Epoch: 638 [300/2589 (12%)]\tLoss: 194.126312\n",
      "Train Epoch: 638 [600/2589 (23%)]\tLoss: 154.302155\n",
      "Train Epoch: 638 [900/2589 (35%)]\tLoss: 165.907257\n",
      "Train Epoch: 638 [1200/2589 (46%)]\tLoss: 408.586639\n",
      "Train Epoch: 638 [1500/2589 (58%)]\tLoss: 217.287537\n",
      "Train Epoch: 638 [1800/2589 (70%)]\tLoss: 251.292892\n",
      "Train Epoch: 638 [2100/2589 (81%)]\tLoss: 315.019440\n",
      "Train Epoch: 638 [2400/2589 (93%)]\tLoss: 203.588379\n",
      "====> Epoch: 638 Average train loss: 238.5691\n",
      "====> Epoch: 638 Average test loss: 926.8932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 639 [0/2589 (0%)]\tLoss: 266.836853\n",
      "Train Epoch: 639 [300/2589 (12%)]\tLoss: 187.258163\n",
      "Train Epoch: 639 [600/2589 (23%)]\tLoss: 179.001953\n",
      "Train Epoch: 639 [900/2589 (35%)]\tLoss: 200.652283\n",
      "Train Epoch: 639 [1200/2589 (46%)]\tLoss: 177.200180\n",
      "Train Epoch: 639 [1500/2589 (58%)]\tLoss: 234.575378\n",
      "Train Epoch: 639 [1800/2589 (70%)]\tLoss: 195.973785\n",
      "Train Epoch: 639 [2100/2589 (81%)]\tLoss: 257.448761\n",
      "Train Epoch: 639 [2400/2589 (93%)]\tLoss: 202.914993\n",
      "====> Epoch: 639 Average train loss: 227.7951\n",
      "====> Epoch: 639 Average test loss: 947.4689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 640 [0/2589 (0%)]\tLoss: 232.740753\n",
      "Train Epoch: 640 [300/2589 (12%)]\tLoss: 213.076141\n",
      "Train Epoch: 640 [600/2589 (23%)]\tLoss: 294.090057\n",
      "Train Epoch: 640 [900/2589 (35%)]\tLoss: 289.337830\n",
      "Train Epoch: 640 [1200/2589 (46%)]\tLoss: 276.490234\n",
      "Train Epoch: 640 [1500/2589 (58%)]\tLoss: 232.388962\n",
      "Train Epoch: 640 [1800/2589 (70%)]\tLoss: 220.186539\n",
      "Train Epoch: 640 [2100/2589 (81%)]\tLoss: 258.605499\n",
      "Train Epoch: 640 [2400/2589 (93%)]\tLoss: 186.000992\n",
      "====> Epoch: 640 Average train loss: 252.3917\n",
      "====> Epoch: 640 Average test loss: 937.7726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 641 [0/2589 (0%)]\tLoss: 225.599472\n",
      "Train Epoch: 641 [300/2589 (12%)]\tLoss: 275.127228\n",
      "Train Epoch: 641 [600/2589 (23%)]\tLoss: 371.329926\n",
      "Train Epoch: 641 [900/2589 (35%)]\tLoss: 170.151718\n",
      "Train Epoch: 641 [1200/2589 (46%)]\tLoss: 254.464615\n",
      "Train Epoch: 641 [1500/2589 (58%)]\tLoss: 212.205963\n",
      "Train Epoch: 641 [1800/2589 (70%)]\tLoss: 199.226028\n",
      "Train Epoch: 641 [2100/2589 (81%)]\tLoss: 189.383575\n",
      "Train Epoch: 641 [2400/2589 (93%)]\tLoss: 258.872437\n",
      "====> Epoch: 641 Average train loss: 230.5426\n",
      "====> Epoch: 641 Average test loss: 930.3733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 642 [0/2589 (0%)]\tLoss: 270.627045\n",
      "Train Epoch: 642 [300/2589 (12%)]\tLoss: 236.475037\n",
      "Train Epoch: 642 [600/2589 (23%)]\tLoss: 185.481873\n",
      "Train Epoch: 642 [900/2589 (35%)]\tLoss: 242.104996\n",
      "Train Epoch: 642 [1200/2589 (46%)]\tLoss: 245.178879\n",
      "Train Epoch: 642 [1500/2589 (58%)]\tLoss: 151.074051\n",
      "Train Epoch: 642 [1800/2589 (70%)]\tLoss: 139.472183\n",
      "Train Epoch: 642 [2100/2589 (81%)]\tLoss: 255.053940\n",
      "Train Epoch: 642 [2400/2589 (93%)]\tLoss: 213.280136\n",
      "====> Epoch: 642 Average train loss: 229.3974\n",
      "====> Epoch: 642 Average test loss: 925.6020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 643 [0/2589 (0%)]\tLoss: 235.119125\n",
      "Train Epoch: 643 [300/2589 (12%)]\tLoss: 286.256195\n",
      "Train Epoch: 643 [600/2589 (23%)]\tLoss: 225.622742\n",
      "Train Epoch: 643 [900/2589 (35%)]\tLoss: 356.378448\n",
      "Train Epoch: 643 [1200/2589 (46%)]\tLoss: 243.143127\n",
      "Train Epoch: 643 [1500/2589 (58%)]\tLoss: 447.092926\n",
      "Train Epoch: 643 [1800/2589 (70%)]\tLoss: 234.180817\n",
      "Train Epoch: 643 [2100/2589 (81%)]\tLoss: 195.895035\n",
      "Train Epoch: 643 [2400/2589 (93%)]\tLoss: 300.203735\n",
      "====> Epoch: 643 Average train loss: 236.1246\n",
      "====> Epoch: 643 Average test loss: 926.9486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 644 [0/2589 (0%)]\tLoss: 197.011780\n",
      "Train Epoch: 644 [300/2589 (12%)]\tLoss: 234.144073\n",
      "Train Epoch: 644 [600/2589 (23%)]\tLoss: 235.399826\n",
      "Train Epoch: 644 [900/2589 (35%)]\tLoss: 208.670822\n",
      "Train Epoch: 644 [1200/2589 (46%)]\tLoss: 192.771652\n",
      "Train Epoch: 644 [1500/2589 (58%)]\tLoss: 284.907562\n",
      "Train Epoch: 644 [1800/2589 (70%)]\tLoss: 233.885086\n",
      "Train Epoch: 644 [2100/2589 (81%)]\tLoss: 159.744217\n",
      "Train Epoch: 644 [2400/2589 (93%)]\tLoss: 208.440643\n",
      "====> Epoch: 644 Average train loss: 219.3875\n",
      "====> Epoch: 644 Average test loss: 922.9025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 645 [0/2589 (0%)]\tLoss: 224.307068\n",
      "Train Epoch: 645 [300/2589 (12%)]\tLoss: 214.674103\n",
      "Train Epoch: 645 [600/2589 (23%)]\tLoss: 274.159210\n",
      "Train Epoch: 645 [900/2589 (35%)]\tLoss: 296.627167\n",
      "Train Epoch: 645 [1200/2589 (46%)]\tLoss: 124.260468\n",
      "Train Epoch: 645 [1500/2589 (58%)]\tLoss: 216.842484\n",
      "Train Epoch: 645 [1800/2589 (70%)]\tLoss: 214.793427\n",
      "Train Epoch: 645 [2100/2589 (81%)]\tLoss: 377.477905\n",
      "Train Epoch: 645 [2400/2589 (93%)]\tLoss: 213.184311\n",
      "====> Epoch: 645 Average train loss: 243.9143\n",
      "====> Epoch: 645 Average test loss: 925.2642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 646 [0/2589 (0%)]\tLoss: 226.850769\n",
      "Train Epoch: 646 [300/2589 (12%)]\tLoss: 204.820709\n",
      "Train Epoch: 646 [600/2589 (23%)]\tLoss: 231.012024\n",
      "Train Epoch: 646 [900/2589 (35%)]\tLoss: 218.088181\n",
      "Train Epoch: 646 [1200/2589 (46%)]\tLoss: 291.598694\n",
      "Train Epoch: 646 [1500/2589 (58%)]\tLoss: 147.056580\n",
      "Train Epoch: 646 [1800/2589 (70%)]\tLoss: 177.490814\n",
      "Train Epoch: 646 [2100/2589 (81%)]\tLoss: 402.078979\n",
      "Train Epoch: 646 [2400/2589 (93%)]\tLoss: 305.246094\n",
      "====> Epoch: 646 Average train loss: 237.1094\n",
      "====> Epoch: 646 Average test loss: 920.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 647 [0/2589 (0%)]\tLoss: 241.312164\n",
      "Train Epoch: 647 [300/2589 (12%)]\tLoss: 241.455887\n",
      "Train Epoch: 647 [600/2589 (23%)]\tLoss: 224.582382\n",
      "Train Epoch: 647 [900/2589 (35%)]\tLoss: 252.844421\n",
      "Train Epoch: 647 [1200/2589 (46%)]\tLoss: 242.635635\n",
      "Train Epoch: 647 [1500/2589 (58%)]\tLoss: 322.838898\n",
      "Train Epoch: 647 [1800/2589 (70%)]\tLoss: 184.478027\n",
      "Train Epoch: 647 [2100/2589 (81%)]\tLoss: 365.820190\n",
      "Train Epoch: 647 [2400/2589 (93%)]\tLoss: 248.683624\n",
      "====> Epoch: 647 Average train loss: 244.0145\n",
      "====> Epoch: 647 Average test loss: 920.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 648 [0/2589 (0%)]\tLoss: 225.424423\n",
      "Train Epoch: 648 [300/2589 (12%)]\tLoss: 174.301895\n",
      "Train Epoch: 648 [600/2589 (23%)]\tLoss: 159.379608\n",
      "Train Epoch: 648 [900/2589 (35%)]\tLoss: 182.451706\n",
      "Train Epoch: 648 [1200/2589 (46%)]\tLoss: 212.934982\n",
      "Train Epoch: 648 [1500/2589 (58%)]\tLoss: 202.874329\n",
      "Train Epoch: 648 [1800/2589 (70%)]\tLoss: 276.491791\n",
      "Train Epoch: 648 [2100/2589 (81%)]\tLoss: 267.247620\n",
      "Train Epoch: 648 [2400/2589 (93%)]\tLoss: 248.467010\n",
      "====> Epoch: 648 Average train loss: 238.1816\n",
      "====> Epoch: 648 Average test loss: 922.3442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 649 [0/2589 (0%)]\tLoss: 151.638535\n",
      "Train Epoch: 649 [300/2589 (12%)]\tLoss: 183.280502\n",
      "Train Epoch: 649 [600/2589 (23%)]\tLoss: 371.259827\n",
      "Train Epoch: 649 [900/2589 (35%)]\tLoss: 231.702408\n",
      "Train Epoch: 649 [1200/2589 (46%)]\tLoss: 214.613190\n",
      "Train Epoch: 649 [1500/2589 (58%)]\tLoss: 234.451950\n",
      "Train Epoch: 649 [1800/2589 (70%)]\tLoss: 140.272385\n",
      "Train Epoch: 649 [2100/2589 (81%)]\tLoss: 233.113968\n",
      "Train Epoch: 649 [2400/2589 (93%)]\tLoss: 279.866547\n",
      "====> Epoch: 649 Average train loss: 230.9290\n",
      "====> Epoch: 649 Average test loss: 923.6201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 650 [0/2589 (0%)]\tLoss: 192.904388\n",
      "Train Epoch: 650 [300/2589 (12%)]\tLoss: 196.262054\n",
      "Train Epoch: 650 [600/2589 (23%)]\tLoss: 210.291122\n",
      "Train Epoch: 650 [900/2589 (35%)]\tLoss: 247.391449\n",
      "Train Epoch: 650 [1200/2589 (46%)]\tLoss: 186.971344\n",
      "Train Epoch: 650 [1500/2589 (58%)]\tLoss: 200.479355\n",
      "Train Epoch: 650 [1800/2589 (70%)]\tLoss: 165.737259\n",
      "Train Epoch: 650 [2100/2589 (81%)]\tLoss: 251.746231\n",
      "Train Epoch: 650 [2400/2589 (93%)]\tLoss: 195.134964\n",
      "====> Epoch: 650 Average train loss: 248.6265\n",
      "====> Epoch: 650 Average test loss: 921.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 651 [0/2589 (0%)]\tLoss: 204.353653\n",
      "Train Epoch: 651 [300/2589 (12%)]\tLoss: 180.942032\n",
      "Train Epoch: 651 [600/2589 (23%)]\tLoss: 264.266541\n",
      "Train Epoch: 651 [900/2589 (35%)]\tLoss: 242.833450\n",
      "Train Epoch: 651 [1200/2589 (46%)]\tLoss: 220.149384\n",
      "Train Epoch: 651 [1500/2589 (58%)]\tLoss: 213.299942\n",
      "Train Epoch: 651 [1800/2589 (70%)]\tLoss: 276.695251\n",
      "Train Epoch: 651 [2100/2589 (81%)]\tLoss: 166.009140\n",
      "Train Epoch: 651 [2400/2589 (93%)]\tLoss: 182.243149\n",
      "====> Epoch: 651 Average train loss: 244.8407\n",
      "====> Epoch: 651 Average test loss: 914.7039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 652 [0/2589 (0%)]\tLoss: 186.979172\n",
      "Train Epoch: 652 [300/2589 (12%)]\tLoss: 200.100967\n",
      "Train Epoch: 652 [600/2589 (23%)]\tLoss: 166.825546\n",
      "Train Epoch: 652 [900/2589 (35%)]\tLoss: 204.020782\n",
      "Train Epoch: 652 [1200/2589 (46%)]\tLoss: 196.605133\n",
      "Train Epoch: 652 [1500/2589 (58%)]\tLoss: 242.043793\n",
      "Train Epoch: 652 [1800/2589 (70%)]\tLoss: 158.996811\n",
      "Train Epoch: 652 [2100/2589 (81%)]\tLoss: 250.051315\n",
      "Train Epoch: 652 [2400/2589 (93%)]\tLoss: 202.947586\n",
      "====> Epoch: 652 Average train loss: 225.2161\n",
      "====> Epoch: 652 Average test loss: 918.4248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 653 [0/2589 (0%)]\tLoss: 170.847382\n",
      "Train Epoch: 653 [300/2589 (12%)]\tLoss: 244.837555\n",
      "Train Epoch: 653 [600/2589 (23%)]\tLoss: 297.379059\n",
      "Train Epoch: 653 [900/2589 (35%)]\tLoss: 253.796219\n",
      "Train Epoch: 653 [1200/2589 (46%)]\tLoss: 270.139282\n",
      "Train Epoch: 653 [1500/2589 (58%)]\tLoss: 273.387390\n",
      "Train Epoch: 653 [1800/2589 (70%)]\tLoss: 234.704071\n",
      "Train Epoch: 653 [2100/2589 (81%)]\tLoss: 169.938248\n",
      "Train Epoch: 653 [2400/2589 (93%)]\tLoss: 336.535706\n",
      "====> Epoch: 653 Average train loss: 245.5017\n",
      "====> Epoch: 653 Average test loss: 917.6498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 654 [0/2589 (0%)]\tLoss: 189.313049\n",
      "Train Epoch: 654 [300/2589 (12%)]\tLoss: 178.393661\n",
      "Train Epoch: 654 [600/2589 (23%)]\tLoss: 397.540314\n",
      "Train Epoch: 654 [900/2589 (35%)]\tLoss: 174.863739\n",
      "Train Epoch: 654 [1200/2589 (46%)]\tLoss: 172.078506\n",
      "Train Epoch: 654 [1500/2589 (58%)]\tLoss: 340.384735\n",
      "Train Epoch: 654 [1800/2589 (70%)]\tLoss: 216.248245\n",
      "Train Epoch: 654 [2100/2589 (81%)]\tLoss: 203.657486\n",
      "Train Epoch: 654 [2400/2589 (93%)]\tLoss: 209.599121\n",
      "====> Epoch: 654 Average train loss: 226.3392\n",
      "====> Epoch: 654 Average test loss: 933.2154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 655 [0/2589 (0%)]\tLoss: 215.247345\n",
      "Train Epoch: 655 [300/2589 (12%)]\tLoss: 238.540390\n",
      "Train Epoch: 655 [600/2589 (23%)]\tLoss: 203.242050\n",
      "Train Epoch: 655 [900/2589 (35%)]\tLoss: 260.355988\n",
      "Train Epoch: 655 [1200/2589 (46%)]\tLoss: 253.998184\n",
      "Train Epoch: 655 [1500/2589 (58%)]\tLoss: 385.147369\n",
      "Train Epoch: 655 [1800/2589 (70%)]\tLoss: 237.234558\n",
      "Train Epoch: 655 [2100/2589 (81%)]\tLoss: 172.230194\n",
      "Train Epoch: 655 [2400/2589 (93%)]\tLoss: 188.804947\n",
      "====> Epoch: 655 Average train loss: 233.3608\n",
      "====> Epoch: 655 Average test loss: 919.3546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 656 [0/2589 (0%)]\tLoss: 175.709427\n",
      "Train Epoch: 656 [300/2589 (12%)]\tLoss: 198.996994\n",
      "Train Epoch: 656 [600/2589 (23%)]\tLoss: 164.771347\n",
      "Train Epoch: 656 [900/2589 (35%)]\tLoss: 244.549637\n",
      "Train Epoch: 656 [1200/2589 (46%)]\tLoss: 268.770844\n",
      "Train Epoch: 656 [1500/2589 (58%)]\tLoss: 262.225372\n",
      "Train Epoch: 656 [1800/2589 (70%)]\tLoss: 205.600403\n",
      "Train Epoch: 656 [2100/2589 (81%)]\tLoss: 178.022079\n",
      "Train Epoch: 656 [2400/2589 (93%)]\tLoss: 249.208817\n",
      "====> Epoch: 656 Average train loss: 234.9039\n",
      "====> Epoch: 656 Average test loss: 913.7731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 657 [0/2589 (0%)]\tLoss: 212.467957\n",
      "Train Epoch: 657 [300/2589 (12%)]\tLoss: 266.828033\n",
      "Train Epoch: 657 [600/2589 (23%)]\tLoss: 175.109940\n",
      "Train Epoch: 657 [900/2589 (35%)]\tLoss: 266.007172\n",
      "Train Epoch: 657 [1200/2589 (46%)]\tLoss: 203.495773\n",
      "Train Epoch: 657 [1500/2589 (58%)]\tLoss: 288.740234\n",
      "Train Epoch: 657 [1800/2589 (70%)]\tLoss: 315.737091\n",
      "Train Epoch: 657 [2100/2589 (81%)]\tLoss: 211.589767\n",
      "Train Epoch: 657 [2400/2589 (93%)]\tLoss: 186.947540\n",
      "====> Epoch: 657 Average train loss: 238.4591\n",
      "====> Epoch: 657 Average test loss: 946.8436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 658 [0/2589 (0%)]\tLoss: 259.950043\n",
      "Train Epoch: 658 [300/2589 (12%)]\tLoss: 221.023499\n",
      "Train Epoch: 658 [600/2589 (23%)]\tLoss: 270.413269\n",
      "Train Epoch: 658 [900/2589 (35%)]\tLoss: 179.866943\n",
      "Train Epoch: 658 [1200/2589 (46%)]\tLoss: 152.100296\n",
      "Train Epoch: 658 [1500/2589 (58%)]\tLoss: 203.474380\n",
      "Train Epoch: 658 [1800/2589 (70%)]\tLoss: 180.168304\n",
      "Train Epoch: 658 [2100/2589 (81%)]\tLoss: 246.454300\n",
      "Train Epoch: 658 [2400/2589 (93%)]\tLoss: 189.711105\n",
      "====> Epoch: 658 Average train loss: 234.9959\n",
      "====> Epoch: 658 Average test loss: 928.8419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 659 [0/2589 (0%)]\tLoss: 156.889099\n",
      "Train Epoch: 659 [300/2589 (12%)]\tLoss: 187.579361\n",
      "Train Epoch: 659 [600/2589 (23%)]\tLoss: 185.282486\n",
      "Train Epoch: 659 [900/2589 (35%)]\tLoss: 157.295181\n",
      "Train Epoch: 659 [1200/2589 (46%)]\tLoss: 183.306259\n",
      "Train Epoch: 659 [1500/2589 (58%)]\tLoss: 196.133698\n",
      "Train Epoch: 659 [1800/2589 (70%)]\tLoss: 211.580460\n",
      "Train Epoch: 659 [2100/2589 (81%)]\tLoss: 286.091248\n",
      "Train Epoch: 659 [2400/2589 (93%)]\tLoss: 234.125946\n",
      "====> Epoch: 659 Average train loss: 232.1298\n",
      "====> Epoch: 659 Average test loss: 933.0939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 660 [0/2589 (0%)]\tLoss: 267.383148\n",
      "Train Epoch: 660 [300/2589 (12%)]\tLoss: 199.198273\n",
      "Train Epoch: 660 [600/2589 (23%)]\tLoss: 278.616394\n",
      "Train Epoch: 660 [900/2589 (35%)]\tLoss: 216.924072\n",
      "Train Epoch: 660 [1200/2589 (46%)]\tLoss: 216.250519\n",
      "Train Epoch: 660 [1500/2589 (58%)]\tLoss: 330.070343\n",
      "Train Epoch: 660 [1800/2589 (70%)]\tLoss: 302.066681\n",
      "Train Epoch: 660 [2100/2589 (81%)]\tLoss: 366.182922\n",
      "Train Epoch: 660 [2400/2589 (93%)]\tLoss: 218.329391\n",
      "====> Epoch: 660 Average train loss: 233.8353\n",
      "====> Epoch: 660 Average test loss: 922.3636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 661 [0/2589 (0%)]\tLoss: 219.310028\n",
      "Train Epoch: 661 [300/2589 (12%)]\tLoss: 309.494720\n",
      "Train Epoch: 661 [600/2589 (23%)]\tLoss: 213.085648\n",
      "Train Epoch: 661 [900/2589 (35%)]\tLoss: 218.690399\n",
      "Train Epoch: 661 [1200/2589 (46%)]\tLoss: 205.055984\n",
      "Train Epoch: 661 [1500/2589 (58%)]\tLoss: 297.940979\n",
      "Train Epoch: 661 [1800/2589 (70%)]\tLoss: 233.125778\n",
      "Train Epoch: 661 [2100/2589 (81%)]\tLoss: 343.011688\n",
      "Train Epoch: 661 [2400/2589 (93%)]\tLoss: 328.328461\n",
      "====> Epoch: 661 Average train loss: 252.0685\n",
      "====> Epoch: 661 Average test loss: 933.0780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 662 [0/2589 (0%)]\tLoss: 221.423538\n",
      "Train Epoch: 662 [300/2589 (12%)]\tLoss: 157.111572\n",
      "Train Epoch: 662 [600/2589 (23%)]\tLoss: 211.362244\n",
      "Train Epoch: 662 [900/2589 (35%)]\tLoss: 217.593918\n",
      "Train Epoch: 662 [1200/2589 (46%)]\tLoss: 186.312775\n",
      "Train Epoch: 662 [1500/2589 (58%)]\tLoss: 205.004486\n",
      "Train Epoch: 662 [1800/2589 (70%)]\tLoss: 278.079651\n",
      "Train Epoch: 662 [2100/2589 (81%)]\tLoss: 310.663025\n",
      "Train Epoch: 662 [2400/2589 (93%)]\tLoss: 273.417969\n",
      "====> Epoch: 662 Average train loss: 233.6388\n",
      "====> Epoch: 662 Average test loss: 924.6882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 663 [0/2589 (0%)]\tLoss: 421.312378\n",
      "Train Epoch: 663 [300/2589 (12%)]\tLoss: 232.684174\n",
      "Train Epoch: 663 [600/2589 (23%)]\tLoss: 474.248016\n",
      "Train Epoch: 663 [900/2589 (35%)]\tLoss: 239.299164\n",
      "Train Epoch: 663 [1200/2589 (46%)]\tLoss: 180.576981\n",
      "Train Epoch: 663 [1500/2589 (58%)]\tLoss: 264.859100\n",
      "Train Epoch: 663 [1800/2589 (70%)]\tLoss: 186.299484\n",
      "Train Epoch: 663 [2100/2589 (81%)]\tLoss: 248.704285\n",
      "Train Epoch: 663 [2400/2589 (93%)]\tLoss: 212.106628\n",
      "====> Epoch: 663 Average train loss: 240.5788\n",
      "====> Epoch: 663 Average test loss: 929.7254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 664 [0/2589 (0%)]\tLoss: 165.201813\n",
      "Train Epoch: 664 [300/2589 (12%)]\tLoss: 233.081894\n",
      "Train Epoch: 664 [600/2589 (23%)]\tLoss: 221.349060\n",
      "Train Epoch: 664 [900/2589 (35%)]\tLoss: 157.352707\n",
      "Train Epoch: 664 [1200/2589 (46%)]\tLoss: 202.772125\n",
      "Train Epoch: 664 [1500/2589 (58%)]\tLoss: 222.208710\n",
      "Train Epoch: 664 [1800/2589 (70%)]\tLoss: 357.108002\n",
      "Train Epoch: 664 [2100/2589 (81%)]\tLoss: 206.720230\n",
      "Train Epoch: 664 [2400/2589 (93%)]\tLoss: 333.114624\n",
      "====> Epoch: 664 Average train loss: 243.1991\n",
      "====> Epoch: 664 Average test loss: 914.0649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 665 [0/2589 (0%)]\tLoss: 183.444550\n",
      "Train Epoch: 665 [300/2589 (12%)]\tLoss: 256.216736\n",
      "Train Epoch: 665 [600/2589 (23%)]\tLoss: 152.983139\n",
      "Train Epoch: 665 [900/2589 (35%)]\tLoss: 166.136032\n",
      "Train Epoch: 665 [1200/2589 (46%)]\tLoss: 195.938416\n",
      "Train Epoch: 665 [1500/2589 (58%)]\tLoss: 163.740967\n",
      "Train Epoch: 665 [1800/2589 (70%)]\tLoss: 343.648102\n",
      "Train Epoch: 665 [2100/2589 (81%)]\tLoss: 153.201523\n",
      "Train Epoch: 665 [2400/2589 (93%)]\tLoss: 251.136810\n",
      "====> Epoch: 665 Average train loss: 231.8616\n",
      "====> Epoch: 665 Average test loss: 925.0682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 666 [0/2589 (0%)]\tLoss: 226.819321\n",
      "Train Epoch: 666 [300/2589 (12%)]\tLoss: 222.741272\n",
      "Train Epoch: 666 [600/2589 (23%)]\tLoss: 230.562668\n",
      "Train Epoch: 666 [900/2589 (35%)]\tLoss: 233.170212\n",
      "Train Epoch: 666 [1200/2589 (46%)]\tLoss: 236.136963\n",
      "Train Epoch: 666 [1500/2589 (58%)]\tLoss: 172.634003\n",
      "Train Epoch: 666 [1800/2589 (70%)]\tLoss: 182.861725\n",
      "Train Epoch: 666 [2100/2589 (81%)]\tLoss: 201.528381\n",
      "Train Epoch: 666 [2400/2589 (93%)]\tLoss: 254.833313\n",
      "====> Epoch: 666 Average train loss: 222.3286\n",
      "====> Epoch: 666 Average test loss: 907.8273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 667 [0/2589 (0%)]\tLoss: 231.175690\n",
      "Train Epoch: 667 [300/2589 (12%)]\tLoss: 160.073059\n",
      "Train Epoch: 667 [600/2589 (23%)]\tLoss: 229.451752\n",
      "Train Epoch: 667 [900/2589 (35%)]\tLoss: 180.531143\n",
      "Train Epoch: 667 [1200/2589 (46%)]\tLoss: 220.319565\n",
      "Train Epoch: 667 [1500/2589 (58%)]\tLoss: 179.406189\n",
      "Train Epoch: 667 [1800/2589 (70%)]\tLoss: 175.514847\n",
      "Train Epoch: 667 [2100/2589 (81%)]\tLoss: 258.081482\n",
      "Train Epoch: 667 [2400/2589 (93%)]\tLoss: 238.969650\n",
      "====> Epoch: 667 Average train loss: 220.5436\n",
      "====> Epoch: 667 Average test loss: 934.1733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 668 [0/2589 (0%)]\tLoss: 288.211151\n",
      "Train Epoch: 668 [300/2589 (12%)]\tLoss: 188.338898\n",
      "Train Epoch: 668 [600/2589 (23%)]\tLoss: 161.522812\n",
      "Train Epoch: 668 [900/2589 (35%)]\tLoss: 195.760849\n",
      "Train Epoch: 668 [1200/2589 (46%)]\tLoss: 183.024521\n",
      "Train Epoch: 668 [1500/2589 (58%)]\tLoss: 209.265060\n",
      "Train Epoch: 668 [1800/2589 (70%)]\tLoss: 291.715790\n",
      "Train Epoch: 668 [2100/2589 (81%)]\tLoss: 268.921539\n",
      "Train Epoch: 668 [2400/2589 (93%)]\tLoss: 277.139496\n",
      "====> Epoch: 668 Average train loss: 234.7137\n",
      "====> Epoch: 668 Average test loss: 926.4156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 669 [0/2589 (0%)]\tLoss: 124.339516\n",
      "Train Epoch: 669 [300/2589 (12%)]\tLoss: 237.806671\n",
      "Train Epoch: 669 [600/2589 (23%)]\tLoss: 244.872559\n",
      "Train Epoch: 669 [900/2589 (35%)]\tLoss: 483.463287\n",
      "Train Epoch: 669 [1200/2589 (46%)]\tLoss: 211.019791\n",
      "Train Epoch: 669 [1500/2589 (58%)]\tLoss: 279.235229\n",
      "Train Epoch: 669 [1800/2589 (70%)]\tLoss: 222.986191\n",
      "Train Epoch: 669 [2100/2589 (81%)]\tLoss: 225.033768\n",
      "Train Epoch: 669 [2400/2589 (93%)]\tLoss: 246.796127\n",
      "====> Epoch: 669 Average train loss: 229.6781\n",
      "====> Epoch: 669 Average test loss: 921.0382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 670 [0/2589 (0%)]\tLoss: 235.481064\n",
      "Train Epoch: 670 [300/2589 (12%)]\tLoss: 348.006195\n",
      "Train Epoch: 670 [600/2589 (23%)]\tLoss: 190.792160\n",
      "Train Epoch: 670 [900/2589 (35%)]\tLoss: 232.189438\n",
      "Train Epoch: 670 [1200/2589 (46%)]\tLoss: 270.404114\n",
      "Train Epoch: 670 [1500/2589 (58%)]\tLoss: 312.478302\n",
      "Train Epoch: 670 [1800/2589 (70%)]\tLoss: 174.813202\n",
      "Train Epoch: 670 [2100/2589 (81%)]\tLoss: 184.591721\n",
      "Train Epoch: 670 [2400/2589 (93%)]\tLoss: 201.414551\n",
      "====> Epoch: 670 Average train loss: 234.2884\n",
      "====> Epoch: 670 Average test loss: 936.9482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 671 [0/2589 (0%)]\tLoss: 152.686279\n",
      "Train Epoch: 671 [300/2589 (12%)]\tLoss: 151.226212\n",
      "Train Epoch: 671 [600/2589 (23%)]\tLoss: 488.179352\n",
      "Train Epoch: 671 [900/2589 (35%)]\tLoss: 254.972702\n",
      "Train Epoch: 671 [1200/2589 (46%)]\tLoss: 196.956833\n",
      "Train Epoch: 671 [1500/2589 (58%)]\tLoss: 227.448044\n",
      "Train Epoch: 671 [1800/2589 (70%)]\tLoss: 207.668137\n",
      "Train Epoch: 671 [2100/2589 (81%)]\tLoss: 222.734146\n",
      "Train Epoch: 671 [2400/2589 (93%)]\tLoss: 263.600586\n",
      "====> Epoch: 671 Average train loss: 238.3089\n",
      "====> Epoch: 671 Average test loss: 931.5528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 672 [0/2589 (0%)]\tLoss: 251.444107\n",
      "Train Epoch: 672 [300/2589 (12%)]\tLoss: 236.904495\n",
      "Train Epoch: 672 [600/2589 (23%)]\tLoss: 223.255783\n",
      "Train Epoch: 672 [900/2589 (35%)]\tLoss: 292.493744\n",
      "Train Epoch: 672 [1200/2589 (46%)]\tLoss: 300.221893\n",
      "Train Epoch: 672 [1500/2589 (58%)]\tLoss: 314.963104\n",
      "Train Epoch: 672 [1800/2589 (70%)]\tLoss: 212.325623\n",
      "Train Epoch: 672 [2100/2589 (81%)]\tLoss: 191.764069\n",
      "Train Epoch: 672 [2400/2589 (93%)]\tLoss: 332.279724\n",
      "====> Epoch: 672 Average train loss: 239.1902\n",
      "====> Epoch: 672 Average test loss: 932.2170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 673 [0/2589 (0%)]\tLoss: 230.074890\n",
      "Train Epoch: 673 [300/2589 (12%)]\tLoss: 257.237396\n",
      "Train Epoch: 673 [600/2589 (23%)]\tLoss: 159.609650\n",
      "Train Epoch: 673 [900/2589 (35%)]\tLoss: 219.501755\n",
      "Train Epoch: 673 [1200/2589 (46%)]\tLoss: 239.029755\n",
      "Train Epoch: 673 [1500/2589 (58%)]\tLoss: 200.875168\n",
      "Train Epoch: 673 [1800/2589 (70%)]\tLoss: 223.550079\n",
      "Train Epoch: 673 [2100/2589 (81%)]\tLoss: 269.255463\n",
      "Train Epoch: 673 [2400/2589 (93%)]\tLoss: 251.078323\n",
      "====> Epoch: 673 Average train loss: 240.3653\n",
      "====> Epoch: 673 Average test loss: 911.3943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 674 [0/2589 (0%)]\tLoss: 155.276199\n",
      "Train Epoch: 674 [300/2589 (12%)]\tLoss: 217.428955\n",
      "Train Epoch: 674 [600/2589 (23%)]\tLoss: 165.008850\n",
      "Train Epoch: 674 [900/2589 (35%)]\tLoss: 289.068085\n",
      "Train Epoch: 674 [1200/2589 (46%)]\tLoss: 300.047455\n",
      "Train Epoch: 674 [1500/2589 (58%)]\tLoss: 271.199066\n",
      "Train Epoch: 674 [1800/2589 (70%)]\tLoss: 283.316528\n",
      "Train Epoch: 674 [2100/2589 (81%)]\tLoss: 270.366852\n",
      "Train Epoch: 674 [2400/2589 (93%)]\tLoss: 307.465027\n",
      "====> Epoch: 674 Average train loss: 224.1592\n",
      "====> Epoch: 674 Average test loss: 919.7773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 675 [0/2589 (0%)]\tLoss: 224.587387\n",
      "Train Epoch: 675 [300/2589 (12%)]\tLoss: 170.776184\n",
      "Train Epoch: 675 [600/2589 (23%)]\tLoss: 344.676056\n",
      "Train Epoch: 675 [900/2589 (35%)]\tLoss: 232.716415\n",
      "Train Epoch: 675 [1200/2589 (46%)]\tLoss: 261.771973\n",
      "Train Epoch: 675 [1500/2589 (58%)]\tLoss: 182.717377\n",
      "Train Epoch: 675 [1800/2589 (70%)]\tLoss: 206.037170\n",
      "Train Epoch: 675 [2100/2589 (81%)]\tLoss: 232.313202\n",
      "Train Epoch: 675 [2400/2589 (93%)]\tLoss: 215.732712\n",
      "====> Epoch: 675 Average train loss: 229.2462\n",
      "====> Epoch: 675 Average test loss: 933.2250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 676 [0/2589 (0%)]\tLoss: 221.768036\n",
      "Train Epoch: 676 [300/2589 (12%)]\tLoss: 233.914001\n",
      "Train Epoch: 676 [600/2589 (23%)]\tLoss: 278.931030\n",
      "Train Epoch: 676 [900/2589 (35%)]\tLoss: 271.313324\n",
      "Train Epoch: 676 [1200/2589 (46%)]\tLoss: 228.305496\n",
      "Train Epoch: 676 [1500/2589 (58%)]\tLoss: 181.075424\n",
      "Train Epoch: 676 [1800/2589 (70%)]\tLoss: 353.085602\n",
      "Train Epoch: 676 [2100/2589 (81%)]\tLoss: 257.976074\n",
      "Train Epoch: 676 [2400/2589 (93%)]\tLoss: 265.497101\n",
      "====> Epoch: 676 Average train loss: 241.0131\n",
      "====> Epoch: 676 Average test loss: 932.1967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 677 [0/2589 (0%)]\tLoss: 223.857407\n",
      "Train Epoch: 677 [300/2589 (12%)]\tLoss: 295.728363\n",
      "Train Epoch: 677 [600/2589 (23%)]\tLoss: 180.436172\n",
      "Train Epoch: 677 [900/2589 (35%)]\tLoss: 201.998672\n",
      "Train Epoch: 677 [1200/2589 (46%)]\tLoss: 436.871155\n",
      "Train Epoch: 677 [1500/2589 (58%)]\tLoss: 184.732986\n",
      "Train Epoch: 677 [1800/2589 (70%)]\tLoss: 239.060562\n",
      "Train Epoch: 677 [2100/2589 (81%)]\tLoss: 317.336914\n",
      "Train Epoch: 677 [2400/2589 (93%)]\tLoss: 237.101578\n",
      "====> Epoch: 677 Average train loss: 249.1332\n",
      "====> Epoch: 677 Average test loss: 907.5116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 678 [0/2589 (0%)]\tLoss: 230.088882\n",
      "Train Epoch: 678 [300/2589 (12%)]\tLoss: 261.182220\n",
      "Train Epoch: 678 [600/2589 (23%)]\tLoss: 332.024567\n",
      "Train Epoch: 678 [900/2589 (35%)]\tLoss: 177.757843\n",
      "Train Epoch: 678 [1200/2589 (46%)]\tLoss: 179.883560\n",
      "Train Epoch: 678 [1500/2589 (58%)]\tLoss: 298.341003\n",
      "Train Epoch: 678 [1800/2589 (70%)]\tLoss: 118.335182\n",
      "Train Epoch: 678 [2100/2589 (81%)]\tLoss: 162.023193\n",
      "Train Epoch: 678 [2400/2589 (93%)]\tLoss: 261.493103\n",
      "====> Epoch: 678 Average train loss: 237.5433\n",
      "====> Epoch: 678 Average test loss: 899.5439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 679 [0/2589 (0%)]\tLoss: 405.404114\n",
      "Train Epoch: 679 [300/2589 (12%)]\tLoss: 203.525055\n",
      "Train Epoch: 679 [600/2589 (23%)]\tLoss: 164.177032\n",
      "Train Epoch: 679 [900/2589 (35%)]\tLoss: 213.271744\n",
      "Train Epoch: 679 [1200/2589 (46%)]\tLoss: 365.309113\n",
      "Train Epoch: 679 [1500/2589 (58%)]\tLoss: 153.020218\n",
      "Train Epoch: 679 [1800/2589 (70%)]\tLoss: 257.568207\n",
      "Train Epoch: 679 [2100/2589 (81%)]\tLoss: 154.429031\n",
      "Train Epoch: 679 [2400/2589 (93%)]\tLoss: 213.205109\n",
      "====> Epoch: 679 Average train loss: 254.6587\n",
      "====> Epoch: 679 Average test loss: 930.1310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 680 [0/2589 (0%)]\tLoss: 220.132751\n",
      "Train Epoch: 680 [300/2589 (12%)]\tLoss: 140.770737\n",
      "Train Epoch: 680 [600/2589 (23%)]\tLoss: 217.380753\n",
      "Train Epoch: 680 [900/2589 (35%)]\tLoss: 200.194656\n",
      "Train Epoch: 680 [1200/2589 (46%)]\tLoss: 273.422668\n",
      "Train Epoch: 680 [1500/2589 (58%)]\tLoss: 218.565170\n",
      "Train Epoch: 680 [1800/2589 (70%)]\tLoss: 215.383743\n",
      "Train Epoch: 680 [2100/2589 (81%)]\tLoss: 232.455246\n",
      "Train Epoch: 680 [2400/2589 (93%)]\tLoss: 173.639175\n",
      "====> Epoch: 680 Average train loss: 226.2243\n",
      "====> Epoch: 680 Average test loss: 923.7153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 681 [0/2589 (0%)]\tLoss: 184.880936\n",
      "Train Epoch: 681 [300/2589 (12%)]\tLoss: 322.708191\n",
      "Train Epoch: 681 [600/2589 (23%)]\tLoss: 232.753601\n",
      "Train Epoch: 681 [900/2589 (35%)]\tLoss: 200.651962\n",
      "Train Epoch: 681 [1200/2589 (46%)]\tLoss: 194.087921\n",
      "Train Epoch: 681 [1500/2589 (58%)]\tLoss: 182.536621\n",
      "Train Epoch: 681 [1800/2589 (70%)]\tLoss: 231.219055\n",
      "Train Epoch: 681 [2100/2589 (81%)]\tLoss: 252.153717\n",
      "Train Epoch: 681 [2400/2589 (93%)]\tLoss: 173.233337\n",
      "====> Epoch: 681 Average train loss: 227.5813\n",
      "====> Epoch: 681 Average test loss: 910.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 682 [0/2589 (0%)]\tLoss: 246.388214\n",
      "Train Epoch: 682 [300/2589 (12%)]\tLoss: 248.471878\n",
      "Train Epoch: 682 [600/2589 (23%)]\tLoss: 181.727921\n",
      "Train Epoch: 682 [900/2589 (35%)]\tLoss: 208.869659\n",
      "Train Epoch: 682 [1200/2589 (46%)]\tLoss: 214.161621\n",
      "Train Epoch: 682 [1500/2589 (58%)]\tLoss: 232.944595\n",
      "Train Epoch: 682 [1800/2589 (70%)]\tLoss: 354.533722\n",
      "Train Epoch: 682 [2100/2589 (81%)]\tLoss: 317.919891\n",
      "Train Epoch: 682 [2400/2589 (93%)]\tLoss: 250.595764\n",
      "====> Epoch: 682 Average train loss: 238.2520\n",
      "====> Epoch: 682 Average test loss: 914.5007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 683 [0/2589 (0%)]\tLoss: 212.290131\n",
      "Train Epoch: 683 [300/2589 (12%)]\tLoss: 221.041489\n",
      "Train Epoch: 683 [600/2589 (23%)]\tLoss: 301.634857\n",
      "Train Epoch: 683 [900/2589 (35%)]\tLoss: 257.484100\n",
      "Train Epoch: 683 [1200/2589 (46%)]\tLoss: 248.360382\n",
      "Train Epoch: 683 [1500/2589 (58%)]\tLoss: 217.499771\n",
      "Train Epoch: 683 [1800/2589 (70%)]\tLoss: 217.303482\n",
      "Train Epoch: 683 [2100/2589 (81%)]\tLoss: 198.701828\n",
      "Train Epoch: 683 [2400/2589 (93%)]\tLoss: 200.049026\n",
      "====> Epoch: 683 Average train loss: 230.8058\n",
      "====> Epoch: 683 Average test loss: 935.2964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 684 [0/2589 (0%)]\tLoss: 375.029358\n",
      "Train Epoch: 684 [300/2589 (12%)]\tLoss: 213.612122\n",
      "Train Epoch: 684 [600/2589 (23%)]\tLoss: 264.342407\n",
      "Train Epoch: 684 [900/2589 (35%)]\tLoss: 178.757431\n",
      "Train Epoch: 684 [1200/2589 (46%)]\tLoss: 247.027008\n",
      "Train Epoch: 684 [1500/2589 (58%)]\tLoss: 189.933792\n",
      "Train Epoch: 684 [1800/2589 (70%)]\tLoss: 178.239761\n",
      "Train Epoch: 684 [2100/2589 (81%)]\tLoss: 207.133728\n",
      "Train Epoch: 684 [2400/2589 (93%)]\tLoss: 287.777008\n",
      "====> Epoch: 684 Average train loss: 215.4420\n",
      "====> Epoch: 684 Average test loss: 909.9298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 685 [0/2589 (0%)]\tLoss: 222.205048\n",
      "Train Epoch: 685 [300/2589 (12%)]\tLoss: 301.822662\n",
      "Train Epoch: 685 [600/2589 (23%)]\tLoss: 199.155731\n",
      "Train Epoch: 685 [900/2589 (35%)]\tLoss: 163.912323\n",
      "Train Epoch: 685 [1200/2589 (46%)]\tLoss: 153.580246\n",
      "Train Epoch: 685 [1500/2589 (58%)]\tLoss: 219.171219\n",
      "Train Epoch: 685 [1800/2589 (70%)]\tLoss: 237.571030\n",
      "Train Epoch: 685 [2100/2589 (81%)]\tLoss: 141.813538\n",
      "Train Epoch: 685 [2400/2589 (93%)]\tLoss: 167.301071\n",
      "====> Epoch: 685 Average train loss: 224.9181\n",
      "====> Epoch: 685 Average test loss: 916.2482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 686 [0/2589 (0%)]\tLoss: 243.228256\n",
      "Train Epoch: 686 [300/2589 (12%)]\tLoss: 210.107040\n",
      "Train Epoch: 686 [600/2589 (23%)]\tLoss: 267.369141\n",
      "Train Epoch: 686 [900/2589 (35%)]\tLoss: 181.837494\n",
      "Train Epoch: 686 [1200/2589 (46%)]\tLoss: 299.892944\n",
      "Train Epoch: 686 [1500/2589 (58%)]\tLoss: 159.504822\n",
      "Train Epoch: 686 [1800/2589 (70%)]\tLoss: 232.786758\n",
      "Train Epoch: 686 [2100/2589 (81%)]\tLoss: 238.965988\n",
      "Train Epoch: 686 [2400/2589 (93%)]\tLoss: 148.149246\n",
      "====> Epoch: 686 Average train loss: 237.4025\n",
      "====> Epoch: 686 Average test loss: 921.8721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 687 [0/2589 (0%)]\tLoss: 210.991470\n",
      "Train Epoch: 687 [300/2589 (12%)]\tLoss: 281.281342\n",
      "Train Epoch: 687 [600/2589 (23%)]\tLoss: 239.346786\n",
      "Train Epoch: 687 [900/2589 (35%)]\tLoss: 196.696060\n",
      "Train Epoch: 687 [1200/2589 (46%)]\tLoss: 178.344528\n",
      "Train Epoch: 687 [1500/2589 (58%)]\tLoss: 208.027588\n",
      "Train Epoch: 687 [1800/2589 (70%)]\tLoss: 194.393127\n",
      "Train Epoch: 687 [2100/2589 (81%)]\tLoss: 204.301514\n",
      "Train Epoch: 687 [2400/2589 (93%)]\tLoss: 196.739975\n",
      "====> Epoch: 687 Average train loss: 233.3461\n",
      "====> Epoch: 687 Average test loss: 912.3662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 688 [0/2589 (0%)]\tLoss: 147.031586\n",
      "Train Epoch: 688 [300/2589 (12%)]\tLoss: 234.100449\n",
      "Train Epoch: 688 [600/2589 (23%)]\tLoss: 194.742233\n",
      "Train Epoch: 688 [900/2589 (35%)]\tLoss: 173.285324\n",
      "Train Epoch: 688 [1200/2589 (46%)]\tLoss: 246.598663\n",
      "Train Epoch: 688 [1500/2589 (58%)]\tLoss: 249.475327\n",
      "Train Epoch: 688 [1800/2589 (70%)]\tLoss: 189.014084\n",
      "Train Epoch: 688 [2100/2589 (81%)]\tLoss: 161.050690\n",
      "Train Epoch: 688 [2400/2589 (93%)]\tLoss: 207.958267\n",
      "====> Epoch: 688 Average train loss: 234.4195\n",
      "====> Epoch: 688 Average test loss: 911.7377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 689 [0/2589 (0%)]\tLoss: 272.050751\n",
      "Train Epoch: 689 [300/2589 (12%)]\tLoss: 193.025848\n",
      "Train Epoch: 689 [600/2589 (23%)]\tLoss: 205.067230\n",
      "Train Epoch: 689 [900/2589 (35%)]\tLoss: 393.217163\n",
      "Train Epoch: 689 [1200/2589 (46%)]\tLoss: 206.320633\n",
      "Train Epoch: 689 [1500/2589 (58%)]\tLoss: 243.772400\n",
      "Train Epoch: 689 [1800/2589 (70%)]\tLoss: 206.821304\n",
      "Train Epoch: 689 [2100/2589 (81%)]\tLoss: 279.787659\n",
      "Train Epoch: 689 [2400/2589 (93%)]\tLoss: 160.618591\n",
      "====> Epoch: 689 Average train loss: 225.3095\n",
      "====> Epoch: 689 Average test loss: 928.8810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 690 [0/2589 (0%)]\tLoss: 201.786301\n",
      "Train Epoch: 690 [300/2589 (12%)]\tLoss: 145.919342\n",
      "Train Epoch: 690 [600/2589 (23%)]\tLoss: 180.916412\n",
      "Train Epoch: 690 [900/2589 (35%)]\tLoss: 365.463074\n",
      "Train Epoch: 690 [1200/2589 (46%)]\tLoss: 184.861130\n",
      "Train Epoch: 690 [1500/2589 (58%)]\tLoss: 220.563461\n",
      "Train Epoch: 690 [1800/2589 (70%)]\tLoss: 215.828903\n",
      "Train Epoch: 690 [2100/2589 (81%)]\tLoss: 212.518646\n",
      "Train Epoch: 690 [2400/2589 (93%)]\tLoss: 215.873993\n",
      "====> Epoch: 690 Average train loss: 225.9261\n",
      "====> Epoch: 690 Average test loss: 921.7541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 691 [0/2589 (0%)]\tLoss: 254.673996\n",
      "Train Epoch: 691 [300/2589 (12%)]\tLoss: 147.596329\n",
      "Train Epoch: 691 [600/2589 (23%)]\tLoss: 173.576660\n",
      "Train Epoch: 691 [900/2589 (35%)]\tLoss: 286.643036\n",
      "Train Epoch: 691 [1200/2589 (46%)]\tLoss: 235.377792\n",
      "Train Epoch: 691 [1500/2589 (58%)]\tLoss: 292.621216\n",
      "Train Epoch: 691 [1800/2589 (70%)]\tLoss: 161.268448\n",
      "Train Epoch: 691 [2100/2589 (81%)]\tLoss: 348.138672\n",
      "Train Epoch: 691 [2400/2589 (93%)]\tLoss: 148.739548\n",
      "====> Epoch: 691 Average train loss: 232.4179\n",
      "====> Epoch: 691 Average test loss: 932.7772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 692 [0/2589 (0%)]\tLoss: 212.198792\n",
      "Train Epoch: 692 [300/2589 (12%)]\tLoss: 242.066895\n",
      "Train Epoch: 692 [600/2589 (23%)]\tLoss: 163.627640\n",
      "Train Epoch: 692 [900/2589 (35%)]\tLoss: 236.018326\n",
      "Train Epoch: 692 [1200/2589 (46%)]\tLoss: 249.031479\n",
      "Train Epoch: 692 [1500/2589 (58%)]\tLoss: 260.612579\n",
      "Train Epoch: 692 [1800/2589 (70%)]\tLoss: 177.386215\n",
      "Train Epoch: 692 [2100/2589 (81%)]\tLoss: 291.216217\n",
      "Train Epoch: 692 [2400/2589 (93%)]\tLoss: 199.959152\n",
      "====> Epoch: 692 Average train loss: 229.1094\n",
      "====> Epoch: 692 Average test loss: 924.6873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 693 [0/2589 (0%)]\tLoss: 305.552765\n",
      "Train Epoch: 693 [300/2589 (12%)]\tLoss: 174.822525\n",
      "Train Epoch: 693 [600/2589 (23%)]\tLoss: 265.099304\n",
      "Train Epoch: 693 [900/2589 (35%)]\tLoss: 291.834106\n",
      "Train Epoch: 693 [1200/2589 (46%)]\tLoss: 148.386856\n",
      "Train Epoch: 693 [1500/2589 (58%)]\tLoss: 213.491211\n",
      "Train Epoch: 693 [1800/2589 (70%)]\tLoss: 142.983002\n",
      "Train Epoch: 693 [2100/2589 (81%)]\tLoss: 313.362183\n",
      "Train Epoch: 693 [2400/2589 (93%)]\tLoss: 317.730927\n",
      "====> Epoch: 693 Average train loss: 223.8308\n",
      "====> Epoch: 693 Average test loss: 913.2642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 694 [0/2589 (0%)]\tLoss: 393.126373\n",
      "Train Epoch: 694 [300/2589 (12%)]\tLoss: 129.179092\n",
      "Train Epoch: 694 [600/2589 (23%)]\tLoss: 164.143051\n",
      "Train Epoch: 694 [900/2589 (35%)]\tLoss: 256.883636\n",
      "Train Epoch: 694 [1200/2589 (46%)]\tLoss: 195.305222\n",
      "Train Epoch: 694 [1500/2589 (58%)]\tLoss: 171.975113\n",
      "Train Epoch: 694 [1800/2589 (70%)]\tLoss: 280.611145\n",
      "Train Epoch: 694 [2100/2589 (81%)]\tLoss: 270.523254\n",
      "Train Epoch: 694 [2400/2589 (93%)]\tLoss: 254.963120\n",
      "====> Epoch: 694 Average train loss: 235.7237\n",
      "====> Epoch: 694 Average test loss: 909.3685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 695 [0/2589 (0%)]\tLoss: 205.564178\n",
      "Train Epoch: 695 [300/2589 (12%)]\tLoss: 351.016205\n",
      "Train Epoch: 695 [600/2589 (23%)]\tLoss: 164.168427\n",
      "Train Epoch: 695 [900/2589 (35%)]\tLoss: 217.939835\n",
      "Train Epoch: 695 [1200/2589 (46%)]\tLoss: 190.725113\n",
      "Train Epoch: 695 [1500/2589 (58%)]\tLoss: 173.450287\n",
      "Train Epoch: 695 [1800/2589 (70%)]\tLoss: 159.991959\n",
      "Train Epoch: 695 [2100/2589 (81%)]\tLoss: 259.075165\n",
      "Train Epoch: 695 [2400/2589 (93%)]\tLoss: 261.660858\n",
      "====> Epoch: 695 Average train loss: 224.7112\n",
      "====> Epoch: 695 Average test loss: 908.5298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 696 [0/2589 (0%)]\tLoss: 160.185028\n",
      "Train Epoch: 696 [300/2589 (12%)]\tLoss: 265.608215\n",
      "Train Epoch: 696 [600/2589 (23%)]\tLoss: 308.827637\n",
      "Train Epoch: 696 [900/2589 (35%)]\tLoss: 237.471207\n",
      "Train Epoch: 696 [1200/2589 (46%)]\tLoss: 248.721771\n",
      "Train Epoch: 696 [1500/2589 (58%)]\tLoss: 142.736359\n",
      "Train Epoch: 696 [1800/2589 (70%)]\tLoss: 221.307205\n",
      "Train Epoch: 696 [2100/2589 (81%)]\tLoss: 232.793991\n",
      "Train Epoch: 696 [2400/2589 (93%)]\tLoss: 196.859222\n",
      "====> Epoch: 696 Average train loss: 239.3468\n",
      "====> Epoch: 696 Average test loss: 925.0832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 697 [0/2589 (0%)]\tLoss: 259.794830\n",
      "Train Epoch: 697 [300/2589 (12%)]\tLoss: 235.616272\n",
      "Train Epoch: 697 [600/2589 (23%)]\tLoss: 253.434830\n",
      "Train Epoch: 697 [900/2589 (35%)]\tLoss: 282.853973\n",
      "Train Epoch: 697 [1200/2589 (46%)]\tLoss: 208.100601\n",
      "Train Epoch: 697 [1500/2589 (58%)]\tLoss: 202.480804\n",
      "Train Epoch: 697 [1800/2589 (70%)]\tLoss: 177.885040\n",
      "Train Epoch: 697 [2100/2589 (81%)]\tLoss: 176.535614\n",
      "Train Epoch: 697 [2400/2589 (93%)]\tLoss: 205.883820\n",
      "====> Epoch: 697 Average train loss: 230.7397\n",
      "====> Epoch: 697 Average test loss: 916.5668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 698 [0/2589 (0%)]\tLoss: 179.667542\n",
      "Train Epoch: 698 [300/2589 (12%)]\tLoss: 166.723785\n",
      "Train Epoch: 698 [600/2589 (23%)]\tLoss: 227.339584\n",
      "Train Epoch: 698 [900/2589 (35%)]\tLoss: 143.129898\n",
      "Train Epoch: 698 [1200/2589 (46%)]\tLoss: 172.473862\n",
      "Train Epoch: 698 [1500/2589 (58%)]\tLoss: 287.527557\n",
      "Train Epoch: 698 [1800/2589 (70%)]\tLoss: 183.687027\n",
      "Train Epoch: 698 [2100/2589 (81%)]\tLoss: 217.854736\n",
      "Train Epoch: 698 [2400/2589 (93%)]\tLoss: 295.453979\n",
      "====> Epoch: 698 Average train loss: 228.5207\n",
      "====> Epoch: 698 Average test loss: 913.1882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 699 [0/2589 (0%)]\tLoss: 238.519928\n",
      "Train Epoch: 699 [300/2589 (12%)]\tLoss: 257.612579\n",
      "Train Epoch: 699 [600/2589 (23%)]\tLoss: 240.453552\n",
      "Train Epoch: 699 [900/2589 (35%)]\tLoss: 217.521057\n",
      "Train Epoch: 699 [1200/2589 (46%)]\tLoss: 251.207275\n",
      "Train Epoch: 699 [1500/2589 (58%)]\tLoss: 206.891418\n",
      "Train Epoch: 699 [1800/2589 (70%)]\tLoss: 202.157730\n",
      "Train Epoch: 699 [2100/2589 (81%)]\tLoss: 210.432587\n",
      "Train Epoch: 699 [2400/2589 (93%)]\tLoss: 169.620270\n",
      "====> Epoch: 699 Average train loss: 236.2736\n",
      "====> Epoch: 699 Average test loss: 934.5139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 700 [0/2589 (0%)]\tLoss: 272.299011\n",
      "Train Epoch: 700 [300/2589 (12%)]\tLoss: 263.271484\n",
      "Train Epoch: 700 [600/2589 (23%)]\tLoss: 179.804977\n",
      "Train Epoch: 700 [900/2589 (35%)]\tLoss: 238.684830\n",
      "Train Epoch: 700 [1200/2589 (46%)]\tLoss: 178.208328\n",
      "Train Epoch: 700 [1500/2589 (58%)]\tLoss: 185.194107\n",
      "Train Epoch: 700 [1800/2589 (70%)]\tLoss: 212.512970\n",
      "Train Epoch: 700 [2100/2589 (81%)]\tLoss: 176.173416\n",
      "Train Epoch: 700 [2400/2589 (93%)]\tLoss: 222.351807\n",
      "====> Epoch: 700 Average train loss: 223.9415\n",
      "====> Epoch: 700 Average test loss: 947.0706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 701 [0/2589 (0%)]\tLoss: 178.211609\n",
      "Train Epoch: 701 [300/2589 (12%)]\tLoss: 246.799057\n",
      "Train Epoch: 701 [600/2589 (23%)]\tLoss: 226.073135\n",
      "Train Epoch: 701 [900/2589 (35%)]\tLoss: 389.940369\n",
      "Train Epoch: 701 [1200/2589 (46%)]\tLoss: 189.297653\n",
      "Train Epoch: 701 [1500/2589 (58%)]\tLoss: 167.230682\n",
      "Train Epoch: 701 [1800/2589 (70%)]\tLoss: 192.085419\n",
      "Train Epoch: 701 [2100/2589 (81%)]\tLoss: 186.872452\n",
      "Train Epoch: 701 [2400/2589 (93%)]\tLoss: 331.433472\n",
      "====> Epoch: 701 Average train loss: 231.8415\n",
      "====> Epoch: 701 Average test loss: 922.8899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 702 [0/2589 (0%)]\tLoss: 216.659088\n",
      "Train Epoch: 702 [300/2589 (12%)]\tLoss: 224.123444\n",
      "Train Epoch: 702 [600/2589 (23%)]\tLoss: 196.485062\n",
      "Train Epoch: 702 [900/2589 (35%)]\tLoss: 169.044724\n",
      "Train Epoch: 702 [1200/2589 (46%)]\tLoss: 296.878906\n",
      "Train Epoch: 702 [1500/2589 (58%)]\tLoss: 170.542587\n",
      "Train Epoch: 702 [1800/2589 (70%)]\tLoss: 241.804840\n",
      "Train Epoch: 702 [2100/2589 (81%)]\tLoss: 305.760040\n",
      "Train Epoch: 702 [2400/2589 (93%)]\tLoss: 247.109299\n",
      "====> Epoch: 702 Average train loss: 241.3297\n",
      "====> Epoch: 702 Average test loss: 913.3884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 703 [0/2589 (0%)]\tLoss: 237.828903\n",
      "Train Epoch: 703 [300/2589 (12%)]\tLoss: 192.427902\n",
      "Train Epoch: 703 [600/2589 (23%)]\tLoss: 240.257019\n",
      "Train Epoch: 703 [900/2589 (35%)]\tLoss: 232.119370\n",
      "Train Epoch: 703 [1200/2589 (46%)]\tLoss: 249.271637\n",
      "Train Epoch: 703 [1500/2589 (58%)]\tLoss: 193.519180\n",
      "Train Epoch: 703 [1800/2589 (70%)]\tLoss: 235.364548\n",
      "Train Epoch: 703 [2100/2589 (81%)]\tLoss: 158.322617\n",
      "Train Epoch: 703 [2400/2589 (93%)]\tLoss: 300.083160\n",
      "====> Epoch: 703 Average train loss: 235.8887\n",
      "====> Epoch: 703 Average test loss: 918.4694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 704 [0/2589 (0%)]\tLoss: 178.358597\n",
      "Train Epoch: 704 [300/2589 (12%)]\tLoss: 183.325623\n",
      "Train Epoch: 704 [600/2589 (23%)]\tLoss: 301.864899\n",
      "Train Epoch: 704 [900/2589 (35%)]\tLoss: 287.225586\n",
      "Train Epoch: 704 [1200/2589 (46%)]\tLoss: 289.282654\n",
      "Train Epoch: 704 [1500/2589 (58%)]\tLoss: 212.111252\n",
      "Train Epoch: 704 [1800/2589 (70%)]\tLoss: 258.182159\n",
      "Train Epoch: 704 [2100/2589 (81%)]\tLoss: 176.629364\n",
      "Train Epoch: 704 [2400/2589 (93%)]\tLoss: 293.143127\n",
      "====> Epoch: 704 Average train loss: 227.7811\n",
      "====> Epoch: 704 Average test loss: 914.4435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 705 [0/2589 (0%)]\tLoss: 174.764130\n",
      "Train Epoch: 705 [300/2589 (12%)]\tLoss: 232.169418\n",
      "Train Epoch: 705 [600/2589 (23%)]\tLoss: 218.894745\n",
      "Train Epoch: 705 [900/2589 (35%)]\tLoss: 289.948303\n",
      "Train Epoch: 705 [1200/2589 (46%)]\tLoss: 173.538605\n",
      "Train Epoch: 705 [1500/2589 (58%)]\tLoss: 245.433578\n",
      "Train Epoch: 705 [1800/2589 (70%)]\tLoss: 201.189957\n",
      "Train Epoch: 705 [2100/2589 (81%)]\tLoss: 239.944046\n",
      "Train Epoch: 705 [2400/2589 (93%)]\tLoss: 222.476501\n",
      "====> Epoch: 705 Average train loss: 226.2133\n",
      "====> Epoch: 705 Average test loss: 902.5438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 706 [0/2589 (0%)]\tLoss: 290.627441\n",
      "Train Epoch: 706 [300/2589 (12%)]\tLoss: 381.344513\n",
      "Train Epoch: 706 [600/2589 (23%)]\tLoss: 196.232666\n",
      "Train Epoch: 706 [900/2589 (35%)]\tLoss: 276.611938\n",
      "Train Epoch: 706 [1200/2589 (46%)]\tLoss: 257.315979\n",
      "Train Epoch: 706 [1500/2589 (58%)]\tLoss: 265.389343\n",
      "Train Epoch: 706 [1800/2589 (70%)]\tLoss: 254.698776\n",
      "Train Epoch: 706 [2100/2589 (81%)]\tLoss: 195.301620\n",
      "Train Epoch: 706 [2400/2589 (93%)]\tLoss: 176.575363\n",
      "====> Epoch: 706 Average train loss: 238.4043\n",
      "====> Epoch: 706 Average test loss: 919.3839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 707 [0/2589 (0%)]\tLoss: 336.928436\n",
      "Train Epoch: 707 [300/2589 (12%)]\tLoss: 188.073456\n",
      "Train Epoch: 707 [600/2589 (23%)]\tLoss: 179.808334\n",
      "Train Epoch: 707 [900/2589 (35%)]\tLoss: 298.419769\n",
      "Train Epoch: 707 [1200/2589 (46%)]\tLoss: 215.511322\n",
      "Train Epoch: 707 [1500/2589 (58%)]\tLoss: 245.493561\n",
      "Train Epoch: 707 [1800/2589 (70%)]\tLoss: 122.630272\n",
      "Train Epoch: 707 [2100/2589 (81%)]\tLoss: 266.860657\n",
      "Train Epoch: 707 [2400/2589 (93%)]\tLoss: 276.045807\n",
      "====> Epoch: 707 Average train loss: 232.8200\n",
      "====> Epoch: 707 Average test loss: 924.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 708 [0/2589 (0%)]\tLoss: 149.629089\n",
      "Train Epoch: 708 [300/2589 (12%)]\tLoss: 226.214676\n",
      "Train Epoch: 708 [600/2589 (23%)]\tLoss: 186.530350\n",
      "Train Epoch: 708 [900/2589 (35%)]\tLoss: 480.770447\n",
      "Train Epoch: 708 [1200/2589 (46%)]\tLoss: 194.165237\n",
      "Train Epoch: 708 [1500/2589 (58%)]\tLoss: 279.791840\n",
      "Train Epoch: 708 [1800/2589 (70%)]\tLoss: 224.871750\n",
      "Train Epoch: 708 [2100/2589 (81%)]\tLoss: 193.666153\n",
      "Train Epoch: 708 [2400/2589 (93%)]\tLoss: 212.599289\n",
      "====> Epoch: 708 Average train loss: 224.8680\n",
      "====> Epoch: 708 Average test loss: 935.6235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 709 [0/2589 (0%)]\tLoss: 171.173599\n",
      "Train Epoch: 709 [300/2589 (12%)]\tLoss: 188.047256\n",
      "Train Epoch: 709 [600/2589 (23%)]\tLoss: 263.758667\n",
      "Train Epoch: 709 [900/2589 (35%)]\tLoss: 160.300842\n",
      "Train Epoch: 709 [1200/2589 (46%)]\tLoss: 235.237579\n",
      "Train Epoch: 709 [1500/2589 (58%)]\tLoss: 192.434494\n",
      "Train Epoch: 709 [1800/2589 (70%)]\tLoss: 165.885895\n",
      "Train Epoch: 709 [2100/2589 (81%)]\tLoss: 158.254166\n",
      "Train Epoch: 709 [2400/2589 (93%)]\tLoss: 189.670670\n",
      "====> Epoch: 709 Average train loss: 222.8324\n",
      "====> Epoch: 709 Average test loss: 911.3135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 710 [0/2589 (0%)]\tLoss: 178.915665\n",
      "Train Epoch: 710 [300/2589 (12%)]\tLoss: 223.632599\n",
      "Train Epoch: 710 [600/2589 (23%)]\tLoss: 140.610046\n",
      "Train Epoch: 710 [900/2589 (35%)]\tLoss: 204.735733\n",
      "Train Epoch: 710 [1200/2589 (46%)]\tLoss: 210.636459\n",
      "Train Epoch: 710 [1500/2589 (58%)]\tLoss: 240.724121\n",
      "Train Epoch: 710 [1800/2589 (70%)]\tLoss: 204.954269\n",
      "Train Epoch: 710 [2100/2589 (81%)]\tLoss: 183.016434\n",
      "Train Epoch: 710 [2400/2589 (93%)]\tLoss: 455.704712\n",
      "====> Epoch: 710 Average train loss: 233.7061\n",
      "====> Epoch: 710 Average test loss: 906.1978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 711 [0/2589 (0%)]\tLoss: 352.158997\n",
      "Train Epoch: 711 [300/2589 (12%)]\tLoss: 162.121796\n",
      "Train Epoch: 711 [600/2589 (23%)]\tLoss: 280.383392\n",
      "Train Epoch: 711 [900/2589 (35%)]\tLoss: 170.151917\n",
      "Train Epoch: 711 [1200/2589 (46%)]\tLoss: 203.580826\n",
      "Train Epoch: 711 [1500/2589 (58%)]\tLoss: 201.819962\n",
      "Train Epoch: 711 [1800/2589 (70%)]\tLoss: 187.637878\n",
      "Train Epoch: 711 [2100/2589 (81%)]\tLoss: 242.206024\n",
      "Train Epoch: 711 [2400/2589 (93%)]\tLoss: 186.465164\n",
      "====> Epoch: 711 Average train loss: 226.3279\n",
      "====> Epoch: 711 Average test loss: 918.8002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 712 [0/2589 (0%)]\tLoss: 168.962173\n",
      "Train Epoch: 712 [300/2589 (12%)]\tLoss: 234.100037\n",
      "Train Epoch: 712 [600/2589 (23%)]\tLoss: 236.892441\n",
      "Train Epoch: 712 [900/2589 (35%)]\tLoss: 221.920578\n",
      "Train Epoch: 712 [1200/2589 (46%)]\tLoss: 415.620697\n",
      "Train Epoch: 712 [1500/2589 (58%)]\tLoss: 203.205780\n",
      "Train Epoch: 712 [1800/2589 (70%)]\tLoss: 192.690933\n",
      "Train Epoch: 712 [2100/2589 (81%)]\tLoss: 218.193527\n",
      "Train Epoch: 712 [2400/2589 (93%)]\tLoss: 176.886215\n",
      "====> Epoch: 712 Average train loss: 237.4179\n",
      "====> Epoch: 712 Average test loss: 929.6111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 713 [0/2589 (0%)]\tLoss: 227.390381\n",
      "Train Epoch: 713 [300/2589 (12%)]\tLoss: 335.402161\n",
      "Train Epoch: 713 [600/2589 (23%)]\tLoss: 277.053284\n",
      "Train Epoch: 713 [900/2589 (35%)]\tLoss: 245.450256\n",
      "Train Epoch: 713 [1200/2589 (46%)]\tLoss: 223.177902\n",
      "Train Epoch: 713 [1500/2589 (58%)]\tLoss: 295.192535\n",
      "Train Epoch: 713 [1800/2589 (70%)]\tLoss: 205.395355\n",
      "Train Epoch: 713 [2100/2589 (81%)]\tLoss: 252.506577\n",
      "Train Epoch: 713 [2400/2589 (93%)]\tLoss: 198.736908\n",
      "====> Epoch: 713 Average train loss: 224.9066\n",
      "====> Epoch: 713 Average test loss: 935.4022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 714 [0/2589 (0%)]\tLoss: 211.265915\n",
      "Train Epoch: 714 [300/2589 (12%)]\tLoss: 256.174408\n",
      "Train Epoch: 714 [600/2589 (23%)]\tLoss: 182.601013\n",
      "Train Epoch: 714 [900/2589 (35%)]\tLoss: 211.866516\n",
      "Train Epoch: 714 [1200/2589 (46%)]\tLoss: 285.433258\n",
      "Train Epoch: 714 [1500/2589 (58%)]\tLoss: 256.837280\n",
      "Train Epoch: 714 [1800/2589 (70%)]\tLoss: 265.923370\n",
      "Train Epoch: 714 [2100/2589 (81%)]\tLoss: 200.127350\n",
      "Train Epoch: 714 [2400/2589 (93%)]\tLoss: 272.663452\n",
      "====> Epoch: 714 Average train loss: 232.2261\n",
      "====> Epoch: 714 Average test loss: 935.2281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 715 [0/2589 (0%)]\tLoss: 270.703033\n",
      "Train Epoch: 715 [300/2589 (12%)]\tLoss: 222.311447\n",
      "Train Epoch: 715 [600/2589 (23%)]\tLoss: 191.686203\n",
      "Train Epoch: 715 [900/2589 (35%)]\tLoss: 165.261856\n",
      "Train Epoch: 715 [1200/2589 (46%)]\tLoss: 241.569611\n",
      "Train Epoch: 715 [1500/2589 (58%)]\tLoss: 207.180161\n",
      "Train Epoch: 715 [1800/2589 (70%)]\tLoss: 307.941986\n",
      "Train Epoch: 715 [2100/2589 (81%)]\tLoss: 260.831543\n",
      "Train Epoch: 715 [2400/2589 (93%)]\tLoss: 195.137711\n",
      "====> Epoch: 715 Average train loss: 225.9053\n",
      "====> Epoch: 715 Average test loss: 927.1843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 716 [0/2589 (0%)]\tLoss: 231.570099\n",
      "Train Epoch: 716 [300/2589 (12%)]\tLoss: 172.604813\n",
      "Train Epoch: 716 [600/2589 (23%)]\tLoss: 292.026733\n",
      "Train Epoch: 716 [900/2589 (35%)]\tLoss: 214.349579\n",
      "Train Epoch: 716 [1200/2589 (46%)]\tLoss: 276.432709\n",
      "Train Epoch: 716 [1500/2589 (58%)]\tLoss: 392.492767\n",
      "Train Epoch: 716 [1800/2589 (70%)]\tLoss: 129.324356\n",
      "Train Epoch: 716 [2100/2589 (81%)]\tLoss: 192.779510\n",
      "Train Epoch: 716 [2400/2589 (93%)]\tLoss: 272.222046\n",
      "====> Epoch: 716 Average train loss: 235.6763\n",
      "====> Epoch: 716 Average test loss: 917.0049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 717 [0/2589 (0%)]\tLoss: 241.542450\n",
      "Train Epoch: 717 [300/2589 (12%)]\tLoss: 416.120911\n",
      "Train Epoch: 717 [600/2589 (23%)]\tLoss: 233.891281\n",
      "Train Epoch: 717 [900/2589 (35%)]\tLoss: 178.332001\n",
      "Train Epoch: 717 [1200/2589 (46%)]\tLoss: 382.715759\n",
      "Train Epoch: 717 [1500/2589 (58%)]\tLoss: 196.763382\n",
      "Train Epoch: 717 [1800/2589 (70%)]\tLoss: 511.288483\n",
      "Train Epoch: 717 [2100/2589 (81%)]\tLoss: 197.649963\n",
      "Train Epoch: 717 [2400/2589 (93%)]\tLoss: 225.734802\n",
      "====> Epoch: 717 Average train loss: 242.0595\n",
      "====> Epoch: 717 Average test loss: 923.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 718 [0/2589 (0%)]\tLoss: 216.472244\n",
      "Train Epoch: 718 [300/2589 (12%)]\tLoss: 172.446091\n",
      "Train Epoch: 718 [600/2589 (23%)]\tLoss: 260.634705\n",
      "Train Epoch: 718 [900/2589 (35%)]\tLoss: 180.472305\n",
      "Train Epoch: 718 [1200/2589 (46%)]\tLoss: 173.974121\n",
      "Train Epoch: 718 [1500/2589 (58%)]\tLoss: 218.547653\n",
      "Train Epoch: 718 [1800/2589 (70%)]\tLoss: 201.998093\n",
      "Train Epoch: 718 [2100/2589 (81%)]\tLoss: 194.774246\n",
      "Train Epoch: 718 [2400/2589 (93%)]\tLoss: 300.583099\n",
      "====> Epoch: 718 Average train loss: 224.7605\n",
      "====> Epoch: 718 Average test loss: 932.0939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 719 [0/2589 (0%)]\tLoss: 180.862106\n",
      "Train Epoch: 719 [300/2589 (12%)]\tLoss: 167.442764\n",
      "Train Epoch: 719 [600/2589 (23%)]\tLoss: 228.048111\n",
      "Train Epoch: 719 [900/2589 (35%)]\tLoss: 170.036942\n",
      "Train Epoch: 719 [1200/2589 (46%)]\tLoss: 209.690720\n",
      "Train Epoch: 719 [1500/2589 (58%)]\tLoss: 324.515747\n",
      "Train Epoch: 719 [1800/2589 (70%)]\tLoss: 259.534393\n",
      "Train Epoch: 719 [2100/2589 (81%)]\tLoss: 232.998276\n",
      "Train Epoch: 719 [2400/2589 (93%)]\tLoss: 235.498718\n",
      "====> Epoch: 719 Average train loss: 234.7753\n",
      "====> Epoch: 719 Average test loss: 927.2061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 720 [0/2589 (0%)]\tLoss: 230.040878\n",
      "Train Epoch: 720 [300/2589 (12%)]\tLoss: 215.505524\n",
      "Train Epoch: 720 [600/2589 (23%)]\tLoss: 144.490662\n",
      "Train Epoch: 720 [900/2589 (35%)]\tLoss: 220.917328\n",
      "Train Epoch: 720 [1200/2589 (46%)]\tLoss: 173.180679\n",
      "Train Epoch: 720 [1500/2589 (58%)]\tLoss: 156.843918\n",
      "Train Epoch: 720 [1800/2589 (70%)]\tLoss: 176.444778\n",
      "Train Epoch: 720 [2100/2589 (81%)]\tLoss: 167.657303\n",
      "Train Epoch: 720 [2400/2589 (93%)]\tLoss: 233.758682\n",
      "====> Epoch: 720 Average train loss: 218.7426\n",
      "====> Epoch: 720 Average test loss: 922.5455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 721 [0/2589 (0%)]\tLoss: 210.242386\n",
      "Train Epoch: 721 [300/2589 (12%)]\tLoss: 225.042450\n",
      "Train Epoch: 721 [600/2589 (23%)]\tLoss: 184.712814\n",
      "Train Epoch: 721 [900/2589 (35%)]\tLoss: 264.458588\n",
      "Train Epoch: 721 [1200/2589 (46%)]\tLoss: 421.210999\n",
      "Train Epoch: 721 [1500/2589 (58%)]\tLoss: 243.021576\n",
      "Train Epoch: 721 [1800/2589 (70%)]\tLoss: 236.296951\n",
      "Train Epoch: 721 [2100/2589 (81%)]\tLoss: 171.619461\n",
      "Train Epoch: 721 [2400/2589 (93%)]\tLoss: 181.440948\n",
      "====> Epoch: 721 Average train loss: 241.2379\n",
      "====> Epoch: 721 Average test loss: 932.2819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 722 [0/2589 (0%)]\tLoss: 201.305374\n",
      "Train Epoch: 722 [300/2589 (12%)]\tLoss: 225.319687\n",
      "Train Epoch: 722 [600/2589 (23%)]\tLoss: 201.019775\n",
      "Train Epoch: 722 [900/2589 (35%)]\tLoss: 200.632095\n",
      "Train Epoch: 722 [1200/2589 (46%)]\tLoss: 188.368454\n",
      "Train Epoch: 722 [1500/2589 (58%)]\tLoss: 229.751801\n",
      "Train Epoch: 722 [1800/2589 (70%)]\tLoss: 201.872757\n",
      "Train Epoch: 722 [2100/2589 (81%)]\tLoss: 229.522461\n",
      "Train Epoch: 722 [2400/2589 (93%)]\tLoss: 253.426575\n",
      "====> Epoch: 722 Average train loss: 226.9434\n",
      "====> Epoch: 722 Average test loss: 921.2998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 723 [0/2589 (0%)]\tLoss: 264.967407\n",
      "Train Epoch: 723 [300/2589 (12%)]\tLoss: 195.446396\n",
      "Train Epoch: 723 [600/2589 (23%)]\tLoss: 195.504211\n",
      "Train Epoch: 723 [900/2589 (35%)]\tLoss: 291.774078\n",
      "Train Epoch: 723 [1200/2589 (46%)]\tLoss: 239.135666\n",
      "Train Epoch: 723 [1500/2589 (58%)]\tLoss: 173.183655\n",
      "Train Epoch: 723 [1800/2589 (70%)]\tLoss: 177.486740\n",
      "Train Epoch: 723 [2100/2589 (81%)]\tLoss: 274.372009\n",
      "Train Epoch: 723 [2400/2589 (93%)]\tLoss: 278.464996\n",
      "====> Epoch: 723 Average train loss: 238.7267\n",
      "====> Epoch: 723 Average test loss: 904.6013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 724 [0/2589 (0%)]\tLoss: 206.772614\n",
      "Train Epoch: 724 [300/2589 (12%)]\tLoss: 224.762192\n",
      "Train Epoch: 724 [600/2589 (23%)]\tLoss: 443.681671\n",
      "Train Epoch: 724 [900/2589 (35%)]\tLoss: 224.518448\n",
      "Train Epoch: 724 [1200/2589 (46%)]\tLoss: 194.096924\n",
      "Train Epoch: 724 [1500/2589 (58%)]\tLoss: 271.753479\n",
      "Train Epoch: 724 [1800/2589 (70%)]\tLoss: 268.173950\n",
      "Train Epoch: 724 [2100/2589 (81%)]\tLoss: 289.415405\n",
      "Train Epoch: 724 [2400/2589 (93%)]\tLoss: 190.410049\n",
      "====> Epoch: 724 Average train loss: 224.8691\n",
      "====> Epoch: 724 Average test loss: 925.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 725 [0/2589 (0%)]\tLoss: 174.986954\n",
      "Train Epoch: 725 [300/2589 (12%)]\tLoss: 206.911163\n",
      "Train Epoch: 725 [600/2589 (23%)]\tLoss: 249.100418\n",
      "Train Epoch: 725 [900/2589 (35%)]\tLoss: 216.568649\n",
      "Train Epoch: 725 [1200/2589 (46%)]\tLoss: 267.533752\n",
      "Train Epoch: 725 [1500/2589 (58%)]\tLoss: 222.987991\n",
      "Train Epoch: 725 [1800/2589 (70%)]\tLoss: 182.219070\n",
      "Train Epoch: 725 [2100/2589 (81%)]\tLoss: 203.646637\n",
      "Train Epoch: 725 [2400/2589 (93%)]\tLoss: 352.014130\n",
      "====> Epoch: 725 Average train loss: 233.5435\n",
      "====> Epoch: 725 Average test loss: 914.9199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 726 [0/2589 (0%)]\tLoss: 175.406998\n",
      "Train Epoch: 726 [300/2589 (12%)]\tLoss: 228.718674\n",
      "Train Epoch: 726 [600/2589 (23%)]\tLoss: 297.766602\n",
      "Train Epoch: 726 [900/2589 (35%)]\tLoss: 224.698013\n",
      "Train Epoch: 726 [1200/2589 (46%)]\tLoss: 215.837082\n",
      "Train Epoch: 726 [1500/2589 (58%)]\tLoss: 183.077164\n",
      "Train Epoch: 726 [1800/2589 (70%)]\tLoss: 175.708176\n",
      "Train Epoch: 726 [2100/2589 (81%)]\tLoss: 180.860779\n",
      "Train Epoch: 726 [2400/2589 (93%)]\tLoss: 170.750198\n",
      "====> Epoch: 726 Average train loss: 225.9436\n",
      "====> Epoch: 726 Average test loss: 944.9866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 727 [0/2589 (0%)]\tLoss: 229.976883\n",
      "Train Epoch: 727 [300/2589 (12%)]\tLoss: 211.588028\n",
      "Train Epoch: 727 [600/2589 (23%)]\tLoss: 217.662445\n",
      "Train Epoch: 727 [900/2589 (35%)]\tLoss: 356.603027\n",
      "Train Epoch: 727 [1200/2589 (46%)]\tLoss: 124.662445\n",
      "Train Epoch: 727 [1500/2589 (58%)]\tLoss: 293.157349\n",
      "Train Epoch: 727 [1800/2589 (70%)]\tLoss: 183.136459\n",
      "Train Epoch: 727 [2100/2589 (81%)]\tLoss: 206.513275\n",
      "Train Epoch: 727 [2400/2589 (93%)]\tLoss: 161.521133\n",
      "====> Epoch: 727 Average train loss: 226.1007\n",
      "====> Epoch: 727 Average test loss: 932.7616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 728 [0/2589 (0%)]\tLoss: 206.842636\n",
      "Train Epoch: 728 [300/2589 (12%)]\tLoss: 303.935883\n",
      "Train Epoch: 728 [600/2589 (23%)]\tLoss: 239.708481\n",
      "Train Epoch: 728 [900/2589 (35%)]\tLoss: 178.666489\n",
      "Train Epoch: 728 [1200/2589 (46%)]\tLoss: 152.644333\n",
      "Train Epoch: 728 [1500/2589 (58%)]\tLoss: 206.547668\n",
      "Train Epoch: 728 [1800/2589 (70%)]\tLoss: 162.281448\n",
      "Train Epoch: 728 [2100/2589 (81%)]\tLoss: 162.834824\n",
      "Train Epoch: 728 [2400/2589 (93%)]\tLoss: 235.061569\n",
      "====> Epoch: 728 Average train loss: 227.3198\n",
      "====> Epoch: 728 Average test loss: 928.2669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 729 [0/2589 (0%)]\tLoss: 201.966843\n",
      "Train Epoch: 729 [300/2589 (12%)]\tLoss: 247.872742\n",
      "Train Epoch: 729 [600/2589 (23%)]\tLoss: 193.149704\n",
      "Train Epoch: 729 [900/2589 (35%)]\tLoss: 195.780014\n",
      "Train Epoch: 729 [1200/2589 (46%)]\tLoss: 165.955017\n",
      "Train Epoch: 729 [1500/2589 (58%)]\tLoss: 188.627472\n",
      "Train Epoch: 729 [1800/2589 (70%)]\tLoss: 214.782623\n",
      "Train Epoch: 729 [2100/2589 (81%)]\tLoss: 390.449738\n",
      "Train Epoch: 729 [2400/2589 (93%)]\tLoss: 202.002502\n",
      "====> Epoch: 729 Average train loss: 224.7845\n",
      "====> Epoch: 729 Average test loss: 928.5215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 730 [0/2589 (0%)]\tLoss: 256.795013\n",
      "Train Epoch: 730 [300/2589 (12%)]\tLoss: 222.232697\n",
      "Train Epoch: 730 [600/2589 (23%)]\tLoss: 168.045471\n",
      "Train Epoch: 730 [900/2589 (35%)]\tLoss: 184.153671\n",
      "Train Epoch: 730 [1200/2589 (46%)]\tLoss: 190.418671\n",
      "Train Epoch: 730 [1500/2589 (58%)]\tLoss: 199.907822\n",
      "Train Epoch: 730 [1800/2589 (70%)]\tLoss: 215.339432\n",
      "Train Epoch: 730 [2100/2589 (81%)]\tLoss: 182.797806\n",
      "Train Epoch: 730 [2400/2589 (93%)]\tLoss: 332.781891\n",
      "====> Epoch: 730 Average train loss: 222.7578\n",
      "====> Epoch: 730 Average test loss: 939.5343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 731 [0/2589 (0%)]\tLoss: 278.393677\n",
      "Train Epoch: 731 [300/2589 (12%)]\tLoss: 243.279694\n",
      "Train Epoch: 731 [600/2589 (23%)]\tLoss: 224.718338\n",
      "Train Epoch: 731 [900/2589 (35%)]\tLoss: 198.464081\n",
      "Train Epoch: 731 [1200/2589 (46%)]\tLoss: 214.452087\n",
      "Train Epoch: 731 [1500/2589 (58%)]\tLoss: 215.560410\n",
      "Train Epoch: 731 [1800/2589 (70%)]\tLoss: 252.818024\n",
      "Train Epoch: 731 [2100/2589 (81%)]\tLoss: 192.423019\n",
      "Train Epoch: 731 [2400/2589 (93%)]\tLoss: 149.056580\n",
      "====> Epoch: 731 Average train loss: 235.3037\n",
      "====> Epoch: 731 Average test loss: 930.5679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 732 [0/2589 (0%)]\tLoss: 182.607346\n",
      "Train Epoch: 732 [300/2589 (12%)]\tLoss: 240.611526\n",
      "Train Epoch: 732 [600/2589 (23%)]\tLoss: 260.850128\n",
      "Train Epoch: 732 [900/2589 (35%)]\tLoss: 556.605042\n",
      "Train Epoch: 732 [1200/2589 (46%)]\tLoss: 146.577179\n",
      "Train Epoch: 732 [1500/2589 (58%)]\tLoss: 188.711487\n",
      "Train Epoch: 732 [1800/2589 (70%)]\tLoss: 165.624619\n",
      "Train Epoch: 732 [2100/2589 (81%)]\tLoss: 280.141724\n",
      "Train Epoch: 732 [2400/2589 (93%)]\tLoss: 163.038757\n",
      "====> Epoch: 732 Average train loss: 231.7488\n",
      "====> Epoch: 732 Average test loss: 940.8660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 733 [0/2589 (0%)]\tLoss: 244.897522\n",
      "Train Epoch: 733 [300/2589 (12%)]\tLoss: 183.960587\n",
      "Train Epoch: 733 [600/2589 (23%)]\tLoss: 216.060577\n",
      "Train Epoch: 733 [900/2589 (35%)]\tLoss: 172.891312\n",
      "Train Epoch: 733 [1200/2589 (46%)]\tLoss: 244.703568\n",
      "Train Epoch: 733 [1500/2589 (58%)]\tLoss: 219.932938\n",
      "Train Epoch: 733 [1800/2589 (70%)]\tLoss: 222.165039\n",
      "Train Epoch: 733 [2100/2589 (81%)]\tLoss: 225.409348\n",
      "Train Epoch: 733 [2400/2589 (93%)]\tLoss: 201.508987\n",
      "====> Epoch: 733 Average train loss: 236.8881\n",
      "====> Epoch: 733 Average test loss: 902.2478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 734 [0/2589 (0%)]\tLoss: 241.298355\n",
      "Train Epoch: 734 [300/2589 (12%)]\tLoss: 340.576355\n",
      "Train Epoch: 734 [600/2589 (23%)]\tLoss: 247.080490\n",
      "Train Epoch: 734 [900/2589 (35%)]\tLoss: 170.429138\n",
      "Train Epoch: 734 [1200/2589 (46%)]\tLoss: 248.538300\n",
      "Train Epoch: 734 [1500/2589 (58%)]\tLoss: 273.397278\n",
      "Train Epoch: 734 [1800/2589 (70%)]\tLoss: 353.002014\n",
      "Train Epoch: 734 [2100/2589 (81%)]\tLoss: 284.799011\n",
      "Train Epoch: 734 [2400/2589 (93%)]\tLoss: 187.172333\n",
      "====> Epoch: 734 Average train loss: 229.5877\n",
      "====> Epoch: 734 Average test loss: 934.1059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 735 [0/2589 (0%)]\tLoss: 160.346481\n",
      "Train Epoch: 735 [300/2589 (12%)]\tLoss: 166.092758\n",
      "Train Epoch: 735 [600/2589 (23%)]\tLoss: 186.966995\n",
      "Train Epoch: 735 [900/2589 (35%)]\tLoss: 251.372757\n",
      "Train Epoch: 735 [1200/2589 (46%)]\tLoss: 170.343842\n",
      "Train Epoch: 735 [1500/2589 (58%)]\tLoss: 226.947540\n",
      "Train Epoch: 735 [1800/2589 (70%)]\tLoss: 319.385895\n",
      "Train Epoch: 735 [2100/2589 (81%)]\tLoss: 208.616348\n",
      "Train Epoch: 735 [2400/2589 (93%)]\tLoss: 235.684265\n",
      "====> Epoch: 735 Average train loss: 225.8123\n",
      "====> Epoch: 735 Average test loss: 917.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 736 [0/2589 (0%)]\tLoss: 224.237823\n",
      "Train Epoch: 736 [300/2589 (12%)]\tLoss: 243.097229\n",
      "Train Epoch: 736 [600/2589 (23%)]\tLoss: 241.526260\n",
      "Train Epoch: 736 [900/2589 (35%)]\tLoss: 241.530182\n",
      "Train Epoch: 736 [1200/2589 (46%)]\tLoss: 199.743973\n",
      "Train Epoch: 736 [1500/2589 (58%)]\tLoss: 360.257843\n",
      "Train Epoch: 736 [1800/2589 (70%)]\tLoss: 261.341736\n",
      "Train Epoch: 736 [2100/2589 (81%)]\tLoss: 240.685226\n",
      "Train Epoch: 736 [2400/2589 (93%)]\tLoss: 172.668610\n",
      "====> Epoch: 736 Average train loss: 228.6258\n",
      "====> Epoch: 736 Average test loss: 930.2425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 737 [0/2589 (0%)]\tLoss: 188.737289\n",
      "Train Epoch: 737 [300/2589 (12%)]\tLoss: 208.933456\n",
      "Train Epoch: 737 [600/2589 (23%)]\tLoss: 255.735321\n",
      "Train Epoch: 737 [900/2589 (35%)]\tLoss: 134.430542\n",
      "Train Epoch: 737 [1200/2589 (46%)]\tLoss: 176.089050\n",
      "Train Epoch: 737 [1500/2589 (58%)]\tLoss: 246.895798\n",
      "Train Epoch: 737 [1800/2589 (70%)]\tLoss: 176.153549\n",
      "Train Epoch: 737 [2100/2589 (81%)]\tLoss: 322.996277\n",
      "Train Epoch: 737 [2400/2589 (93%)]\tLoss: 337.520844\n",
      "====> Epoch: 737 Average train loss: 240.9593\n",
      "====> Epoch: 737 Average test loss: 930.6790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 738 [0/2589 (0%)]\tLoss: 166.708176\n",
      "Train Epoch: 738 [300/2589 (12%)]\tLoss: 529.726624\n",
      "Train Epoch: 738 [600/2589 (23%)]\tLoss: 203.077072\n",
      "Train Epoch: 738 [900/2589 (35%)]\tLoss: 182.241211\n",
      "Train Epoch: 738 [1200/2589 (46%)]\tLoss: 291.079376\n",
      "Train Epoch: 738 [1500/2589 (58%)]\tLoss: 175.112076\n",
      "Train Epoch: 738 [1800/2589 (70%)]\tLoss: 223.391769\n",
      "Train Epoch: 738 [2100/2589 (81%)]\tLoss: 193.883072\n",
      "Train Epoch: 738 [2400/2589 (93%)]\tLoss: 262.122803\n",
      "====> Epoch: 738 Average train loss: 240.3705\n",
      "====> Epoch: 738 Average test loss: 913.5607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 739 [0/2589 (0%)]\tLoss: 233.914642\n",
      "Train Epoch: 739 [300/2589 (12%)]\tLoss: 345.798645\n",
      "Train Epoch: 739 [600/2589 (23%)]\tLoss: 354.204712\n",
      "Train Epoch: 739 [900/2589 (35%)]\tLoss: 220.184097\n",
      "Train Epoch: 739 [1200/2589 (46%)]\tLoss: 360.774048\n",
      "Train Epoch: 739 [1500/2589 (58%)]\tLoss: 241.443100\n",
      "Train Epoch: 739 [1800/2589 (70%)]\tLoss: 182.156815\n",
      "Train Epoch: 739 [2100/2589 (81%)]\tLoss: 253.203156\n",
      "Train Epoch: 739 [2400/2589 (93%)]\tLoss: 200.009094\n",
      "====> Epoch: 739 Average train loss: 243.1063\n",
      "====> Epoch: 739 Average test loss: 923.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 740 [0/2589 (0%)]\tLoss: 272.641968\n",
      "Train Epoch: 740 [300/2589 (12%)]\tLoss: 339.651886\n",
      "Train Epoch: 740 [600/2589 (23%)]\tLoss: 168.550873\n",
      "Train Epoch: 740 [900/2589 (35%)]\tLoss: 179.778564\n",
      "Train Epoch: 740 [1200/2589 (46%)]\tLoss: 235.658981\n",
      "Train Epoch: 740 [1500/2589 (58%)]\tLoss: 230.795853\n",
      "Train Epoch: 740 [1800/2589 (70%)]\tLoss: 177.289810\n",
      "Train Epoch: 740 [2100/2589 (81%)]\tLoss: 266.802307\n",
      "Train Epoch: 740 [2400/2589 (93%)]\tLoss: 266.572784\n",
      "====> Epoch: 740 Average train loss: 231.5682\n",
      "====> Epoch: 740 Average test loss: 910.8677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 741 [0/2589 (0%)]\tLoss: 195.441757\n",
      "Train Epoch: 741 [300/2589 (12%)]\tLoss: 333.106628\n",
      "Train Epoch: 741 [600/2589 (23%)]\tLoss: 452.343109\n",
      "Train Epoch: 741 [900/2589 (35%)]\tLoss: 217.580170\n",
      "Train Epoch: 741 [1200/2589 (46%)]\tLoss: 241.906693\n",
      "Train Epoch: 741 [1500/2589 (58%)]\tLoss: 190.573273\n",
      "Train Epoch: 741 [1800/2589 (70%)]\tLoss: 260.296509\n",
      "Train Epoch: 741 [2100/2589 (81%)]\tLoss: 202.807404\n",
      "Train Epoch: 741 [2400/2589 (93%)]\tLoss: 313.861420\n",
      "====> Epoch: 741 Average train loss: 231.1578\n",
      "====> Epoch: 741 Average test loss: 929.4772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 742 [0/2589 (0%)]\tLoss: 284.576080\n",
      "Train Epoch: 742 [300/2589 (12%)]\tLoss: 408.899750\n",
      "Train Epoch: 742 [600/2589 (23%)]\tLoss: 181.144592\n",
      "Train Epoch: 742 [900/2589 (35%)]\tLoss: 254.404022\n",
      "Train Epoch: 742 [1200/2589 (46%)]\tLoss: 250.113480\n",
      "Train Epoch: 742 [1500/2589 (58%)]\tLoss: 245.268524\n",
      "Train Epoch: 742 [1800/2589 (70%)]\tLoss: 333.862823\n",
      "Train Epoch: 742 [2100/2589 (81%)]\tLoss: 214.790512\n",
      "Train Epoch: 742 [2400/2589 (93%)]\tLoss: 322.091888\n",
      "====> Epoch: 742 Average train loss: 234.2056\n",
      "====> Epoch: 742 Average test loss: 920.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 743 [0/2589 (0%)]\tLoss: 144.504654\n",
      "Train Epoch: 743 [300/2589 (12%)]\tLoss: 187.768738\n",
      "Train Epoch: 743 [600/2589 (23%)]\tLoss: 208.042572\n",
      "Train Epoch: 743 [900/2589 (35%)]\tLoss: 175.412384\n",
      "Train Epoch: 743 [1200/2589 (46%)]\tLoss: 187.824005\n",
      "Train Epoch: 743 [1500/2589 (58%)]\tLoss: 407.893921\n",
      "Train Epoch: 743 [1800/2589 (70%)]\tLoss: 175.096024\n",
      "Train Epoch: 743 [2100/2589 (81%)]\tLoss: 161.672821\n",
      "Train Epoch: 743 [2400/2589 (93%)]\tLoss: 214.501175\n",
      "====> Epoch: 743 Average train loss: 234.3468\n",
      "====> Epoch: 743 Average test loss: 926.5548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 744 [0/2589 (0%)]\tLoss: 293.130432\n",
      "Train Epoch: 744 [300/2589 (12%)]\tLoss: 247.217102\n",
      "Train Epoch: 744 [600/2589 (23%)]\tLoss: 263.852142\n",
      "Train Epoch: 744 [900/2589 (35%)]\tLoss: 295.678864\n",
      "Train Epoch: 744 [1200/2589 (46%)]\tLoss: 165.249924\n",
      "Train Epoch: 744 [1500/2589 (58%)]\tLoss: 212.815323\n",
      "Train Epoch: 744 [1800/2589 (70%)]\tLoss: 266.657379\n",
      "Train Epoch: 744 [2100/2589 (81%)]\tLoss: 212.139236\n",
      "Train Epoch: 744 [2400/2589 (93%)]\tLoss: 208.428452\n",
      "====> Epoch: 744 Average train loss: 237.4189\n",
      "====> Epoch: 744 Average test loss: 920.0748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 745 [0/2589 (0%)]\tLoss: 305.642181\n",
      "Train Epoch: 745 [300/2589 (12%)]\tLoss: 200.156784\n",
      "Train Epoch: 745 [600/2589 (23%)]\tLoss: 159.916199\n",
      "Train Epoch: 745 [900/2589 (35%)]\tLoss: 215.069366\n",
      "Train Epoch: 745 [1200/2589 (46%)]\tLoss: 132.036392\n",
      "Train Epoch: 745 [1500/2589 (58%)]\tLoss: 271.796082\n",
      "Train Epoch: 745 [1800/2589 (70%)]\tLoss: 252.224030\n",
      "Train Epoch: 745 [2100/2589 (81%)]\tLoss: 249.038651\n",
      "Train Epoch: 745 [2400/2589 (93%)]\tLoss: 182.439102\n",
      "====> Epoch: 745 Average train loss: 231.9269\n",
      "====> Epoch: 745 Average test loss: 935.3744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 746 [0/2589 (0%)]\tLoss: 472.893982\n",
      "Train Epoch: 746 [300/2589 (12%)]\tLoss: 217.518127\n",
      "Train Epoch: 746 [600/2589 (23%)]\tLoss: 321.647003\n",
      "Train Epoch: 746 [900/2589 (35%)]\tLoss: 183.128860\n",
      "Train Epoch: 746 [1200/2589 (46%)]\tLoss: 252.724411\n",
      "Train Epoch: 746 [1500/2589 (58%)]\tLoss: 256.430695\n",
      "Train Epoch: 746 [1800/2589 (70%)]\tLoss: 225.329651\n",
      "Train Epoch: 746 [2100/2589 (81%)]\tLoss: 216.587402\n",
      "Train Epoch: 746 [2400/2589 (93%)]\tLoss: 280.116547\n",
      "====> Epoch: 746 Average train loss: 236.1515\n",
      "====> Epoch: 746 Average test loss: 915.6927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 747 [0/2589 (0%)]\tLoss: 198.533783\n",
      "Train Epoch: 747 [300/2589 (12%)]\tLoss: 174.176666\n",
      "Train Epoch: 747 [600/2589 (23%)]\tLoss: 175.234894\n",
      "Train Epoch: 747 [900/2589 (35%)]\tLoss: 238.610672\n",
      "Train Epoch: 747 [1200/2589 (46%)]\tLoss: 211.986740\n",
      "Train Epoch: 747 [1500/2589 (58%)]\tLoss: 243.812592\n",
      "Train Epoch: 747 [1800/2589 (70%)]\tLoss: 270.853088\n",
      "Train Epoch: 747 [2100/2589 (81%)]\tLoss: 204.534439\n",
      "Train Epoch: 747 [2400/2589 (93%)]\tLoss: 202.919937\n",
      "====> Epoch: 747 Average train loss: 233.8441\n",
      "====> Epoch: 747 Average test loss: 929.1382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 748 [0/2589 (0%)]\tLoss: 231.547455\n",
      "Train Epoch: 748 [300/2589 (12%)]\tLoss: 166.770569\n",
      "Train Epoch: 748 [600/2589 (23%)]\tLoss: 234.110245\n",
      "Train Epoch: 748 [900/2589 (35%)]\tLoss: 272.540680\n",
      "Train Epoch: 748 [1200/2589 (46%)]\tLoss: 212.570419\n",
      "Train Epoch: 748 [1500/2589 (58%)]\tLoss: 315.238007\n",
      "Train Epoch: 748 [1800/2589 (70%)]\tLoss: 198.073502\n",
      "Train Epoch: 748 [2100/2589 (81%)]\tLoss: 226.423111\n",
      "Train Epoch: 748 [2400/2589 (93%)]\tLoss: 206.336166\n",
      "====> Epoch: 748 Average train loss: 230.4626\n",
      "====> Epoch: 748 Average test loss: 933.3841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 749 [0/2589 (0%)]\tLoss: 288.184418\n",
      "Train Epoch: 749 [300/2589 (12%)]\tLoss: 207.364517\n",
      "Train Epoch: 749 [600/2589 (23%)]\tLoss: 167.896866\n",
      "Train Epoch: 749 [900/2589 (35%)]\tLoss: 173.718964\n",
      "Train Epoch: 749 [1200/2589 (46%)]\tLoss: 372.863556\n",
      "Train Epoch: 749 [1500/2589 (58%)]\tLoss: 209.458313\n",
      "Train Epoch: 749 [1800/2589 (70%)]\tLoss: 283.628052\n",
      "Train Epoch: 749 [2100/2589 (81%)]\tLoss: 274.863373\n",
      "Train Epoch: 749 [2400/2589 (93%)]\tLoss: 215.099396\n",
      "====> Epoch: 749 Average train loss: 232.6705\n",
      "====> Epoch: 749 Average test loss: 921.3451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 750 [0/2589 (0%)]\tLoss: 228.567093\n",
      "Train Epoch: 750 [300/2589 (12%)]\tLoss: 240.549332\n",
      "Train Epoch: 750 [600/2589 (23%)]\tLoss: 219.202530\n",
      "Train Epoch: 750 [900/2589 (35%)]\tLoss: 188.029007\n",
      "Train Epoch: 750 [1200/2589 (46%)]\tLoss: 223.441925\n",
      "Train Epoch: 750 [1500/2589 (58%)]\tLoss: 215.810028\n",
      "Train Epoch: 750 [1800/2589 (70%)]\tLoss: 208.226105\n",
      "Train Epoch: 750 [2100/2589 (81%)]\tLoss: 176.499313\n",
      "Train Epoch: 750 [2400/2589 (93%)]\tLoss: 263.015625\n",
      "====> Epoch: 750 Average train loss: 224.7210\n",
      "====> Epoch: 750 Average test loss: 909.4071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 751 [0/2589 (0%)]\tLoss: 235.191574\n",
      "Train Epoch: 751 [300/2589 (12%)]\tLoss: 551.337585\n",
      "Train Epoch: 751 [600/2589 (23%)]\tLoss: 246.139175\n",
      "Train Epoch: 751 [900/2589 (35%)]\tLoss: 224.449921\n",
      "Train Epoch: 751 [1200/2589 (46%)]\tLoss: 248.282166\n",
      "Train Epoch: 751 [1500/2589 (58%)]\tLoss: 273.024292\n",
      "Train Epoch: 751 [1800/2589 (70%)]\tLoss: 195.124512\n",
      "Train Epoch: 751 [2100/2589 (81%)]\tLoss: 256.573700\n",
      "Train Epoch: 751 [2400/2589 (93%)]\tLoss: 233.936874\n",
      "====> Epoch: 751 Average train loss: 236.2645\n",
      "====> Epoch: 751 Average test loss: 950.3907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 752 [0/2589 (0%)]\tLoss: 303.198303\n",
      "Train Epoch: 752 [300/2589 (12%)]\tLoss: 264.750092\n",
      "Train Epoch: 752 [600/2589 (23%)]\tLoss: 213.157043\n",
      "Train Epoch: 752 [900/2589 (35%)]\tLoss: 173.510239\n",
      "Train Epoch: 752 [1200/2589 (46%)]\tLoss: 280.430664\n",
      "Train Epoch: 752 [1500/2589 (58%)]\tLoss: 333.831055\n",
      "Train Epoch: 752 [1800/2589 (70%)]\tLoss: 212.182129\n",
      "Train Epoch: 752 [2100/2589 (81%)]\tLoss: 304.070129\n",
      "Train Epoch: 752 [2400/2589 (93%)]\tLoss: 208.396973\n",
      "====> Epoch: 752 Average train loss: 235.1208\n",
      "====> Epoch: 752 Average test loss: 923.0970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 753 [0/2589 (0%)]\tLoss: 194.824661\n",
      "Train Epoch: 753 [300/2589 (12%)]\tLoss: 240.614960\n",
      "Train Epoch: 753 [600/2589 (23%)]\tLoss: 160.102081\n",
      "Train Epoch: 753 [900/2589 (35%)]\tLoss: 188.154160\n",
      "Train Epoch: 753 [1200/2589 (46%)]\tLoss: 266.482178\n",
      "Train Epoch: 753 [1500/2589 (58%)]\tLoss: 205.107819\n",
      "Train Epoch: 753 [1800/2589 (70%)]\tLoss: 300.174652\n",
      "Train Epoch: 753 [2100/2589 (81%)]\tLoss: 229.886185\n",
      "Train Epoch: 753 [2400/2589 (93%)]\tLoss: 233.131256\n",
      "====> Epoch: 753 Average train loss: 233.9392\n",
      "====> Epoch: 753 Average test loss: 887.4952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 754 [0/2589 (0%)]\tLoss: 292.278503\n",
      "Train Epoch: 754 [300/2589 (12%)]\tLoss: 316.097870\n",
      "Train Epoch: 754 [600/2589 (23%)]\tLoss: 355.596008\n",
      "Train Epoch: 754 [900/2589 (35%)]\tLoss: 185.502243\n",
      "Train Epoch: 754 [1200/2589 (46%)]\tLoss: 245.338181\n",
      "Train Epoch: 754 [1500/2589 (58%)]\tLoss: 191.451172\n",
      "Train Epoch: 754 [1800/2589 (70%)]\tLoss: 198.654068\n",
      "Train Epoch: 754 [2100/2589 (81%)]\tLoss: 256.309448\n",
      "Train Epoch: 754 [2400/2589 (93%)]\tLoss: 230.579895\n",
      "====> Epoch: 754 Average train loss: 229.3496\n",
      "====> Epoch: 754 Average test loss: 918.3213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 755 [0/2589 (0%)]\tLoss: 211.079834\n",
      "Train Epoch: 755 [300/2589 (12%)]\tLoss: 252.719864\n",
      "Train Epoch: 755 [600/2589 (23%)]\tLoss: 162.809067\n",
      "Train Epoch: 755 [900/2589 (35%)]\tLoss: 185.100403\n",
      "Train Epoch: 755 [1200/2589 (46%)]\tLoss: 301.542633\n",
      "Train Epoch: 755 [1500/2589 (58%)]\tLoss: 175.804306\n",
      "Train Epoch: 755 [1800/2589 (70%)]\tLoss: 335.766571\n",
      "Train Epoch: 755 [2100/2589 (81%)]\tLoss: 205.408249\n",
      "Train Epoch: 755 [2400/2589 (93%)]\tLoss: 400.883881\n",
      "====> Epoch: 755 Average train loss: 233.5302\n",
      "====> Epoch: 755 Average test loss: 928.4930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 756 [0/2589 (0%)]\tLoss: 206.746124\n",
      "Train Epoch: 756 [300/2589 (12%)]\tLoss: 218.362381\n",
      "Train Epoch: 756 [600/2589 (23%)]\tLoss: 241.051483\n",
      "Train Epoch: 756 [900/2589 (35%)]\tLoss: 181.347015\n",
      "Train Epoch: 756 [1200/2589 (46%)]\tLoss: 238.806992\n",
      "Train Epoch: 756 [1500/2589 (58%)]\tLoss: 242.310791\n",
      "Train Epoch: 756 [1800/2589 (70%)]\tLoss: 199.968506\n",
      "Train Epoch: 756 [2100/2589 (81%)]\tLoss: 183.156693\n",
      "Train Epoch: 756 [2400/2589 (93%)]\tLoss: 203.603760\n",
      "====> Epoch: 756 Average train loss: 239.3958\n",
      "====> Epoch: 756 Average test loss: 915.8951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 757 [0/2589 (0%)]\tLoss: 249.696091\n",
      "Train Epoch: 757 [300/2589 (12%)]\tLoss: 207.325363\n",
      "Train Epoch: 757 [600/2589 (23%)]\tLoss: 160.469803\n",
      "Train Epoch: 757 [900/2589 (35%)]\tLoss: 229.776428\n",
      "Train Epoch: 757 [1200/2589 (46%)]\tLoss: 205.616882\n",
      "Train Epoch: 757 [1500/2589 (58%)]\tLoss: 295.601562\n",
      "Train Epoch: 757 [1800/2589 (70%)]\tLoss: 199.364975\n",
      "Train Epoch: 757 [2100/2589 (81%)]\tLoss: 131.705109\n",
      "Train Epoch: 757 [2400/2589 (93%)]\tLoss: 187.173798\n",
      "====> Epoch: 757 Average train loss: 231.5127\n",
      "====> Epoch: 757 Average test loss: 936.3358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 758 [0/2589 (0%)]\tLoss: 215.605011\n",
      "Train Epoch: 758 [300/2589 (12%)]\tLoss: 217.378845\n",
      "Train Epoch: 758 [600/2589 (23%)]\tLoss: 228.445023\n",
      "Train Epoch: 758 [900/2589 (35%)]\tLoss: 439.696381\n",
      "Train Epoch: 758 [1200/2589 (46%)]\tLoss: 265.524414\n",
      "Train Epoch: 758 [1500/2589 (58%)]\tLoss: 310.832642\n",
      "Train Epoch: 758 [1800/2589 (70%)]\tLoss: 218.482773\n",
      "Train Epoch: 758 [2100/2589 (81%)]\tLoss: 203.585709\n",
      "Train Epoch: 758 [2400/2589 (93%)]\tLoss: 252.236176\n",
      "====> Epoch: 758 Average train loss: 229.5616\n",
      "====> Epoch: 758 Average test loss: 940.7196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 759 [0/2589 (0%)]\tLoss: 399.007263\n",
      "Train Epoch: 759 [300/2589 (12%)]\tLoss: 258.138000\n",
      "Train Epoch: 759 [600/2589 (23%)]\tLoss: 277.304840\n",
      "Train Epoch: 759 [900/2589 (35%)]\tLoss: 221.323334\n",
      "Train Epoch: 759 [1200/2589 (46%)]\tLoss: 194.162537\n",
      "Train Epoch: 759 [1500/2589 (58%)]\tLoss: 191.372101\n",
      "Train Epoch: 759 [1800/2589 (70%)]\tLoss: 250.840332\n",
      "Train Epoch: 759 [2100/2589 (81%)]\tLoss: 210.903336\n",
      "Train Epoch: 759 [2400/2589 (93%)]\tLoss: 182.754532\n",
      "====> Epoch: 759 Average train loss: 233.4395\n",
      "====> Epoch: 759 Average test loss: 912.8572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 760 [0/2589 (0%)]\tLoss: 228.509323\n",
      "Train Epoch: 760 [300/2589 (12%)]\tLoss: 148.722763\n",
      "Train Epoch: 760 [600/2589 (23%)]\tLoss: 265.459503\n",
      "Train Epoch: 760 [900/2589 (35%)]\tLoss: 192.731308\n",
      "Train Epoch: 760 [1200/2589 (46%)]\tLoss: 209.500351\n",
      "Train Epoch: 760 [1500/2589 (58%)]\tLoss: 224.009689\n",
      "Train Epoch: 760 [1800/2589 (70%)]\tLoss: 349.207947\n",
      "Train Epoch: 760 [2100/2589 (81%)]\tLoss: 214.193924\n",
      "Train Epoch: 760 [2400/2589 (93%)]\tLoss: 188.283264\n",
      "====> Epoch: 760 Average train loss: 225.4145\n",
      "====> Epoch: 760 Average test loss: 930.8631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 761 [0/2589 (0%)]\tLoss: 262.366333\n",
      "Train Epoch: 761 [300/2589 (12%)]\tLoss: 180.912994\n",
      "Train Epoch: 761 [600/2589 (23%)]\tLoss: 256.341797\n",
      "Train Epoch: 761 [900/2589 (35%)]\tLoss: 165.389359\n",
      "Train Epoch: 761 [1200/2589 (46%)]\tLoss: 249.561813\n",
      "Train Epoch: 761 [1500/2589 (58%)]\tLoss: 231.989914\n",
      "Train Epoch: 761 [1800/2589 (70%)]\tLoss: 385.931702\n",
      "Train Epoch: 761 [2100/2589 (81%)]\tLoss: 142.018799\n",
      "Train Epoch: 761 [2400/2589 (93%)]\tLoss: 230.823761\n",
      "====> Epoch: 761 Average train loss: 224.8655\n",
      "====> Epoch: 761 Average test loss: 921.2173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 762 [0/2589 (0%)]\tLoss: 388.551910\n",
      "Train Epoch: 762 [300/2589 (12%)]\tLoss: 179.167801\n",
      "Train Epoch: 762 [600/2589 (23%)]\tLoss: 159.603531\n",
      "Train Epoch: 762 [900/2589 (35%)]\tLoss: 195.869217\n",
      "Train Epoch: 762 [1200/2589 (46%)]\tLoss: 177.755157\n",
      "Train Epoch: 762 [1500/2589 (58%)]\tLoss: 220.053680\n",
      "Train Epoch: 762 [1800/2589 (70%)]\tLoss: 226.542969\n",
      "Train Epoch: 762 [2100/2589 (81%)]\tLoss: 173.160995\n",
      "Train Epoch: 762 [2400/2589 (93%)]\tLoss: 245.349289\n",
      "====> Epoch: 762 Average train loss: 221.7535\n",
      "====> Epoch: 762 Average test loss: 936.6171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 763 [0/2589 (0%)]\tLoss: 245.770279\n",
      "Train Epoch: 763 [300/2589 (12%)]\tLoss: 250.409317\n",
      "Train Epoch: 763 [600/2589 (23%)]\tLoss: 189.823181\n",
      "Train Epoch: 763 [900/2589 (35%)]\tLoss: 315.122467\n",
      "Train Epoch: 763 [1200/2589 (46%)]\tLoss: 177.876404\n",
      "Train Epoch: 763 [1500/2589 (58%)]\tLoss: 181.994064\n",
      "Train Epoch: 763 [1800/2589 (70%)]\tLoss: 193.433578\n",
      "Train Epoch: 763 [2100/2589 (81%)]\tLoss: 367.466766\n",
      "Train Epoch: 763 [2400/2589 (93%)]\tLoss: 157.139664\n",
      "====> Epoch: 763 Average train loss: 231.5222\n",
      "====> Epoch: 763 Average test loss: 932.5391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 764 [0/2589 (0%)]\tLoss: 276.286438\n",
      "Train Epoch: 764 [300/2589 (12%)]\tLoss: 225.904327\n",
      "Train Epoch: 764 [600/2589 (23%)]\tLoss: 349.795380\n",
      "Train Epoch: 764 [900/2589 (35%)]\tLoss: 211.006042\n",
      "Train Epoch: 764 [1200/2589 (46%)]\tLoss: 175.225906\n",
      "Train Epoch: 764 [1500/2589 (58%)]\tLoss: 290.660004\n",
      "Train Epoch: 764 [1800/2589 (70%)]\tLoss: 251.305984\n",
      "Train Epoch: 764 [2100/2589 (81%)]\tLoss: 202.046326\n",
      "Train Epoch: 764 [2400/2589 (93%)]\tLoss: 223.760742\n",
      "====> Epoch: 764 Average train loss: 228.0066\n",
      "====> Epoch: 764 Average test loss: 933.3027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 765 [0/2589 (0%)]\tLoss: 252.386383\n",
      "Train Epoch: 765 [300/2589 (12%)]\tLoss: 240.660233\n",
      "Train Epoch: 765 [600/2589 (23%)]\tLoss: 244.853546\n",
      "Train Epoch: 765 [900/2589 (35%)]\tLoss: 253.994110\n",
      "Train Epoch: 765 [1200/2589 (46%)]\tLoss: 204.022430\n",
      "Train Epoch: 765 [1500/2589 (58%)]\tLoss: 219.794296\n",
      "Train Epoch: 765 [1800/2589 (70%)]\tLoss: 214.014633\n",
      "Train Epoch: 765 [2100/2589 (81%)]\tLoss: 173.952087\n",
      "Train Epoch: 765 [2400/2589 (93%)]\tLoss: 230.021194\n",
      "====> Epoch: 765 Average train loss: 223.0784\n",
      "====> Epoch: 765 Average test loss: 929.8088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 766 [0/2589 (0%)]\tLoss: 242.206757\n",
      "Train Epoch: 766 [300/2589 (12%)]\tLoss: 227.642624\n",
      "Train Epoch: 766 [600/2589 (23%)]\tLoss: 198.857742\n",
      "Train Epoch: 766 [900/2589 (35%)]\tLoss: 294.178925\n",
      "Train Epoch: 766 [1200/2589 (46%)]\tLoss: 263.414490\n",
      "Train Epoch: 766 [1500/2589 (58%)]\tLoss: 340.690430\n",
      "Train Epoch: 766 [1800/2589 (70%)]\tLoss: 246.143265\n",
      "Train Epoch: 766 [2100/2589 (81%)]\tLoss: 179.526810\n",
      "Train Epoch: 766 [2400/2589 (93%)]\tLoss: 202.184052\n",
      "====> Epoch: 766 Average train loss: 227.8365\n",
      "====> Epoch: 766 Average test loss: 939.1506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 767 [0/2589 (0%)]\tLoss: 188.136154\n",
      "Train Epoch: 767 [300/2589 (12%)]\tLoss: 243.775085\n",
      "Train Epoch: 767 [600/2589 (23%)]\tLoss: 221.263245\n",
      "Train Epoch: 767 [900/2589 (35%)]\tLoss: 289.385925\n",
      "Train Epoch: 767 [1200/2589 (46%)]\tLoss: 201.718430\n",
      "Train Epoch: 767 [1500/2589 (58%)]\tLoss: 241.467987\n",
      "Train Epoch: 767 [1800/2589 (70%)]\tLoss: 296.301849\n",
      "Train Epoch: 767 [2100/2589 (81%)]\tLoss: 218.425583\n",
      "Train Epoch: 767 [2400/2589 (93%)]\tLoss: 266.164429\n",
      "====> Epoch: 767 Average train loss: 230.3974\n",
      "====> Epoch: 767 Average test loss: 914.0834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 768 [0/2589 (0%)]\tLoss: 209.658768\n",
      "Train Epoch: 768 [300/2589 (12%)]\tLoss: 216.642105\n",
      "Train Epoch: 768 [600/2589 (23%)]\tLoss: 185.488937\n",
      "Train Epoch: 768 [900/2589 (35%)]\tLoss: 152.940170\n",
      "Train Epoch: 768 [1200/2589 (46%)]\tLoss: 209.318863\n",
      "Train Epoch: 768 [1500/2589 (58%)]\tLoss: 457.798126\n",
      "Train Epoch: 768 [1800/2589 (70%)]\tLoss: 139.811127\n",
      "Train Epoch: 768 [2100/2589 (81%)]\tLoss: 196.946396\n",
      "Train Epoch: 768 [2400/2589 (93%)]\tLoss: 163.384933\n",
      "====> Epoch: 768 Average train loss: 224.5341\n",
      "====> Epoch: 768 Average test loss: 918.4409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 769 [0/2589 (0%)]\tLoss: 270.998260\n",
      "Train Epoch: 769 [300/2589 (12%)]\tLoss: 239.828156\n",
      "Train Epoch: 769 [600/2589 (23%)]\tLoss: 151.101501\n",
      "Train Epoch: 769 [900/2589 (35%)]\tLoss: 213.067245\n",
      "Train Epoch: 769 [1200/2589 (46%)]\tLoss: 210.662140\n",
      "Train Epoch: 769 [1500/2589 (58%)]\tLoss: 249.592316\n",
      "Train Epoch: 769 [1800/2589 (70%)]\tLoss: 201.166183\n",
      "Train Epoch: 769 [2100/2589 (81%)]\tLoss: 213.074966\n",
      "Train Epoch: 769 [2400/2589 (93%)]\tLoss: 243.152481\n",
      "====> Epoch: 769 Average train loss: 222.2863\n",
      "====> Epoch: 769 Average test loss: 924.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 770 [0/2589 (0%)]\tLoss: 149.952698\n",
      "Train Epoch: 770 [300/2589 (12%)]\tLoss: 176.698273\n",
      "Train Epoch: 770 [600/2589 (23%)]\tLoss: 226.736481\n",
      "Train Epoch: 770 [900/2589 (35%)]\tLoss: 177.991974\n",
      "Train Epoch: 770 [1200/2589 (46%)]\tLoss: 173.234802\n",
      "Train Epoch: 770 [1500/2589 (58%)]\tLoss: 170.422775\n",
      "Train Epoch: 770 [1800/2589 (70%)]\tLoss: 266.207886\n",
      "Train Epoch: 770 [2100/2589 (81%)]\tLoss: 184.369690\n",
      "Train Epoch: 770 [2400/2589 (93%)]\tLoss: 152.933807\n",
      "====> Epoch: 770 Average train loss: 241.8361\n",
      "====> Epoch: 770 Average test loss: 922.8170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 771 [0/2589 (0%)]\tLoss: 227.971298\n",
      "Train Epoch: 771 [300/2589 (12%)]\tLoss: 274.720123\n",
      "Train Epoch: 771 [600/2589 (23%)]\tLoss: 225.088837\n",
      "Train Epoch: 771 [900/2589 (35%)]\tLoss: 244.860168\n",
      "Train Epoch: 771 [1200/2589 (46%)]\tLoss: 316.427765\n",
      "Train Epoch: 771 [1500/2589 (58%)]\tLoss: 185.724472\n",
      "Train Epoch: 771 [1800/2589 (70%)]\tLoss: 343.642029\n",
      "Train Epoch: 771 [2100/2589 (81%)]\tLoss: 263.934723\n",
      "Train Epoch: 771 [2400/2589 (93%)]\tLoss: 190.492050\n",
      "====> Epoch: 771 Average train loss: 243.4018\n",
      "====> Epoch: 771 Average test loss: 944.4625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 772 [0/2589 (0%)]\tLoss: 113.656296\n",
      "Train Epoch: 772 [300/2589 (12%)]\tLoss: 278.701111\n",
      "Train Epoch: 772 [600/2589 (23%)]\tLoss: 178.912643\n",
      "Train Epoch: 772 [900/2589 (35%)]\tLoss: 160.616028\n",
      "Train Epoch: 772 [1200/2589 (46%)]\tLoss: 185.015244\n",
      "Train Epoch: 772 [1500/2589 (58%)]\tLoss: 248.965103\n",
      "Train Epoch: 772 [1800/2589 (70%)]\tLoss: 187.974380\n",
      "Train Epoch: 772 [2100/2589 (81%)]\tLoss: 227.383957\n",
      "Train Epoch: 772 [2400/2589 (93%)]\tLoss: 272.335297\n",
      "====> Epoch: 772 Average train loss: 235.3018\n",
      "====> Epoch: 772 Average test loss: 918.8835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 773 [0/2589 (0%)]\tLoss: 197.563995\n",
      "Train Epoch: 773 [300/2589 (12%)]\tLoss: 168.368423\n",
      "Train Epoch: 773 [600/2589 (23%)]\tLoss: 210.045013\n",
      "Train Epoch: 773 [900/2589 (35%)]\tLoss: 421.821289\n",
      "Train Epoch: 773 [1200/2589 (46%)]\tLoss: 202.834610\n",
      "Train Epoch: 773 [1500/2589 (58%)]\tLoss: 216.841324\n",
      "Train Epoch: 773 [1800/2589 (70%)]\tLoss: 211.845367\n",
      "Train Epoch: 773 [2100/2589 (81%)]\tLoss: 227.199997\n",
      "Train Epoch: 773 [2400/2589 (93%)]\tLoss: 201.849060\n",
      "====> Epoch: 773 Average train loss: 228.7345\n",
      "====> Epoch: 773 Average test loss: 907.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 774 [0/2589 (0%)]\tLoss: 191.094955\n",
      "Train Epoch: 774 [300/2589 (12%)]\tLoss: 135.580963\n",
      "Train Epoch: 774 [600/2589 (23%)]\tLoss: 190.875259\n",
      "Train Epoch: 774 [900/2589 (35%)]\tLoss: 163.443192\n",
      "Train Epoch: 774 [1200/2589 (46%)]\tLoss: 216.371902\n",
      "Train Epoch: 774 [1500/2589 (58%)]\tLoss: 206.094421\n",
      "Train Epoch: 774 [1800/2589 (70%)]\tLoss: 230.971115\n",
      "Train Epoch: 774 [2100/2589 (81%)]\tLoss: 160.733719\n",
      "Train Epoch: 774 [2400/2589 (93%)]\tLoss: 193.675858\n",
      "====> Epoch: 774 Average train loss: 230.3942\n",
      "====> Epoch: 774 Average test loss: 917.7537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 775 [0/2589 (0%)]\tLoss: 231.376602\n",
      "Train Epoch: 775 [300/2589 (12%)]\tLoss: 216.878265\n",
      "Train Epoch: 775 [600/2589 (23%)]\tLoss: 195.888824\n",
      "Train Epoch: 775 [900/2589 (35%)]\tLoss: 174.915009\n",
      "Train Epoch: 775 [1200/2589 (46%)]\tLoss: 263.892914\n",
      "Train Epoch: 775 [1500/2589 (58%)]\tLoss: 195.554855\n",
      "Train Epoch: 775 [1800/2589 (70%)]\tLoss: 182.136795\n",
      "Train Epoch: 775 [2100/2589 (81%)]\tLoss: 200.397354\n",
      "Train Epoch: 775 [2400/2589 (93%)]\tLoss: 232.800690\n",
      "====> Epoch: 775 Average train loss: 235.9734\n",
      "====> Epoch: 775 Average test loss: 928.4144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 776 [0/2589 (0%)]\tLoss: 170.458405\n",
      "Train Epoch: 776 [300/2589 (12%)]\tLoss: 224.025681\n",
      "Train Epoch: 776 [600/2589 (23%)]\tLoss: 196.610489\n",
      "Train Epoch: 776 [900/2589 (35%)]\tLoss: 306.778107\n",
      "Train Epoch: 776 [1200/2589 (46%)]\tLoss: 220.015915\n",
      "Train Epoch: 776 [1500/2589 (58%)]\tLoss: 267.121460\n",
      "Train Epoch: 776 [1800/2589 (70%)]\tLoss: 265.278839\n",
      "Train Epoch: 776 [2100/2589 (81%)]\tLoss: 307.966583\n",
      "Train Epoch: 776 [2400/2589 (93%)]\tLoss: 220.954025\n",
      "====> Epoch: 776 Average train loss: 230.4842\n",
      "====> Epoch: 776 Average test loss: 940.5654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 777 [0/2589 (0%)]\tLoss: 194.558640\n",
      "Train Epoch: 777 [300/2589 (12%)]\tLoss: 149.022400\n",
      "Train Epoch: 777 [600/2589 (23%)]\tLoss: 258.556763\n",
      "Train Epoch: 777 [900/2589 (35%)]\tLoss: 276.200684\n",
      "Train Epoch: 777 [1200/2589 (46%)]\tLoss: 235.250977\n",
      "Train Epoch: 777 [1500/2589 (58%)]\tLoss: 163.374741\n",
      "Train Epoch: 777 [1800/2589 (70%)]\tLoss: 194.734222\n",
      "Train Epoch: 777 [2100/2589 (81%)]\tLoss: 220.764984\n",
      "Train Epoch: 777 [2400/2589 (93%)]\tLoss: 187.290939\n",
      "====> Epoch: 777 Average train loss: 231.3927\n",
      "====> Epoch: 777 Average test loss: 909.4650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 778 [0/2589 (0%)]\tLoss: 186.323059\n",
      "Train Epoch: 778 [300/2589 (12%)]\tLoss: 180.674316\n",
      "Train Epoch: 778 [600/2589 (23%)]\tLoss: 295.374420\n",
      "Train Epoch: 778 [900/2589 (35%)]\tLoss: 191.810150\n",
      "Train Epoch: 778 [1200/2589 (46%)]\tLoss: 282.623138\n",
      "Train Epoch: 778 [1500/2589 (58%)]\tLoss: 213.774033\n",
      "Train Epoch: 778 [1800/2589 (70%)]\tLoss: 248.020325\n",
      "Train Epoch: 778 [2100/2589 (81%)]\tLoss: 371.385559\n",
      "Train Epoch: 778 [2400/2589 (93%)]\tLoss: 172.462997\n",
      "====> Epoch: 778 Average train loss: 224.5846\n",
      "====> Epoch: 778 Average test loss: 907.2331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 779 [0/2589 (0%)]\tLoss: 132.997208\n",
      "Train Epoch: 779 [300/2589 (12%)]\tLoss: 259.222443\n",
      "Train Epoch: 779 [600/2589 (23%)]\tLoss: 227.217529\n",
      "Train Epoch: 779 [900/2589 (35%)]\tLoss: 233.832199\n",
      "Train Epoch: 779 [1200/2589 (46%)]\tLoss: 297.728790\n",
      "Train Epoch: 779 [1500/2589 (58%)]\tLoss: 299.458344\n",
      "Train Epoch: 779 [1800/2589 (70%)]\tLoss: 270.439789\n",
      "Train Epoch: 779 [2100/2589 (81%)]\tLoss: 580.792053\n",
      "Train Epoch: 779 [2400/2589 (93%)]\tLoss: 223.843414\n",
      "====> Epoch: 779 Average train loss: 231.2379\n",
      "====> Epoch: 779 Average test loss: 918.0778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 780 [0/2589 (0%)]\tLoss: 290.218597\n",
      "Train Epoch: 780 [300/2589 (12%)]\tLoss: 196.496048\n",
      "Train Epoch: 780 [600/2589 (23%)]\tLoss: 181.885742\n",
      "Train Epoch: 780 [900/2589 (35%)]\tLoss: 350.912476\n",
      "Train Epoch: 780 [1200/2589 (46%)]\tLoss: 166.188126\n",
      "Train Epoch: 780 [1500/2589 (58%)]\tLoss: 209.687057\n",
      "Train Epoch: 780 [1800/2589 (70%)]\tLoss: 298.556610\n",
      "Train Epoch: 780 [2100/2589 (81%)]\tLoss: 233.614975\n",
      "Train Epoch: 780 [2400/2589 (93%)]\tLoss: 210.969650\n",
      "====> Epoch: 780 Average train loss: 229.0451\n",
      "====> Epoch: 780 Average test loss: 920.3412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 781 [0/2589 (0%)]\tLoss: 256.770752\n",
      "Train Epoch: 781 [300/2589 (12%)]\tLoss: 186.257477\n",
      "Train Epoch: 781 [600/2589 (23%)]\tLoss: 201.955093\n",
      "Train Epoch: 781 [900/2589 (35%)]\tLoss: 236.720871\n",
      "Train Epoch: 781 [1200/2589 (46%)]\tLoss: 376.695923\n",
      "Train Epoch: 781 [1500/2589 (58%)]\tLoss: 230.780273\n",
      "Train Epoch: 781 [1800/2589 (70%)]\tLoss: 172.551102\n",
      "Train Epoch: 781 [2100/2589 (81%)]\tLoss: 151.412659\n",
      "Train Epoch: 781 [2400/2589 (93%)]\tLoss: 192.121582\n",
      "====> Epoch: 781 Average train loss: 225.9884\n",
      "====> Epoch: 781 Average test loss: 920.2222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 782 [0/2589 (0%)]\tLoss: 171.744781\n",
      "Train Epoch: 782 [300/2589 (12%)]\tLoss: 239.245667\n",
      "Train Epoch: 782 [600/2589 (23%)]\tLoss: 347.442047\n",
      "Train Epoch: 782 [900/2589 (35%)]\tLoss: 244.651428\n",
      "Train Epoch: 782 [1200/2589 (46%)]\tLoss: 255.156799\n",
      "Train Epoch: 782 [1500/2589 (58%)]\tLoss: 260.435638\n",
      "Train Epoch: 782 [1800/2589 (70%)]\tLoss: 225.432770\n",
      "Train Epoch: 782 [2100/2589 (81%)]\tLoss: 161.894760\n",
      "Train Epoch: 782 [2400/2589 (93%)]\tLoss: 215.813126\n",
      "====> Epoch: 782 Average train loss: 229.8716\n",
      "====> Epoch: 782 Average test loss: 930.6821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 783 [0/2589 (0%)]\tLoss: 216.814529\n",
      "Train Epoch: 783 [300/2589 (12%)]\tLoss: 295.029633\n",
      "Train Epoch: 783 [600/2589 (23%)]\tLoss: 184.520248\n",
      "Train Epoch: 783 [900/2589 (35%)]\tLoss: 195.118866\n",
      "Train Epoch: 783 [1200/2589 (46%)]\tLoss: 271.283813\n",
      "Train Epoch: 783 [1500/2589 (58%)]\tLoss: 237.519745\n",
      "Train Epoch: 783 [1800/2589 (70%)]\tLoss: 272.044373\n",
      "Train Epoch: 783 [2100/2589 (81%)]\tLoss: 273.397430\n",
      "Train Epoch: 783 [2400/2589 (93%)]\tLoss: 294.263824\n",
      "====> Epoch: 783 Average train loss: 236.5037\n",
      "====> Epoch: 783 Average test loss: 905.5007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 784 [0/2589 (0%)]\tLoss: 184.087357\n",
      "Train Epoch: 784 [300/2589 (12%)]\tLoss: 228.698441\n",
      "Train Epoch: 784 [600/2589 (23%)]\tLoss: 193.462799\n",
      "Train Epoch: 784 [900/2589 (35%)]\tLoss: 283.835846\n",
      "Train Epoch: 784 [1200/2589 (46%)]\tLoss: 257.478760\n",
      "Train Epoch: 784 [1500/2589 (58%)]\tLoss: 224.746399\n",
      "Train Epoch: 784 [1800/2589 (70%)]\tLoss: 212.572906\n",
      "Train Epoch: 784 [2100/2589 (81%)]\tLoss: 266.186646\n",
      "Train Epoch: 784 [2400/2589 (93%)]\tLoss: 137.262375\n",
      "====> Epoch: 784 Average train loss: 222.7617\n",
      "====> Epoch: 784 Average test loss: 916.7612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 785 [0/2589 (0%)]\tLoss: 235.448135\n",
      "Train Epoch: 785 [300/2589 (12%)]\tLoss: 377.133392\n",
      "Train Epoch: 785 [600/2589 (23%)]\tLoss: 211.993958\n",
      "Train Epoch: 785 [900/2589 (35%)]\tLoss: 175.770996\n",
      "Train Epoch: 785 [1200/2589 (46%)]\tLoss: 192.561966\n",
      "Train Epoch: 785 [1500/2589 (58%)]\tLoss: 207.729477\n",
      "Train Epoch: 785 [1800/2589 (70%)]\tLoss: 333.503723\n",
      "Train Epoch: 785 [2100/2589 (81%)]\tLoss: 218.674164\n",
      "Train Epoch: 785 [2400/2589 (93%)]\tLoss: 210.282303\n",
      "====> Epoch: 785 Average train loss: 219.4843\n",
      "====> Epoch: 785 Average test loss: 934.0158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 786 [0/2589 (0%)]\tLoss: 152.329498\n",
      "Train Epoch: 786 [300/2589 (12%)]\tLoss: 168.338028\n",
      "Train Epoch: 786 [600/2589 (23%)]\tLoss: 229.962540\n",
      "Train Epoch: 786 [900/2589 (35%)]\tLoss: 168.913086\n",
      "Train Epoch: 786 [1200/2589 (46%)]\tLoss: 166.336258\n",
      "Train Epoch: 786 [1500/2589 (58%)]\tLoss: 165.764984\n",
      "Train Epoch: 786 [1800/2589 (70%)]\tLoss: 220.552643\n",
      "Train Epoch: 786 [2100/2589 (81%)]\tLoss: 147.168228\n",
      "Train Epoch: 786 [2400/2589 (93%)]\tLoss: 160.173813\n",
      "====> Epoch: 786 Average train loss: 222.2796\n",
      "====> Epoch: 786 Average test loss: 919.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 787 [0/2589 (0%)]\tLoss: 265.150421\n",
      "Train Epoch: 787 [300/2589 (12%)]\tLoss: 350.384766\n",
      "Train Epoch: 787 [600/2589 (23%)]\tLoss: 240.077545\n",
      "Train Epoch: 787 [900/2589 (35%)]\tLoss: 194.033585\n",
      "Train Epoch: 787 [1200/2589 (46%)]\tLoss: 195.053848\n",
      "Train Epoch: 787 [1500/2589 (58%)]\tLoss: 226.387802\n",
      "Train Epoch: 787 [1800/2589 (70%)]\tLoss: 219.561340\n",
      "Train Epoch: 787 [2100/2589 (81%)]\tLoss: 226.600784\n",
      "Train Epoch: 787 [2400/2589 (93%)]\tLoss: 233.995712\n",
      "====> Epoch: 787 Average train loss: 237.8611\n",
      "====> Epoch: 787 Average test loss: 918.8957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 788 [0/2589 (0%)]\tLoss: 209.872467\n",
      "Train Epoch: 788 [300/2589 (12%)]\tLoss: 241.377975\n",
      "Train Epoch: 788 [600/2589 (23%)]\tLoss: 254.403214\n",
      "Train Epoch: 788 [900/2589 (35%)]\tLoss: 262.745758\n",
      "Train Epoch: 788 [1200/2589 (46%)]\tLoss: 294.183380\n",
      "Train Epoch: 788 [1500/2589 (58%)]\tLoss: 139.569733\n",
      "Train Epoch: 788 [1800/2589 (70%)]\tLoss: 191.983887\n",
      "Train Epoch: 788 [2100/2589 (81%)]\tLoss: 176.868622\n",
      "Train Epoch: 788 [2400/2589 (93%)]\tLoss: 213.049744\n",
      "====> Epoch: 788 Average train loss: 221.3685\n",
      "====> Epoch: 788 Average test loss: 936.7821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 789 [0/2589 (0%)]\tLoss: 229.507996\n",
      "Train Epoch: 789 [300/2589 (12%)]\tLoss: 267.483948\n",
      "Train Epoch: 789 [600/2589 (23%)]\tLoss: 244.490479\n",
      "Train Epoch: 789 [900/2589 (35%)]\tLoss: 174.880600\n",
      "Train Epoch: 789 [1200/2589 (46%)]\tLoss: 184.389404\n",
      "Train Epoch: 789 [1500/2589 (58%)]\tLoss: 323.346649\n",
      "Train Epoch: 789 [1800/2589 (70%)]\tLoss: 164.734451\n",
      "Train Epoch: 789 [2100/2589 (81%)]\tLoss: 432.259277\n",
      "Train Epoch: 789 [2400/2589 (93%)]\tLoss: 354.647980\n",
      "====> Epoch: 789 Average train loss: 219.6028\n",
      "====> Epoch: 789 Average test loss: 906.6262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 790 [0/2589 (0%)]\tLoss: 157.698898\n",
      "Train Epoch: 790 [300/2589 (12%)]\tLoss: 154.571396\n",
      "Train Epoch: 790 [600/2589 (23%)]\tLoss: 322.281616\n",
      "Train Epoch: 790 [900/2589 (35%)]\tLoss: 197.097198\n",
      "Train Epoch: 790 [1200/2589 (46%)]\tLoss: 271.460022\n",
      "Train Epoch: 790 [1500/2589 (58%)]\tLoss: 272.013306\n",
      "Train Epoch: 790 [1800/2589 (70%)]\tLoss: 173.545212\n",
      "Train Epoch: 790 [2100/2589 (81%)]\tLoss: 195.798935\n",
      "Train Epoch: 790 [2400/2589 (93%)]\tLoss: 235.380722\n",
      "====> Epoch: 790 Average train loss: 221.6686\n",
      "====> Epoch: 790 Average test loss: 920.2072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 791 [0/2589 (0%)]\tLoss: 214.788513\n",
      "Train Epoch: 791 [300/2589 (12%)]\tLoss: 186.625000\n",
      "Train Epoch: 791 [600/2589 (23%)]\tLoss: 207.799362\n",
      "Train Epoch: 791 [900/2589 (35%)]\tLoss: 168.103088\n",
      "Train Epoch: 791 [1200/2589 (46%)]\tLoss: 237.294327\n",
      "Train Epoch: 791 [1500/2589 (58%)]\tLoss: 250.932358\n",
      "Train Epoch: 791 [1800/2589 (70%)]\tLoss: 145.466461\n",
      "Train Epoch: 791 [2100/2589 (81%)]\tLoss: 177.291046\n",
      "Train Epoch: 791 [2400/2589 (93%)]\tLoss: 211.215591\n",
      "====> Epoch: 791 Average train loss: 214.6692\n",
      "====> Epoch: 791 Average test loss: 918.6841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 792 [0/2589 (0%)]\tLoss: 170.322708\n",
      "Train Epoch: 792 [300/2589 (12%)]\tLoss: 264.939087\n",
      "Train Epoch: 792 [600/2589 (23%)]\tLoss: 141.844955\n",
      "Train Epoch: 792 [900/2589 (35%)]\tLoss: 219.814972\n",
      "Train Epoch: 792 [1200/2589 (46%)]\tLoss: 200.786804\n",
      "Train Epoch: 792 [1500/2589 (58%)]\tLoss: 205.076416\n",
      "Train Epoch: 792 [1800/2589 (70%)]\tLoss: 393.410187\n",
      "Train Epoch: 792 [2100/2589 (81%)]\tLoss: 152.906036\n",
      "Train Epoch: 792 [2400/2589 (93%)]\tLoss: 161.837158\n",
      "====> Epoch: 792 Average train loss: 227.9193\n",
      "====> Epoch: 792 Average test loss: 904.2941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 793 [0/2589 (0%)]\tLoss: 193.172653\n",
      "Train Epoch: 793 [300/2589 (12%)]\tLoss: 207.774643\n",
      "Train Epoch: 793 [600/2589 (23%)]\tLoss: 183.821991\n",
      "Train Epoch: 793 [900/2589 (35%)]\tLoss: 243.547714\n",
      "Train Epoch: 793 [1200/2589 (46%)]\tLoss: 229.176865\n",
      "Train Epoch: 793 [1500/2589 (58%)]\tLoss: 179.545563\n",
      "Train Epoch: 793 [1800/2589 (70%)]\tLoss: 212.690598\n",
      "Train Epoch: 793 [2100/2589 (81%)]\tLoss: 209.560211\n",
      "Train Epoch: 793 [2400/2589 (93%)]\tLoss: 283.651947\n",
      "====> Epoch: 793 Average train loss: 227.5126\n",
      "====> Epoch: 793 Average test loss: 919.7481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 794 [0/2589 (0%)]\tLoss: 256.553894\n",
      "Train Epoch: 794 [300/2589 (12%)]\tLoss: 233.878326\n",
      "Train Epoch: 794 [600/2589 (23%)]\tLoss: 239.083466\n",
      "Train Epoch: 794 [900/2589 (35%)]\tLoss: 231.338531\n",
      "Train Epoch: 794 [1200/2589 (46%)]\tLoss: 193.925949\n",
      "Train Epoch: 794 [1500/2589 (58%)]\tLoss: 176.866653\n",
      "Train Epoch: 794 [1800/2589 (70%)]\tLoss: 168.928558\n",
      "Train Epoch: 794 [2100/2589 (81%)]\tLoss: 245.211884\n",
      "Train Epoch: 794 [2400/2589 (93%)]\tLoss: 215.436996\n",
      "====> Epoch: 794 Average train loss: 217.4028\n",
      "====> Epoch: 794 Average test loss: 923.4731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 795 [0/2589 (0%)]\tLoss: 162.438858\n",
      "Train Epoch: 795 [300/2589 (12%)]\tLoss: 343.396667\n",
      "Train Epoch: 795 [600/2589 (23%)]\tLoss: 191.447922\n",
      "Train Epoch: 795 [900/2589 (35%)]\tLoss: 257.050812\n",
      "Train Epoch: 795 [1200/2589 (46%)]\tLoss: 163.079330\n",
      "Train Epoch: 795 [1500/2589 (58%)]\tLoss: 356.303436\n",
      "Train Epoch: 795 [1800/2589 (70%)]\tLoss: 374.572632\n",
      "Train Epoch: 795 [2100/2589 (81%)]\tLoss: 160.564453\n",
      "Train Epoch: 795 [2400/2589 (93%)]\tLoss: 170.038589\n",
      "====> Epoch: 795 Average train loss: 237.0513\n",
      "====> Epoch: 795 Average test loss: 912.0459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 796 [0/2589 (0%)]\tLoss: 308.894104\n",
      "Train Epoch: 796 [300/2589 (12%)]\tLoss: 227.233749\n",
      "Train Epoch: 796 [600/2589 (23%)]\tLoss: 190.143127\n",
      "Train Epoch: 796 [900/2589 (35%)]\tLoss: 149.951340\n",
      "Train Epoch: 796 [1200/2589 (46%)]\tLoss: 276.284760\n",
      "Train Epoch: 796 [1500/2589 (58%)]\tLoss: 248.396500\n",
      "Train Epoch: 796 [1800/2589 (70%)]\tLoss: 199.577576\n",
      "Train Epoch: 796 [2100/2589 (81%)]\tLoss: 294.036621\n",
      "Train Epoch: 796 [2400/2589 (93%)]\tLoss: 159.498108\n",
      "====> Epoch: 796 Average train loss: 234.2115\n",
      "====> Epoch: 796 Average test loss: 932.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 797 [0/2589 (0%)]\tLoss: 188.901108\n",
      "Train Epoch: 797 [300/2589 (12%)]\tLoss: 191.637070\n",
      "Train Epoch: 797 [600/2589 (23%)]\tLoss: 157.779053\n",
      "Train Epoch: 797 [900/2589 (35%)]\tLoss: 216.572769\n",
      "Train Epoch: 797 [1200/2589 (46%)]\tLoss: 186.538147\n",
      "Train Epoch: 797 [1500/2589 (58%)]\tLoss: 305.353851\n",
      "Train Epoch: 797 [1800/2589 (70%)]\tLoss: 251.403152\n",
      "Train Epoch: 797 [2100/2589 (81%)]\tLoss: 178.563797\n",
      "Train Epoch: 797 [2400/2589 (93%)]\tLoss: 136.108597\n",
      "====> Epoch: 797 Average train loss: 228.4153\n",
      "====> Epoch: 797 Average test loss: 925.3831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 798 [0/2589 (0%)]\tLoss: 208.147842\n",
      "Train Epoch: 798 [300/2589 (12%)]\tLoss: 327.145660\n",
      "Train Epoch: 798 [600/2589 (23%)]\tLoss: 178.642014\n",
      "Train Epoch: 798 [900/2589 (35%)]\tLoss: 186.971619\n",
      "Train Epoch: 798 [1200/2589 (46%)]\tLoss: 175.071838\n",
      "Train Epoch: 798 [1500/2589 (58%)]\tLoss: 342.368958\n",
      "Train Epoch: 798 [1800/2589 (70%)]\tLoss: 190.239151\n",
      "Train Epoch: 798 [2100/2589 (81%)]\tLoss: 173.642136\n",
      "Train Epoch: 798 [2400/2589 (93%)]\tLoss: 344.206482\n",
      "====> Epoch: 798 Average train loss: 225.0686\n",
      "====> Epoch: 798 Average test loss: 919.7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 799 [0/2589 (0%)]\tLoss: 218.512222\n",
      "Train Epoch: 799 [300/2589 (12%)]\tLoss: 180.053650\n",
      "Train Epoch: 799 [600/2589 (23%)]\tLoss: 124.524193\n",
      "Train Epoch: 799 [900/2589 (35%)]\tLoss: 179.384720\n",
      "Train Epoch: 799 [1200/2589 (46%)]\tLoss: 238.035324\n",
      "Train Epoch: 799 [1500/2589 (58%)]\tLoss: 274.020081\n",
      "Train Epoch: 799 [1800/2589 (70%)]\tLoss: 222.322617\n",
      "Train Epoch: 799 [2100/2589 (81%)]\tLoss: 193.067276\n",
      "Train Epoch: 799 [2400/2589 (93%)]\tLoss: 167.513931\n",
      "====> Epoch: 799 Average train loss: 228.2961\n",
      "====> Epoch: 799 Average test loss: 928.0640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 800 [0/2589 (0%)]\tLoss: 247.515808\n",
      "Train Epoch: 800 [300/2589 (12%)]\tLoss: 238.142426\n",
      "Train Epoch: 800 [600/2589 (23%)]\tLoss: 233.705399\n",
      "Train Epoch: 800 [900/2589 (35%)]\tLoss: 230.849899\n",
      "Train Epoch: 800 [1200/2589 (46%)]\tLoss: 195.518372\n",
      "Train Epoch: 800 [1500/2589 (58%)]\tLoss: 191.560165\n",
      "Train Epoch: 800 [1800/2589 (70%)]\tLoss: 255.597214\n",
      "Train Epoch: 800 [2100/2589 (81%)]\tLoss: 213.329056\n",
      "Train Epoch: 800 [2400/2589 (93%)]\tLoss: 305.215698\n",
      "====> Epoch: 800 Average train loss: 225.1239\n",
      "====> Epoch: 800 Average test loss: 927.2464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 801 [0/2589 (0%)]\tLoss: 315.975189\n",
      "Train Epoch: 801 [300/2589 (12%)]\tLoss: 213.326202\n",
      "Train Epoch: 801 [600/2589 (23%)]\tLoss: 607.263489\n",
      "Train Epoch: 801 [900/2589 (35%)]\tLoss: 198.438797\n",
      "Train Epoch: 801 [1200/2589 (46%)]\tLoss: 279.611969\n",
      "Train Epoch: 801 [1500/2589 (58%)]\tLoss: 180.489563\n",
      "Train Epoch: 801 [1800/2589 (70%)]\tLoss: 245.542831\n",
      "Train Epoch: 801 [2100/2589 (81%)]\tLoss: 258.937683\n",
      "Train Epoch: 801 [2400/2589 (93%)]\tLoss: 229.058655\n",
      "====> Epoch: 801 Average train loss: 226.0254\n",
      "====> Epoch: 801 Average test loss: 931.4110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 802 [0/2589 (0%)]\tLoss: 161.291916\n",
      "Train Epoch: 802 [300/2589 (12%)]\tLoss: 153.754013\n",
      "Train Epoch: 802 [600/2589 (23%)]\tLoss: 179.708740\n",
      "Train Epoch: 802 [900/2589 (35%)]\tLoss: 249.366486\n",
      "Train Epoch: 802 [1200/2589 (46%)]\tLoss: 184.732819\n",
      "Train Epoch: 802 [1500/2589 (58%)]\tLoss: 208.706253\n",
      "Train Epoch: 802 [1800/2589 (70%)]\tLoss: 289.175232\n",
      "Train Epoch: 802 [2100/2589 (81%)]\tLoss: 208.177200\n",
      "Train Epoch: 802 [2400/2589 (93%)]\tLoss: 279.369720\n",
      "====> Epoch: 802 Average train loss: 238.6998\n",
      "====> Epoch: 802 Average test loss: 937.6574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 803 [0/2589 (0%)]\tLoss: 180.315735\n",
      "Train Epoch: 803 [300/2589 (12%)]\tLoss: 247.091644\n",
      "Train Epoch: 803 [600/2589 (23%)]\tLoss: 224.603210\n",
      "Train Epoch: 803 [900/2589 (35%)]\tLoss: 175.293137\n",
      "Train Epoch: 803 [1200/2589 (46%)]\tLoss: 169.292389\n",
      "Train Epoch: 803 [1500/2589 (58%)]\tLoss: 308.374329\n",
      "Train Epoch: 803 [1800/2589 (70%)]\tLoss: 216.041306\n",
      "Train Epoch: 803 [2100/2589 (81%)]\tLoss: 310.664856\n",
      "Train Epoch: 803 [2400/2589 (93%)]\tLoss: 191.605072\n",
      "====> Epoch: 803 Average train loss: 229.1145\n",
      "====> Epoch: 803 Average test loss: 921.2577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 804 [0/2589 (0%)]\tLoss: 292.489532\n",
      "Train Epoch: 804 [300/2589 (12%)]\tLoss: 183.496521\n",
      "Train Epoch: 804 [600/2589 (23%)]\tLoss: 108.812096\n",
      "Train Epoch: 804 [900/2589 (35%)]\tLoss: 166.080978\n",
      "Train Epoch: 804 [1200/2589 (46%)]\tLoss: 214.077118\n",
      "Train Epoch: 804 [1500/2589 (58%)]\tLoss: 208.938293\n",
      "Train Epoch: 804 [1800/2589 (70%)]\tLoss: 270.508575\n",
      "Train Epoch: 804 [2100/2589 (81%)]\tLoss: 287.713165\n",
      "Train Epoch: 804 [2400/2589 (93%)]\tLoss: 340.683167\n",
      "====> Epoch: 804 Average train loss: 232.1030\n",
      "====> Epoch: 804 Average test loss: 917.3104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 805 [0/2589 (0%)]\tLoss: 197.944168\n",
      "Train Epoch: 805 [300/2589 (12%)]\tLoss: 209.939529\n",
      "Train Epoch: 805 [600/2589 (23%)]\tLoss: 273.444061\n",
      "Train Epoch: 805 [900/2589 (35%)]\tLoss: 239.350418\n",
      "Train Epoch: 805 [1200/2589 (46%)]\tLoss: 214.556808\n",
      "Train Epoch: 805 [1500/2589 (58%)]\tLoss: 159.875046\n",
      "Train Epoch: 805 [1800/2589 (70%)]\tLoss: 181.225372\n",
      "Train Epoch: 805 [2100/2589 (81%)]\tLoss: 173.398575\n",
      "Train Epoch: 805 [2400/2589 (93%)]\tLoss: 170.568100\n",
      "====> Epoch: 805 Average train loss: 221.0775\n",
      "====> Epoch: 805 Average test loss: 919.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 806 [0/2589 (0%)]\tLoss: 214.367096\n",
      "Train Epoch: 806 [300/2589 (12%)]\tLoss: 202.951492\n",
      "Train Epoch: 806 [600/2589 (23%)]\tLoss: 241.201614\n",
      "Train Epoch: 806 [900/2589 (35%)]\tLoss: 209.829758\n",
      "Train Epoch: 806 [1200/2589 (46%)]\tLoss: 272.823181\n",
      "Train Epoch: 806 [1500/2589 (58%)]\tLoss: 163.128204\n",
      "Train Epoch: 806 [1800/2589 (70%)]\tLoss: 237.724884\n",
      "Train Epoch: 806 [2100/2589 (81%)]\tLoss: 218.756897\n",
      "Train Epoch: 806 [2400/2589 (93%)]\tLoss: 199.147919\n",
      "====> Epoch: 806 Average train loss: 220.6301\n",
      "====> Epoch: 806 Average test loss: 928.7535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 807 [0/2589 (0%)]\tLoss: 146.702362\n",
      "Train Epoch: 807 [300/2589 (12%)]\tLoss: 180.170425\n",
      "Train Epoch: 807 [600/2589 (23%)]\tLoss: 174.496445\n",
      "Train Epoch: 807 [900/2589 (35%)]\tLoss: 154.344177\n",
      "Train Epoch: 807 [1200/2589 (46%)]\tLoss: 172.855667\n",
      "Train Epoch: 807 [1500/2589 (58%)]\tLoss: 202.487457\n",
      "Train Epoch: 807 [1800/2589 (70%)]\tLoss: 164.167221\n",
      "Train Epoch: 807 [2100/2589 (81%)]\tLoss: 177.990555\n",
      "Train Epoch: 807 [2400/2589 (93%)]\tLoss: 204.250717\n",
      "====> Epoch: 807 Average train loss: 223.6701\n",
      "====> Epoch: 807 Average test loss: 924.2704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 808 [0/2589 (0%)]\tLoss: 144.167267\n",
      "Train Epoch: 808 [300/2589 (12%)]\tLoss: 185.741318\n",
      "Train Epoch: 808 [600/2589 (23%)]\tLoss: 463.501740\n",
      "Train Epoch: 808 [900/2589 (35%)]\tLoss: 184.479431\n",
      "Train Epoch: 808 [1200/2589 (46%)]\tLoss: 223.786072\n",
      "Train Epoch: 808 [1500/2589 (58%)]\tLoss: 156.064484\n",
      "Train Epoch: 808 [1800/2589 (70%)]\tLoss: 217.488373\n",
      "Train Epoch: 808 [2100/2589 (81%)]\tLoss: 149.833954\n",
      "Train Epoch: 808 [2400/2589 (93%)]\tLoss: 149.668716\n",
      "====> Epoch: 808 Average train loss: 231.2755\n",
      "====> Epoch: 808 Average test loss: 927.0893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 809 [0/2589 (0%)]\tLoss: 277.504242\n",
      "Train Epoch: 809 [300/2589 (12%)]\tLoss: 172.000900\n",
      "Train Epoch: 809 [600/2589 (23%)]\tLoss: 261.032440\n",
      "Train Epoch: 809 [900/2589 (35%)]\tLoss: 167.846390\n",
      "Train Epoch: 809 [1200/2589 (46%)]\tLoss: 233.343765\n",
      "Train Epoch: 809 [1500/2589 (58%)]\tLoss: 195.470505\n",
      "Train Epoch: 809 [1800/2589 (70%)]\tLoss: 337.856873\n",
      "Train Epoch: 809 [2100/2589 (81%)]\tLoss: 214.518951\n",
      "Train Epoch: 809 [2400/2589 (93%)]\tLoss: 233.425491\n",
      "====> Epoch: 809 Average train loss: 224.7327\n",
      "====> Epoch: 809 Average test loss: 916.9529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 810 [0/2589 (0%)]\tLoss: 179.889816\n",
      "Train Epoch: 810 [300/2589 (12%)]\tLoss: 155.666733\n",
      "Train Epoch: 810 [600/2589 (23%)]\tLoss: 194.107285\n",
      "Train Epoch: 810 [900/2589 (35%)]\tLoss: 348.294067\n",
      "Train Epoch: 810 [1200/2589 (46%)]\tLoss: 140.901520\n",
      "Train Epoch: 810 [1500/2589 (58%)]\tLoss: 249.474152\n",
      "Train Epoch: 810 [1800/2589 (70%)]\tLoss: 229.678665\n",
      "Train Epoch: 810 [2100/2589 (81%)]\tLoss: 236.421219\n",
      "Train Epoch: 810 [2400/2589 (93%)]\tLoss: 227.972519\n",
      "====> Epoch: 810 Average train loss: 225.3199\n",
      "====> Epoch: 810 Average test loss: 907.8461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 811 [0/2589 (0%)]\tLoss: 180.263763\n",
      "Train Epoch: 811 [300/2589 (12%)]\tLoss: 190.031219\n",
      "Train Epoch: 811 [600/2589 (23%)]\tLoss: 245.313828\n",
      "Train Epoch: 811 [900/2589 (35%)]\tLoss: 180.203217\n",
      "Train Epoch: 811 [1200/2589 (46%)]\tLoss: 184.618835\n",
      "Train Epoch: 811 [1500/2589 (58%)]\tLoss: 720.439697\n",
      "Train Epoch: 811 [1800/2589 (70%)]\tLoss: 224.554291\n",
      "Train Epoch: 811 [2100/2589 (81%)]\tLoss: 286.454620\n",
      "Train Epoch: 811 [2400/2589 (93%)]\tLoss: 165.008316\n",
      "====> Epoch: 811 Average train loss: 228.7659\n",
      "====> Epoch: 811 Average test loss: 920.4410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 812 [0/2589 (0%)]\tLoss: 354.247284\n",
      "Train Epoch: 812 [300/2589 (12%)]\tLoss: 211.837860\n",
      "Train Epoch: 812 [600/2589 (23%)]\tLoss: 486.792084\n",
      "Train Epoch: 812 [900/2589 (35%)]\tLoss: 242.017120\n",
      "Train Epoch: 812 [1200/2589 (46%)]\tLoss: 186.327362\n",
      "Train Epoch: 812 [1500/2589 (58%)]\tLoss: 223.550476\n",
      "Train Epoch: 812 [1800/2589 (70%)]\tLoss: 186.592911\n",
      "Train Epoch: 812 [2100/2589 (81%)]\tLoss: 234.141663\n",
      "Train Epoch: 812 [2400/2589 (93%)]\tLoss: 163.762619\n",
      "====> Epoch: 812 Average train loss: 236.4936\n",
      "====> Epoch: 812 Average test loss: 932.5378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 813 [0/2589 (0%)]\tLoss: 197.273331\n",
      "Train Epoch: 813 [300/2589 (12%)]\tLoss: 183.021896\n",
      "Train Epoch: 813 [600/2589 (23%)]\tLoss: 125.616814\n",
      "Train Epoch: 813 [900/2589 (35%)]\tLoss: 143.321060\n",
      "Train Epoch: 813 [1200/2589 (46%)]\tLoss: 169.264069\n",
      "Train Epoch: 813 [1500/2589 (58%)]\tLoss: 190.516922\n",
      "Train Epoch: 813 [1800/2589 (70%)]\tLoss: 274.863983\n",
      "Train Epoch: 813 [2100/2589 (81%)]\tLoss: 197.294907\n",
      "Train Epoch: 813 [2400/2589 (93%)]\tLoss: 216.731308\n",
      "====> Epoch: 813 Average train loss: 214.7218\n",
      "====> Epoch: 813 Average test loss: 922.0958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 814 [0/2589 (0%)]\tLoss: 191.760010\n",
      "Train Epoch: 814 [300/2589 (12%)]\tLoss: 168.653839\n",
      "Train Epoch: 814 [600/2589 (23%)]\tLoss: 151.964935\n",
      "Train Epoch: 814 [900/2589 (35%)]\tLoss: 221.765930\n",
      "Train Epoch: 814 [1200/2589 (46%)]\tLoss: 238.024857\n",
      "Train Epoch: 814 [1500/2589 (58%)]\tLoss: 235.229889\n",
      "Train Epoch: 814 [1800/2589 (70%)]\tLoss: 186.401276\n",
      "Train Epoch: 814 [2100/2589 (81%)]\tLoss: 307.167786\n",
      "Train Epoch: 814 [2400/2589 (93%)]\tLoss: 286.545471\n",
      "====> Epoch: 814 Average train loss: 220.3235\n",
      "====> Epoch: 814 Average test loss: 926.3730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 815 [0/2589 (0%)]\tLoss: 210.653900\n",
      "Train Epoch: 815 [300/2589 (12%)]\tLoss: 194.522186\n",
      "Train Epoch: 815 [600/2589 (23%)]\tLoss: 135.316483\n",
      "Train Epoch: 815 [900/2589 (35%)]\tLoss: 179.225327\n",
      "Train Epoch: 815 [1200/2589 (46%)]\tLoss: 271.217255\n",
      "Train Epoch: 815 [1500/2589 (58%)]\tLoss: 175.990372\n",
      "Train Epoch: 815 [1800/2589 (70%)]\tLoss: 172.929657\n",
      "Train Epoch: 815 [2100/2589 (81%)]\tLoss: 213.522903\n",
      "Train Epoch: 815 [2400/2589 (93%)]\tLoss: 221.366074\n",
      "====> Epoch: 815 Average train loss: 230.1850\n",
      "====> Epoch: 815 Average test loss: 935.9640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 816 [0/2589 (0%)]\tLoss: 225.378708\n",
      "Train Epoch: 816 [300/2589 (12%)]\tLoss: 251.634659\n",
      "Train Epoch: 816 [600/2589 (23%)]\tLoss: 198.005051\n",
      "Train Epoch: 816 [900/2589 (35%)]\tLoss: 304.946930\n",
      "Train Epoch: 816 [1200/2589 (46%)]\tLoss: 167.591446\n",
      "Train Epoch: 816 [1500/2589 (58%)]\tLoss: 215.188278\n",
      "Train Epoch: 816 [1800/2589 (70%)]\tLoss: 219.603760\n",
      "Train Epoch: 816 [2100/2589 (81%)]\tLoss: 255.114227\n",
      "Train Epoch: 816 [2400/2589 (93%)]\tLoss: 245.051712\n",
      "====> Epoch: 816 Average train loss: 228.4573\n",
      "====> Epoch: 816 Average test loss: 916.6880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 817 [0/2589 (0%)]\tLoss: 241.638214\n",
      "Train Epoch: 817 [300/2589 (12%)]\tLoss: 205.486893\n",
      "Train Epoch: 817 [600/2589 (23%)]\tLoss: 214.782257\n",
      "Train Epoch: 817 [900/2589 (35%)]\tLoss: 211.502350\n",
      "Train Epoch: 817 [1200/2589 (46%)]\tLoss: 191.609756\n",
      "Train Epoch: 817 [1500/2589 (58%)]\tLoss: 189.316406\n",
      "Train Epoch: 817 [1800/2589 (70%)]\tLoss: 317.914551\n",
      "Train Epoch: 817 [2100/2589 (81%)]\tLoss: 143.355301\n",
      "Train Epoch: 817 [2400/2589 (93%)]\tLoss: 194.007614\n",
      "====> Epoch: 817 Average train loss: 217.4225\n",
      "====> Epoch: 817 Average test loss: 927.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 818 [0/2589 (0%)]\tLoss: 182.030991\n",
      "Train Epoch: 818 [300/2589 (12%)]\tLoss: 214.341049\n",
      "Train Epoch: 818 [600/2589 (23%)]\tLoss: 215.823563\n",
      "Train Epoch: 818 [900/2589 (35%)]\tLoss: 156.078812\n",
      "Train Epoch: 818 [1200/2589 (46%)]\tLoss: 158.660797\n",
      "Train Epoch: 818 [1500/2589 (58%)]\tLoss: 189.141693\n",
      "Train Epoch: 818 [1800/2589 (70%)]\tLoss: 238.907730\n",
      "Train Epoch: 818 [2100/2589 (81%)]\tLoss: 151.739731\n",
      "Train Epoch: 818 [2400/2589 (93%)]\tLoss: 241.066025\n",
      "====> Epoch: 818 Average train loss: 219.4635\n",
      "====> Epoch: 818 Average test loss: 931.5206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 819 [0/2589 (0%)]\tLoss: 209.426697\n",
      "Train Epoch: 819 [300/2589 (12%)]\tLoss: 231.014130\n",
      "Train Epoch: 819 [600/2589 (23%)]\tLoss: 192.217758\n",
      "Train Epoch: 819 [900/2589 (35%)]\tLoss: 302.134888\n",
      "Train Epoch: 819 [1200/2589 (46%)]\tLoss: 292.086548\n",
      "Train Epoch: 819 [1500/2589 (58%)]\tLoss: 240.564911\n",
      "Train Epoch: 819 [1800/2589 (70%)]\tLoss: 241.694992\n",
      "Train Epoch: 819 [2100/2589 (81%)]\tLoss: 280.345093\n",
      "Train Epoch: 819 [2400/2589 (93%)]\tLoss: 210.894669\n",
      "====> Epoch: 819 Average train loss: 241.0842\n",
      "====> Epoch: 819 Average test loss: 926.4920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 820 [0/2589 (0%)]\tLoss: 173.068588\n",
      "Train Epoch: 820 [300/2589 (12%)]\tLoss: 247.541412\n",
      "Train Epoch: 820 [600/2589 (23%)]\tLoss: 206.162109\n",
      "Train Epoch: 820 [900/2589 (35%)]\tLoss: 269.525085\n",
      "Train Epoch: 820 [1200/2589 (46%)]\tLoss: 243.780167\n",
      "Train Epoch: 820 [1500/2589 (58%)]\tLoss: 175.582382\n",
      "Train Epoch: 820 [1800/2589 (70%)]\tLoss: 263.994202\n",
      "Train Epoch: 820 [2100/2589 (81%)]\tLoss: 177.891678\n",
      "Train Epoch: 820 [2400/2589 (93%)]\tLoss: 214.977020\n",
      "====> Epoch: 820 Average train loss: 222.5957\n",
      "====> Epoch: 820 Average test loss: 944.7476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 821 [0/2589 (0%)]\tLoss: 158.725815\n",
      "Train Epoch: 821 [300/2589 (12%)]\tLoss: 182.141891\n",
      "Train Epoch: 821 [600/2589 (23%)]\tLoss: 257.448059\n",
      "Train Epoch: 821 [900/2589 (35%)]\tLoss: 234.810684\n",
      "Train Epoch: 821 [1200/2589 (46%)]\tLoss: 221.158997\n",
      "Train Epoch: 821 [1500/2589 (58%)]\tLoss: 333.579681\n",
      "Train Epoch: 821 [1800/2589 (70%)]\tLoss: 124.508965\n",
      "Train Epoch: 821 [2100/2589 (81%)]\tLoss: 203.662949\n",
      "Train Epoch: 821 [2400/2589 (93%)]\tLoss: 231.715271\n",
      "====> Epoch: 821 Average train loss: 230.8917\n",
      "====> Epoch: 821 Average test loss: 925.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 822 [0/2589 (0%)]\tLoss: 235.694870\n",
      "Train Epoch: 822 [300/2589 (12%)]\tLoss: 183.662582\n",
      "Train Epoch: 822 [600/2589 (23%)]\tLoss: 266.641174\n",
      "Train Epoch: 822 [900/2589 (35%)]\tLoss: 232.380905\n",
      "Train Epoch: 822 [1200/2589 (46%)]\tLoss: 304.399780\n",
      "Train Epoch: 822 [1500/2589 (58%)]\tLoss: 232.048965\n",
      "Train Epoch: 822 [1800/2589 (70%)]\tLoss: 191.954010\n",
      "Train Epoch: 822 [2100/2589 (81%)]\tLoss: 233.639648\n",
      "Train Epoch: 822 [2400/2589 (93%)]\tLoss: 201.499771\n",
      "====> Epoch: 822 Average train loss: 221.4867\n",
      "====> Epoch: 822 Average test loss: 923.3164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 823 [0/2589 (0%)]\tLoss: 212.297424\n",
      "Train Epoch: 823 [300/2589 (12%)]\tLoss: 216.255066\n",
      "Train Epoch: 823 [600/2589 (23%)]\tLoss: 201.121323\n",
      "Train Epoch: 823 [900/2589 (35%)]\tLoss: 327.480164\n",
      "Train Epoch: 823 [1200/2589 (46%)]\tLoss: 167.284866\n",
      "Train Epoch: 823 [1500/2589 (58%)]\tLoss: 202.115646\n",
      "Train Epoch: 823 [1800/2589 (70%)]\tLoss: 224.230621\n",
      "Train Epoch: 823 [2100/2589 (81%)]\tLoss: 213.700012\n",
      "Train Epoch: 823 [2400/2589 (93%)]\tLoss: 180.691559\n",
      "====> Epoch: 823 Average train loss: 235.9282\n",
      "====> Epoch: 823 Average test loss: 931.8005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 824 [0/2589 (0%)]\tLoss: 174.933304\n",
      "Train Epoch: 824 [300/2589 (12%)]\tLoss: 255.704742\n",
      "Train Epoch: 824 [600/2589 (23%)]\tLoss: 242.364044\n",
      "Train Epoch: 824 [900/2589 (35%)]\tLoss: 184.897202\n",
      "Train Epoch: 824 [1200/2589 (46%)]\tLoss: 298.302429\n",
      "Train Epoch: 824 [1500/2589 (58%)]\tLoss: 323.346191\n",
      "Train Epoch: 824 [1800/2589 (70%)]\tLoss: 286.244507\n",
      "Train Epoch: 824 [2100/2589 (81%)]\tLoss: 377.093048\n",
      "Train Epoch: 824 [2400/2589 (93%)]\tLoss: 207.956329\n",
      "====> Epoch: 824 Average train loss: 233.7225\n",
      "====> Epoch: 824 Average test loss: 915.7063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 825 [0/2589 (0%)]\tLoss: 180.878738\n",
      "Train Epoch: 825 [300/2589 (12%)]\tLoss: 182.171417\n",
      "Train Epoch: 825 [600/2589 (23%)]\tLoss: 266.308868\n",
      "Train Epoch: 825 [900/2589 (35%)]\tLoss: 420.044647\n",
      "Train Epoch: 825 [1200/2589 (46%)]\tLoss: 182.890335\n",
      "Train Epoch: 825 [1500/2589 (58%)]\tLoss: 241.686111\n",
      "Train Epoch: 825 [1800/2589 (70%)]\tLoss: 209.103851\n",
      "Train Epoch: 825 [2100/2589 (81%)]\tLoss: 188.170410\n",
      "Train Epoch: 825 [2400/2589 (93%)]\tLoss: 187.977203\n",
      "====> Epoch: 825 Average train loss: 220.7718\n",
      "====> Epoch: 825 Average test loss: 916.9369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 826 [0/2589 (0%)]\tLoss: 212.220810\n",
      "Train Epoch: 826 [300/2589 (12%)]\tLoss: 164.265640\n",
      "Train Epoch: 826 [600/2589 (23%)]\tLoss: 196.843765\n",
      "Train Epoch: 826 [900/2589 (35%)]\tLoss: 162.024506\n",
      "Train Epoch: 826 [1200/2589 (46%)]\tLoss: 151.435928\n",
      "Train Epoch: 826 [1500/2589 (58%)]\tLoss: 222.090729\n",
      "Train Epoch: 826 [1800/2589 (70%)]\tLoss: 226.787567\n",
      "Train Epoch: 826 [2100/2589 (81%)]\tLoss: 182.084030\n",
      "Train Epoch: 826 [2400/2589 (93%)]\tLoss: 233.664978\n",
      "====> Epoch: 826 Average train loss: 224.3452\n",
      "====> Epoch: 826 Average test loss: 932.3326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 827 [0/2589 (0%)]\tLoss: 274.918884\n",
      "Train Epoch: 827 [300/2589 (12%)]\tLoss: 186.658234\n",
      "Train Epoch: 827 [600/2589 (23%)]\tLoss: 168.953400\n",
      "Train Epoch: 827 [900/2589 (35%)]\tLoss: 289.813507\n",
      "Train Epoch: 827 [1200/2589 (46%)]\tLoss: 216.607895\n",
      "Train Epoch: 827 [1500/2589 (58%)]\tLoss: 164.392166\n",
      "Train Epoch: 827 [1800/2589 (70%)]\tLoss: 226.545929\n",
      "Train Epoch: 827 [2100/2589 (81%)]\tLoss: 160.702118\n",
      "Train Epoch: 827 [2400/2589 (93%)]\tLoss: 222.592194\n",
      "====> Epoch: 827 Average train loss: 218.8226\n",
      "====> Epoch: 827 Average test loss: 908.0933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 828 [0/2589 (0%)]\tLoss: 228.086456\n",
      "Train Epoch: 828 [300/2589 (12%)]\tLoss: 175.983231\n",
      "Train Epoch: 828 [600/2589 (23%)]\tLoss: 232.264847\n",
      "Train Epoch: 828 [900/2589 (35%)]\tLoss: 177.787094\n",
      "Train Epoch: 828 [1200/2589 (46%)]\tLoss: 197.291733\n",
      "Train Epoch: 828 [1500/2589 (58%)]\tLoss: 176.949051\n",
      "Train Epoch: 828 [1800/2589 (70%)]\tLoss: 250.805450\n",
      "Train Epoch: 828 [2100/2589 (81%)]\tLoss: 209.454773\n",
      "Train Epoch: 828 [2400/2589 (93%)]\tLoss: 163.110123\n",
      "====> Epoch: 828 Average train loss: 226.6616\n",
      "====> Epoch: 828 Average test loss: 913.1623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 829 [0/2589 (0%)]\tLoss: 161.687347\n",
      "Train Epoch: 829 [300/2589 (12%)]\tLoss: 236.974899\n",
      "Train Epoch: 829 [600/2589 (23%)]\tLoss: 215.475983\n",
      "Train Epoch: 829 [900/2589 (35%)]\tLoss: 142.849716\n",
      "Train Epoch: 829 [1200/2589 (46%)]\tLoss: 242.133713\n",
      "Train Epoch: 829 [1500/2589 (58%)]\tLoss: 159.612320\n",
      "Train Epoch: 829 [1800/2589 (70%)]\tLoss: 174.345505\n",
      "Train Epoch: 829 [2100/2589 (81%)]\tLoss: 218.417877\n",
      "Train Epoch: 829 [2400/2589 (93%)]\tLoss: 207.233475\n",
      "====> Epoch: 829 Average train loss: 224.0935\n",
      "====> Epoch: 829 Average test loss: 922.0436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 830 [0/2589 (0%)]\tLoss: 191.400406\n",
      "Train Epoch: 830 [300/2589 (12%)]\tLoss: 208.470764\n",
      "Train Epoch: 830 [600/2589 (23%)]\tLoss: 277.809631\n",
      "Train Epoch: 830 [900/2589 (35%)]\tLoss: 202.829742\n",
      "Train Epoch: 830 [1200/2589 (46%)]\tLoss: 285.836884\n",
      "Train Epoch: 830 [1500/2589 (58%)]\tLoss: 466.394012\n",
      "Train Epoch: 830 [1800/2589 (70%)]\tLoss: 156.948471\n",
      "Train Epoch: 830 [2100/2589 (81%)]\tLoss: 195.333588\n",
      "Train Epoch: 830 [2400/2589 (93%)]\tLoss: 183.294357\n",
      "====> Epoch: 830 Average train loss: 232.8672\n",
      "====> Epoch: 830 Average test loss: 930.0529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 831 [0/2589 (0%)]\tLoss: 235.628433\n",
      "Train Epoch: 831 [300/2589 (12%)]\tLoss: 154.435944\n",
      "Train Epoch: 831 [600/2589 (23%)]\tLoss: 292.275909\n",
      "Train Epoch: 831 [900/2589 (35%)]\tLoss: 314.500275\n",
      "Train Epoch: 831 [1200/2589 (46%)]\tLoss: 244.899872\n",
      "Train Epoch: 831 [1500/2589 (58%)]\tLoss: 273.811981\n",
      "Train Epoch: 831 [1800/2589 (70%)]\tLoss: 354.872742\n",
      "Train Epoch: 831 [2100/2589 (81%)]\tLoss: 224.755508\n",
      "Train Epoch: 831 [2400/2589 (93%)]\tLoss: 202.810837\n",
      "====> Epoch: 831 Average train loss: 233.1887\n",
      "====> Epoch: 831 Average test loss: 923.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 832 [0/2589 (0%)]\tLoss: 201.084869\n",
      "Train Epoch: 832 [300/2589 (12%)]\tLoss: 204.792755\n",
      "Train Epoch: 832 [600/2589 (23%)]\tLoss: 296.646973\n",
      "Train Epoch: 832 [900/2589 (35%)]\tLoss: 270.442780\n",
      "Train Epoch: 832 [1200/2589 (46%)]\tLoss: 193.126694\n",
      "Train Epoch: 832 [1500/2589 (58%)]\tLoss: 195.542511\n",
      "Train Epoch: 832 [1800/2589 (70%)]\tLoss: 250.035706\n",
      "Train Epoch: 832 [2100/2589 (81%)]\tLoss: 206.916763\n",
      "Train Epoch: 832 [2400/2589 (93%)]\tLoss: 173.455978\n",
      "====> Epoch: 832 Average train loss: 235.8912\n",
      "====> Epoch: 832 Average test loss: 935.0682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 833 [0/2589 (0%)]\tLoss: 353.089691\n",
      "Train Epoch: 833 [300/2589 (12%)]\tLoss: 176.885345\n",
      "Train Epoch: 833 [600/2589 (23%)]\tLoss: 270.256561\n",
      "Train Epoch: 833 [900/2589 (35%)]\tLoss: 224.532028\n",
      "Train Epoch: 833 [1200/2589 (46%)]\tLoss: 296.117004\n",
      "Train Epoch: 833 [1500/2589 (58%)]\tLoss: 226.583633\n",
      "Train Epoch: 833 [1800/2589 (70%)]\tLoss: 235.467804\n",
      "Train Epoch: 833 [2100/2589 (81%)]\tLoss: 270.665741\n",
      "Train Epoch: 833 [2400/2589 (93%)]\tLoss: 236.712616\n",
      "====> Epoch: 833 Average train loss: 230.9431\n",
      "====> Epoch: 833 Average test loss: 923.7843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 834 [0/2589 (0%)]\tLoss: 164.030701\n",
      "Train Epoch: 834 [300/2589 (12%)]\tLoss: 380.312073\n",
      "Train Epoch: 834 [600/2589 (23%)]\tLoss: 217.878387\n",
      "Train Epoch: 834 [900/2589 (35%)]\tLoss: 208.518158\n",
      "Train Epoch: 834 [1200/2589 (46%)]\tLoss: 189.749786\n",
      "Train Epoch: 834 [1500/2589 (58%)]\tLoss: 339.183868\n",
      "Train Epoch: 834 [1800/2589 (70%)]\tLoss: 239.419907\n",
      "Train Epoch: 834 [2100/2589 (81%)]\tLoss: 189.491882\n",
      "Train Epoch: 834 [2400/2589 (93%)]\tLoss: 238.510803\n",
      "====> Epoch: 834 Average train loss: 216.0542\n",
      "====> Epoch: 834 Average test loss: 922.2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 835 [0/2589 (0%)]\tLoss: 221.818268\n",
      "Train Epoch: 835 [300/2589 (12%)]\tLoss: 223.291809\n",
      "Train Epoch: 835 [600/2589 (23%)]\tLoss: 335.568634\n",
      "Train Epoch: 835 [900/2589 (35%)]\tLoss: 232.882736\n",
      "Train Epoch: 835 [1200/2589 (46%)]\tLoss: 202.329453\n",
      "Train Epoch: 835 [1500/2589 (58%)]\tLoss: 247.308167\n",
      "Train Epoch: 835 [1800/2589 (70%)]\tLoss: 290.657440\n",
      "Train Epoch: 835 [2100/2589 (81%)]\tLoss: 169.593750\n",
      "Train Epoch: 835 [2400/2589 (93%)]\tLoss: 354.841003\n",
      "====> Epoch: 835 Average train loss: 229.6523\n",
      "====> Epoch: 835 Average test loss: 912.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 836 [0/2589 (0%)]\tLoss: 192.715134\n",
      "Train Epoch: 836 [300/2589 (12%)]\tLoss: 268.715210\n",
      "Train Epoch: 836 [600/2589 (23%)]\tLoss: 215.673111\n",
      "Train Epoch: 836 [900/2589 (35%)]\tLoss: 183.275192\n",
      "Train Epoch: 836 [1200/2589 (46%)]\tLoss: 338.918091\n",
      "Train Epoch: 836 [1500/2589 (58%)]\tLoss: 138.903152\n",
      "Train Epoch: 836 [1800/2589 (70%)]\tLoss: 224.284317\n",
      "Train Epoch: 836 [2100/2589 (81%)]\tLoss: 238.742767\n",
      "Train Epoch: 836 [2400/2589 (93%)]\tLoss: 281.725525\n",
      "====> Epoch: 836 Average train loss: 236.1399\n",
      "====> Epoch: 836 Average test loss: 923.3500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 837 [0/2589 (0%)]\tLoss: 202.575485\n",
      "Train Epoch: 837 [300/2589 (12%)]\tLoss: 245.734283\n",
      "Train Epoch: 837 [600/2589 (23%)]\tLoss: 212.157333\n",
      "Train Epoch: 837 [900/2589 (35%)]\tLoss: 234.910324\n",
      "Train Epoch: 837 [1200/2589 (46%)]\tLoss: 274.621094\n",
      "Train Epoch: 837 [1500/2589 (58%)]\tLoss: 310.185669\n",
      "Train Epoch: 837 [1800/2589 (70%)]\tLoss: 170.402298\n",
      "Train Epoch: 837 [2100/2589 (81%)]\tLoss: 186.278229\n",
      "Train Epoch: 837 [2400/2589 (93%)]\tLoss: 178.570343\n",
      "====> Epoch: 837 Average train loss: 242.0010\n",
      "====> Epoch: 837 Average test loss: 911.8161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 838 [0/2589 (0%)]\tLoss: 176.676697\n",
      "Train Epoch: 838 [300/2589 (12%)]\tLoss: 208.716064\n",
      "Train Epoch: 838 [600/2589 (23%)]\tLoss: 332.711975\n",
      "Train Epoch: 838 [900/2589 (35%)]\tLoss: 219.161072\n",
      "Train Epoch: 838 [1200/2589 (46%)]\tLoss: 201.720078\n",
      "Train Epoch: 838 [1500/2589 (58%)]\tLoss: 274.153717\n",
      "Train Epoch: 838 [1800/2589 (70%)]\tLoss: 306.678619\n",
      "Train Epoch: 838 [2100/2589 (81%)]\tLoss: 140.922440\n",
      "Train Epoch: 838 [2400/2589 (93%)]\tLoss: 152.529160\n",
      "====> Epoch: 838 Average train loss: 225.3949\n",
      "====> Epoch: 838 Average test loss: 920.7045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 839 [0/2589 (0%)]\tLoss: 204.462540\n",
      "Train Epoch: 839 [300/2589 (12%)]\tLoss: 195.426666\n",
      "Train Epoch: 839 [600/2589 (23%)]\tLoss: 189.394211\n",
      "Train Epoch: 839 [900/2589 (35%)]\tLoss: 252.167389\n",
      "Train Epoch: 839 [1200/2589 (46%)]\tLoss: 194.766312\n",
      "Train Epoch: 839 [1500/2589 (58%)]\tLoss: 142.630630\n",
      "Train Epoch: 839 [1800/2589 (70%)]\tLoss: 224.273987\n",
      "Train Epoch: 839 [2100/2589 (81%)]\tLoss: 219.722397\n",
      "Train Epoch: 839 [2400/2589 (93%)]\tLoss: 210.208160\n",
      "====> Epoch: 839 Average train loss: 217.5856\n",
      "====> Epoch: 839 Average test loss: 912.7739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 840 [0/2589 (0%)]\tLoss: 195.415970\n",
      "Train Epoch: 840 [300/2589 (12%)]\tLoss: 193.289383\n",
      "Train Epoch: 840 [600/2589 (23%)]\tLoss: 243.233856\n",
      "Train Epoch: 840 [900/2589 (35%)]\tLoss: 183.659439\n",
      "Train Epoch: 840 [1200/2589 (46%)]\tLoss: 182.020752\n",
      "Train Epoch: 840 [1500/2589 (58%)]\tLoss: 226.064026\n",
      "Train Epoch: 840 [1800/2589 (70%)]\tLoss: 233.794678\n",
      "Train Epoch: 840 [2100/2589 (81%)]\tLoss: 217.462173\n",
      "Train Epoch: 840 [2400/2589 (93%)]\tLoss: 231.716599\n",
      "====> Epoch: 840 Average train loss: 217.5176\n",
      "====> Epoch: 840 Average test loss: 921.6125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 841 [0/2589 (0%)]\tLoss: 160.551270\n",
      "Train Epoch: 841 [300/2589 (12%)]\tLoss: 232.812668\n",
      "Train Epoch: 841 [600/2589 (23%)]\tLoss: 165.499680\n",
      "Train Epoch: 841 [900/2589 (35%)]\tLoss: 201.540421\n",
      "Train Epoch: 841 [1200/2589 (46%)]\tLoss: 200.247711\n",
      "Train Epoch: 841 [1500/2589 (58%)]\tLoss: 270.978180\n",
      "Train Epoch: 841 [1800/2589 (70%)]\tLoss: 230.509033\n",
      "Train Epoch: 841 [2100/2589 (81%)]\tLoss: 236.630417\n",
      "Train Epoch: 841 [2400/2589 (93%)]\tLoss: 328.643951\n",
      "====> Epoch: 841 Average train loss: 220.3825\n",
      "====> Epoch: 841 Average test loss: 921.2021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 842 [0/2589 (0%)]\tLoss: 223.768295\n",
      "Train Epoch: 842 [300/2589 (12%)]\tLoss: 219.288101\n",
      "Train Epoch: 842 [600/2589 (23%)]\tLoss: 151.411682\n",
      "Train Epoch: 842 [900/2589 (35%)]\tLoss: 201.133316\n",
      "Train Epoch: 842 [1200/2589 (46%)]\tLoss: 551.247864\n",
      "Train Epoch: 842 [1500/2589 (58%)]\tLoss: 249.863739\n",
      "Train Epoch: 842 [1800/2589 (70%)]\tLoss: 240.336823\n",
      "Train Epoch: 842 [2100/2589 (81%)]\tLoss: 316.115082\n",
      "Train Epoch: 842 [2400/2589 (93%)]\tLoss: 216.895645\n",
      "====> Epoch: 842 Average train loss: 241.0078\n",
      "====> Epoch: 842 Average test loss: 920.6301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 843 [0/2589 (0%)]\tLoss: 218.611511\n",
      "Train Epoch: 843 [300/2589 (12%)]\tLoss: 286.425354\n",
      "Train Epoch: 843 [600/2589 (23%)]\tLoss: 171.998108\n",
      "Train Epoch: 843 [900/2589 (35%)]\tLoss: 264.453613\n",
      "Train Epoch: 843 [1200/2589 (46%)]\tLoss: 199.507141\n",
      "Train Epoch: 843 [1500/2589 (58%)]\tLoss: 183.884766\n",
      "Train Epoch: 843 [1800/2589 (70%)]\tLoss: 251.409210\n",
      "Train Epoch: 843 [2100/2589 (81%)]\tLoss: 300.076721\n",
      "Train Epoch: 843 [2400/2589 (93%)]\tLoss: 140.483658\n",
      "====> Epoch: 843 Average train loss: 228.3486\n",
      "====> Epoch: 843 Average test loss: 919.8060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 844 [0/2589 (0%)]\tLoss: 380.810944\n",
      "Train Epoch: 844 [300/2589 (12%)]\tLoss: 209.070084\n",
      "Train Epoch: 844 [600/2589 (23%)]\tLoss: 349.929016\n",
      "Train Epoch: 844 [900/2589 (35%)]\tLoss: 260.983734\n",
      "Train Epoch: 844 [1200/2589 (46%)]\tLoss: 291.671997\n",
      "Train Epoch: 844 [1500/2589 (58%)]\tLoss: 215.987930\n",
      "Train Epoch: 844 [1800/2589 (70%)]\tLoss: 194.173965\n",
      "Train Epoch: 844 [2100/2589 (81%)]\tLoss: 211.355850\n",
      "Train Epoch: 844 [2400/2589 (93%)]\tLoss: 220.153458\n",
      "====> Epoch: 844 Average train loss: 235.3972\n",
      "====> Epoch: 844 Average test loss: 895.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 845 [0/2589 (0%)]\tLoss: 170.199570\n",
      "Train Epoch: 845 [300/2589 (12%)]\tLoss: 234.681259\n",
      "Train Epoch: 845 [600/2589 (23%)]\tLoss: 259.038757\n",
      "Train Epoch: 845 [900/2589 (35%)]\tLoss: 345.619171\n",
      "Train Epoch: 845 [1200/2589 (46%)]\tLoss: 312.405304\n",
      "Train Epoch: 845 [1500/2589 (58%)]\tLoss: 182.265900\n",
      "Train Epoch: 845 [1800/2589 (70%)]\tLoss: 223.721527\n",
      "Train Epoch: 845 [2100/2589 (81%)]\tLoss: 170.014130\n",
      "Train Epoch: 845 [2400/2589 (93%)]\tLoss: 193.168182\n",
      "====> Epoch: 845 Average train loss: 227.1790\n",
      "====> Epoch: 845 Average test loss: 936.2440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 846 [0/2589 (0%)]\tLoss: 223.081299\n",
      "Train Epoch: 846 [300/2589 (12%)]\tLoss: 242.232742\n",
      "Train Epoch: 846 [600/2589 (23%)]\tLoss: 168.713943\n",
      "Train Epoch: 846 [900/2589 (35%)]\tLoss: 177.733566\n",
      "Train Epoch: 846 [1200/2589 (46%)]\tLoss: 175.363235\n",
      "Train Epoch: 846 [1500/2589 (58%)]\tLoss: 259.992950\n",
      "Train Epoch: 846 [1800/2589 (70%)]\tLoss: 234.302444\n",
      "Train Epoch: 846 [2100/2589 (81%)]\tLoss: 299.062164\n",
      "Train Epoch: 846 [2400/2589 (93%)]\tLoss: 191.595047\n",
      "====> Epoch: 846 Average train loss: 224.8898\n",
      "====> Epoch: 846 Average test loss: 923.8436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 847 [0/2589 (0%)]\tLoss: 163.900467\n",
      "Train Epoch: 847 [300/2589 (12%)]\tLoss: 352.241608\n",
      "Train Epoch: 847 [600/2589 (23%)]\tLoss: 288.439789\n",
      "Train Epoch: 847 [900/2589 (35%)]\tLoss: 145.374771\n",
      "Train Epoch: 847 [1200/2589 (46%)]\tLoss: 214.688080\n",
      "Train Epoch: 847 [1500/2589 (58%)]\tLoss: 278.961273\n",
      "Train Epoch: 847 [1800/2589 (70%)]\tLoss: 249.569855\n",
      "Train Epoch: 847 [2100/2589 (81%)]\tLoss: 222.005127\n",
      "Train Epoch: 847 [2400/2589 (93%)]\tLoss: 272.460297\n",
      "====> Epoch: 847 Average train loss: 230.9333\n",
      "====> Epoch: 847 Average test loss: 948.2270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 848 [0/2589 (0%)]\tLoss: 250.063217\n",
      "Train Epoch: 848 [300/2589 (12%)]\tLoss: 219.910309\n",
      "Train Epoch: 848 [600/2589 (23%)]\tLoss: 345.265076\n",
      "Train Epoch: 848 [900/2589 (35%)]\tLoss: 198.110672\n",
      "Train Epoch: 848 [1200/2589 (46%)]\tLoss: 233.696823\n",
      "Train Epoch: 848 [1500/2589 (58%)]\tLoss: 197.601425\n",
      "Train Epoch: 848 [1800/2589 (70%)]\tLoss: 218.126373\n",
      "Train Epoch: 848 [2100/2589 (81%)]\tLoss: 175.318848\n",
      "Train Epoch: 848 [2400/2589 (93%)]\tLoss: 195.812317\n",
      "====> Epoch: 848 Average train loss: 220.0924\n",
      "====> Epoch: 848 Average test loss: 919.6782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 849 [0/2589 (0%)]\tLoss: 392.035034\n",
      "Train Epoch: 849 [300/2589 (12%)]\tLoss: 339.990448\n",
      "Train Epoch: 849 [600/2589 (23%)]\tLoss: 243.925156\n",
      "Train Epoch: 849 [900/2589 (35%)]\tLoss: 218.572250\n",
      "Train Epoch: 849 [1200/2589 (46%)]\tLoss: 275.619629\n",
      "Train Epoch: 849 [1500/2589 (58%)]\tLoss: 234.874451\n",
      "Train Epoch: 849 [1800/2589 (70%)]\tLoss: 246.656937\n",
      "Train Epoch: 849 [2100/2589 (81%)]\tLoss: 176.977982\n",
      "Train Epoch: 849 [2400/2589 (93%)]\tLoss: 286.558136\n",
      "====> Epoch: 849 Average train loss: 234.7659\n",
      "====> Epoch: 849 Average test loss: 913.9066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 850 [0/2589 (0%)]\tLoss: 155.827148\n",
      "Train Epoch: 850 [300/2589 (12%)]\tLoss: 178.759995\n",
      "Train Epoch: 850 [600/2589 (23%)]\tLoss: 170.634598\n",
      "Train Epoch: 850 [900/2589 (35%)]\tLoss: 242.758316\n",
      "Train Epoch: 850 [1200/2589 (46%)]\tLoss: 258.126831\n",
      "Train Epoch: 850 [1500/2589 (58%)]\tLoss: 265.608063\n",
      "Train Epoch: 850 [1800/2589 (70%)]\tLoss: 185.935898\n",
      "Train Epoch: 850 [2100/2589 (81%)]\tLoss: 208.331772\n",
      "Train Epoch: 850 [2400/2589 (93%)]\tLoss: 186.035721\n",
      "====> Epoch: 850 Average train loss: 216.2564\n",
      "====> Epoch: 850 Average test loss: 930.1568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 851 [0/2589 (0%)]\tLoss: 199.478867\n",
      "Train Epoch: 851 [300/2589 (12%)]\tLoss: 161.206024\n",
      "Train Epoch: 851 [600/2589 (23%)]\tLoss: 185.779160\n",
      "Train Epoch: 851 [900/2589 (35%)]\tLoss: 196.188446\n",
      "Train Epoch: 851 [1200/2589 (46%)]\tLoss: 450.726929\n",
      "Train Epoch: 851 [1500/2589 (58%)]\tLoss: 143.210510\n",
      "Train Epoch: 851 [1800/2589 (70%)]\tLoss: 223.119858\n",
      "Train Epoch: 851 [2100/2589 (81%)]\tLoss: 334.133087\n",
      "Train Epoch: 851 [2400/2589 (93%)]\tLoss: 283.047058\n",
      "====> Epoch: 851 Average train loss: 218.4338\n",
      "====> Epoch: 851 Average test loss: 931.7657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 852 [0/2589 (0%)]\tLoss: 330.044098\n",
      "Train Epoch: 852 [300/2589 (12%)]\tLoss: 173.359406\n",
      "Train Epoch: 852 [600/2589 (23%)]\tLoss: 144.954651\n",
      "Train Epoch: 852 [900/2589 (35%)]\tLoss: 167.392731\n",
      "Train Epoch: 852 [1200/2589 (46%)]\tLoss: 180.957687\n",
      "Train Epoch: 852 [1500/2589 (58%)]\tLoss: 209.614655\n",
      "Train Epoch: 852 [1800/2589 (70%)]\tLoss: 258.564636\n",
      "Train Epoch: 852 [2100/2589 (81%)]\tLoss: 244.614639\n",
      "Train Epoch: 852 [2400/2589 (93%)]\tLoss: 244.720184\n",
      "====> Epoch: 852 Average train loss: 224.3590\n",
      "====> Epoch: 852 Average test loss: 911.4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 853 [0/2589 (0%)]\tLoss: 211.600113\n",
      "Train Epoch: 853 [300/2589 (12%)]\tLoss: 201.507065\n",
      "Train Epoch: 853 [600/2589 (23%)]\tLoss: 177.702866\n",
      "Train Epoch: 853 [900/2589 (35%)]\tLoss: 159.156326\n",
      "Train Epoch: 853 [1200/2589 (46%)]\tLoss: 344.487213\n",
      "Train Epoch: 853 [1500/2589 (58%)]\tLoss: 227.785828\n",
      "Train Epoch: 853 [1800/2589 (70%)]\tLoss: 244.614807\n",
      "Train Epoch: 853 [2100/2589 (81%)]\tLoss: 246.460480\n",
      "Train Epoch: 853 [2400/2589 (93%)]\tLoss: 367.053711\n",
      "====> Epoch: 853 Average train loss: 234.6985\n",
      "====> Epoch: 853 Average test loss: 922.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 854 [0/2589 (0%)]\tLoss: 333.951111\n",
      "Train Epoch: 854 [300/2589 (12%)]\tLoss: 212.198334\n",
      "Train Epoch: 854 [600/2589 (23%)]\tLoss: 219.926453\n",
      "Train Epoch: 854 [900/2589 (35%)]\tLoss: 211.890854\n",
      "Train Epoch: 854 [1200/2589 (46%)]\tLoss: 177.312515\n",
      "Train Epoch: 854 [1500/2589 (58%)]\tLoss: 206.685867\n",
      "Train Epoch: 854 [1800/2589 (70%)]\tLoss: 151.575912\n",
      "Train Epoch: 854 [2100/2589 (81%)]\tLoss: 213.956833\n",
      "Train Epoch: 854 [2400/2589 (93%)]\tLoss: 306.864380\n",
      "====> Epoch: 854 Average train loss: 223.2951\n",
      "====> Epoch: 854 Average test loss: 911.0117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 855 [0/2589 (0%)]\tLoss: 177.281052\n",
      "Train Epoch: 855 [300/2589 (12%)]\tLoss: 216.922043\n",
      "Train Epoch: 855 [600/2589 (23%)]\tLoss: 185.539551\n",
      "Train Epoch: 855 [900/2589 (35%)]\tLoss: 188.237366\n",
      "Train Epoch: 855 [1200/2589 (46%)]\tLoss: 189.291290\n",
      "Train Epoch: 855 [1500/2589 (58%)]\tLoss: 217.944626\n",
      "Train Epoch: 855 [1800/2589 (70%)]\tLoss: 169.844498\n",
      "Train Epoch: 855 [2100/2589 (81%)]\tLoss: 282.211731\n",
      "Train Epoch: 855 [2400/2589 (93%)]\tLoss: 224.618011\n",
      "====> Epoch: 855 Average train loss: 230.0661\n",
      "====> Epoch: 855 Average test loss: 918.4299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 856 [0/2589 (0%)]\tLoss: 213.763962\n",
      "Train Epoch: 856 [300/2589 (12%)]\tLoss: 239.439545\n",
      "Train Epoch: 856 [600/2589 (23%)]\tLoss: 323.154358\n",
      "Train Epoch: 856 [900/2589 (35%)]\tLoss: 170.904068\n",
      "Train Epoch: 856 [1200/2589 (46%)]\tLoss: 240.323013\n",
      "Train Epoch: 856 [1500/2589 (58%)]\tLoss: 267.773346\n",
      "Train Epoch: 856 [1800/2589 (70%)]\tLoss: 182.932938\n",
      "Train Epoch: 856 [2100/2589 (81%)]\tLoss: 171.745667\n",
      "Train Epoch: 856 [2400/2589 (93%)]\tLoss: 289.449036\n",
      "====> Epoch: 856 Average train loss: 232.3610\n",
      "====> Epoch: 856 Average test loss: 913.9585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 857 [0/2589 (0%)]\tLoss: 171.129562\n",
      "Train Epoch: 857 [300/2589 (12%)]\tLoss: 227.834167\n",
      "Train Epoch: 857 [600/2589 (23%)]\tLoss: 167.312241\n",
      "Train Epoch: 857 [900/2589 (35%)]\tLoss: 163.811447\n",
      "Train Epoch: 857 [1200/2589 (46%)]\tLoss: 190.835037\n",
      "Train Epoch: 857 [1500/2589 (58%)]\tLoss: 252.915359\n",
      "Train Epoch: 857 [1800/2589 (70%)]\tLoss: 159.569717\n",
      "Train Epoch: 857 [2100/2589 (81%)]\tLoss: 267.499115\n",
      "Train Epoch: 857 [2400/2589 (93%)]\tLoss: 251.318359\n",
      "====> Epoch: 857 Average train loss: 213.1220\n",
      "====> Epoch: 857 Average test loss: 945.2865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 858 [0/2589 (0%)]\tLoss: 289.417694\n",
      "Train Epoch: 858 [300/2589 (12%)]\tLoss: 224.760986\n",
      "Train Epoch: 858 [600/2589 (23%)]\tLoss: 248.768784\n",
      "Train Epoch: 858 [900/2589 (35%)]\tLoss: 203.278610\n",
      "Train Epoch: 858 [1200/2589 (46%)]\tLoss: 288.611908\n",
      "Train Epoch: 858 [1500/2589 (58%)]\tLoss: 231.421585\n",
      "Train Epoch: 858 [1800/2589 (70%)]\tLoss: 133.336685\n",
      "Train Epoch: 858 [2100/2589 (81%)]\tLoss: 185.492386\n",
      "Train Epoch: 858 [2400/2589 (93%)]\tLoss: 183.262924\n",
      "====> Epoch: 858 Average train loss: 217.6290\n",
      "====> Epoch: 858 Average test loss: 918.4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 859 [0/2589 (0%)]\tLoss: 214.170990\n",
      "Train Epoch: 859 [300/2589 (12%)]\tLoss: 156.671936\n",
      "Train Epoch: 859 [600/2589 (23%)]\tLoss: 248.753769\n",
      "Train Epoch: 859 [900/2589 (35%)]\tLoss: 279.540100\n",
      "Train Epoch: 859 [1200/2589 (46%)]\tLoss: 223.729889\n",
      "Train Epoch: 859 [1500/2589 (58%)]\tLoss: 329.204590\n",
      "Train Epoch: 859 [1800/2589 (70%)]\tLoss: 182.858612\n",
      "Train Epoch: 859 [2100/2589 (81%)]\tLoss: 183.061172\n",
      "Train Epoch: 859 [2400/2589 (93%)]\tLoss: 231.480774\n",
      "====> Epoch: 859 Average train loss: 219.2078\n",
      "====> Epoch: 859 Average test loss: 917.9567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 860 [0/2589 (0%)]\tLoss: 161.434906\n",
      "Train Epoch: 860 [300/2589 (12%)]\tLoss: 174.651917\n",
      "Train Epoch: 860 [600/2589 (23%)]\tLoss: 271.287415\n",
      "Train Epoch: 860 [900/2589 (35%)]\tLoss: 390.482910\n",
      "Train Epoch: 860 [1200/2589 (46%)]\tLoss: 240.130234\n",
      "Train Epoch: 860 [1500/2589 (58%)]\tLoss: 177.279465\n",
      "Train Epoch: 860 [1800/2589 (70%)]\tLoss: 229.393845\n",
      "Train Epoch: 860 [2100/2589 (81%)]\tLoss: 193.587234\n",
      "Train Epoch: 860 [2400/2589 (93%)]\tLoss: 418.832520\n",
      "====> Epoch: 860 Average train loss: 229.9428\n",
      "====> Epoch: 860 Average test loss: 911.1133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 861 [0/2589 (0%)]\tLoss: 245.612366\n",
      "Train Epoch: 861 [300/2589 (12%)]\tLoss: 223.569962\n",
      "Train Epoch: 861 [600/2589 (23%)]\tLoss: 323.784760\n",
      "Train Epoch: 861 [900/2589 (35%)]\tLoss: 180.175369\n",
      "Train Epoch: 861 [1200/2589 (46%)]\tLoss: 227.602112\n",
      "Train Epoch: 861 [1500/2589 (58%)]\tLoss: 212.379974\n",
      "Train Epoch: 861 [1800/2589 (70%)]\tLoss: 254.437042\n",
      "Train Epoch: 861 [2100/2589 (81%)]\tLoss: 262.984924\n",
      "Train Epoch: 861 [2400/2589 (93%)]\tLoss: 208.591568\n",
      "====> Epoch: 861 Average train loss: 223.6395\n",
      "====> Epoch: 861 Average test loss: 919.1132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 862 [0/2589 (0%)]\tLoss: 235.763840\n",
      "Train Epoch: 862 [300/2589 (12%)]\tLoss: 189.393829\n",
      "Train Epoch: 862 [600/2589 (23%)]\tLoss: 273.050903\n",
      "Train Epoch: 862 [900/2589 (35%)]\tLoss: 247.778397\n",
      "Train Epoch: 862 [1200/2589 (46%)]\tLoss: 167.405624\n",
      "Train Epoch: 862 [1500/2589 (58%)]\tLoss: 355.944946\n",
      "Train Epoch: 862 [1800/2589 (70%)]\tLoss: 225.421646\n",
      "Train Epoch: 862 [2100/2589 (81%)]\tLoss: 219.726700\n",
      "Train Epoch: 862 [2400/2589 (93%)]\tLoss: 154.023773\n",
      "====> Epoch: 862 Average train loss: 227.7243\n",
      "====> Epoch: 862 Average test loss: 922.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 863 [0/2589 (0%)]\tLoss: 182.147675\n",
      "Train Epoch: 863 [300/2589 (12%)]\tLoss: 220.289871\n",
      "Train Epoch: 863 [600/2589 (23%)]\tLoss: 195.751770\n",
      "Train Epoch: 863 [900/2589 (35%)]\tLoss: 147.749771\n",
      "Train Epoch: 863 [1200/2589 (46%)]\tLoss: 216.703873\n",
      "Train Epoch: 863 [1500/2589 (58%)]\tLoss: 173.776627\n",
      "Train Epoch: 863 [1800/2589 (70%)]\tLoss: 381.168854\n",
      "Train Epoch: 863 [2100/2589 (81%)]\tLoss: 235.686005\n",
      "Train Epoch: 863 [2400/2589 (93%)]\tLoss: 231.331558\n",
      "====> Epoch: 863 Average train loss: 224.0472\n",
      "====> Epoch: 863 Average test loss: 918.8647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 864 [0/2589 (0%)]\tLoss: 189.325302\n",
      "Train Epoch: 864 [300/2589 (12%)]\tLoss: 312.059113\n",
      "Train Epoch: 864 [600/2589 (23%)]\tLoss: 236.571075\n",
      "Train Epoch: 864 [900/2589 (35%)]\tLoss: 216.033936\n",
      "Train Epoch: 864 [1200/2589 (46%)]\tLoss: 256.334503\n",
      "Train Epoch: 864 [1500/2589 (58%)]\tLoss: 236.239319\n",
      "Train Epoch: 864 [1800/2589 (70%)]\tLoss: 190.791275\n",
      "Train Epoch: 864 [2100/2589 (81%)]\tLoss: 233.745407\n",
      "Train Epoch: 864 [2400/2589 (93%)]\tLoss: 176.077133\n",
      "====> Epoch: 864 Average train loss: 230.9305\n",
      "====> Epoch: 864 Average test loss: 938.6795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 865 [0/2589 (0%)]\tLoss: 239.312225\n",
      "Train Epoch: 865 [300/2589 (12%)]\tLoss: 199.162735\n",
      "Train Epoch: 865 [600/2589 (23%)]\tLoss: 156.719940\n",
      "Train Epoch: 865 [900/2589 (35%)]\tLoss: 228.360550\n",
      "Train Epoch: 865 [1200/2589 (46%)]\tLoss: 238.666077\n",
      "Train Epoch: 865 [1500/2589 (58%)]\tLoss: 225.755310\n",
      "Train Epoch: 865 [1800/2589 (70%)]\tLoss: 251.275925\n",
      "Train Epoch: 865 [2100/2589 (81%)]\tLoss: 255.534149\n",
      "Train Epoch: 865 [2400/2589 (93%)]\tLoss: 176.644547\n",
      "====> Epoch: 865 Average train loss: 218.3256\n",
      "====> Epoch: 865 Average test loss: 925.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 866 [0/2589 (0%)]\tLoss: 239.763016\n",
      "Train Epoch: 866 [300/2589 (12%)]\tLoss: 136.934982\n",
      "Train Epoch: 866 [600/2589 (23%)]\tLoss: 267.137756\n",
      "Train Epoch: 866 [900/2589 (35%)]\tLoss: 230.649963\n",
      "Train Epoch: 866 [1200/2589 (46%)]\tLoss: 317.867249\n",
      "Train Epoch: 866 [1500/2589 (58%)]\tLoss: 298.247925\n",
      "Train Epoch: 866 [1800/2589 (70%)]\tLoss: 281.576385\n",
      "Train Epoch: 866 [2100/2589 (81%)]\tLoss: 282.101837\n",
      "Train Epoch: 866 [2400/2589 (93%)]\tLoss: 179.674988\n",
      "====> Epoch: 866 Average train loss: 221.7773\n",
      "====> Epoch: 866 Average test loss: 941.2596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 867 [0/2589 (0%)]\tLoss: 202.823959\n",
      "Train Epoch: 867 [300/2589 (12%)]\tLoss: 262.451050\n",
      "Train Epoch: 867 [600/2589 (23%)]\tLoss: 244.913269\n",
      "Train Epoch: 867 [900/2589 (35%)]\tLoss: 263.443481\n",
      "Train Epoch: 867 [1200/2589 (46%)]\tLoss: 262.548523\n",
      "Train Epoch: 867 [1500/2589 (58%)]\tLoss: 193.049835\n",
      "Train Epoch: 867 [1800/2589 (70%)]\tLoss: 222.000443\n",
      "Train Epoch: 867 [2100/2589 (81%)]\tLoss: 422.915466\n",
      "Train Epoch: 867 [2400/2589 (93%)]\tLoss: 240.035172\n",
      "====> Epoch: 867 Average train loss: 234.5817\n",
      "====> Epoch: 867 Average test loss: 921.5139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 868 [0/2589 (0%)]\tLoss: 200.654297\n",
      "Train Epoch: 868 [300/2589 (12%)]\tLoss: 230.314972\n",
      "Train Epoch: 868 [600/2589 (23%)]\tLoss: 164.688187\n",
      "Train Epoch: 868 [900/2589 (35%)]\tLoss: 350.017151\n",
      "Train Epoch: 868 [1200/2589 (46%)]\tLoss: 255.420975\n",
      "Train Epoch: 868 [1500/2589 (58%)]\tLoss: 205.368805\n",
      "Train Epoch: 868 [1800/2589 (70%)]\tLoss: 229.960831\n",
      "Train Epoch: 868 [2100/2589 (81%)]\tLoss: 233.402008\n",
      "Train Epoch: 868 [2400/2589 (93%)]\tLoss: 141.160721\n",
      "====> Epoch: 868 Average train loss: 227.2524\n",
      "====> Epoch: 868 Average test loss: 924.3536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 869 [0/2589 (0%)]\tLoss: 209.971970\n",
      "Train Epoch: 869 [300/2589 (12%)]\tLoss: 208.747955\n",
      "Train Epoch: 869 [600/2589 (23%)]\tLoss: 168.631012\n",
      "Train Epoch: 869 [900/2589 (35%)]\tLoss: 190.677826\n",
      "Train Epoch: 869 [1200/2589 (46%)]\tLoss: 286.038025\n",
      "Train Epoch: 869 [1500/2589 (58%)]\tLoss: 176.623032\n",
      "Train Epoch: 869 [1800/2589 (70%)]\tLoss: 156.532501\n",
      "Train Epoch: 869 [2100/2589 (81%)]\tLoss: 280.492584\n",
      "Train Epoch: 869 [2400/2589 (93%)]\tLoss: 172.403275\n",
      "====> Epoch: 869 Average train loss: 230.0710\n",
      "====> Epoch: 869 Average test loss: 925.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 870 [0/2589 (0%)]\tLoss: 156.701416\n",
      "Train Epoch: 870 [300/2589 (12%)]\tLoss: 163.541199\n",
      "Train Epoch: 870 [600/2589 (23%)]\tLoss: 226.868683\n",
      "Train Epoch: 870 [900/2589 (35%)]\tLoss: 251.546387\n",
      "Train Epoch: 870 [1200/2589 (46%)]\tLoss: 194.666977\n",
      "Train Epoch: 870 [1500/2589 (58%)]\tLoss: 192.225067\n",
      "Train Epoch: 870 [1800/2589 (70%)]\tLoss: 140.720078\n",
      "Train Epoch: 870 [2100/2589 (81%)]\tLoss: 158.967224\n",
      "Train Epoch: 870 [2400/2589 (93%)]\tLoss: 203.315216\n",
      "====> Epoch: 870 Average train loss: 219.5772\n",
      "====> Epoch: 870 Average test loss: 909.2545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 871 [0/2589 (0%)]\tLoss: 361.176422\n",
      "Train Epoch: 871 [300/2589 (12%)]\tLoss: 196.901169\n",
      "Train Epoch: 871 [600/2589 (23%)]\tLoss: 221.541809\n",
      "Train Epoch: 871 [900/2589 (35%)]\tLoss: 249.088104\n",
      "Train Epoch: 871 [1200/2589 (46%)]\tLoss: 198.499786\n",
      "Train Epoch: 871 [1500/2589 (58%)]\tLoss: 134.229111\n",
      "Train Epoch: 871 [1800/2589 (70%)]\tLoss: 272.271545\n",
      "Train Epoch: 871 [2100/2589 (81%)]\tLoss: 246.575027\n",
      "Train Epoch: 871 [2400/2589 (93%)]\tLoss: 343.112579\n",
      "====> Epoch: 871 Average train loss: 223.2203\n",
      "====> Epoch: 871 Average test loss: 918.6344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 872 [0/2589 (0%)]\tLoss: 167.946930\n",
      "Train Epoch: 872 [300/2589 (12%)]\tLoss: 276.639587\n",
      "Train Epoch: 872 [600/2589 (23%)]\tLoss: 179.123398\n",
      "Train Epoch: 872 [900/2589 (35%)]\tLoss: 196.810074\n",
      "Train Epoch: 872 [1200/2589 (46%)]\tLoss: 334.942535\n",
      "Train Epoch: 872 [1500/2589 (58%)]\tLoss: 301.135681\n",
      "Train Epoch: 872 [1800/2589 (70%)]\tLoss: 230.493622\n",
      "Train Epoch: 872 [2100/2589 (81%)]\tLoss: 245.428391\n",
      "Train Epoch: 872 [2400/2589 (93%)]\tLoss: 191.643616\n",
      "====> Epoch: 872 Average train loss: 229.3188\n",
      "====> Epoch: 872 Average test loss: 920.2099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 873 [0/2589 (0%)]\tLoss: 243.972702\n",
      "Train Epoch: 873 [300/2589 (12%)]\tLoss: 309.171356\n",
      "Train Epoch: 873 [600/2589 (23%)]\tLoss: 198.424789\n",
      "Train Epoch: 873 [900/2589 (35%)]\tLoss: 230.847275\n",
      "Train Epoch: 873 [1200/2589 (46%)]\tLoss: 110.499496\n",
      "Train Epoch: 873 [1500/2589 (58%)]\tLoss: 263.173218\n",
      "Train Epoch: 873 [1800/2589 (70%)]\tLoss: 228.098450\n",
      "Train Epoch: 873 [2100/2589 (81%)]\tLoss: 344.788055\n",
      "Train Epoch: 873 [2400/2589 (93%)]\tLoss: 165.190399\n",
      "====> Epoch: 873 Average train loss: 224.1432\n",
      "====> Epoch: 873 Average test loss: 905.1424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 874 [0/2589 (0%)]\tLoss: 163.163223\n",
      "Train Epoch: 874 [300/2589 (12%)]\tLoss: 228.988678\n",
      "Train Epoch: 874 [600/2589 (23%)]\tLoss: 191.935928\n",
      "Train Epoch: 874 [900/2589 (35%)]\tLoss: 293.808960\n",
      "Train Epoch: 874 [1200/2589 (46%)]\tLoss: 310.573334\n",
      "Train Epoch: 874 [1500/2589 (58%)]\tLoss: 153.039291\n",
      "Train Epoch: 874 [1800/2589 (70%)]\tLoss: 168.395447\n",
      "Train Epoch: 874 [2100/2589 (81%)]\tLoss: 413.661652\n",
      "Train Epoch: 874 [2400/2589 (93%)]\tLoss: 147.926407\n",
      "====> Epoch: 874 Average train loss: 227.6955\n",
      "====> Epoch: 874 Average test loss: 918.1973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 875 [0/2589 (0%)]\tLoss: 181.612198\n",
      "Train Epoch: 875 [300/2589 (12%)]\tLoss: 265.683868\n",
      "Train Epoch: 875 [600/2589 (23%)]\tLoss: 232.934952\n",
      "Train Epoch: 875 [900/2589 (35%)]\tLoss: 237.918854\n",
      "Train Epoch: 875 [1200/2589 (46%)]\tLoss: 186.946945\n",
      "Train Epoch: 875 [1500/2589 (58%)]\tLoss: 275.476379\n",
      "Train Epoch: 875 [1800/2589 (70%)]\tLoss: 198.979111\n",
      "Train Epoch: 875 [2100/2589 (81%)]\tLoss: 273.172089\n",
      "Train Epoch: 875 [2400/2589 (93%)]\tLoss: 234.258087\n",
      "====> Epoch: 875 Average train loss: 227.6146\n",
      "====> Epoch: 875 Average test loss: 914.5988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 876 [0/2589 (0%)]\tLoss: 152.658142\n",
      "Train Epoch: 876 [300/2589 (12%)]\tLoss: 205.722687\n",
      "Train Epoch: 876 [600/2589 (23%)]\tLoss: 269.947693\n",
      "Train Epoch: 876 [900/2589 (35%)]\tLoss: 169.580154\n",
      "Train Epoch: 876 [1200/2589 (46%)]\tLoss: 170.424377\n",
      "Train Epoch: 876 [1500/2589 (58%)]\tLoss: 182.110748\n",
      "Train Epoch: 876 [1800/2589 (70%)]\tLoss: 291.356964\n",
      "Train Epoch: 876 [2100/2589 (81%)]\tLoss: 242.749359\n",
      "Train Epoch: 876 [2400/2589 (93%)]\tLoss: 177.762268\n",
      "====> Epoch: 876 Average train loss: 227.5173\n",
      "====> Epoch: 876 Average test loss: 920.5174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 877 [0/2589 (0%)]\tLoss: 179.912598\n",
      "Train Epoch: 877 [300/2589 (12%)]\tLoss: 286.235870\n",
      "Train Epoch: 877 [600/2589 (23%)]\tLoss: 324.585419\n",
      "Train Epoch: 877 [900/2589 (35%)]\tLoss: 195.122025\n",
      "Train Epoch: 877 [1200/2589 (46%)]\tLoss: 215.977631\n",
      "Train Epoch: 877 [1500/2589 (58%)]\tLoss: 212.027771\n",
      "Train Epoch: 877 [1800/2589 (70%)]\tLoss: 168.966003\n",
      "Train Epoch: 877 [2100/2589 (81%)]\tLoss: 275.401093\n",
      "Train Epoch: 877 [2400/2589 (93%)]\tLoss: 212.351044\n",
      "====> Epoch: 877 Average train loss: 229.9454\n",
      "====> Epoch: 877 Average test loss: 912.7460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 878 [0/2589 (0%)]\tLoss: 250.528229\n",
      "Train Epoch: 878 [300/2589 (12%)]\tLoss: 167.276398\n",
      "Train Epoch: 878 [600/2589 (23%)]\tLoss: 183.667419\n",
      "Train Epoch: 878 [900/2589 (35%)]\tLoss: 216.627411\n",
      "Train Epoch: 878 [1200/2589 (46%)]\tLoss: 185.809601\n",
      "Train Epoch: 878 [1500/2589 (58%)]\tLoss: 177.141434\n",
      "Train Epoch: 878 [1800/2589 (70%)]\tLoss: 186.611526\n",
      "Train Epoch: 878 [2100/2589 (81%)]\tLoss: 224.823776\n",
      "Train Epoch: 878 [2400/2589 (93%)]\tLoss: 215.405182\n",
      "====> Epoch: 878 Average train loss: 218.7224\n",
      "====> Epoch: 878 Average test loss: 919.6663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 879 [0/2589 (0%)]\tLoss: 256.214203\n",
      "Train Epoch: 879 [300/2589 (12%)]\tLoss: 173.834824\n",
      "Train Epoch: 879 [600/2589 (23%)]\tLoss: 244.345352\n",
      "Train Epoch: 879 [900/2589 (35%)]\tLoss: 193.115921\n",
      "Train Epoch: 879 [1200/2589 (46%)]\tLoss: 249.951080\n",
      "Train Epoch: 879 [1500/2589 (58%)]\tLoss: 240.802048\n",
      "Train Epoch: 879 [1800/2589 (70%)]\tLoss: 374.780853\n",
      "Train Epoch: 879 [2100/2589 (81%)]\tLoss: 228.248734\n",
      "Train Epoch: 879 [2400/2589 (93%)]\tLoss: 152.393127\n",
      "====> Epoch: 879 Average train loss: 233.8880\n",
      "====> Epoch: 879 Average test loss: 941.8832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 880 [0/2589 (0%)]\tLoss: 212.444717\n",
      "Train Epoch: 880 [300/2589 (12%)]\tLoss: 215.450592\n",
      "Train Epoch: 880 [600/2589 (23%)]\tLoss: 380.381226\n",
      "Train Epoch: 880 [900/2589 (35%)]\tLoss: 262.421021\n",
      "Train Epoch: 880 [1200/2589 (46%)]\tLoss: 187.292938\n",
      "Train Epoch: 880 [1500/2589 (58%)]\tLoss: 183.665054\n",
      "Train Epoch: 880 [1800/2589 (70%)]\tLoss: 248.949615\n",
      "Train Epoch: 880 [2100/2589 (81%)]\tLoss: 174.860031\n",
      "Train Epoch: 880 [2400/2589 (93%)]\tLoss: 315.089325\n",
      "====> Epoch: 880 Average train loss: 225.4101\n",
      "====> Epoch: 880 Average test loss: 922.8687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 881 [0/2589 (0%)]\tLoss: 166.838440\n",
      "Train Epoch: 881 [300/2589 (12%)]\tLoss: 226.385651\n",
      "Train Epoch: 881 [600/2589 (23%)]\tLoss: 243.444901\n",
      "Train Epoch: 881 [900/2589 (35%)]\tLoss: 219.040131\n",
      "Train Epoch: 881 [1200/2589 (46%)]\tLoss: 233.588730\n",
      "Train Epoch: 881 [1500/2589 (58%)]\tLoss: 371.420776\n",
      "Train Epoch: 881 [1800/2589 (70%)]\tLoss: 209.583069\n",
      "Train Epoch: 881 [2100/2589 (81%)]\tLoss: 370.242859\n",
      "Train Epoch: 881 [2400/2589 (93%)]\tLoss: 155.496185\n",
      "====> Epoch: 881 Average train loss: 223.1892\n",
      "====> Epoch: 881 Average test loss: 915.5067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 882 [0/2589 (0%)]\tLoss: 147.871964\n",
      "Train Epoch: 882 [300/2589 (12%)]\tLoss: 229.098328\n",
      "Train Epoch: 882 [600/2589 (23%)]\tLoss: 230.284698\n",
      "Train Epoch: 882 [900/2589 (35%)]\tLoss: 244.123062\n",
      "Train Epoch: 882 [1200/2589 (46%)]\tLoss: 342.070587\n",
      "Train Epoch: 882 [1500/2589 (58%)]\tLoss: 174.186783\n",
      "Train Epoch: 882 [1800/2589 (70%)]\tLoss: 188.455795\n",
      "Train Epoch: 882 [2100/2589 (81%)]\tLoss: 208.207809\n",
      "Train Epoch: 882 [2400/2589 (93%)]\tLoss: 234.874420\n",
      "====> Epoch: 882 Average train loss: 225.7927\n",
      "====> Epoch: 882 Average test loss: 919.4209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 883 [0/2589 (0%)]\tLoss: 275.844269\n",
      "Train Epoch: 883 [300/2589 (12%)]\tLoss: 258.170502\n",
      "Train Epoch: 883 [600/2589 (23%)]\tLoss: 206.698013\n",
      "Train Epoch: 883 [900/2589 (35%)]\tLoss: 221.212296\n",
      "Train Epoch: 883 [1200/2589 (46%)]\tLoss: 255.531738\n",
      "Train Epoch: 883 [1500/2589 (58%)]\tLoss: 193.257919\n",
      "Train Epoch: 883 [1800/2589 (70%)]\tLoss: 182.366501\n",
      "Train Epoch: 883 [2100/2589 (81%)]\tLoss: 143.908188\n",
      "Train Epoch: 883 [2400/2589 (93%)]\tLoss: 251.268875\n",
      "====> Epoch: 883 Average train loss: 231.6987\n",
      "====> Epoch: 883 Average test loss: 916.3008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 884 [0/2589 (0%)]\tLoss: 397.835907\n",
      "Train Epoch: 884 [300/2589 (12%)]\tLoss: 192.144699\n",
      "Train Epoch: 884 [600/2589 (23%)]\tLoss: 284.055573\n",
      "Train Epoch: 884 [900/2589 (35%)]\tLoss: 325.816864\n",
      "Train Epoch: 884 [1200/2589 (46%)]\tLoss: 362.046753\n",
      "Train Epoch: 884 [1500/2589 (58%)]\tLoss: 191.376541\n",
      "Train Epoch: 884 [1800/2589 (70%)]\tLoss: 205.426819\n",
      "Train Epoch: 884 [2100/2589 (81%)]\tLoss: 288.725708\n",
      "Train Epoch: 884 [2400/2589 (93%)]\tLoss: 152.638824\n",
      "====> Epoch: 884 Average train loss: 225.4596\n",
      "====> Epoch: 884 Average test loss: 912.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 885 [0/2589 (0%)]\tLoss: 265.405365\n",
      "Train Epoch: 885 [300/2589 (12%)]\tLoss: 252.209152\n",
      "Train Epoch: 885 [600/2589 (23%)]\tLoss: 212.212234\n",
      "Train Epoch: 885 [900/2589 (35%)]\tLoss: 206.184158\n",
      "Train Epoch: 885 [1200/2589 (46%)]\tLoss: 257.767426\n",
      "Train Epoch: 885 [1500/2589 (58%)]\tLoss: 197.596176\n",
      "Train Epoch: 885 [1800/2589 (70%)]\tLoss: 175.569016\n",
      "Train Epoch: 885 [2100/2589 (81%)]\tLoss: 146.974197\n",
      "Train Epoch: 885 [2400/2589 (93%)]\tLoss: 267.737823\n",
      "====> Epoch: 885 Average train loss: 233.4589\n",
      "====> Epoch: 885 Average test loss: 904.0607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 886 [0/2589 (0%)]\tLoss: 206.662903\n",
      "Train Epoch: 886 [300/2589 (12%)]\tLoss: 155.912491\n",
      "Train Epoch: 886 [600/2589 (23%)]\tLoss: 101.717682\n",
      "Train Epoch: 886 [900/2589 (35%)]\tLoss: 143.664459\n",
      "Train Epoch: 886 [1200/2589 (46%)]\tLoss: 163.764725\n",
      "Train Epoch: 886 [1500/2589 (58%)]\tLoss: 262.990814\n",
      "Train Epoch: 886 [1800/2589 (70%)]\tLoss: 210.480240\n",
      "Train Epoch: 886 [2100/2589 (81%)]\tLoss: 181.920120\n",
      "Train Epoch: 886 [2400/2589 (93%)]\tLoss: 141.558853\n",
      "====> Epoch: 886 Average train loss: 217.5131\n",
      "====> Epoch: 886 Average test loss: 928.4863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 887 [0/2589 (0%)]\tLoss: 156.357132\n",
      "Train Epoch: 887 [300/2589 (12%)]\tLoss: 279.546936\n",
      "Train Epoch: 887 [600/2589 (23%)]\tLoss: 181.290207\n",
      "Train Epoch: 887 [900/2589 (35%)]\tLoss: 172.011185\n",
      "Train Epoch: 887 [1200/2589 (46%)]\tLoss: 168.981995\n",
      "Train Epoch: 887 [1500/2589 (58%)]\tLoss: 174.103165\n",
      "Train Epoch: 887 [1800/2589 (70%)]\tLoss: 170.209305\n",
      "Train Epoch: 887 [2100/2589 (81%)]\tLoss: 205.358612\n",
      "Train Epoch: 887 [2400/2589 (93%)]\tLoss: 327.244659\n",
      "====> Epoch: 887 Average train loss: 223.3356\n",
      "====> Epoch: 887 Average test loss: 915.5897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 888 [0/2589 (0%)]\tLoss: 185.601959\n",
      "Train Epoch: 888 [300/2589 (12%)]\tLoss: 266.495575\n",
      "Train Epoch: 888 [600/2589 (23%)]\tLoss: 147.779297\n",
      "Train Epoch: 888 [900/2589 (35%)]\tLoss: 465.559662\n",
      "Train Epoch: 888 [1200/2589 (46%)]\tLoss: 195.218231\n",
      "Train Epoch: 888 [1500/2589 (58%)]\tLoss: 201.139908\n",
      "Train Epoch: 888 [1800/2589 (70%)]\tLoss: 188.257721\n",
      "Train Epoch: 888 [2100/2589 (81%)]\tLoss: 243.437897\n",
      "Train Epoch: 888 [2400/2589 (93%)]\tLoss: 181.870865\n",
      "====> Epoch: 888 Average train loss: 229.9032\n",
      "====> Epoch: 888 Average test loss: 922.5697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 889 [0/2589 (0%)]\tLoss: 168.175720\n",
      "Train Epoch: 889 [300/2589 (12%)]\tLoss: 250.410706\n",
      "Train Epoch: 889 [600/2589 (23%)]\tLoss: 215.292099\n",
      "Train Epoch: 889 [900/2589 (35%)]\tLoss: 199.625824\n",
      "Train Epoch: 889 [1200/2589 (46%)]\tLoss: 238.233200\n",
      "Train Epoch: 889 [1500/2589 (58%)]\tLoss: 194.698441\n",
      "Train Epoch: 889 [1800/2589 (70%)]\tLoss: 156.737030\n",
      "Train Epoch: 889 [2100/2589 (81%)]\tLoss: 206.559067\n",
      "Train Epoch: 889 [2400/2589 (93%)]\tLoss: 408.748016\n",
      "====> Epoch: 889 Average train loss: 217.0917\n",
      "====> Epoch: 889 Average test loss: 902.5334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 890 [0/2589 (0%)]\tLoss: 201.386932\n",
      "Train Epoch: 890 [300/2589 (12%)]\tLoss: 316.985352\n",
      "Train Epoch: 890 [600/2589 (23%)]\tLoss: 190.013611\n",
      "Train Epoch: 890 [900/2589 (35%)]\tLoss: 216.185379\n",
      "Train Epoch: 890 [1200/2589 (46%)]\tLoss: 243.808395\n",
      "Train Epoch: 890 [1500/2589 (58%)]\tLoss: 186.859482\n",
      "Train Epoch: 890 [1800/2589 (70%)]\tLoss: 198.988373\n",
      "Train Epoch: 890 [2100/2589 (81%)]\tLoss: 278.136536\n",
      "Train Epoch: 890 [2400/2589 (93%)]\tLoss: 320.773651\n",
      "====> Epoch: 890 Average train loss: 228.5958\n",
      "====> Epoch: 890 Average test loss: 918.4245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 891 [0/2589 (0%)]\tLoss: 172.074722\n",
      "Train Epoch: 891 [300/2589 (12%)]\tLoss: 350.699249\n",
      "Train Epoch: 891 [600/2589 (23%)]\tLoss: 150.037247\n",
      "Train Epoch: 891 [900/2589 (35%)]\tLoss: 189.810928\n",
      "Train Epoch: 891 [1200/2589 (46%)]\tLoss: 301.653198\n",
      "Train Epoch: 891 [1500/2589 (58%)]\tLoss: 210.999603\n",
      "Train Epoch: 891 [1800/2589 (70%)]\tLoss: 203.387955\n",
      "Train Epoch: 891 [2100/2589 (81%)]\tLoss: 142.093094\n",
      "Train Epoch: 891 [2400/2589 (93%)]\tLoss: 130.604355\n",
      "====> Epoch: 891 Average train loss: 226.2426\n",
      "====> Epoch: 891 Average test loss: 928.6641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 892 [0/2589 (0%)]\tLoss: 215.963577\n",
      "Train Epoch: 892 [300/2589 (12%)]\tLoss: 349.587738\n",
      "Train Epoch: 892 [600/2589 (23%)]\tLoss: 158.889679\n",
      "Train Epoch: 892 [900/2589 (35%)]\tLoss: 249.228500\n",
      "Train Epoch: 892 [1200/2589 (46%)]\tLoss: 237.801102\n",
      "Train Epoch: 892 [1500/2589 (58%)]\tLoss: 176.839325\n",
      "Train Epoch: 892 [1800/2589 (70%)]\tLoss: 114.876549\n",
      "Train Epoch: 892 [2100/2589 (81%)]\tLoss: 153.408951\n",
      "Train Epoch: 892 [2400/2589 (93%)]\tLoss: 186.149734\n",
      "====> Epoch: 892 Average train loss: 215.0177\n",
      "====> Epoch: 892 Average test loss: 913.0483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 893 [0/2589 (0%)]\tLoss: 156.385590\n",
      "Train Epoch: 893 [300/2589 (12%)]\tLoss: 181.510162\n",
      "Train Epoch: 893 [600/2589 (23%)]\tLoss: 225.798676\n",
      "Train Epoch: 893 [900/2589 (35%)]\tLoss: 334.834259\n",
      "Train Epoch: 893 [1200/2589 (46%)]\tLoss: 222.107193\n",
      "Train Epoch: 893 [1500/2589 (58%)]\tLoss: 199.230957\n",
      "Train Epoch: 893 [1800/2589 (70%)]\tLoss: 239.949677\n",
      "Train Epoch: 893 [2100/2589 (81%)]\tLoss: 210.092560\n",
      "Train Epoch: 893 [2400/2589 (93%)]\tLoss: 253.781723\n",
      "====> Epoch: 893 Average train loss: 221.1523\n",
      "====> Epoch: 893 Average test loss: 929.7913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 894 [0/2589 (0%)]\tLoss: 181.192841\n",
      "Train Epoch: 894 [300/2589 (12%)]\tLoss: 184.038422\n",
      "Train Epoch: 894 [600/2589 (23%)]\tLoss: 217.214828\n",
      "Train Epoch: 894 [900/2589 (35%)]\tLoss: 212.684128\n",
      "Train Epoch: 894 [1200/2589 (46%)]\tLoss: 194.722717\n",
      "Train Epoch: 894 [1500/2589 (58%)]\tLoss: 235.268509\n",
      "Train Epoch: 894 [1800/2589 (70%)]\tLoss: 226.628891\n",
      "Train Epoch: 894 [2100/2589 (81%)]\tLoss: 246.423691\n",
      "Train Epoch: 894 [2400/2589 (93%)]\tLoss: 244.932419\n",
      "====> Epoch: 894 Average train loss: 227.5531\n",
      "====> Epoch: 894 Average test loss: 915.8445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 895 [0/2589 (0%)]\tLoss: 203.741531\n",
      "Train Epoch: 895 [300/2589 (12%)]\tLoss: 168.415207\n",
      "Train Epoch: 895 [600/2589 (23%)]\tLoss: 274.863342\n",
      "Train Epoch: 895 [900/2589 (35%)]\tLoss: 205.855789\n",
      "Train Epoch: 895 [1200/2589 (46%)]\tLoss: 431.115265\n",
      "Train Epoch: 895 [1500/2589 (58%)]\tLoss: 172.437302\n",
      "Train Epoch: 895 [1800/2589 (70%)]\tLoss: 297.170502\n",
      "Train Epoch: 895 [2100/2589 (81%)]\tLoss: 140.816666\n",
      "Train Epoch: 895 [2400/2589 (93%)]\tLoss: 213.056244\n",
      "====> Epoch: 895 Average train loss: 220.7215\n",
      "====> Epoch: 895 Average test loss: 914.3964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 896 [0/2589 (0%)]\tLoss: 184.355148\n",
      "Train Epoch: 896 [300/2589 (12%)]\tLoss: 200.901947\n",
      "Train Epoch: 896 [600/2589 (23%)]\tLoss: 188.270660\n",
      "Train Epoch: 896 [900/2589 (35%)]\tLoss: 146.768814\n",
      "Train Epoch: 896 [1200/2589 (46%)]\tLoss: 243.294678\n",
      "Train Epoch: 896 [1500/2589 (58%)]\tLoss: 195.074478\n",
      "Train Epoch: 896 [1800/2589 (70%)]\tLoss: 156.479584\n",
      "Train Epoch: 896 [2100/2589 (81%)]\tLoss: 261.123169\n",
      "Train Epoch: 896 [2400/2589 (93%)]\tLoss: 243.202560\n",
      "====> Epoch: 896 Average train loss: 225.3489\n",
      "====> Epoch: 896 Average test loss: 922.5917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 897 [0/2589 (0%)]\tLoss: 154.651520\n",
      "Train Epoch: 897 [300/2589 (12%)]\tLoss: 193.754669\n",
      "Train Epoch: 897 [600/2589 (23%)]\tLoss: 193.631668\n",
      "Train Epoch: 897 [900/2589 (35%)]\tLoss: 230.466980\n",
      "Train Epoch: 897 [1200/2589 (46%)]\tLoss: 212.234344\n",
      "Train Epoch: 897 [1500/2589 (58%)]\tLoss: 216.506119\n",
      "Train Epoch: 897 [1800/2589 (70%)]\tLoss: 133.311493\n",
      "Train Epoch: 897 [2100/2589 (81%)]\tLoss: 498.226776\n",
      "Train Epoch: 897 [2400/2589 (93%)]\tLoss: 211.908066\n",
      "====> Epoch: 897 Average train loss: 227.1416\n",
      "====> Epoch: 897 Average test loss: 913.4549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 898 [0/2589 (0%)]\tLoss: 220.106506\n",
      "Train Epoch: 898 [300/2589 (12%)]\tLoss: 215.450928\n",
      "Train Epoch: 898 [600/2589 (23%)]\tLoss: 172.250183\n",
      "Train Epoch: 898 [900/2589 (35%)]\tLoss: 318.167175\n",
      "Train Epoch: 898 [1200/2589 (46%)]\tLoss: 235.237839\n",
      "Train Epoch: 898 [1500/2589 (58%)]\tLoss: 313.331116\n",
      "Train Epoch: 898 [1800/2589 (70%)]\tLoss: 141.863754\n",
      "Train Epoch: 898 [2100/2589 (81%)]\tLoss: 206.724503\n",
      "Train Epoch: 898 [2400/2589 (93%)]\tLoss: 221.544922\n",
      "====> Epoch: 898 Average train loss: 234.3784\n",
      "====> Epoch: 898 Average test loss: 912.0304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 899 [0/2589 (0%)]\tLoss: 378.619843\n",
      "Train Epoch: 899 [300/2589 (12%)]\tLoss: 178.781586\n",
      "Train Epoch: 899 [600/2589 (23%)]\tLoss: 287.678833\n",
      "Train Epoch: 899 [900/2589 (35%)]\tLoss: 207.266571\n",
      "Train Epoch: 899 [1200/2589 (46%)]\tLoss: 313.562531\n",
      "Train Epoch: 899 [1500/2589 (58%)]\tLoss: 166.675919\n",
      "Train Epoch: 899 [1800/2589 (70%)]\tLoss: 186.612000\n",
      "Train Epoch: 899 [2100/2589 (81%)]\tLoss: 209.621841\n",
      "Train Epoch: 899 [2400/2589 (93%)]\tLoss: 289.936493\n",
      "====> Epoch: 899 Average train loss: 227.6198\n",
      "====> Epoch: 899 Average test loss: 919.7251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 900 [0/2589 (0%)]\tLoss: 183.244049\n",
      "Train Epoch: 900 [300/2589 (12%)]\tLoss: 231.337601\n",
      "Train Epoch: 900 [600/2589 (23%)]\tLoss: 207.153259\n",
      "Train Epoch: 900 [900/2589 (35%)]\tLoss: 242.174973\n",
      "Train Epoch: 900 [1200/2589 (46%)]\tLoss: 187.279434\n",
      "Train Epoch: 900 [1500/2589 (58%)]\tLoss: 185.427597\n",
      "Train Epoch: 900 [1800/2589 (70%)]\tLoss: 267.152893\n",
      "Train Epoch: 900 [2100/2589 (81%)]\tLoss: 300.938416\n",
      "Train Epoch: 900 [2400/2589 (93%)]\tLoss: 200.385666\n",
      "====> Epoch: 900 Average train loss: 228.0800\n",
      "====> Epoch: 900 Average test loss: 921.4709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 901 [0/2589 (0%)]\tLoss: 124.803108\n",
      "Train Epoch: 901 [300/2589 (12%)]\tLoss: 175.910751\n",
      "Train Epoch: 901 [600/2589 (23%)]\tLoss: 241.207092\n",
      "Train Epoch: 901 [900/2589 (35%)]\tLoss: 255.593491\n",
      "Train Epoch: 901 [1200/2589 (46%)]\tLoss: 186.513275\n",
      "Train Epoch: 901 [1500/2589 (58%)]\tLoss: 187.307358\n",
      "Train Epoch: 901 [1800/2589 (70%)]\tLoss: 224.844482\n",
      "Train Epoch: 901 [2100/2589 (81%)]\tLoss: 189.569321\n",
      "Train Epoch: 901 [2400/2589 (93%)]\tLoss: 244.710373\n",
      "====> Epoch: 901 Average train loss: 223.9752\n",
      "====> Epoch: 901 Average test loss: 934.4851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 902 [0/2589 (0%)]\tLoss: 191.693985\n",
      "Train Epoch: 902 [300/2589 (12%)]\tLoss: 174.063416\n",
      "Train Epoch: 902 [600/2589 (23%)]\tLoss: 290.430115\n",
      "Train Epoch: 902 [900/2589 (35%)]\tLoss: 198.854950\n",
      "Train Epoch: 902 [1200/2589 (46%)]\tLoss: 186.087723\n",
      "Train Epoch: 902 [1500/2589 (58%)]\tLoss: 230.200592\n",
      "Train Epoch: 902 [1800/2589 (70%)]\tLoss: 237.189423\n",
      "Train Epoch: 902 [2100/2589 (81%)]\tLoss: 193.480545\n",
      "Train Epoch: 902 [2400/2589 (93%)]\tLoss: 195.374100\n",
      "====> Epoch: 902 Average train loss: 228.0553\n",
      "====> Epoch: 902 Average test loss: 913.8414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 903 [0/2589 (0%)]\tLoss: 166.459961\n",
      "Train Epoch: 903 [300/2589 (12%)]\tLoss: 168.507812\n",
      "Train Epoch: 903 [600/2589 (23%)]\tLoss: 190.038834\n",
      "Train Epoch: 903 [900/2589 (35%)]\tLoss: 171.331238\n",
      "Train Epoch: 903 [1200/2589 (46%)]\tLoss: 383.740143\n",
      "Train Epoch: 903 [1500/2589 (58%)]\tLoss: 206.455780\n",
      "Train Epoch: 903 [1800/2589 (70%)]\tLoss: 211.893326\n",
      "Train Epoch: 903 [2100/2589 (81%)]\tLoss: 227.934677\n",
      "Train Epoch: 903 [2400/2589 (93%)]\tLoss: 190.342255\n",
      "====> Epoch: 903 Average train loss: 221.9098\n",
      "====> Epoch: 903 Average test loss: 925.7066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 904 [0/2589 (0%)]\tLoss: 153.286102\n",
      "Train Epoch: 904 [300/2589 (12%)]\tLoss: 209.806778\n",
      "Train Epoch: 904 [600/2589 (23%)]\tLoss: 230.649811\n",
      "Train Epoch: 904 [900/2589 (35%)]\tLoss: 195.139832\n",
      "Train Epoch: 904 [1200/2589 (46%)]\tLoss: 262.784454\n",
      "Train Epoch: 904 [1500/2589 (58%)]\tLoss: 241.763855\n",
      "Train Epoch: 904 [1800/2589 (70%)]\tLoss: 169.949966\n",
      "Train Epoch: 904 [2100/2589 (81%)]\tLoss: 259.140442\n",
      "Train Epoch: 904 [2400/2589 (93%)]\tLoss: 240.139679\n",
      "====> Epoch: 904 Average train loss: 235.1071\n",
      "====> Epoch: 904 Average test loss: 931.0349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 905 [0/2589 (0%)]\tLoss: 271.728241\n",
      "Train Epoch: 905 [300/2589 (12%)]\tLoss: 127.916245\n",
      "Train Epoch: 905 [600/2589 (23%)]\tLoss: 240.856277\n",
      "Train Epoch: 905 [900/2589 (35%)]\tLoss: 268.074829\n",
      "Train Epoch: 905 [1200/2589 (46%)]\tLoss: 245.317413\n",
      "Train Epoch: 905 [1500/2589 (58%)]\tLoss: 181.463531\n",
      "Train Epoch: 905 [1800/2589 (70%)]\tLoss: 355.603363\n",
      "Train Epoch: 905 [2100/2589 (81%)]\tLoss: 279.284515\n",
      "Train Epoch: 905 [2400/2589 (93%)]\tLoss: 221.728790\n",
      "====> Epoch: 905 Average train loss: 242.6971\n",
      "====> Epoch: 905 Average test loss: 900.4077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 906 [0/2589 (0%)]\tLoss: 148.974350\n",
      "Train Epoch: 906 [300/2589 (12%)]\tLoss: 181.968781\n",
      "Train Epoch: 906 [600/2589 (23%)]\tLoss: 355.745056\n",
      "Train Epoch: 906 [900/2589 (35%)]\tLoss: 126.486664\n",
      "Train Epoch: 906 [1200/2589 (46%)]\tLoss: 312.294434\n",
      "Train Epoch: 906 [1500/2589 (58%)]\tLoss: 237.757751\n",
      "Train Epoch: 906 [1800/2589 (70%)]\tLoss: 146.655365\n",
      "Train Epoch: 906 [2100/2589 (81%)]\tLoss: 235.482224\n",
      "Train Epoch: 906 [2400/2589 (93%)]\tLoss: 243.813187\n",
      "====> Epoch: 906 Average train loss: 233.3673\n",
      "====> Epoch: 906 Average test loss: 913.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 907 [0/2589 (0%)]\tLoss: 227.804047\n",
      "Train Epoch: 907 [300/2589 (12%)]\tLoss: 167.181381\n",
      "Train Epoch: 907 [600/2589 (23%)]\tLoss: 198.334534\n",
      "Train Epoch: 907 [900/2589 (35%)]\tLoss: 197.765228\n",
      "Train Epoch: 907 [1200/2589 (46%)]\tLoss: 179.424072\n",
      "Train Epoch: 907 [1500/2589 (58%)]\tLoss: 196.498611\n",
      "Train Epoch: 907 [1800/2589 (70%)]\tLoss: 306.150513\n",
      "Train Epoch: 907 [2100/2589 (81%)]\tLoss: 429.325256\n",
      "Train Epoch: 907 [2400/2589 (93%)]\tLoss: 272.816345\n",
      "====> Epoch: 907 Average train loss: 232.3330\n",
      "====> Epoch: 907 Average test loss: 924.6249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 908 [0/2589 (0%)]\tLoss: 191.586975\n",
      "Train Epoch: 908 [300/2589 (12%)]\tLoss: 162.580276\n",
      "Train Epoch: 908 [600/2589 (23%)]\tLoss: 180.620834\n",
      "Train Epoch: 908 [900/2589 (35%)]\tLoss: 243.365143\n",
      "Train Epoch: 908 [1200/2589 (46%)]\tLoss: 198.067154\n",
      "Train Epoch: 908 [1500/2589 (58%)]\tLoss: 165.101776\n",
      "Train Epoch: 908 [1800/2589 (70%)]\tLoss: 260.036713\n",
      "Train Epoch: 908 [2100/2589 (81%)]\tLoss: 200.999664\n",
      "Train Epoch: 908 [2400/2589 (93%)]\tLoss: 167.630402\n",
      "====> Epoch: 908 Average train loss: 215.0771\n",
      "====> Epoch: 908 Average test loss: 925.5906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 909 [0/2589 (0%)]\tLoss: 168.714020\n",
      "Train Epoch: 909 [300/2589 (12%)]\tLoss: 154.739288\n",
      "Train Epoch: 909 [600/2589 (23%)]\tLoss: 305.191559\n",
      "Train Epoch: 909 [900/2589 (35%)]\tLoss: 192.542618\n",
      "Train Epoch: 909 [1200/2589 (46%)]\tLoss: 194.497803\n",
      "Train Epoch: 909 [1500/2589 (58%)]\tLoss: 171.767715\n",
      "Train Epoch: 909 [1800/2589 (70%)]\tLoss: 175.098801\n",
      "Train Epoch: 909 [2100/2589 (81%)]\tLoss: 374.432770\n",
      "Train Epoch: 909 [2400/2589 (93%)]\tLoss: 237.452667\n",
      "====> Epoch: 909 Average train loss: 224.0996\n",
      "====> Epoch: 909 Average test loss: 939.3173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 910 [0/2589 (0%)]\tLoss: 228.134094\n",
      "Train Epoch: 910 [300/2589 (12%)]\tLoss: 278.983917\n",
      "Train Epoch: 910 [600/2589 (23%)]\tLoss: 156.424088\n",
      "Train Epoch: 910 [900/2589 (35%)]\tLoss: 180.181656\n",
      "Train Epoch: 910 [1200/2589 (46%)]\tLoss: 204.614792\n",
      "Train Epoch: 910 [1500/2589 (58%)]\tLoss: 168.153519\n",
      "Train Epoch: 910 [1800/2589 (70%)]\tLoss: 223.336426\n",
      "Train Epoch: 910 [2100/2589 (81%)]\tLoss: 290.332306\n",
      "Train Epoch: 910 [2400/2589 (93%)]\tLoss: 157.179626\n",
      "====> Epoch: 910 Average train loss: 227.7089\n",
      "====> Epoch: 910 Average test loss: 921.1235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 911 [0/2589 (0%)]\tLoss: 169.098495\n",
      "Train Epoch: 911 [300/2589 (12%)]\tLoss: 187.920502\n",
      "Train Epoch: 911 [600/2589 (23%)]\tLoss: 209.157684\n",
      "Train Epoch: 911 [900/2589 (35%)]\tLoss: 173.678391\n",
      "Train Epoch: 911 [1200/2589 (46%)]\tLoss: 202.070099\n",
      "Train Epoch: 911 [1500/2589 (58%)]\tLoss: 214.941330\n",
      "Train Epoch: 911 [1800/2589 (70%)]\tLoss: 182.570312\n",
      "Train Epoch: 911 [2100/2589 (81%)]\tLoss: 177.149841\n",
      "Train Epoch: 911 [2400/2589 (93%)]\tLoss: 232.831802\n",
      "====> Epoch: 911 Average train loss: 223.6037\n",
      "====> Epoch: 911 Average test loss: 919.6273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 912 [0/2589 (0%)]\tLoss: 203.577835\n",
      "Train Epoch: 912 [300/2589 (12%)]\tLoss: 178.285110\n",
      "Train Epoch: 912 [600/2589 (23%)]\tLoss: 158.528152\n",
      "Train Epoch: 912 [900/2589 (35%)]\tLoss: 229.912048\n",
      "Train Epoch: 912 [1200/2589 (46%)]\tLoss: 156.507309\n",
      "Train Epoch: 912 [1500/2589 (58%)]\tLoss: 250.592453\n",
      "Train Epoch: 912 [1800/2589 (70%)]\tLoss: 194.269470\n",
      "Train Epoch: 912 [2100/2589 (81%)]\tLoss: 198.391891\n",
      "Train Epoch: 912 [2400/2589 (93%)]\tLoss: 185.145477\n",
      "====> Epoch: 912 Average train loss: 216.1571\n",
      "====> Epoch: 912 Average test loss: 925.0604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 913 [0/2589 (0%)]\tLoss: 276.243683\n",
      "Train Epoch: 913 [300/2589 (12%)]\tLoss: 166.393616\n",
      "Train Epoch: 913 [600/2589 (23%)]\tLoss: 251.044525\n",
      "Train Epoch: 913 [900/2589 (35%)]\tLoss: 187.094482\n",
      "Train Epoch: 913 [1200/2589 (46%)]\tLoss: 277.978241\n",
      "Train Epoch: 913 [1500/2589 (58%)]\tLoss: 152.721451\n",
      "Train Epoch: 913 [1800/2589 (70%)]\tLoss: 245.031601\n",
      "Train Epoch: 913 [2100/2589 (81%)]\tLoss: 222.306107\n",
      "Train Epoch: 913 [2400/2589 (93%)]\tLoss: 251.055664\n",
      "====> Epoch: 913 Average train loss: 230.3177\n",
      "====> Epoch: 913 Average test loss: 924.2225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 914 [0/2589 (0%)]\tLoss: 202.199646\n",
      "Train Epoch: 914 [300/2589 (12%)]\tLoss: 210.219421\n",
      "Train Epoch: 914 [600/2589 (23%)]\tLoss: 176.274109\n",
      "Train Epoch: 914 [900/2589 (35%)]\tLoss: 190.692474\n",
      "Train Epoch: 914 [1200/2589 (46%)]\tLoss: 137.060577\n",
      "Train Epoch: 914 [1500/2589 (58%)]\tLoss: 280.368317\n",
      "Train Epoch: 914 [1800/2589 (70%)]\tLoss: 220.363907\n",
      "Train Epoch: 914 [2100/2589 (81%)]\tLoss: 158.858841\n",
      "Train Epoch: 914 [2400/2589 (93%)]\tLoss: 234.803055\n",
      "====> Epoch: 914 Average train loss: 225.5748\n",
      "====> Epoch: 914 Average test loss: 917.0291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 915 [0/2589 (0%)]\tLoss: 166.469696\n",
      "Train Epoch: 915 [300/2589 (12%)]\tLoss: 218.490341\n",
      "Train Epoch: 915 [600/2589 (23%)]\tLoss: 253.685440\n",
      "Train Epoch: 915 [900/2589 (35%)]\tLoss: 286.008759\n",
      "Train Epoch: 915 [1200/2589 (46%)]\tLoss: 226.760651\n",
      "Train Epoch: 915 [1500/2589 (58%)]\tLoss: 204.184402\n",
      "Train Epoch: 915 [1800/2589 (70%)]\tLoss: 214.012283\n",
      "Train Epoch: 915 [2100/2589 (81%)]\tLoss: 456.199921\n",
      "Train Epoch: 915 [2400/2589 (93%)]\tLoss: 178.735565\n",
      "====> Epoch: 915 Average train loss: 235.8506\n",
      "====> Epoch: 915 Average test loss: 915.2355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 916 [0/2589 (0%)]\tLoss: 208.656158\n",
      "Train Epoch: 916 [300/2589 (12%)]\tLoss: 169.169418\n",
      "Train Epoch: 916 [600/2589 (23%)]\tLoss: 298.609436\n",
      "Train Epoch: 916 [900/2589 (35%)]\tLoss: 161.642776\n",
      "Train Epoch: 916 [1200/2589 (46%)]\tLoss: 271.961548\n",
      "Train Epoch: 916 [1500/2589 (58%)]\tLoss: 230.328506\n",
      "Train Epoch: 916 [1800/2589 (70%)]\tLoss: 165.947922\n",
      "Train Epoch: 916 [2100/2589 (81%)]\tLoss: 247.375046\n",
      "Train Epoch: 916 [2400/2589 (93%)]\tLoss: 144.781937\n",
      "====> Epoch: 916 Average train loss: 227.9424\n",
      "====> Epoch: 916 Average test loss: 917.3990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 917 [0/2589 (0%)]\tLoss: 206.053726\n",
      "Train Epoch: 917 [300/2589 (12%)]\tLoss: 148.112640\n",
      "Train Epoch: 917 [600/2589 (23%)]\tLoss: 225.475632\n",
      "Train Epoch: 917 [900/2589 (35%)]\tLoss: 287.047913\n",
      "Train Epoch: 917 [1200/2589 (46%)]\tLoss: 153.885834\n",
      "Train Epoch: 917 [1500/2589 (58%)]\tLoss: 216.849670\n",
      "Train Epoch: 917 [1800/2589 (70%)]\tLoss: 189.038467\n",
      "Train Epoch: 917 [2100/2589 (81%)]\tLoss: 245.852371\n",
      "Train Epoch: 917 [2400/2589 (93%)]\tLoss: 172.744583\n",
      "====> Epoch: 917 Average train loss: 212.1947\n",
      "====> Epoch: 917 Average test loss: 915.1010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 918 [0/2589 (0%)]\tLoss: 235.068008\n",
      "Train Epoch: 918 [300/2589 (12%)]\tLoss: 187.788574\n",
      "Train Epoch: 918 [600/2589 (23%)]\tLoss: 381.411987\n",
      "Train Epoch: 918 [900/2589 (35%)]\tLoss: 166.584564\n",
      "Train Epoch: 918 [1200/2589 (46%)]\tLoss: 155.055206\n",
      "Train Epoch: 918 [1500/2589 (58%)]\tLoss: 248.795822\n",
      "Train Epoch: 918 [1800/2589 (70%)]\tLoss: 234.024963\n",
      "Train Epoch: 918 [2100/2589 (81%)]\tLoss: 135.975693\n",
      "Train Epoch: 918 [2400/2589 (93%)]\tLoss: 188.161591\n",
      "====> Epoch: 918 Average train loss: 220.3136\n",
      "====> Epoch: 918 Average test loss: 929.9051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 919 [0/2589 (0%)]\tLoss: 149.356552\n",
      "Train Epoch: 919 [300/2589 (12%)]\tLoss: 209.872818\n",
      "Train Epoch: 919 [600/2589 (23%)]\tLoss: 200.925522\n",
      "Train Epoch: 919 [900/2589 (35%)]\tLoss: 207.452652\n",
      "Train Epoch: 919 [1200/2589 (46%)]\tLoss: 185.041153\n",
      "Train Epoch: 919 [1500/2589 (58%)]\tLoss: 257.984528\n",
      "Train Epoch: 919 [1800/2589 (70%)]\tLoss: 178.605377\n",
      "Train Epoch: 919 [2100/2589 (81%)]\tLoss: 281.723053\n",
      "Train Epoch: 919 [2400/2589 (93%)]\tLoss: 280.012177\n",
      "====> Epoch: 919 Average train loss: 218.0750\n",
      "====> Epoch: 919 Average test loss: 904.5812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 920 [0/2589 (0%)]\tLoss: 126.519249\n",
      "Train Epoch: 920 [300/2589 (12%)]\tLoss: 238.290283\n",
      "Train Epoch: 920 [600/2589 (23%)]\tLoss: 197.303696\n",
      "Train Epoch: 920 [900/2589 (35%)]\tLoss: 201.034607\n",
      "Train Epoch: 920 [1200/2589 (46%)]\tLoss: 281.763824\n",
      "Train Epoch: 920 [1500/2589 (58%)]\tLoss: 257.446472\n",
      "Train Epoch: 920 [1800/2589 (70%)]\tLoss: 150.553879\n",
      "Train Epoch: 920 [2100/2589 (81%)]\tLoss: 277.205841\n",
      "Train Epoch: 920 [2400/2589 (93%)]\tLoss: 191.334488\n",
      "====> Epoch: 920 Average train loss: 223.5858\n",
      "====> Epoch: 920 Average test loss: 920.5883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 921 [0/2589 (0%)]\tLoss: 182.224121\n",
      "Train Epoch: 921 [300/2589 (12%)]\tLoss: 229.270966\n",
      "Train Epoch: 921 [600/2589 (23%)]\tLoss: 180.042236\n",
      "Train Epoch: 921 [900/2589 (35%)]\tLoss: 174.669250\n",
      "Train Epoch: 921 [1200/2589 (46%)]\tLoss: 304.029938\n",
      "Train Epoch: 921 [1500/2589 (58%)]\tLoss: 242.822922\n",
      "Train Epoch: 921 [1800/2589 (70%)]\tLoss: 225.559326\n",
      "Train Epoch: 921 [2100/2589 (81%)]\tLoss: 160.318619\n",
      "Train Epoch: 921 [2400/2589 (93%)]\tLoss: 186.096176\n",
      "====> Epoch: 921 Average train loss: 223.5573\n",
      "====> Epoch: 921 Average test loss: 919.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 922 [0/2589 (0%)]\tLoss: 284.001099\n",
      "Train Epoch: 922 [300/2589 (12%)]\tLoss: 240.870514\n",
      "Train Epoch: 922 [600/2589 (23%)]\tLoss: 185.032913\n",
      "Train Epoch: 922 [900/2589 (35%)]\tLoss: 277.535583\n",
      "Train Epoch: 922 [1200/2589 (46%)]\tLoss: 271.454224\n",
      "Train Epoch: 922 [1500/2589 (58%)]\tLoss: 192.098282\n",
      "Train Epoch: 922 [1800/2589 (70%)]\tLoss: 200.964432\n",
      "Train Epoch: 922 [2100/2589 (81%)]\tLoss: 246.333984\n",
      "Train Epoch: 922 [2400/2589 (93%)]\tLoss: 207.693329\n",
      "====> Epoch: 922 Average train loss: 222.0718\n",
      "====> Epoch: 922 Average test loss: 911.9692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 923 [0/2589 (0%)]\tLoss: 190.471146\n",
      "Train Epoch: 923 [300/2589 (12%)]\tLoss: 205.816559\n",
      "Train Epoch: 923 [600/2589 (23%)]\tLoss: 288.929962\n",
      "Train Epoch: 923 [900/2589 (35%)]\tLoss: 216.109833\n",
      "Train Epoch: 923 [1200/2589 (46%)]\tLoss: 288.607147\n",
      "Train Epoch: 923 [1500/2589 (58%)]\tLoss: 161.434372\n",
      "Train Epoch: 923 [1800/2589 (70%)]\tLoss: 194.185959\n",
      "Train Epoch: 923 [2100/2589 (81%)]\tLoss: 231.020691\n",
      "Train Epoch: 923 [2400/2589 (93%)]\tLoss: 146.857666\n",
      "====> Epoch: 923 Average train loss: 227.3910\n",
      "====> Epoch: 923 Average test loss: 930.7366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 924 [0/2589 (0%)]\tLoss: 188.656052\n",
      "Train Epoch: 924 [300/2589 (12%)]\tLoss: 177.809998\n",
      "Train Epoch: 924 [600/2589 (23%)]\tLoss: 185.516495\n",
      "Train Epoch: 924 [900/2589 (35%)]\tLoss: 281.600403\n",
      "Train Epoch: 924 [1200/2589 (46%)]\tLoss: 222.366791\n",
      "Train Epoch: 924 [1500/2589 (58%)]\tLoss: 220.050156\n",
      "Train Epoch: 924 [1800/2589 (70%)]\tLoss: 258.908813\n",
      "Train Epoch: 924 [2100/2589 (81%)]\tLoss: 184.943375\n",
      "Train Epoch: 924 [2400/2589 (93%)]\tLoss: 244.267120\n",
      "====> Epoch: 924 Average train loss: 227.8506\n",
      "====> Epoch: 924 Average test loss: 931.6341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 925 [0/2589 (0%)]\tLoss: 220.652435\n",
      "Train Epoch: 925 [300/2589 (12%)]\tLoss: 140.962296\n",
      "Train Epoch: 925 [600/2589 (23%)]\tLoss: 173.732162\n",
      "Train Epoch: 925 [900/2589 (35%)]\tLoss: 217.897110\n",
      "Train Epoch: 925 [1200/2589 (46%)]\tLoss: 191.151306\n",
      "Train Epoch: 925 [1500/2589 (58%)]\tLoss: 148.917694\n",
      "Train Epoch: 925 [1800/2589 (70%)]\tLoss: 166.187119\n",
      "Train Epoch: 925 [2100/2589 (81%)]\tLoss: 196.952393\n",
      "Train Epoch: 925 [2400/2589 (93%)]\tLoss: 168.275070\n",
      "====> Epoch: 925 Average train loss: 216.4423\n",
      "====> Epoch: 925 Average test loss: 932.0647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 926 [0/2589 (0%)]\tLoss: 220.124985\n",
      "Train Epoch: 926 [300/2589 (12%)]\tLoss: 185.832382\n",
      "Train Epoch: 926 [600/2589 (23%)]\tLoss: 171.382843\n",
      "Train Epoch: 926 [900/2589 (35%)]\tLoss: 286.102570\n",
      "Train Epoch: 926 [1200/2589 (46%)]\tLoss: 350.056427\n",
      "Train Epoch: 926 [1500/2589 (58%)]\tLoss: 217.877838\n",
      "Train Epoch: 926 [1800/2589 (70%)]\tLoss: 296.018982\n",
      "Train Epoch: 926 [2100/2589 (81%)]\tLoss: 211.045639\n",
      "Train Epoch: 926 [2400/2589 (93%)]\tLoss: 219.076218\n",
      "====> Epoch: 926 Average train loss: 229.3561\n",
      "====> Epoch: 926 Average test loss: 923.8376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 927 [0/2589 (0%)]\tLoss: 193.897049\n",
      "Train Epoch: 927 [300/2589 (12%)]\tLoss: 171.933517\n",
      "Train Epoch: 927 [600/2589 (23%)]\tLoss: 219.615250\n",
      "Train Epoch: 927 [900/2589 (35%)]\tLoss: 146.290436\n",
      "Train Epoch: 927 [1200/2589 (46%)]\tLoss: 257.040405\n",
      "Train Epoch: 927 [1500/2589 (58%)]\tLoss: 183.085587\n",
      "Train Epoch: 927 [1800/2589 (70%)]\tLoss: 251.177643\n",
      "Train Epoch: 927 [2100/2589 (81%)]\tLoss: 128.735184\n",
      "Train Epoch: 927 [2400/2589 (93%)]\tLoss: 209.826569\n",
      "====> Epoch: 927 Average train loss: 216.4743\n",
      "====> Epoch: 927 Average test loss: 923.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 928 [0/2589 (0%)]\tLoss: 207.118942\n",
      "Train Epoch: 928 [300/2589 (12%)]\tLoss: 195.044678\n",
      "Train Epoch: 928 [600/2589 (23%)]\tLoss: 202.295685\n",
      "Train Epoch: 928 [900/2589 (35%)]\tLoss: 238.495697\n",
      "Train Epoch: 928 [1200/2589 (46%)]\tLoss: 239.994888\n",
      "Train Epoch: 928 [1500/2589 (58%)]\tLoss: 198.100342\n",
      "Train Epoch: 928 [1800/2589 (70%)]\tLoss: 222.241379\n",
      "Train Epoch: 928 [2100/2589 (81%)]\tLoss: 204.848206\n",
      "Train Epoch: 928 [2400/2589 (93%)]\tLoss: 255.637527\n",
      "====> Epoch: 928 Average train loss: 226.6909\n",
      "====> Epoch: 928 Average test loss: 924.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 929 [0/2589 (0%)]\tLoss: 236.608307\n",
      "Train Epoch: 929 [300/2589 (12%)]\tLoss: 176.555115\n",
      "Train Epoch: 929 [600/2589 (23%)]\tLoss: 196.431091\n",
      "Train Epoch: 929 [900/2589 (35%)]\tLoss: 275.496490\n",
      "Train Epoch: 929 [1200/2589 (46%)]\tLoss: 309.355927\n",
      "Train Epoch: 929 [1500/2589 (58%)]\tLoss: 272.883972\n",
      "Train Epoch: 929 [1800/2589 (70%)]\tLoss: 175.775391\n",
      "Train Epoch: 929 [2100/2589 (81%)]\tLoss: 192.817520\n",
      "Train Epoch: 929 [2400/2589 (93%)]\tLoss: 304.002472\n",
      "====> Epoch: 929 Average train loss: 217.3496\n",
      "====> Epoch: 929 Average test loss: 909.6996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 930 [0/2589 (0%)]\tLoss: 447.934052\n",
      "Train Epoch: 930 [300/2589 (12%)]\tLoss: 200.841278\n",
      "Train Epoch: 930 [600/2589 (23%)]\tLoss: 197.103363\n",
      "Train Epoch: 930 [900/2589 (35%)]\tLoss: 200.462646\n",
      "Train Epoch: 930 [1200/2589 (46%)]\tLoss: 164.791763\n",
      "Train Epoch: 930 [1500/2589 (58%)]\tLoss: 148.881866\n",
      "Train Epoch: 930 [1800/2589 (70%)]\tLoss: 150.454788\n",
      "Train Epoch: 930 [2100/2589 (81%)]\tLoss: 217.442245\n",
      "Train Epoch: 930 [2400/2589 (93%)]\tLoss: 203.321381\n",
      "====> Epoch: 930 Average train loss: 213.7493\n",
      "====> Epoch: 930 Average test loss: 927.0864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 931 [0/2589 (0%)]\tLoss: 146.746292\n",
      "Train Epoch: 931 [300/2589 (12%)]\tLoss: 271.197876\n",
      "Train Epoch: 931 [600/2589 (23%)]\tLoss: 307.854126\n",
      "Train Epoch: 931 [900/2589 (35%)]\tLoss: 207.045395\n",
      "Train Epoch: 931 [1200/2589 (46%)]\tLoss: 219.992249\n",
      "Train Epoch: 931 [1500/2589 (58%)]\tLoss: 254.670975\n",
      "Train Epoch: 931 [1800/2589 (70%)]\tLoss: 225.990051\n",
      "Train Epoch: 931 [2100/2589 (81%)]\tLoss: 272.069214\n",
      "Train Epoch: 931 [2400/2589 (93%)]\tLoss: 201.819427\n",
      "====> Epoch: 931 Average train loss: 217.6658\n",
      "====> Epoch: 931 Average test loss: 934.2384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 932 [0/2589 (0%)]\tLoss: 277.486725\n",
      "Train Epoch: 932 [300/2589 (12%)]\tLoss: 236.979660\n",
      "Train Epoch: 932 [600/2589 (23%)]\tLoss: 157.056580\n",
      "Train Epoch: 932 [900/2589 (35%)]\tLoss: 247.590332\n",
      "Train Epoch: 932 [1200/2589 (46%)]\tLoss: 189.256088\n",
      "Train Epoch: 932 [1500/2589 (58%)]\tLoss: 189.844406\n",
      "Train Epoch: 932 [1800/2589 (70%)]\tLoss: 188.578629\n",
      "Train Epoch: 932 [2100/2589 (81%)]\tLoss: 169.549347\n",
      "Train Epoch: 932 [2400/2589 (93%)]\tLoss: 231.120407\n",
      "====> Epoch: 932 Average train loss: 221.9424\n",
      "====> Epoch: 932 Average test loss: 905.1603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 933 [0/2589 (0%)]\tLoss: 229.378632\n",
      "Train Epoch: 933 [300/2589 (12%)]\tLoss: 234.927841\n",
      "Train Epoch: 933 [600/2589 (23%)]\tLoss: 268.388763\n",
      "Train Epoch: 933 [900/2589 (35%)]\tLoss: 231.540421\n",
      "Train Epoch: 933 [1200/2589 (46%)]\tLoss: 188.254822\n",
      "Train Epoch: 933 [1500/2589 (58%)]\tLoss: 300.490723\n",
      "Train Epoch: 933 [1800/2589 (70%)]\tLoss: 168.250137\n",
      "Train Epoch: 933 [2100/2589 (81%)]\tLoss: 126.437744\n",
      "Train Epoch: 933 [2400/2589 (93%)]\tLoss: 179.670410\n",
      "====> Epoch: 933 Average train loss: 225.9419\n",
      "====> Epoch: 933 Average test loss: 917.3388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 934 [0/2589 (0%)]\tLoss: 228.394791\n",
      "Train Epoch: 934 [300/2589 (12%)]\tLoss: 267.221069\n",
      "Train Epoch: 934 [600/2589 (23%)]\tLoss: 219.777374\n",
      "Train Epoch: 934 [900/2589 (35%)]\tLoss: 311.081970\n",
      "Train Epoch: 934 [1200/2589 (46%)]\tLoss: 304.843170\n",
      "Train Epoch: 934 [1500/2589 (58%)]\tLoss: 195.163284\n",
      "Train Epoch: 934 [1800/2589 (70%)]\tLoss: 243.924347\n",
      "Train Epoch: 934 [2100/2589 (81%)]\tLoss: 192.582001\n",
      "Train Epoch: 934 [2400/2589 (93%)]\tLoss: 202.214645\n",
      "====> Epoch: 934 Average train loss: 233.1745\n",
      "====> Epoch: 934 Average test loss: 909.5701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 935 [0/2589 (0%)]\tLoss: 226.639938\n",
      "Train Epoch: 935 [300/2589 (12%)]\tLoss: 271.840149\n",
      "Train Epoch: 935 [600/2589 (23%)]\tLoss: 185.346359\n",
      "Train Epoch: 935 [900/2589 (35%)]\tLoss: 283.169067\n",
      "Train Epoch: 935 [1200/2589 (46%)]\tLoss: 321.489594\n",
      "Train Epoch: 935 [1500/2589 (58%)]\tLoss: 292.054840\n",
      "Train Epoch: 935 [1800/2589 (70%)]\tLoss: 362.708923\n",
      "Train Epoch: 935 [2100/2589 (81%)]\tLoss: 191.821548\n",
      "Train Epoch: 935 [2400/2589 (93%)]\tLoss: 241.398575\n",
      "====> Epoch: 935 Average train loss: 208.0739\n",
      "====> Epoch: 935 Average test loss: 936.2688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 936 [0/2589 (0%)]\tLoss: 189.301865\n",
      "Train Epoch: 936 [300/2589 (12%)]\tLoss: 213.640228\n",
      "Train Epoch: 936 [600/2589 (23%)]\tLoss: 177.776520\n",
      "Train Epoch: 936 [900/2589 (35%)]\tLoss: 251.011307\n",
      "Train Epoch: 936 [1200/2589 (46%)]\tLoss: 213.555801\n",
      "Train Epoch: 936 [1500/2589 (58%)]\tLoss: 188.762589\n",
      "Train Epoch: 936 [1800/2589 (70%)]\tLoss: 316.467316\n",
      "Train Epoch: 936 [2100/2589 (81%)]\tLoss: 210.945740\n",
      "Train Epoch: 936 [2400/2589 (93%)]\tLoss: 230.327545\n",
      "====> Epoch: 936 Average train loss: 213.4161\n",
      "====> Epoch: 936 Average test loss: 920.6678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 937 [0/2589 (0%)]\tLoss: 231.471756\n",
      "Train Epoch: 937 [300/2589 (12%)]\tLoss: 184.957520\n",
      "Train Epoch: 937 [600/2589 (23%)]\tLoss: 378.765808\n",
      "Train Epoch: 937 [900/2589 (35%)]\tLoss: 281.379486\n",
      "Train Epoch: 937 [1200/2589 (46%)]\tLoss: 272.714996\n",
      "Train Epoch: 937 [1500/2589 (58%)]\tLoss: 237.140152\n",
      "Train Epoch: 937 [1800/2589 (70%)]\tLoss: 206.448532\n",
      "Train Epoch: 937 [2100/2589 (81%)]\tLoss: 271.449280\n",
      "Train Epoch: 937 [2400/2589 (93%)]\tLoss: 285.114319\n",
      "====> Epoch: 937 Average train loss: 220.8018\n",
      "====> Epoch: 937 Average test loss: 927.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 938 [0/2589 (0%)]\tLoss: 194.194016\n",
      "Train Epoch: 938 [300/2589 (12%)]\tLoss: 210.663712\n",
      "Train Epoch: 938 [600/2589 (23%)]\tLoss: 247.681503\n",
      "Train Epoch: 938 [900/2589 (35%)]\tLoss: 168.949692\n",
      "Train Epoch: 938 [1200/2589 (46%)]\tLoss: 462.182037\n",
      "Train Epoch: 938 [1500/2589 (58%)]\tLoss: 146.259995\n",
      "Train Epoch: 938 [1800/2589 (70%)]\tLoss: 357.257874\n",
      "Train Epoch: 938 [2100/2589 (81%)]\tLoss: 223.393021\n",
      "Train Epoch: 938 [2400/2589 (93%)]\tLoss: 177.296829\n",
      "====> Epoch: 938 Average train loss: 217.7607\n",
      "====> Epoch: 938 Average test loss: 913.1456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 939 [0/2589 (0%)]\tLoss: 218.743454\n",
      "Train Epoch: 939 [300/2589 (12%)]\tLoss: 195.806564\n",
      "Train Epoch: 939 [600/2589 (23%)]\tLoss: 165.267258\n",
      "Train Epoch: 939 [900/2589 (35%)]\tLoss: 162.799088\n",
      "Train Epoch: 939 [1200/2589 (46%)]\tLoss: 226.093231\n",
      "Train Epoch: 939 [1500/2589 (58%)]\tLoss: 201.084427\n",
      "Train Epoch: 939 [1800/2589 (70%)]\tLoss: 189.329697\n",
      "Train Epoch: 939 [2100/2589 (81%)]\tLoss: 137.524857\n",
      "Train Epoch: 939 [2400/2589 (93%)]\tLoss: 184.236725\n",
      "====> Epoch: 939 Average train loss: 213.0112\n",
      "====> Epoch: 939 Average test loss: 903.2831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 940 [0/2589 (0%)]\tLoss: 236.694656\n",
      "Train Epoch: 940 [300/2589 (12%)]\tLoss: 304.034973\n",
      "Train Epoch: 940 [600/2589 (23%)]\tLoss: 166.393845\n",
      "Train Epoch: 940 [900/2589 (35%)]\tLoss: 242.001373\n",
      "Train Epoch: 940 [1200/2589 (46%)]\tLoss: 210.968719\n",
      "Train Epoch: 940 [1500/2589 (58%)]\tLoss: 192.671829\n",
      "Train Epoch: 940 [1800/2589 (70%)]\tLoss: 180.177963\n",
      "Train Epoch: 940 [2100/2589 (81%)]\tLoss: 173.589294\n",
      "Train Epoch: 940 [2400/2589 (93%)]\tLoss: 182.115448\n",
      "====> Epoch: 940 Average train loss: 222.0422\n",
      "====> Epoch: 940 Average test loss: 908.1425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 941 [0/2589 (0%)]\tLoss: 203.558136\n",
      "Train Epoch: 941 [300/2589 (12%)]\tLoss: 308.430603\n",
      "Train Epoch: 941 [600/2589 (23%)]\tLoss: 215.758591\n",
      "Train Epoch: 941 [900/2589 (35%)]\tLoss: 184.490082\n",
      "Train Epoch: 941 [1200/2589 (46%)]\tLoss: 210.531754\n",
      "Train Epoch: 941 [1500/2589 (58%)]\tLoss: 191.792648\n",
      "Train Epoch: 941 [1800/2589 (70%)]\tLoss: 290.865540\n",
      "Train Epoch: 941 [2100/2589 (81%)]\tLoss: 215.322433\n",
      "Train Epoch: 941 [2400/2589 (93%)]\tLoss: 250.165176\n",
      "====> Epoch: 941 Average train loss: 220.9340\n",
      "====> Epoch: 941 Average test loss: 926.3231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 942 [0/2589 (0%)]\tLoss: 245.849686\n",
      "Train Epoch: 942 [300/2589 (12%)]\tLoss: 251.238251\n",
      "Train Epoch: 942 [600/2589 (23%)]\tLoss: 189.007767\n",
      "Train Epoch: 942 [900/2589 (35%)]\tLoss: 273.957703\n",
      "Train Epoch: 942 [1200/2589 (46%)]\tLoss: 231.121780\n",
      "Train Epoch: 942 [1500/2589 (58%)]\tLoss: 353.570953\n",
      "Train Epoch: 942 [1800/2589 (70%)]\tLoss: 179.719559\n",
      "Train Epoch: 942 [2100/2589 (81%)]\tLoss: 230.817245\n",
      "Train Epoch: 942 [2400/2589 (93%)]\tLoss: 218.661880\n",
      "====> Epoch: 942 Average train loss: 219.7824\n",
      "====> Epoch: 942 Average test loss: 935.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 943 [0/2589 (0%)]\tLoss: 203.765320\n",
      "Train Epoch: 943 [300/2589 (12%)]\tLoss: 138.568222\n",
      "Train Epoch: 943 [600/2589 (23%)]\tLoss: 244.474716\n",
      "Train Epoch: 943 [900/2589 (35%)]\tLoss: 179.944351\n",
      "Train Epoch: 943 [1200/2589 (46%)]\tLoss: 190.669342\n",
      "Train Epoch: 943 [1500/2589 (58%)]\tLoss: 190.765945\n",
      "Train Epoch: 943 [1800/2589 (70%)]\tLoss: 215.433014\n",
      "Train Epoch: 943 [2100/2589 (81%)]\tLoss: 235.219696\n",
      "Train Epoch: 943 [2400/2589 (93%)]\tLoss: 152.044678\n",
      "====> Epoch: 943 Average train loss: 233.5070\n",
      "====> Epoch: 943 Average test loss: 933.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 944 [0/2589 (0%)]\tLoss: 181.524734\n",
      "Train Epoch: 944 [300/2589 (12%)]\tLoss: 213.379623\n",
      "Train Epoch: 944 [600/2589 (23%)]\tLoss: 223.731613\n",
      "Train Epoch: 944 [900/2589 (35%)]\tLoss: 199.481415\n",
      "Train Epoch: 944 [1200/2589 (46%)]\tLoss: 169.284348\n",
      "Train Epoch: 944 [1500/2589 (58%)]\tLoss: 155.808365\n",
      "Train Epoch: 944 [1800/2589 (70%)]\tLoss: 190.598785\n",
      "Train Epoch: 944 [2100/2589 (81%)]\tLoss: 166.071121\n",
      "Train Epoch: 944 [2400/2589 (93%)]\tLoss: 220.821091\n",
      "====> Epoch: 944 Average train loss: 220.3777\n",
      "====> Epoch: 944 Average test loss: 916.9326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 945 [0/2589 (0%)]\tLoss: 272.481842\n",
      "Train Epoch: 945 [300/2589 (12%)]\tLoss: 107.519371\n",
      "Train Epoch: 945 [600/2589 (23%)]\tLoss: 206.022034\n",
      "Train Epoch: 945 [900/2589 (35%)]\tLoss: 341.757782\n",
      "Train Epoch: 945 [1200/2589 (46%)]\tLoss: 473.693878\n",
      "Train Epoch: 945 [1500/2589 (58%)]\tLoss: 164.565430\n",
      "Train Epoch: 945 [1800/2589 (70%)]\tLoss: 267.935944\n",
      "Train Epoch: 945 [2100/2589 (81%)]\tLoss: 204.591309\n",
      "Train Epoch: 945 [2400/2589 (93%)]\tLoss: 201.855133\n",
      "====> Epoch: 945 Average train loss: 227.0068\n",
      "====> Epoch: 945 Average test loss: 918.1589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 946 [0/2589 (0%)]\tLoss: 358.333771\n",
      "Train Epoch: 946 [300/2589 (12%)]\tLoss: 223.939621\n",
      "Train Epoch: 946 [600/2589 (23%)]\tLoss: 354.208435\n",
      "Train Epoch: 946 [900/2589 (35%)]\tLoss: 235.106644\n",
      "Train Epoch: 946 [1200/2589 (46%)]\tLoss: 283.536652\n",
      "Train Epoch: 946 [1500/2589 (58%)]\tLoss: 191.244690\n",
      "Train Epoch: 946 [1800/2589 (70%)]\tLoss: 281.065369\n",
      "Train Epoch: 946 [2100/2589 (81%)]\tLoss: 231.699692\n",
      "Train Epoch: 946 [2400/2589 (93%)]\tLoss: 222.979874\n",
      "====> Epoch: 946 Average train loss: 224.2305\n",
      "====> Epoch: 946 Average test loss: 901.4816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 947 [0/2589 (0%)]\tLoss: 232.945663\n",
      "Train Epoch: 947 [300/2589 (12%)]\tLoss: 204.407211\n",
      "Train Epoch: 947 [600/2589 (23%)]\tLoss: 180.820480\n",
      "Train Epoch: 947 [900/2589 (35%)]\tLoss: 135.819077\n",
      "Train Epoch: 947 [1200/2589 (46%)]\tLoss: 485.851898\n",
      "Train Epoch: 947 [1500/2589 (58%)]\tLoss: 198.361099\n",
      "Train Epoch: 947 [1800/2589 (70%)]\tLoss: 204.841568\n",
      "Train Epoch: 947 [2100/2589 (81%)]\tLoss: 185.854294\n",
      "Train Epoch: 947 [2400/2589 (93%)]\tLoss: 332.509552\n",
      "====> Epoch: 947 Average train loss: 220.9111\n",
      "====> Epoch: 947 Average test loss: 941.3802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 948 [0/2589 (0%)]\tLoss: 177.041534\n",
      "Train Epoch: 948 [300/2589 (12%)]\tLoss: 151.089737\n",
      "Train Epoch: 948 [600/2589 (23%)]\tLoss: 209.359344\n",
      "Train Epoch: 948 [900/2589 (35%)]\tLoss: 238.685699\n",
      "Train Epoch: 948 [1200/2589 (46%)]\tLoss: 183.961136\n",
      "Train Epoch: 948 [1500/2589 (58%)]\tLoss: 254.899185\n",
      "Train Epoch: 948 [1800/2589 (70%)]\tLoss: 138.579697\n",
      "Train Epoch: 948 [2100/2589 (81%)]\tLoss: 256.894318\n",
      "Train Epoch: 948 [2400/2589 (93%)]\tLoss: 212.887833\n",
      "====> Epoch: 948 Average train loss: 218.9665\n",
      "====> Epoch: 948 Average test loss: 930.1332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 949 [0/2589 (0%)]\tLoss: 219.054443\n",
      "Train Epoch: 949 [300/2589 (12%)]\tLoss: 144.548203\n",
      "Train Epoch: 949 [600/2589 (23%)]\tLoss: 186.967102\n",
      "Train Epoch: 949 [900/2589 (35%)]\tLoss: 308.540100\n",
      "Train Epoch: 949 [1200/2589 (46%)]\tLoss: 314.022430\n",
      "Train Epoch: 949 [1500/2589 (58%)]\tLoss: 202.070618\n",
      "Train Epoch: 949 [1800/2589 (70%)]\tLoss: 538.149231\n",
      "Train Epoch: 949 [2100/2589 (81%)]\tLoss: 177.909225\n",
      "Train Epoch: 949 [2400/2589 (93%)]\tLoss: 177.321686\n",
      "====> Epoch: 949 Average train loss: 234.3949\n",
      "====> Epoch: 949 Average test loss: 936.8192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 950 [0/2589 (0%)]\tLoss: 349.925629\n",
      "Train Epoch: 950 [300/2589 (12%)]\tLoss: 245.576828\n",
      "Train Epoch: 950 [600/2589 (23%)]\tLoss: 174.169693\n",
      "Train Epoch: 950 [900/2589 (35%)]\tLoss: 237.411652\n",
      "Train Epoch: 950 [1200/2589 (46%)]\tLoss: 158.692123\n",
      "Train Epoch: 950 [1500/2589 (58%)]\tLoss: 271.635223\n",
      "Train Epoch: 950 [1800/2589 (70%)]\tLoss: 165.281311\n",
      "Train Epoch: 950 [2100/2589 (81%)]\tLoss: 173.602676\n",
      "Train Epoch: 950 [2400/2589 (93%)]\tLoss: 210.536148\n",
      "====> Epoch: 950 Average train loss: 229.4032\n",
      "====> Epoch: 950 Average test loss: 906.8313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 951 [0/2589 (0%)]\tLoss: 207.015686\n",
      "Train Epoch: 951 [300/2589 (12%)]\tLoss: 274.286499\n",
      "Train Epoch: 951 [600/2589 (23%)]\tLoss: 202.333344\n",
      "Train Epoch: 951 [900/2589 (35%)]\tLoss: 202.443787\n",
      "Train Epoch: 951 [1200/2589 (46%)]\tLoss: 192.846741\n",
      "Train Epoch: 951 [1500/2589 (58%)]\tLoss: 305.546356\n",
      "Train Epoch: 951 [1800/2589 (70%)]\tLoss: 189.574661\n",
      "Train Epoch: 951 [2100/2589 (81%)]\tLoss: 198.168594\n",
      "Train Epoch: 951 [2400/2589 (93%)]\tLoss: 200.709702\n",
      "====> Epoch: 951 Average train loss: 218.9246\n",
      "====> Epoch: 951 Average test loss: 920.0360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 952 [0/2589 (0%)]\tLoss: 173.797821\n",
      "Train Epoch: 952 [300/2589 (12%)]\tLoss: 347.396179\n",
      "Train Epoch: 952 [600/2589 (23%)]\tLoss: 408.335571\n",
      "Train Epoch: 952 [900/2589 (35%)]\tLoss: 217.799103\n",
      "Train Epoch: 952 [1200/2589 (46%)]\tLoss: 218.799881\n",
      "Train Epoch: 952 [1500/2589 (58%)]\tLoss: 291.253967\n",
      "Train Epoch: 952 [1800/2589 (70%)]\tLoss: 146.139999\n",
      "Train Epoch: 952 [2100/2589 (81%)]\tLoss: 214.241714\n",
      "Train Epoch: 952 [2400/2589 (93%)]\tLoss: 159.341400\n",
      "====> Epoch: 952 Average train loss: 216.1917\n",
      "====> Epoch: 952 Average test loss: 919.7415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 953 [0/2589 (0%)]\tLoss: 229.458588\n",
      "Train Epoch: 953 [300/2589 (12%)]\tLoss: 187.466171\n",
      "Train Epoch: 953 [600/2589 (23%)]\tLoss: 178.566177\n",
      "Train Epoch: 953 [900/2589 (35%)]\tLoss: 222.000061\n",
      "Train Epoch: 953 [1200/2589 (46%)]\tLoss: 170.764145\n",
      "Train Epoch: 953 [1500/2589 (58%)]\tLoss: 215.797409\n",
      "Train Epoch: 953 [1800/2589 (70%)]\tLoss: 392.295898\n",
      "Train Epoch: 953 [2100/2589 (81%)]\tLoss: 296.046234\n",
      "Train Epoch: 953 [2400/2589 (93%)]\tLoss: 184.059769\n",
      "====> Epoch: 953 Average train loss: 219.7515\n",
      "====> Epoch: 953 Average test loss: 918.8506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 954 [0/2589 (0%)]\tLoss: 213.055130\n",
      "Train Epoch: 954 [300/2589 (12%)]\tLoss: 202.792145\n",
      "Train Epoch: 954 [600/2589 (23%)]\tLoss: 203.245544\n",
      "Train Epoch: 954 [900/2589 (35%)]\tLoss: 212.653534\n",
      "Train Epoch: 954 [1200/2589 (46%)]\tLoss: 161.224869\n",
      "Train Epoch: 954 [1500/2589 (58%)]\tLoss: 202.149887\n",
      "Train Epoch: 954 [1800/2589 (70%)]\tLoss: 208.841019\n",
      "Train Epoch: 954 [2100/2589 (81%)]\tLoss: 217.346161\n",
      "Train Epoch: 954 [2400/2589 (93%)]\tLoss: 158.657715\n",
      "====> Epoch: 954 Average train loss: 222.9817\n",
      "====> Epoch: 954 Average test loss: 926.8358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 955 [0/2589 (0%)]\tLoss: 235.321289\n",
      "Train Epoch: 955 [300/2589 (12%)]\tLoss: 288.287109\n",
      "Train Epoch: 955 [600/2589 (23%)]\tLoss: 254.904510\n",
      "Train Epoch: 955 [900/2589 (35%)]\tLoss: 169.029007\n",
      "Train Epoch: 955 [1200/2589 (46%)]\tLoss: 177.784256\n",
      "Train Epoch: 955 [1500/2589 (58%)]\tLoss: 179.834869\n",
      "Train Epoch: 955 [1800/2589 (70%)]\tLoss: 153.589539\n",
      "Train Epoch: 955 [2100/2589 (81%)]\tLoss: 190.989746\n",
      "Train Epoch: 955 [2400/2589 (93%)]\tLoss: 188.640045\n",
      "====> Epoch: 955 Average train loss: 223.7998\n",
      "====> Epoch: 955 Average test loss: 916.5007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 956 [0/2589 (0%)]\tLoss: 224.908783\n",
      "Train Epoch: 956 [300/2589 (12%)]\tLoss: 144.832382\n",
      "Train Epoch: 956 [600/2589 (23%)]\tLoss: 234.502502\n",
      "Train Epoch: 956 [900/2589 (35%)]\tLoss: 201.578583\n",
      "Train Epoch: 956 [1200/2589 (46%)]\tLoss: 289.548279\n",
      "Train Epoch: 956 [1500/2589 (58%)]\tLoss: 136.934479\n",
      "Train Epoch: 956 [1800/2589 (70%)]\tLoss: 187.625198\n",
      "Train Epoch: 956 [2100/2589 (81%)]\tLoss: 328.684662\n",
      "Train Epoch: 956 [2400/2589 (93%)]\tLoss: 181.343079\n",
      "====> Epoch: 956 Average train loss: 222.3228\n",
      "====> Epoch: 956 Average test loss: 925.6571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 957 [0/2589 (0%)]\tLoss: 190.078384\n",
      "Train Epoch: 957 [300/2589 (12%)]\tLoss: 227.298645\n",
      "Train Epoch: 957 [600/2589 (23%)]\tLoss: 237.035858\n",
      "Train Epoch: 957 [900/2589 (35%)]\tLoss: 238.506882\n",
      "Train Epoch: 957 [1200/2589 (46%)]\tLoss: 222.115234\n",
      "Train Epoch: 957 [1500/2589 (58%)]\tLoss: 262.498199\n",
      "Train Epoch: 957 [1800/2589 (70%)]\tLoss: 205.846390\n",
      "Train Epoch: 957 [2100/2589 (81%)]\tLoss: 159.025925\n",
      "Train Epoch: 957 [2400/2589 (93%)]\tLoss: 224.763809\n",
      "====> Epoch: 957 Average train loss: 216.8729\n",
      "====> Epoch: 957 Average test loss: 931.6483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 958 [0/2589 (0%)]\tLoss: 255.148453\n",
      "Train Epoch: 958 [300/2589 (12%)]\tLoss: 169.069916\n",
      "Train Epoch: 958 [600/2589 (23%)]\tLoss: 155.823380\n",
      "Train Epoch: 958 [900/2589 (35%)]\tLoss: 292.933990\n",
      "Train Epoch: 958 [1200/2589 (46%)]\tLoss: 222.938019\n",
      "Train Epoch: 958 [1500/2589 (58%)]\tLoss: 240.185211\n",
      "Train Epoch: 958 [1800/2589 (70%)]\tLoss: 216.309662\n",
      "Train Epoch: 958 [2100/2589 (81%)]\tLoss: 270.636658\n",
      "Train Epoch: 958 [2400/2589 (93%)]\tLoss: 264.055389\n",
      "====> Epoch: 958 Average train loss: 221.1810\n",
      "====> Epoch: 958 Average test loss: 915.8021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 959 [0/2589 (0%)]\tLoss: 171.569077\n",
      "Train Epoch: 959 [300/2589 (12%)]\tLoss: 220.774750\n",
      "Train Epoch: 959 [600/2589 (23%)]\tLoss: 180.240387\n",
      "Train Epoch: 959 [900/2589 (35%)]\tLoss: 214.852737\n",
      "Train Epoch: 959 [1200/2589 (46%)]\tLoss: 175.987000\n",
      "Train Epoch: 959 [1500/2589 (58%)]\tLoss: 225.300842\n",
      "Train Epoch: 959 [1800/2589 (70%)]\tLoss: 170.485184\n",
      "Train Epoch: 959 [2100/2589 (81%)]\tLoss: 186.436920\n",
      "Train Epoch: 959 [2400/2589 (93%)]\tLoss: 186.798004\n",
      "====> Epoch: 959 Average train loss: 223.8979\n",
      "====> Epoch: 959 Average test loss: 909.0002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 960 [0/2589 (0%)]\tLoss: 386.357361\n",
      "Train Epoch: 960 [300/2589 (12%)]\tLoss: 140.190750\n",
      "Train Epoch: 960 [600/2589 (23%)]\tLoss: 202.230881\n",
      "Train Epoch: 960 [900/2589 (35%)]\tLoss: 261.936584\n",
      "Train Epoch: 960 [1200/2589 (46%)]\tLoss: 353.227203\n",
      "Train Epoch: 960 [1500/2589 (58%)]\tLoss: 371.433899\n",
      "Train Epoch: 960 [1800/2589 (70%)]\tLoss: 229.469543\n",
      "Train Epoch: 960 [2100/2589 (81%)]\tLoss: 259.593964\n",
      "Train Epoch: 960 [2400/2589 (93%)]\tLoss: 232.924103\n",
      "====> Epoch: 960 Average train loss: 234.7980\n",
      "====> Epoch: 960 Average test loss: 914.0406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 961 [0/2589 (0%)]\tLoss: 192.383530\n",
      "Train Epoch: 961 [300/2589 (12%)]\tLoss: 178.255829\n",
      "Train Epoch: 961 [600/2589 (23%)]\tLoss: 396.458191\n",
      "Train Epoch: 961 [900/2589 (35%)]\tLoss: 259.889893\n",
      "Train Epoch: 961 [1200/2589 (46%)]\tLoss: 192.413986\n",
      "Train Epoch: 961 [1500/2589 (58%)]\tLoss: 249.736176\n",
      "Train Epoch: 961 [1800/2589 (70%)]\tLoss: 221.184662\n",
      "Train Epoch: 961 [2100/2589 (81%)]\tLoss: 193.732697\n",
      "Train Epoch: 961 [2400/2589 (93%)]\tLoss: 219.261398\n",
      "====> Epoch: 961 Average train loss: 215.5899\n",
      "====> Epoch: 961 Average test loss: 911.5643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 962 [0/2589 (0%)]\tLoss: 191.031982\n",
      "Train Epoch: 962 [300/2589 (12%)]\tLoss: 217.857437\n",
      "Train Epoch: 962 [600/2589 (23%)]\tLoss: 151.703232\n",
      "Train Epoch: 962 [900/2589 (35%)]\tLoss: 322.611267\n",
      "Train Epoch: 962 [1200/2589 (46%)]\tLoss: 167.772736\n",
      "Train Epoch: 962 [1500/2589 (58%)]\tLoss: 346.062469\n",
      "Train Epoch: 962 [1800/2589 (70%)]\tLoss: 229.720551\n",
      "Train Epoch: 962 [2100/2589 (81%)]\tLoss: 255.439651\n",
      "Train Epoch: 962 [2400/2589 (93%)]\tLoss: 182.220352\n",
      "====> Epoch: 962 Average train loss: 217.9161\n",
      "====> Epoch: 962 Average test loss: 905.9645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 963 [0/2589 (0%)]\tLoss: 155.258743\n",
      "Train Epoch: 963 [300/2589 (12%)]\tLoss: 285.739929\n",
      "Train Epoch: 963 [600/2589 (23%)]\tLoss: 175.765076\n",
      "Train Epoch: 963 [900/2589 (35%)]\tLoss: 161.892059\n",
      "Train Epoch: 963 [1200/2589 (46%)]\tLoss: 310.336090\n",
      "Train Epoch: 963 [1500/2589 (58%)]\tLoss: 206.180893\n",
      "Train Epoch: 963 [1800/2589 (70%)]\tLoss: 270.147430\n",
      "Train Epoch: 963 [2100/2589 (81%)]\tLoss: 367.596161\n",
      "Train Epoch: 963 [2400/2589 (93%)]\tLoss: 226.296692\n",
      "====> Epoch: 963 Average train loss: 218.8295\n",
      "====> Epoch: 963 Average test loss: 906.2852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 964 [0/2589 (0%)]\tLoss: 231.381073\n",
      "Train Epoch: 964 [300/2589 (12%)]\tLoss: 194.656509\n",
      "Train Epoch: 964 [600/2589 (23%)]\tLoss: 169.853180\n",
      "Train Epoch: 964 [900/2589 (35%)]\tLoss: 335.053741\n",
      "Train Epoch: 964 [1200/2589 (46%)]\tLoss: 183.183807\n",
      "Train Epoch: 964 [1500/2589 (58%)]\tLoss: 243.789719\n",
      "Train Epoch: 964 [1800/2589 (70%)]\tLoss: 271.302887\n",
      "Train Epoch: 964 [2100/2589 (81%)]\tLoss: 357.382202\n",
      "Train Epoch: 964 [2400/2589 (93%)]\tLoss: 170.924026\n",
      "====> Epoch: 964 Average train loss: 211.0016\n",
      "====> Epoch: 964 Average test loss: 925.3298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 965 [0/2589 (0%)]\tLoss: 177.836456\n",
      "Train Epoch: 965 [300/2589 (12%)]\tLoss: 400.974976\n",
      "Train Epoch: 965 [600/2589 (23%)]\tLoss: 278.101654\n",
      "Train Epoch: 965 [900/2589 (35%)]\tLoss: 160.970047\n",
      "Train Epoch: 965 [1200/2589 (46%)]\tLoss: 298.890076\n",
      "Train Epoch: 965 [1500/2589 (58%)]\tLoss: 194.793182\n",
      "Train Epoch: 965 [1800/2589 (70%)]\tLoss: 222.580307\n",
      "Train Epoch: 965 [2100/2589 (81%)]\tLoss: 210.743164\n",
      "Train Epoch: 965 [2400/2589 (93%)]\tLoss: 204.262878\n",
      "====> Epoch: 965 Average train loss: 225.7260\n",
      "====> Epoch: 965 Average test loss: 912.1046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 966 [0/2589 (0%)]\tLoss: 198.787247\n",
      "Train Epoch: 966 [300/2589 (12%)]\tLoss: 297.691376\n",
      "Train Epoch: 966 [600/2589 (23%)]\tLoss: 177.785782\n",
      "Train Epoch: 966 [900/2589 (35%)]\tLoss: 188.052567\n",
      "Train Epoch: 966 [1200/2589 (46%)]\tLoss: 250.533295\n",
      "Train Epoch: 966 [1500/2589 (58%)]\tLoss: 225.659882\n",
      "Train Epoch: 966 [1800/2589 (70%)]\tLoss: 192.530518\n",
      "Train Epoch: 966 [2100/2589 (81%)]\tLoss: 151.063416\n",
      "Train Epoch: 966 [2400/2589 (93%)]\tLoss: 271.582916\n",
      "====> Epoch: 966 Average train loss: 219.5806\n",
      "====> Epoch: 966 Average test loss: 911.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 967 [0/2589 (0%)]\tLoss: 269.605804\n",
      "Train Epoch: 967 [300/2589 (12%)]\tLoss: 174.372742\n",
      "Train Epoch: 967 [600/2589 (23%)]\tLoss: 267.450195\n",
      "Train Epoch: 967 [900/2589 (35%)]\tLoss: 237.867035\n",
      "Train Epoch: 967 [1200/2589 (46%)]\tLoss: 300.850586\n",
      "Train Epoch: 967 [1500/2589 (58%)]\tLoss: 291.431427\n",
      "Train Epoch: 967 [1800/2589 (70%)]\tLoss: 253.594162\n",
      "Train Epoch: 967 [2100/2589 (81%)]\tLoss: 136.318451\n",
      "Train Epoch: 967 [2400/2589 (93%)]\tLoss: 235.340332\n",
      "====> Epoch: 967 Average train loss: 222.3844\n",
      "====> Epoch: 967 Average test loss: 920.6605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 968 [0/2589 (0%)]\tLoss: 265.313568\n",
      "Train Epoch: 968 [300/2589 (12%)]\tLoss: 167.357025\n",
      "Train Epoch: 968 [600/2589 (23%)]\tLoss: 225.132294\n",
      "Train Epoch: 968 [900/2589 (35%)]\tLoss: 237.424698\n",
      "Train Epoch: 968 [1200/2589 (46%)]\tLoss: 188.554367\n",
      "Train Epoch: 968 [1500/2589 (58%)]\tLoss: 115.387352\n",
      "Train Epoch: 968 [1800/2589 (70%)]\tLoss: 482.014069\n",
      "Train Epoch: 968 [2100/2589 (81%)]\tLoss: 260.686371\n",
      "Train Epoch: 968 [2400/2589 (93%)]\tLoss: 266.492310\n",
      "====> Epoch: 968 Average train loss: 231.6743\n",
      "====> Epoch: 968 Average test loss: 927.5978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 969 [0/2589 (0%)]\tLoss: 174.081039\n",
      "Train Epoch: 969 [300/2589 (12%)]\tLoss: 242.549469\n",
      "Train Epoch: 969 [600/2589 (23%)]\tLoss: 183.870773\n",
      "Train Epoch: 969 [900/2589 (35%)]\tLoss: 287.989655\n",
      "Train Epoch: 969 [1200/2589 (46%)]\tLoss: 194.094299\n",
      "Train Epoch: 969 [1500/2589 (58%)]\tLoss: 223.631348\n",
      "Train Epoch: 969 [1800/2589 (70%)]\tLoss: 248.791046\n",
      "Train Epoch: 969 [2100/2589 (81%)]\tLoss: 224.061935\n",
      "Train Epoch: 969 [2400/2589 (93%)]\tLoss: 191.455338\n",
      "====> Epoch: 969 Average train loss: 223.7194\n",
      "====> Epoch: 969 Average test loss: 930.2839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 970 [0/2589 (0%)]\tLoss: 130.483109\n",
      "Train Epoch: 970 [300/2589 (12%)]\tLoss: 207.769989\n",
      "Train Epoch: 970 [600/2589 (23%)]\tLoss: 195.051224\n",
      "Train Epoch: 970 [900/2589 (35%)]\tLoss: 270.301575\n",
      "Train Epoch: 970 [1200/2589 (46%)]\tLoss: 203.272003\n",
      "Train Epoch: 970 [1500/2589 (58%)]\tLoss: 185.279129\n",
      "Train Epoch: 970 [1800/2589 (70%)]\tLoss: 148.893951\n",
      "Train Epoch: 970 [2100/2589 (81%)]\tLoss: 258.599396\n",
      "Train Epoch: 970 [2400/2589 (93%)]\tLoss: 229.614807\n",
      "====> Epoch: 970 Average train loss: 217.8438\n",
      "====> Epoch: 970 Average test loss: 914.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 971 [0/2589 (0%)]\tLoss: 129.642410\n",
      "Train Epoch: 971 [300/2589 (12%)]\tLoss: 335.641235\n",
      "Train Epoch: 971 [600/2589 (23%)]\tLoss: 235.980377\n",
      "Train Epoch: 971 [900/2589 (35%)]\tLoss: 211.846649\n",
      "Train Epoch: 971 [1200/2589 (46%)]\tLoss: 139.675674\n",
      "Train Epoch: 971 [1500/2589 (58%)]\tLoss: 179.900986\n",
      "Train Epoch: 971 [1800/2589 (70%)]\tLoss: 243.886185\n",
      "Train Epoch: 971 [2100/2589 (81%)]\tLoss: 155.592255\n",
      "Train Epoch: 971 [2400/2589 (93%)]\tLoss: 179.293777\n",
      "====> Epoch: 971 Average train loss: 207.0188\n",
      "====> Epoch: 971 Average test loss: 919.5758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 972 [0/2589 (0%)]\tLoss: 176.814423\n",
      "Train Epoch: 972 [300/2589 (12%)]\tLoss: 220.859558\n",
      "Train Epoch: 972 [600/2589 (23%)]\tLoss: 136.644531\n",
      "Train Epoch: 972 [900/2589 (35%)]\tLoss: 142.558823\n",
      "Train Epoch: 972 [1200/2589 (46%)]\tLoss: 243.887100\n",
      "Train Epoch: 972 [1500/2589 (58%)]\tLoss: 175.655029\n",
      "Train Epoch: 972 [1800/2589 (70%)]\tLoss: 148.856644\n",
      "Train Epoch: 972 [2100/2589 (81%)]\tLoss: 297.467377\n",
      "Train Epoch: 972 [2400/2589 (93%)]\tLoss: 242.812836\n",
      "====> Epoch: 972 Average train loss: 222.5491\n",
      "====> Epoch: 972 Average test loss: 921.2005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 973 [0/2589 (0%)]\tLoss: 157.560898\n",
      "Train Epoch: 973 [300/2589 (12%)]\tLoss: 226.749405\n",
      "Train Epoch: 973 [600/2589 (23%)]\tLoss: 253.055206\n",
      "Train Epoch: 973 [900/2589 (35%)]\tLoss: 155.958542\n",
      "Train Epoch: 973 [1200/2589 (46%)]\tLoss: 455.836639\n",
      "Train Epoch: 973 [1500/2589 (58%)]\tLoss: 196.632797\n",
      "Train Epoch: 973 [1800/2589 (70%)]\tLoss: 223.510559\n",
      "Train Epoch: 973 [2100/2589 (81%)]\tLoss: 378.151367\n",
      "Train Epoch: 973 [2400/2589 (93%)]\tLoss: 174.125504\n",
      "====> Epoch: 973 Average train loss: 218.9248\n",
      "====> Epoch: 973 Average test loss: 923.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 974 [0/2589 (0%)]\tLoss: 159.423935\n",
      "Train Epoch: 974 [300/2589 (12%)]\tLoss: 287.583313\n",
      "Train Epoch: 974 [600/2589 (23%)]\tLoss: 357.828308\n",
      "Train Epoch: 974 [900/2589 (35%)]\tLoss: 201.895676\n",
      "Train Epoch: 974 [1200/2589 (46%)]\tLoss: 288.573944\n",
      "Train Epoch: 974 [1500/2589 (58%)]\tLoss: 216.616699\n",
      "Train Epoch: 974 [1800/2589 (70%)]\tLoss: 162.121780\n",
      "Train Epoch: 974 [2100/2589 (81%)]\tLoss: 208.279007\n",
      "Train Epoch: 974 [2400/2589 (93%)]\tLoss: 243.336182\n",
      "====> Epoch: 974 Average train loss: 224.3309\n",
      "====> Epoch: 974 Average test loss: 906.6896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 975 [0/2589 (0%)]\tLoss: 233.179337\n",
      "Train Epoch: 975 [300/2589 (12%)]\tLoss: 201.829559\n",
      "Train Epoch: 975 [600/2589 (23%)]\tLoss: 151.471375\n",
      "Train Epoch: 975 [900/2589 (35%)]\tLoss: 198.813766\n",
      "Train Epoch: 975 [1200/2589 (46%)]\tLoss: 217.194397\n",
      "Train Epoch: 975 [1500/2589 (58%)]\tLoss: 237.140869\n",
      "Train Epoch: 975 [1800/2589 (70%)]\tLoss: 374.513550\n",
      "Train Epoch: 975 [2100/2589 (81%)]\tLoss: 215.305450\n",
      "Train Epoch: 975 [2400/2589 (93%)]\tLoss: 266.928986\n",
      "====> Epoch: 975 Average train loss: 218.7365\n",
      "====> Epoch: 975 Average test loss: 922.8031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 976 [0/2589 (0%)]\tLoss: 172.469299\n",
      "Train Epoch: 976 [300/2589 (12%)]\tLoss: 209.268829\n",
      "Train Epoch: 976 [600/2589 (23%)]\tLoss: 216.039398\n",
      "Train Epoch: 976 [900/2589 (35%)]\tLoss: 187.425461\n",
      "Train Epoch: 976 [1200/2589 (46%)]\tLoss: 189.020752\n",
      "Train Epoch: 976 [1500/2589 (58%)]\tLoss: 235.072281\n",
      "Train Epoch: 976 [1800/2589 (70%)]\tLoss: 312.003265\n",
      "Train Epoch: 976 [2100/2589 (81%)]\tLoss: 170.985855\n",
      "Train Epoch: 976 [2400/2589 (93%)]\tLoss: 229.451813\n",
      "====> Epoch: 976 Average train loss: 214.2206\n",
      "====> Epoch: 976 Average test loss: 920.5437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 977 [0/2589 (0%)]\tLoss: 256.887817\n",
      "Train Epoch: 977 [300/2589 (12%)]\tLoss: 183.663086\n",
      "Train Epoch: 977 [600/2589 (23%)]\tLoss: 164.531525\n",
      "Train Epoch: 977 [900/2589 (35%)]\tLoss: 177.395950\n",
      "Train Epoch: 977 [1200/2589 (46%)]\tLoss: 169.232071\n",
      "Train Epoch: 977 [1500/2589 (58%)]\tLoss: 145.389679\n",
      "Train Epoch: 977 [1800/2589 (70%)]\tLoss: 214.657654\n",
      "Train Epoch: 977 [2100/2589 (81%)]\tLoss: 231.232849\n",
      "Train Epoch: 977 [2400/2589 (93%)]\tLoss: 225.866760\n",
      "====> Epoch: 977 Average train loss: 218.7429\n",
      "====> Epoch: 977 Average test loss: 910.6541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 978 [0/2589 (0%)]\tLoss: 205.743484\n",
      "Train Epoch: 978 [300/2589 (12%)]\tLoss: 183.532990\n",
      "Train Epoch: 978 [600/2589 (23%)]\tLoss: 245.849380\n",
      "Train Epoch: 978 [900/2589 (35%)]\tLoss: 197.186722\n",
      "Train Epoch: 978 [1200/2589 (46%)]\tLoss: 206.202164\n",
      "Train Epoch: 978 [1500/2589 (58%)]\tLoss: 263.171722\n",
      "Train Epoch: 978 [1800/2589 (70%)]\tLoss: 168.785217\n",
      "Train Epoch: 978 [2100/2589 (81%)]\tLoss: 171.777344\n",
      "Train Epoch: 978 [2400/2589 (93%)]\tLoss: 206.981339\n",
      "====> Epoch: 978 Average train loss: 220.6035\n",
      "====> Epoch: 978 Average test loss: 921.4467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 979 [0/2589 (0%)]\tLoss: 188.063995\n",
      "Train Epoch: 979 [300/2589 (12%)]\tLoss: 137.503082\n",
      "Train Epoch: 979 [600/2589 (23%)]\tLoss: 220.945847\n",
      "Train Epoch: 979 [900/2589 (35%)]\tLoss: 147.390564\n",
      "Train Epoch: 979 [1200/2589 (46%)]\tLoss: 196.414642\n",
      "Train Epoch: 979 [1500/2589 (58%)]\tLoss: 241.269867\n",
      "Train Epoch: 979 [1800/2589 (70%)]\tLoss: 176.604980\n",
      "Train Epoch: 979 [2100/2589 (81%)]\tLoss: 266.929291\n",
      "Train Epoch: 979 [2400/2589 (93%)]\tLoss: 231.401901\n",
      "====> Epoch: 979 Average train loss: 220.9084\n",
      "====> Epoch: 979 Average test loss: 924.8824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 980 [0/2589 (0%)]\tLoss: 304.909882\n",
      "Train Epoch: 980 [300/2589 (12%)]\tLoss: 202.357239\n",
      "Train Epoch: 980 [600/2589 (23%)]\tLoss: 156.733200\n",
      "Train Epoch: 980 [900/2589 (35%)]\tLoss: 205.419006\n",
      "Train Epoch: 980 [1200/2589 (46%)]\tLoss: 221.250641\n",
      "Train Epoch: 980 [1500/2589 (58%)]\tLoss: 184.655090\n",
      "Train Epoch: 980 [1800/2589 (70%)]\tLoss: 157.126434\n",
      "Train Epoch: 980 [2100/2589 (81%)]\tLoss: 149.458893\n",
      "Train Epoch: 980 [2400/2589 (93%)]\tLoss: 170.481232\n",
      "====> Epoch: 980 Average train loss: 219.9696\n",
      "====> Epoch: 980 Average test loss: 917.8488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 981 [0/2589 (0%)]\tLoss: 197.909332\n",
      "Train Epoch: 981 [300/2589 (12%)]\tLoss: 154.759445\n",
      "Train Epoch: 981 [600/2589 (23%)]\tLoss: 266.710968\n",
      "Train Epoch: 981 [900/2589 (35%)]\tLoss: 279.919220\n",
      "Train Epoch: 981 [1200/2589 (46%)]\tLoss: 289.682129\n",
      "Train Epoch: 981 [1500/2589 (58%)]\tLoss: 242.895859\n",
      "Train Epoch: 981 [1800/2589 (70%)]\tLoss: 181.476486\n",
      "Train Epoch: 981 [2100/2589 (81%)]\tLoss: 183.441742\n",
      "Train Epoch: 981 [2400/2589 (93%)]\tLoss: 237.260483\n",
      "====> Epoch: 981 Average train loss: 226.3959\n",
      "====> Epoch: 981 Average test loss: 925.5671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 982 [0/2589 (0%)]\tLoss: 168.694611\n",
      "Train Epoch: 982 [300/2589 (12%)]\tLoss: 206.252106\n",
      "Train Epoch: 982 [600/2589 (23%)]\tLoss: 215.317703\n",
      "Train Epoch: 982 [900/2589 (35%)]\tLoss: 175.808517\n",
      "Train Epoch: 982 [1200/2589 (46%)]\tLoss: 217.386902\n",
      "Train Epoch: 982 [1500/2589 (58%)]\tLoss: 224.893890\n",
      "Train Epoch: 982 [1800/2589 (70%)]\tLoss: 180.240189\n",
      "Train Epoch: 982 [2100/2589 (81%)]\tLoss: 204.628723\n",
      "Train Epoch: 982 [2400/2589 (93%)]\tLoss: 171.769867\n",
      "====> Epoch: 982 Average train loss: 230.5272\n",
      "====> Epoch: 982 Average test loss: 919.7086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 983 [0/2589 (0%)]\tLoss: 215.782608\n",
      "Train Epoch: 983 [300/2589 (12%)]\tLoss: 167.550049\n",
      "Train Epoch: 983 [600/2589 (23%)]\tLoss: 200.288147\n",
      "Train Epoch: 983 [900/2589 (35%)]\tLoss: 108.919266\n",
      "Train Epoch: 983 [1200/2589 (46%)]\tLoss: 166.868484\n",
      "Train Epoch: 983 [1500/2589 (58%)]\tLoss: 245.376114\n",
      "Train Epoch: 983 [1800/2589 (70%)]\tLoss: 228.266983\n",
      "Train Epoch: 983 [2100/2589 (81%)]\tLoss: 460.215790\n",
      "Train Epoch: 983 [2400/2589 (93%)]\tLoss: 159.590576\n",
      "====> Epoch: 983 Average train loss: 231.6779\n",
      "====> Epoch: 983 Average test loss: 908.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 984 [0/2589 (0%)]\tLoss: 158.499969\n",
      "Train Epoch: 984 [300/2589 (12%)]\tLoss: 280.588562\n",
      "Train Epoch: 984 [600/2589 (23%)]\tLoss: 325.923737\n",
      "Train Epoch: 984 [900/2589 (35%)]\tLoss: 208.323395\n",
      "Train Epoch: 984 [1200/2589 (46%)]\tLoss: 225.287308\n",
      "Train Epoch: 984 [1500/2589 (58%)]\tLoss: 257.748199\n",
      "Train Epoch: 984 [1800/2589 (70%)]\tLoss: 381.458038\n",
      "Train Epoch: 984 [2100/2589 (81%)]\tLoss: 193.436096\n",
      "Train Epoch: 984 [2400/2589 (93%)]\tLoss: 224.997711\n",
      "====> Epoch: 984 Average train loss: 232.1152\n",
      "====> Epoch: 984 Average test loss: 902.3160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 985 [0/2589 (0%)]\tLoss: 198.217636\n",
      "Train Epoch: 985 [300/2589 (12%)]\tLoss: 142.121597\n",
      "Train Epoch: 985 [600/2589 (23%)]\tLoss: 256.772369\n",
      "Train Epoch: 985 [900/2589 (35%)]\tLoss: 346.756409\n",
      "Train Epoch: 985 [1200/2589 (46%)]\tLoss: 269.149139\n",
      "Train Epoch: 985 [1500/2589 (58%)]\tLoss: 276.652344\n",
      "Train Epoch: 985 [1800/2589 (70%)]\tLoss: 172.479675\n",
      "Train Epoch: 985 [2100/2589 (81%)]\tLoss: 320.542816\n",
      "Train Epoch: 985 [2400/2589 (93%)]\tLoss: 145.148743\n",
      "====> Epoch: 985 Average train loss: 223.1597\n",
      "====> Epoch: 985 Average test loss: 922.8545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 986 [0/2589 (0%)]\tLoss: 252.284424\n",
      "Train Epoch: 986 [300/2589 (12%)]\tLoss: 452.458801\n",
      "Train Epoch: 986 [600/2589 (23%)]\tLoss: 179.478012\n",
      "Train Epoch: 986 [900/2589 (35%)]\tLoss: 229.079254\n",
      "Train Epoch: 986 [1200/2589 (46%)]\tLoss: 207.909576\n",
      "Train Epoch: 986 [1500/2589 (58%)]\tLoss: 206.500031\n",
      "Train Epoch: 986 [1800/2589 (70%)]\tLoss: 189.208878\n",
      "Train Epoch: 986 [2100/2589 (81%)]\tLoss: 185.854599\n",
      "Train Epoch: 986 [2400/2589 (93%)]\tLoss: 168.822678\n",
      "====> Epoch: 986 Average train loss: 230.1801\n",
      "====> Epoch: 986 Average test loss: 905.6076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 987 [0/2589 (0%)]\tLoss: 191.697891\n",
      "Train Epoch: 987 [300/2589 (12%)]\tLoss: 159.068756\n",
      "Train Epoch: 987 [600/2589 (23%)]\tLoss: 130.875153\n",
      "Train Epoch: 987 [900/2589 (35%)]\tLoss: 164.482697\n",
      "Train Epoch: 987 [1200/2589 (46%)]\tLoss: 193.094284\n",
      "Train Epoch: 987 [1500/2589 (58%)]\tLoss: 207.195541\n",
      "Train Epoch: 987 [1800/2589 (70%)]\tLoss: 186.978378\n",
      "Train Epoch: 987 [2100/2589 (81%)]\tLoss: 220.258606\n",
      "Train Epoch: 987 [2400/2589 (93%)]\tLoss: 214.291763\n",
      "====> Epoch: 987 Average train loss: 226.9033\n",
      "====> Epoch: 987 Average test loss: 938.5719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 988 [0/2589 (0%)]\tLoss: 194.033463\n",
      "Train Epoch: 988 [300/2589 (12%)]\tLoss: 162.336975\n",
      "Train Epoch: 988 [600/2589 (23%)]\tLoss: 152.968597\n",
      "Train Epoch: 988 [900/2589 (35%)]\tLoss: 184.982224\n",
      "Train Epoch: 988 [1200/2589 (46%)]\tLoss: 170.707230\n",
      "Train Epoch: 988 [1500/2589 (58%)]\tLoss: 145.400879\n",
      "Train Epoch: 988 [1800/2589 (70%)]\tLoss: 152.642639\n",
      "Train Epoch: 988 [2100/2589 (81%)]\tLoss: 240.667084\n",
      "Train Epoch: 988 [2400/2589 (93%)]\tLoss: 251.845474\n",
      "====> Epoch: 988 Average train loss: 224.6403\n",
      "====> Epoch: 988 Average test loss: 920.7640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 989 [0/2589 (0%)]\tLoss: 272.707550\n",
      "Train Epoch: 989 [300/2589 (12%)]\tLoss: 215.885162\n",
      "Train Epoch: 989 [600/2589 (23%)]\tLoss: 152.310379\n",
      "Train Epoch: 989 [900/2589 (35%)]\tLoss: 256.228577\n",
      "Train Epoch: 989 [1200/2589 (46%)]\tLoss: 198.070374\n",
      "Train Epoch: 989 [1500/2589 (58%)]\tLoss: 150.160858\n",
      "Train Epoch: 989 [1800/2589 (70%)]\tLoss: 184.032440\n",
      "Train Epoch: 989 [2100/2589 (81%)]\tLoss: 184.704437\n",
      "Train Epoch: 989 [2400/2589 (93%)]\tLoss: 208.855927\n",
      "====> Epoch: 989 Average train loss: 225.8999\n",
      "====> Epoch: 989 Average test loss: 902.0135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 990 [0/2589 (0%)]\tLoss: 196.999283\n",
      "Train Epoch: 990 [300/2589 (12%)]\tLoss: 262.529755\n",
      "Train Epoch: 990 [600/2589 (23%)]\tLoss: 159.113205\n",
      "Train Epoch: 990 [900/2589 (35%)]\tLoss: 171.848984\n",
      "Train Epoch: 990 [1200/2589 (46%)]\tLoss: 166.545395\n",
      "Train Epoch: 990 [1500/2589 (58%)]\tLoss: 154.647064\n",
      "Train Epoch: 990 [1800/2589 (70%)]\tLoss: 194.822525\n",
      "Train Epoch: 990 [2100/2589 (81%)]\tLoss: 257.947327\n",
      "Train Epoch: 990 [2400/2589 (93%)]\tLoss: 208.287857\n",
      "====> Epoch: 990 Average train loss: 220.0289\n",
      "====> Epoch: 990 Average test loss: 902.7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 991 [0/2589 (0%)]\tLoss: 180.060318\n",
      "Train Epoch: 991 [300/2589 (12%)]\tLoss: 264.628906\n",
      "Train Epoch: 991 [600/2589 (23%)]\tLoss: 177.965561\n",
      "Train Epoch: 991 [900/2589 (35%)]\tLoss: 227.661423\n",
      "Train Epoch: 991 [1200/2589 (46%)]\tLoss: 213.019318\n",
      "Train Epoch: 991 [1500/2589 (58%)]\tLoss: 276.317474\n",
      "Train Epoch: 991 [1800/2589 (70%)]\tLoss: 172.937897\n",
      "Train Epoch: 991 [2100/2589 (81%)]\tLoss: 188.666702\n",
      "Train Epoch: 991 [2400/2589 (93%)]\tLoss: 202.922134\n",
      "====> Epoch: 991 Average train loss: 221.0845\n",
      "====> Epoch: 991 Average test loss: 902.7967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 992 [0/2589 (0%)]\tLoss: 179.069977\n",
      "Train Epoch: 992 [300/2589 (12%)]\tLoss: 234.663239\n",
      "Train Epoch: 992 [600/2589 (23%)]\tLoss: 174.831284\n",
      "Train Epoch: 992 [900/2589 (35%)]\tLoss: 213.277695\n",
      "Train Epoch: 992 [1200/2589 (46%)]\tLoss: 212.293625\n",
      "Train Epoch: 992 [1500/2589 (58%)]\tLoss: 140.612381\n",
      "Train Epoch: 992 [1800/2589 (70%)]\tLoss: 400.479584\n",
      "Train Epoch: 992 [2100/2589 (81%)]\tLoss: 244.005173\n",
      "Train Epoch: 992 [2400/2589 (93%)]\tLoss: 309.798126\n",
      "====> Epoch: 992 Average train loss: 228.4483\n",
      "====> Epoch: 992 Average test loss: 907.2820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 993 [0/2589 (0%)]\tLoss: 251.071106\n",
      "Train Epoch: 993 [300/2589 (12%)]\tLoss: 178.578415\n",
      "Train Epoch: 993 [600/2589 (23%)]\tLoss: 177.292145\n",
      "Train Epoch: 993 [900/2589 (35%)]\tLoss: 247.571747\n",
      "Train Epoch: 993 [1200/2589 (46%)]\tLoss: 206.207016\n",
      "Train Epoch: 993 [1500/2589 (58%)]\tLoss: 180.616837\n",
      "Train Epoch: 993 [1800/2589 (70%)]\tLoss: 185.876068\n",
      "Train Epoch: 993 [2100/2589 (81%)]\tLoss: 197.619827\n",
      "Train Epoch: 993 [2400/2589 (93%)]\tLoss: 170.548615\n",
      "====> Epoch: 993 Average train loss: 231.0720\n",
      "====> Epoch: 993 Average test loss: 922.2150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 994 [0/2589 (0%)]\tLoss: 127.428757\n",
      "Train Epoch: 994 [300/2589 (12%)]\tLoss: 285.876587\n",
      "Train Epoch: 994 [600/2589 (23%)]\tLoss: 321.838318\n",
      "Train Epoch: 994 [900/2589 (35%)]\tLoss: 200.599869\n",
      "Train Epoch: 994 [1200/2589 (46%)]\tLoss: 201.001892\n",
      "Train Epoch: 994 [1500/2589 (58%)]\tLoss: 138.471786\n",
      "Train Epoch: 994 [1800/2589 (70%)]\tLoss: 241.530045\n",
      "Train Epoch: 994 [2100/2589 (81%)]\tLoss: 273.904755\n",
      "Train Epoch: 994 [2400/2589 (93%)]\tLoss: 256.899689\n",
      "====> Epoch: 994 Average train loss: 220.7244\n",
      "====> Epoch: 994 Average test loss: 909.8915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 995 [0/2589 (0%)]\tLoss: 256.005096\n",
      "Train Epoch: 995 [300/2589 (12%)]\tLoss: 202.546646\n",
      "Train Epoch: 995 [600/2589 (23%)]\tLoss: 162.259918\n",
      "Train Epoch: 995 [900/2589 (35%)]\tLoss: 164.334930\n",
      "Train Epoch: 995 [1200/2589 (46%)]\tLoss: 203.087204\n",
      "Train Epoch: 995 [1500/2589 (58%)]\tLoss: 173.856583\n",
      "Train Epoch: 995 [1800/2589 (70%)]\tLoss: 295.515686\n",
      "Train Epoch: 995 [2100/2589 (81%)]\tLoss: 200.390213\n",
      "Train Epoch: 995 [2400/2589 (93%)]\tLoss: 148.916809\n",
      "====> Epoch: 995 Average train loss: 216.5180\n",
      "====> Epoch: 995 Average test loss: 929.6526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 996 [0/2589 (0%)]\tLoss: 174.479492\n",
      "Train Epoch: 996 [300/2589 (12%)]\tLoss: 255.294189\n",
      "Train Epoch: 996 [600/2589 (23%)]\tLoss: 239.077850\n",
      "Train Epoch: 996 [900/2589 (35%)]\tLoss: 233.993820\n",
      "Train Epoch: 996 [1200/2589 (46%)]\tLoss: 267.093628\n",
      "Train Epoch: 996 [1500/2589 (58%)]\tLoss: 288.120728\n",
      "Train Epoch: 996 [1800/2589 (70%)]\tLoss: 270.713959\n",
      "Train Epoch: 996 [2100/2589 (81%)]\tLoss: 349.310364\n",
      "Train Epoch: 996 [2400/2589 (93%)]\tLoss: 228.682129\n",
      "====> Epoch: 996 Average train loss: 227.3865\n",
      "====> Epoch: 996 Average test loss: 911.6296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 997 [0/2589 (0%)]\tLoss: 190.389786\n",
      "Train Epoch: 997 [300/2589 (12%)]\tLoss: 283.819550\n",
      "Train Epoch: 997 [600/2589 (23%)]\tLoss: 199.125717\n",
      "Train Epoch: 997 [900/2589 (35%)]\tLoss: 238.928574\n",
      "Train Epoch: 997 [1200/2589 (46%)]\tLoss: 246.711731\n",
      "Train Epoch: 997 [1500/2589 (58%)]\tLoss: 184.831772\n",
      "Train Epoch: 997 [1800/2589 (70%)]\tLoss: 251.795670\n",
      "Train Epoch: 997 [2100/2589 (81%)]\tLoss: 273.475006\n",
      "Train Epoch: 997 [2400/2589 (93%)]\tLoss: 162.759125\n",
      "====> Epoch: 997 Average train loss: 226.4108\n",
      "====> Epoch: 997 Average test loss: 919.7786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 998 [0/2589 (0%)]\tLoss: 223.950485\n",
      "Train Epoch: 998 [300/2589 (12%)]\tLoss: 202.974564\n",
      "Train Epoch: 998 [600/2589 (23%)]\tLoss: 341.263336\n",
      "Train Epoch: 998 [900/2589 (35%)]\tLoss: 174.599045\n",
      "Train Epoch: 998 [1200/2589 (46%)]\tLoss: 201.670120\n",
      "Train Epoch: 998 [1500/2589 (58%)]\tLoss: 346.213287\n",
      "Train Epoch: 998 [1800/2589 (70%)]\tLoss: 195.701981\n",
      "Train Epoch: 998 [2100/2589 (81%)]\tLoss: 270.876678\n",
      "Train Epoch: 998 [2400/2589 (93%)]\tLoss: 155.714310\n",
      "====> Epoch: 998 Average train loss: 221.3455\n",
      "====> Epoch: 998 Average test loss: 911.3724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 999 [0/2589 (0%)]\tLoss: 138.972748\n",
      "Train Epoch: 999 [300/2589 (12%)]\tLoss: 182.821518\n",
      "Train Epoch: 999 [600/2589 (23%)]\tLoss: 231.432434\n",
      "Train Epoch: 999 [900/2589 (35%)]\tLoss: 183.489090\n",
      "Train Epoch: 999 [1200/2589 (46%)]\tLoss: 182.596878\n",
      "Train Epoch: 999 [1500/2589 (58%)]\tLoss: 202.302475\n",
      "Train Epoch: 999 [1800/2589 (70%)]\tLoss: 315.586456\n",
      "Train Epoch: 999 [2100/2589 (81%)]\tLoss: 222.651886\n",
      "Train Epoch: 999 [2400/2589 (93%)]\tLoss: 184.123688\n",
      "====> Epoch: 999 Average train loss: 216.8745\n",
      "====> Epoch: 999 Average test loss: 917.4277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1000 [0/2589 (0%)]\tLoss: 169.757706\n",
      "Train Epoch: 1000 [300/2589 (12%)]\tLoss: 219.392181\n",
      "Train Epoch: 1000 [600/2589 (23%)]\tLoss: 200.202621\n",
      "Train Epoch: 1000 [900/2589 (35%)]\tLoss: 316.843384\n",
      "Train Epoch: 1000 [1200/2589 (46%)]\tLoss: 216.005234\n",
      "Train Epoch: 1000 [1500/2589 (58%)]\tLoss: 206.896652\n",
      "Train Epoch: 1000 [1800/2589 (70%)]\tLoss: 237.990677\n",
      "Train Epoch: 1000 [2100/2589 (81%)]\tLoss: 227.714417\n",
      "Train Epoch: 1000 [2400/2589 (93%)]\tLoss: 251.777908\n",
      "====> Epoch: 1000 Average train loss: 218.7892\n",
      "====> Epoch: 1000 Average test loss: 911.1132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1001 [0/2589 (0%)]\tLoss: 170.034760\n",
      "Train Epoch: 1001 [300/2589 (12%)]\tLoss: 229.816574\n",
      "Train Epoch: 1001 [600/2589 (23%)]\tLoss: 195.183136\n",
      "Train Epoch: 1001 [900/2589 (35%)]\tLoss: 181.247177\n",
      "Train Epoch: 1001 [1200/2589 (46%)]\tLoss: 369.051819\n",
      "Train Epoch: 1001 [1500/2589 (58%)]\tLoss: 215.672928\n",
      "Train Epoch: 1001 [1800/2589 (70%)]\tLoss: 227.917328\n",
      "Train Epoch: 1001 [2100/2589 (81%)]\tLoss: 178.338867\n",
      "Train Epoch: 1001 [2400/2589 (93%)]\tLoss: 166.319229\n",
      "====> Epoch: 1001 Average train loss: 220.0497\n",
      "====> Epoch: 1001 Average test loss: 912.8835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1002 [0/2589 (0%)]\tLoss: 385.909729\n",
      "Train Epoch: 1002 [300/2589 (12%)]\tLoss: 211.735352\n",
      "Train Epoch: 1002 [600/2589 (23%)]\tLoss: 221.379944\n",
      "Train Epoch: 1002 [900/2589 (35%)]\tLoss: 227.623306\n",
      "Train Epoch: 1002 [1200/2589 (46%)]\tLoss: 165.439789\n",
      "Train Epoch: 1002 [1500/2589 (58%)]\tLoss: 123.570854\n",
      "Train Epoch: 1002 [1800/2589 (70%)]\tLoss: 185.983231\n",
      "Train Epoch: 1002 [2100/2589 (81%)]\tLoss: 189.099442\n",
      "Train Epoch: 1002 [2400/2589 (93%)]\tLoss: 216.004974\n",
      "====> Epoch: 1002 Average train loss: 217.4729\n",
      "====> Epoch: 1002 Average test loss: 911.6564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1003 [0/2589 (0%)]\tLoss: 162.122391\n",
      "Train Epoch: 1003 [300/2589 (12%)]\tLoss: 186.560486\n",
      "Train Epoch: 1003 [600/2589 (23%)]\tLoss: 156.763489\n",
      "Train Epoch: 1003 [900/2589 (35%)]\tLoss: 141.756378\n",
      "Train Epoch: 1003 [1200/2589 (46%)]\tLoss: 212.492935\n",
      "Train Epoch: 1003 [1500/2589 (58%)]\tLoss: 272.929291\n",
      "Train Epoch: 1003 [1800/2589 (70%)]\tLoss: 231.671524\n",
      "Train Epoch: 1003 [2100/2589 (81%)]\tLoss: 288.989594\n",
      "Train Epoch: 1003 [2400/2589 (93%)]\tLoss: 204.249481\n",
      "====> Epoch: 1003 Average train loss: 223.2943\n",
      "====> Epoch: 1003 Average test loss: 921.0449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1004 [0/2589 (0%)]\tLoss: 292.844269\n",
      "Train Epoch: 1004 [300/2589 (12%)]\tLoss: 136.590622\n",
      "Train Epoch: 1004 [600/2589 (23%)]\tLoss: 192.041611\n",
      "Train Epoch: 1004 [900/2589 (35%)]\tLoss: 220.258041\n",
      "Train Epoch: 1004 [1200/2589 (46%)]\tLoss: 295.023987\n",
      "Train Epoch: 1004 [1500/2589 (58%)]\tLoss: 193.758987\n",
      "Train Epoch: 1004 [1800/2589 (70%)]\tLoss: 169.097992\n",
      "Train Epoch: 1004 [2100/2589 (81%)]\tLoss: 209.526611\n",
      "Train Epoch: 1004 [2400/2589 (93%)]\tLoss: 159.517761\n",
      "====> Epoch: 1004 Average train loss: 214.3564\n",
      "====> Epoch: 1004 Average test loss: 910.0952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1005 [0/2589 (0%)]\tLoss: 304.958282\n",
      "Train Epoch: 1005 [300/2589 (12%)]\tLoss: 327.055023\n",
      "Train Epoch: 1005 [600/2589 (23%)]\tLoss: 264.431213\n",
      "Train Epoch: 1005 [900/2589 (35%)]\tLoss: 227.481873\n",
      "Train Epoch: 1005 [1200/2589 (46%)]\tLoss: 264.643005\n",
      "Train Epoch: 1005 [1500/2589 (58%)]\tLoss: 317.490021\n",
      "Train Epoch: 1005 [1800/2589 (70%)]\tLoss: 223.431915\n",
      "Train Epoch: 1005 [2100/2589 (81%)]\tLoss: 248.316620\n",
      "Train Epoch: 1005 [2400/2589 (93%)]\tLoss: 189.330399\n",
      "====> Epoch: 1005 Average train loss: 227.7644\n",
      "====> Epoch: 1005 Average test loss: 918.6065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1006 [0/2589 (0%)]\tLoss: 242.884033\n",
      "Train Epoch: 1006 [300/2589 (12%)]\tLoss: 270.598450\n",
      "Train Epoch: 1006 [600/2589 (23%)]\tLoss: 255.289627\n",
      "Train Epoch: 1006 [900/2589 (35%)]\tLoss: 134.203674\n",
      "Train Epoch: 1006 [1200/2589 (46%)]\tLoss: 239.112717\n",
      "Train Epoch: 1006 [1500/2589 (58%)]\tLoss: 212.677826\n",
      "Train Epoch: 1006 [1800/2589 (70%)]\tLoss: 220.543991\n",
      "Train Epoch: 1006 [2100/2589 (81%)]\tLoss: 346.469818\n",
      "Train Epoch: 1006 [2400/2589 (93%)]\tLoss: 199.132919\n",
      "====> Epoch: 1006 Average train loss: 220.8800\n",
      "====> Epoch: 1006 Average test loss: 907.6752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1007 [0/2589 (0%)]\tLoss: 235.971588\n",
      "Train Epoch: 1007 [300/2589 (12%)]\tLoss: 164.660950\n",
      "Train Epoch: 1007 [600/2589 (23%)]\tLoss: 207.806122\n",
      "Train Epoch: 1007 [900/2589 (35%)]\tLoss: 182.091034\n",
      "Train Epoch: 1007 [1200/2589 (46%)]\tLoss: 156.232269\n",
      "Train Epoch: 1007 [1500/2589 (58%)]\tLoss: 194.139023\n",
      "Train Epoch: 1007 [1800/2589 (70%)]\tLoss: 157.771332\n",
      "Train Epoch: 1007 [2100/2589 (81%)]\tLoss: 180.936676\n",
      "Train Epoch: 1007 [2400/2589 (93%)]\tLoss: 308.293579\n",
      "====> Epoch: 1007 Average train loss: 218.6069\n",
      "====> Epoch: 1007 Average test loss: 921.0909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1008 [0/2589 (0%)]\tLoss: 345.533813\n",
      "Train Epoch: 1008 [300/2589 (12%)]\tLoss: 237.171402\n",
      "Train Epoch: 1008 [600/2589 (23%)]\tLoss: 164.904968\n",
      "Train Epoch: 1008 [900/2589 (35%)]\tLoss: 186.613174\n",
      "Train Epoch: 1008 [1200/2589 (46%)]\tLoss: 236.084717\n",
      "Train Epoch: 1008 [1500/2589 (58%)]\tLoss: 238.711868\n",
      "Train Epoch: 1008 [1800/2589 (70%)]\tLoss: 225.150314\n",
      "Train Epoch: 1008 [2100/2589 (81%)]\tLoss: 186.916916\n",
      "Train Epoch: 1008 [2400/2589 (93%)]\tLoss: 175.008331\n",
      "====> Epoch: 1008 Average train loss: 223.9025\n",
      "====> Epoch: 1008 Average test loss: 912.2410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1009 [0/2589 (0%)]\tLoss: 163.212708\n",
      "Train Epoch: 1009 [300/2589 (12%)]\tLoss: 181.354721\n",
      "Train Epoch: 1009 [600/2589 (23%)]\tLoss: 340.825836\n",
      "Train Epoch: 1009 [900/2589 (35%)]\tLoss: 174.398163\n",
      "Train Epoch: 1009 [1200/2589 (46%)]\tLoss: 215.569687\n",
      "Train Epoch: 1009 [1500/2589 (58%)]\tLoss: 355.740082\n",
      "Train Epoch: 1009 [1800/2589 (70%)]\tLoss: 251.710098\n",
      "Train Epoch: 1009 [2100/2589 (81%)]\tLoss: 273.559265\n",
      "Train Epoch: 1009 [2400/2589 (93%)]\tLoss: 145.371490\n",
      "====> Epoch: 1009 Average train loss: 224.3203\n",
      "====> Epoch: 1009 Average test loss: 903.1479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1010 [0/2589 (0%)]\tLoss: 189.563828\n",
      "Train Epoch: 1010 [300/2589 (12%)]\tLoss: 173.373322\n",
      "Train Epoch: 1010 [600/2589 (23%)]\tLoss: 165.607651\n",
      "Train Epoch: 1010 [900/2589 (35%)]\tLoss: 158.723541\n",
      "Train Epoch: 1010 [1200/2589 (46%)]\tLoss: 164.243927\n",
      "Train Epoch: 1010 [1500/2589 (58%)]\tLoss: 167.881836\n",
      "Train Epoch: 1010 [1800/2589 (70%)]\tLoss: 179.010605\n",
      "Train Epoch: 1010 [2100/2589 (81%)]\tLoss: 158.785751\n",
      "Train Epoch: 1010 [2400/2589 (93%)]\tLoss: 173.401657\n",
      "====> Epoch: 1010 Average train loss: 217.3259\n",
      "====> Epoch: 1010 Average test loss: 898.4249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1011 [0/2589 (0%)]\tLoss: 208.574921\n",
      "Train Epoch: 1011 [300/2589 (12%)]\tLoss: 223.814362\n",
      "Train Epoch: 1011 [600/2589 (23%)]\tLoss: 175.232224\n",
      "Train Epoch: 1011 [900/2589 (35%)]\tLoss: 198.229752\n",
      "Train Epoch: 1011 [1200/2589 (46%)]\tLoss: 254.987610\n",
      "Train Epoch: 1011 [1500/2589 (58%)]\tLoss: 245.679993\n",
      "Train Epoch: 1011 [1800/2589 (70%)]\tLoss: 175.980743\n",
      "Train Epoch: 1011 [2100/2589 (81%)]\tLoss: 221.136520\n",
      "Train Epoch: 1011 [2400/2589 (93%)]\tLoss: 186.799957\n",
      "====> Epoch: 1011 Average train loss: 215.4220\n",
      "====> Epoch: 1011 Average test loss: 911.6842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1012 [0/2589 (0%)]\tLoss: 224.871094\n",
      "Train Epoch: 1012 [300/2589 (12%)]\tLoss: 153.165619\n",
      "Train Epoch: 1012 [600/2589 (23%)]\tLoss: 184.216385\n",
      "Train Epoch: 1012 [900/2589 (35%)]\tLoss: 230.464066\n",
      "Train Epoch: 1012 [1200/2589 (46%)]\tLoss: 189.113525\n",
      "Train Epoch: 1012 [1500/2589 (58%)]\tLoss: 236.202957\n",
      "Train Epoch: 1012 [1800/2589 (70%)]\tLoss: 239.935135\n",
      "Train Epoch: 1012 [2100/2589 (81%)]\tLoss: 165.153580\n",
      "Train Epoch: 1012 [2400/2589 (93%)]\tLoss: 167.201584\n",
      "====> Epoch: 1012 Average train loss: 213.6366\n",
      "====> Epoch: 1012 Average test loss: 914.6043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1013 [0/2589 (0%)]\tLoss: 168.213638\n",
      "Train Epoch: 1013 [300/2589 (12%)]\tLoss: 126.973183\n",
      "Train Epoch: 1013 [600/2589 (23%)]\tLoss: 180.057877\n",
      "Train Epoch: 1013 [900/2589 (35%)]\tLoss: 229.330185\n",
      "Train Epoch: 1013 [1200/2589 (46%)]\tLoss: 223.815628\n",
      "Train Epoch: 1013 [1500/2589 (58%)]\tLoss: 233.229141\n",
      "Train Epoch: 1013 [1800/2589 (70%)]\tLoss: 210.789856\n",
      "Train Epoch: 1013 [2100/2589 (81%)]\tLoss: 261.071411\n",
      "Train Epoch: 1013 [2400/2589 (93%)]\tLoss: 262.549927\n",
      "====> Epoch: 1013 Average train loss: 228.3717\n",
      "====> Epoch: 1013 Average test loss: 921.2060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1014 [0/2589 (0%)]\tLoss: 291.403870\n",
      "Train Epoch: 1014 [300/2589 (12%)]\tLoss: 198.353363\n",
      "Train Epoch: 1014 [600/2589 (23%)]\tLoss: 154.871719\n",
      "Train Epoch: 1014 [900/2589 (35%)]\tLoss: 159.485535\n",
      "Train Epoch: 1014 [1200/2589 (46%)]\tLoss: 262.431976\n",
      "Train Epoch: 1014 [1500/2589 (58%)]\tLoss: 294.847076\n",
      "Train Epoch: 1014 [1800/2589 (70%)]\tLoss: 144.709625\n",
      "Train Epoch: 1014 [2100/2589 (81%)]\tLoss: 204.421341\n",
      "Train Epoch: 1014 [2400/2589 (93%)]\tLoss: 283.775269\n",
      "====> Epoch: 1014 Average train loss: 204.0321\n",
      "====> Epoch: 1014 Average test loss: 914.5446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1015 [0/2589 (0%)]\tLoss: 186.202606\n",
      "Train Epoch: 1015 [300/2589 (12%)]\tLoss: 311.030609\n",
      "Train Epoch: 1015 [600/2589 (23%)]\tLoss: 161.047913\n",
      "Train Epoch: 1015 [900/2589 (35%)]\tLoss: 136.906021\n",
      "Train Epoch: 1015 [1200/2589 (46%)]\tLoss: 215.895370\n",
      "Train Epoch: 1015 [1500/2589 (58%)]\tLoss: 205.678253\n",
      "Train Epoch: 1015 [1800/2589 (70%)]\tLoss: 159.936066\n",
      "Train Epoch: 1015 [2100/2589 (81%)]\tLoss: 239.338531\n",
      "Train Epoch: 1015 [2400/2589 (93%)]\tLoss: 362.108185\n",
      "====> Epoch: 1015 Average train loss: 221.9470\n",
      "====> Epoch: 1015 Average test loss: 900.6713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1016 [0/2589 (0%)]\tLoss: 200.996048\n",
      "Train Epoch: 1016 [300/2589 (12%)]\tLoss: 174.600647\n",
      "Train Epoch: 1016 [600/2589 (23%)]\tLoss: 354.980316\n",
      "Train Epoch: 1016 [900/2589 (35%)]\tLoss: 181.440933\n",
      "Train Epoch: 1016 [1200/2589 (46%)]\tLoss: 266.621460\n",
      "Train Epoch: 1016 [1500/2589 (58%)]\tLoss: 218.838821\n",
      "Train Epoch: 1016 [1800/2589 (70%)]\tLoss: 255.274734\n",
      "Train Epoch: 1016 [2100/2589 (81%)]\tLoss: 201.377777\n",
      "Train Epoch: 1016 [2400/2589 (93%)]\tLoss: 185.011658\n",
      "====> Epoch: 1016 Average train loss: 229.1729\n",
      "====> Epoch: 1016 Average test loss: 894.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1017 [0/2589 (0%)]\tLoss: 290.987366\n",
      "Train Epoch: 1017 [300/2589 (12%)]\tLoss: 267.707855\n",
      "Train Epoch: 1017 [600/2589 (23%)]\tLoss: 427.530457\n",
      "Train Epoch: 1017 [900/2589 (35%)]\tLoss: 191.870346\n",
      "Train Epoch: 1017 [1200/2589 (46%)]\tLoss: 252.044601\n",
      "Train Epoch: 1017 [1500/2589 (58%)]\tLoss: 217.998749\n",
      "Train Epoch: 1017 [1800/2589 (70%)]\tLoss: 277.184418\n",
      "Train Epoch: 1017 [2100/2589 (81%)]\tLoss: 239.537003\n",
      "Train Epoch: 1017 [2400/2589 (93%)]\tLoss: 277.267578\n",
      "====> Epoch: 1017 Average train loss: 227.6412\n",
      "====> Epoch: 1017 Average test loss: 915.1722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1018 [0/2589 (0%)]\tLoss: 154.488983\n",
      "Train Epoch: 1018 [300/2589 (12%)]\tLoss: 341.548218\n",
      "Train Epoch: 1018 [600/2589 (23%)]\tLoss: 169.034180\n",
      "Train Epoch: 1018 [900/2589 (35%)]\tLoss: 219.078339\n",
      "Train Epoch: 1018 [1200/2589 (46%)]\tLoss: 215.763092\n",
      "Train Epoch: 1018 [1500/2589 (58%)]\tLoss: 256.337616\n",
      "Train Epoch: 1018 [1800/2589 (70%)]\tLoss: 150.003616\n",
      "Train Epoch: 1018 [2100/2589 (81%)]\tLoss: 163.439789\n",
      "Train Epoch: 1018 [2400/2589 (93%)]\tLoss: 240.350479\n",
      "====> Epoch: 1018 Average train loss: 217.7207\n",
      "====> Epoch: 1018 Average test loss: 928.6439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1019 [0/2589 (0%)]\tLoss: 193.003967\n",
      "Train Epoch: 1019 [300/2589 (12%)]\tLoss: 167.067093\n",
      "Train Epoch: 1019 [600/2589 (23%)]\tLoss: 268.500885\n",
      "Train Epoch: 1019 [900/2589 (35%)]\tLoss: 232.651627\n",
      "Train Epoch: 1019 [1200/2589 (46%)]\tLoss: 190.263092\n",
      "Train Epoch: 1019 [1500/2589 (58%)]\tLoss: 336.446564\n",
      "Train Epoch: 1019 [1800/2589 (70%)]\tLoss: 165.714813\n",
      "Train Epoch: 1019 [2100/2589 (81%)]\tLoss: 200.403702\n",
      "Train Epoch: 1019 [2400/2589 (93%)]\tLoss: 288.604034\n",
      "====> Epoch: 1019 Average train loss: 221.4705\n",
      "====> Epoch: 1019 Average test loss: 919.9284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1020 [0/2589 (0%)]\tLoss: 216.523178\n",
      "Train Epoch: 1020 [300/2589 (12%)]\tLoss: 253.998398\n",
      "Train Epoch: 1020 [600/2589 (23%)]\tLoss: 195.240570\n",
      "Train Epoch: 1020 [900/2589 (35%)]\tLoss: 185.569885\n",
      "Train Epoch: 1020 [1200/2589 (46%)]\tLoss: 216.568954\n",
      "Train Epoch: 1020 [1500/2589 (58%)]\tLoss: 222.167831\n",
      "Train Epoch: 1020 [1800/2589 (70%)]\tLoss: 217.134689\n",
      "Train Epoch: 1020 [2100/2589 (81%)]\tLoss: 180.779953\n",
      "Train Epoch: 1020 [2400/2589 (93%)]\tLoss: 231.614655\n",
      "====> Epoch: 1020 Average train loss: 220.5838\n",
      "====> Epoch: 1020 Average test loss: 914.0754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1021 [0/2589 (0%)]\tLoss: 336.670227\n",
      "Train Epoch: 1021 [300/2589 (12%)]\tLoss: 170.987640\n",
      "Train Epoch: 1021 [600/2589 (23%)]\tLoss: 169.235214\n",
      "Train Epoch: 1021 [900/2589 (35%)]\tLoss: 186.131882\n",
      "Train Epoch: 1021 [1200/2589 (46%)]\tLoss: 169.583099\n",
      "Train Epoch: 1021 [1500/2589 (58%)]\tLoss: 210.663010\n",
      "Train Epoch: 1021 [1800/2589 (70%)]\tLoss: 183.520752\n",
      "Train Epoch: 1021 [2100/2589 (81%)]\tLoss: 163.329910\n",
      "Train Epoch: 1021 [2400/2589 (93%)]\tLoss: 250.660400\n",
      "====> Epoch: 1021 Average train loss: 203.5586\n",
      "====> Epoch: 1021 Average test loss: 932.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1022 [0/2589 (0%)]\tLoss: 177.801178\n",
      "Train Epoch: 1022 [300/2589 (12%)]\tLoss: 234.210312\n",
      "Train Epoch: 1022 [600/2589 (23%)]\tLoss: 128.821487\n",
      "Train Epoch: 1022 [900/2589 (35%)]\tLoss: 155.315231\n",
      "Train Epoch: 1022 [1200/2589 (46%)]\tLoss: 185.971222\n",
      "Train Epoch: 1022 [1500/2589 (58%)]\tLoss: 188.333954\n",
      "Train Epoch: 1022 [1800/2589 (70%)]\tLoss: 176.235855\n",
      "Train Epoch: 1022 [2100/2589 (81%)]\tLoss: 158.441177\n",
      "Train Epoch: 1022 [2400/2589 (93%)]\tLoss: 202.709030\n",
      "====> Epoch: 1022 Average train loss: 216.6941\n",
      "====> Epoch: 1022 Average test loss: 922.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1023 [0/2589 (0%)]\tLoss: 289.970215\n",
      "Train Epoch: 1023 [300/2589 (12%)]\tLoss: 219.636139\n",
      "Train Epoch: 1023 [600/2589 (23%)]\tLoss: 147.068878\n",
      "Train Epoch: 1023 [900/2589 (35%)]\tLoss: 298.151947\n",
      "Train Epoch: 1023 [1200/2589 (46%)]\tLoss: 323.241425\n",
      "Train Epoch: 1023 [1500/2589 (58%)]\tLoss: 235.896713\n",
      "Train Epoch: 1023 [1800/2589 (70%)]\tLoss: 209.954147\n",
      "Train Epoch: 1023 [2100/2589 (81%)]\tLoss: 249.740051\n",
      "Train Epoch: 1023 [2400/2589 (93%)]\tLoss: 159.416367\n",
      "====> Epoch: 1023 Average train loss: 225.6445\n",
      "====> Epoch: 1023 Average test loss: 925.8443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1024 [0/2589 (0%)]\tLoss: 556.587646\n",
      "Train Epoch: 1024 [300/2589 (12%)]\tLoss: 150.416855\n",
      "Train Epoch: 1024 [600/2589 (23%)]\tLoss: 203.285904\n",
      "Train Epoch: 1024 [900/2589 (35%)]\tLoss: 174.418350\n",
      "Train Epoch: 1024 [1200/2589 (46%)]\tLoss: 204.900436\n",
      "Train Epoch: 1024 [1500/2589 (58%)]\tLoss: 254.466980\n",
      "Train Epoch: 1024 [1800/2589 (70%)]\tLoss: 150.022293\n",
      "Train Epoch: 1024 [2100/2589 (81%)]\tLoss: 219.381058\n",
      "Train Epoch: 1024 [2400/2589 (93%)]\tLoss: 159.923660\n",
      "====> Epoch: 1024 Average train loss: 229.0290\n",
      "====> Epoch: 1024 Average test loss: 905.7930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1025 [0/2589 (0%)]\tLoss: 241.335770\n",
      "Train Epoch: 1025 [300/2589 (12%)]\tLoss: 261.658173\n",
      "Train Epoch: 1025 [600/2589 (23%)]\tLoss: 245.341156\n",
      "Train Epoch: 1025 [900/2589 (35%)]\tLoss: 253.904144\n",
      "Train Epoch: 1025 [1200/2589 (46%)]\tLoss: 367.482391\n",
      "Train Epoch: 1025 [1500/2589 (58%)]\tLoss: 162.797226\n",
      "Train Epoch: 1025 [1800/2589 (70%)]\tLoss: 181.684525\n",
      "Train Epoch: 1025 [2100/2589 (81%)]\tLoss: 188.402939\n",
      "Train Epoch: 1025 [2400/2589 (93%)]\tLoss: 297.513702\n",
      "====> Epoch: 1025 Average train loss: 224.5988\n",
      "====> Epoch: 1025 Average test loss: 950.0643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1026 [0/2589 (0%)]\tLoss: 317.697174\n",
      "Train Epoch: 1026 [300/2589 (12%)]\tLoss: 172.072586\n",
      "Train Epoch: 1026 [600/2589 (23%)]\tLoss: 222.055145\n",
      "Train Epoch: 1026 [900/2589 (35%)]\tLoss: 224.202072\n",
      "Train Epoch: 1026 [1200/2589 (46%)]\tLoss: 197.349426\n",
      "Train Epoch: 1026 [1500/2589 (58%)]\tLoss: 206.673035\n",
      "Train Epoch: 1026 [1800/2589 (70%)]\tLoss: 158.410217\n",
      "Train Epoch: 1026 [2100/2589 (81%)]\tLoss: 265.706146\n",
      "Train Epoch: 1026 [2400/2589 (93%)]\tLoss: 167.887344\n",
      "====> Epoch: 1026 Average train loss: 215.4314\n",
      "====> Epoch: 1026 Average test loss: 910.2963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1027 [0/2589 (0%)]\tLoss: 267.455353\n",
      "Train Epoch: 1027 [300/2589 (12%)]\tLoss: 157.409378\n",
      "Train Epoch: 1027 [600/2589 (23%)]\tLoss: 167.496017\n",
      "Train Epoch: 1027 [900/2589 (35%)]\tLoss: 367.217499\n",
      "Train Epoch: 1027 [1200/2589 (46%)]\tLoss: 274.830292\n",
      "Train Epoch: 1027 [1500/2589 (58%)]\tLoss: 259.191467\n",
      "Train Epoch: 1027 [1800/2589 (70%)]\tLoss: 214.985855\n",
      "Train Epoch: 1027 [2100/2589 (81%)]\tLoss: 258.100006\n",
      "Train Epoch: 1027 [2400/2589 (93%)]\tLoss: 220.062790\n",
      "====> Epoch: 1027 Average train loss: 231.9991\n",
      "====> Epoch: 1027 Average test loss: 924.6318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1028 [0/2589 (0%)]\tLoss: 264.693634\n",
      "Train Epoch: 1028 [300/2589 (12%)]\tLoss: 207.926773\n",
      "Train Epoch: 1028 [600/2589 (23%)]\tLoss: 172.894150\n",
      "Train Epoch: 1028 [900/2589 (35%)]\tLoss: 159.151550\n",
      "Train Epoch: 1028 [1200/2589 (46%)]\tLoss: 237.101471\n",
      "Train Epoch: 1028 [1500/2589 (58%)]\tLoss: 170.424515\n",
      "Train Epoch: 1028 [1800/2589 (70%)]\tLoss: 139.806229\n",
      "Train Epoch: 1028 [2100/2589 (81%)]\tLoss: 324.182465\n",
      "Train Epoch: 1028 [2400/2589 (93%)]\tLoss: 187.410843\n",
      "====> Epoch: 1028 Average train loss: 223.7586\n",
      "====> Epoch: 1028 Average test loss: 922.0298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1029 [0/2589 (0%)]\tLoss: 214.174072\n",
      "Train Epoch: 1029 [300/2589 (12%)]\tLoss: 171.875916\n",
      "Train Epoch: 1029 [600/2589 (23%)]\tLoss: 295.134949\n",
      "Train Epoch: 1029 [900/2589 (35%)]\tLoss: 233.057770\n",
      "Train Epoch: 1029 [1200/2589 (46%)]\tLoss: 253.716965\n",
      "Train Epoch: 1029 [1500/2589 (58%)]\tLoss: 290.301147\n",
      "Train Epoch: 1029 [1800/2589 (70%)]\tLoss: 224.584686\n",
      "Train Epoch: 1029 [2100/2589 (81%)]\tLoss: 277.705109\n",
      "Train Epoch: 1029 [2400/2589 (93%)]\tLoss: 203.805878\n",
      "====> Epoch: 1029 Average train loss: 220.5288\n",
      "====> Epoch: 1029 Average test loss: 937.6298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1030 [0/2589 (0%)]\tLoss: 152.857819\n",
      "Train Epoch: 1030 [300/2589 (12%)]\tLoss: 177.956833\n",
      "Train Epoch: 1030 [600/2589 (23%)]\tLoss: 315.117523\n",
      "Train Epoch: 1030 [900/2589 (35%)]\tLoss: 162.345322\n",
      "Train Epoch: 1030 [1200/2589 (46%)]\tLoss: 295.089935\n",
      "Train Epoch: 1030 [1500/2589 (58%)]\tLoss: 219.567200\n",
      "Train Epoch: 1030 [1800/2589 (70%)]\tLoss: 166.402069\n",
      "Train Epoch: 1030 [2100/2589 (81%)]\tLoss: 199.778427\n",
      "Train Epoch: 1030 [2400/2589 (93%)]\tLoss: 162.048859\n",
      "====> Epoch: 1030 Average train loss: 225.6573\n",
      "====> Epoch: 1030 Average test loss: 914.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1031 [0/2589 (0%)]\tLoss: 230.324127\n",
      "Train Epoch: 1031 [300/2589 (12%)]\tLoss: 139.142319\n",
      "Train Epoch: 1031 [600/2589 (23%)]\tLoss: 177.075424\n",
      "Train Epoch: 1031 [900/2589 (35%)]\tLoss: 283.639343\n",
      "Train Epoch: 1031 [1200/2589 (46%)]\tLoss: 168.389999\n",
      "Train Epoch: 1031 [1500/2589 (58%)]\tLoss: 254.938980\n",
      "Train Epoch: 1031 [1800/2589 (70%)]\tLoss: 187.532211\n",
      "Train Epoch: 1031 [2100/2589 (81%)]\tLoss: 185.148834\n",
      "Train Epoch: 1031 [2400/2589 (93%)]\tLoss: 166.290771\n",
      "====> Epoch: 1031 Average train loss: 221.2879\n",
      "====> Epoch: 1031 Average test loss: 922.6869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1032 [0/2589 (0%)]\tLoss: 236.589249\n",
      "Train Epoch: 1032 [300/2589 (12%)]\tLoss: 157.013138\n",
      "Train Epoch: 1032 [600/2589 (23%)]\tLoss: 219.681351\n",
      "Train Epoch: 1032 [900/2589 (35%)]\tLoss: 210.023972\n",
      "Train Epoch: 1032 [1200/2589 (46%)]\tLoss: 166.198441\n",
      "Train Epoch: 1032 [1500/2589 (58%)]\tLoss: 193.863449\n",
      "Train Epoch: 1032 [1800/2589 (70%)]\tLoss: 238.729019\n",
      "Train Epoch: 1032 [2100/2589 (81%)]\tLoss: 243.906082\n",
      "Train Epoch: 1032 [2400/2589 (93%)]\tLoss: 278.646179\n",
      "====> Epoch: 1032 Average train loss: 224.6276\n",
      "====> Epoch: 1032 Average test loss: 892.6747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1033 [0/2589 (0%)]\tLoss: 199.098694\n",
      "Train Epoch: 1033 [300/2589 (12%)]\tLoss: 259.811829\n",
      "Train Epoch: 1033 [600/2589 (23%)]\tLoss: 182.375015\n",
      "Train Epoch: 1033 [900/2589 (35%)]\tLoss: 240.851486\n",
      "Train Epoch: 1033 [1200/2589 (46%)]\tLoss: 453.408203\n",
      "Train Epoch: 1033 [1500/2589 (58%)]\tLoss: 262.097504\n",
      "Train Epoch: 1033 [1800/2589 (70%)]\tLoss: 193.528534\n",
      "Train Epoch: 1033 [2100/2589 (81%)]\tLoss: 164.341537\n",
      "Train Epoch: 1033 [2400/2589 (93%)]\tLoss: 126.387779\n",
      "====> Epoch: 1033 Average train loss: 222.7188\n",
      "====> Epoch: 1033 Average test loss: 918.3889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1034 [0/2589 (0%)]\tLoss: 328.872833\n",
      "Train Epoch: 1034 [300/2589 (12%)]\tLoss: 155.258362\n",
      "Train Epoch: 1034 [600/2589 (23%)]\tLoss: 216.334671\n",
      "Train Epoch: 1034 [900/2589 (35%)]\tLoss: 335.451996\n",
      "Train Epoch: 1034 [1200/2589 (46%)]\tLoss: 239.215607\n",
      "Train Epoch: 1034 [1500/2589 (58%)]\tLoss: 187.529205\n",
      "Train Epoch: 1034 [1800/2589 (70%)]\tLoss: 226.889786\n",
      "Train Epoch: 1034 [2100/2589 (81%)]\tLoss: 217.125565\n",
      "Train Epoch: 1034 [2400/2589 (93%)]\tLoss: 230.158051\n",
      "====> Epoch: 1034 Average train loss: 224.1833\n",
      "====> Epoch: 1034 Average test loss: 923.3188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1035 [0/2589 (0%)]\tLoss: 248.356842\n",
      "Train Epoch: 1035 [300/2589 (12%)]\tLoss: 210.790100\n",
      "Train Epoch: 1035 [600/2589 (23%)]\tLoss: 268.365387\n",
      "Train Epoch: 1035 [900/2589 (35%)]\tLoss: 141.306641\n",
      "Train Epoch: 1035 [1200/2589 (46%)]\tLoss: 184.956558\n",
      "Train Epoch: 1035 [1500/2589 (58%)]\tLoss: 216.606934\n",
      "Train Epoch: 1035 [1800/2589 (70%)]\tLoss: 182.532532\n",
      "Train Epoch: 1035 [2100/2589 (81%)]\tLoss: 204.497269\n",
      "Train Epoch: 1035 [2400/2589 (93%)]\tLoss: 154.389664\n",
      "====> Epoch: 1035 Average train loss: 218.6434\n",
      "====> Epoch: 1035 Average test loss: 923.8241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1036 [0/2589 (0%)]\tLoss: 273.715881\n",
      "Train Epoch: 1036 [300/2589 (12%)]\tLoss: 238.205429\n",
      "Train Epoch: 1036 [600/2589 (23%)]\tLoss: 235.396545\n",
      "Train Epoch: 1036 [900/2589 (35%)]\tLoss: 279.017761\n",
      "Train Epoch: 1036 [1200/2589 (46%)]\tLoss: 214.949020\n",
      "Train Epoch: 1036 [1500/2589 (58%)]\tLoss: 230.394760\n",
      "Train Epoch: 1036 [1800/2589 (70%)]\tLoss: 229.272766\n",
      "Train Epoch: 1036 [2100/2589 (81%)]\tLoss: 167.000046\n",
      "Train Epoch: 1036 [2400/2589 (93%)]\tLoss: 222.460022\n",
      "====> Epoch: 1036 Average train loss: 225.1093\n",
      "====> Epoch: 1036 Average test loss: 932.5580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1037 [0/2589 (0%)]\tLoss: 232.312881\n",
      "Train Epoch: 1037 [300/2589 (12%)]\tLoss: 217.962433\n",
      "Train Epoch: 1037 [600/2589 (23%)]\tLoss: 241.094574\n",
      "Train Epoch: 1037 [900/2589 (35%)]\tLoss: 183.151123\n",
      "Train Epoch: 1037 [1200/2589 (46%)]\tLoss: 189.435837\n",
      "Train Epoch: 1037 [1500/2589 (58%)]\tLoss: 204.160385\n",
      "Train Epoch: 1037 [1800/2589 (70%)]\tLoss: 239.622559\n",
      "Train Epoch: 1037 [2100/2589 (81%)]\tLoss: 131.591949\n",
      "Train Epoch: 1037 [2400/2589 (93%)]\tLoss: 140.969879\n",
      "====> Epoch: 1037 Average train loss: 222.3569\n",
      "====> Epoch: 1037 Average test loss: 923.7487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1038 [0/2589 (0%)]\tLoss: 197.173141\n",
      "Train Epoch: 1038 [300/2589 (12%)]\tLoss: 163.703018\n",
      "Train Epoch: 1038 [600/2589 (23%)]\tLoss: 235.540817\n",
      "Train Epoch: 1038 [900/2589 (35%)]\tLoss: 207.084122\n",
      "Train Epoch: 1038 [1200/2589 (46%)]\tLoss: 254.647049\n",
      "Train Epoch: 1038 [1500/2589 (58%)]\tLoss: 177.861557\n",
      "Train Epoch: 1038 [1800/2589 (70%)]\tLoss: 265.870728\n",
      "Train Epoch: 1038 [2100/2589 (81%)]\tLoss: 194.001755\n",
      "Train Epoch: 1038 [2400/2589 (93%)]\tLoss: 165.307816\n",
      "====> Epoch: 1038 Average train loss: 218.1221\n",
      "====> Epoch: 1038 Average test loss: 913.4822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1039 [0/2589 (0%)]\tLoss: 396.411133\n",
      "Train Epoch: 1039 [300/2589 (12%)]\tLoss: 233.192001\n",
      "Train Epoch: 1039 [600/2589 (23%)]\tLoss: 269.931213\n",
      "Train Epoch: 1039 [900/2589 (35%)]\tLoss: 268.177277\n",
      "Train Epoch: 1039 [1200/2589 (46%)]\tLoss: 186.417511\n",
      "Train Epoch: 1039 [1500/2589 (58%)]\tLoss: 169.535095\n",
      "Train Epoch: 1039 [1800/2589 (70%)]\tLoss: 248.465271\n",
      "Train Epoch: 1039 [2100/2589 (81%)]\tLoss: 206.531998\n",
      "Train Epoch: 1039 [2400/2589 (93%)]\tLoss: 283.604309\n",
      "====> Epoch: 1039 Average train loss: 220.9098\n",
      "====> Epoch: 1039 Average test loss: 913.4336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1040 [0/2589 (0%)]\tLoss: 248.352219\n",
      "Train Epoch: 1040 [300/2589 (12%)]\tLoss: 212.789291\n",
      "Train Epoch: 1040 [600/2589 (23%)]\tLoss: 173.037109\n",
      "Train Epoch: 1040 [900/2589 (35%)]\tLoss: 185.232590\n",
      "Train Epoch: 1040 [1200/2589 (46%)]\tLoss: 191.771271\n",
      "Train Epoch: 1040 [1500/2589 (58%)]\tLoss: 189.455856\n",
      "Train Epoch: 1040 [1800/2589 (70%)]\tLoss: 191.092621\n",
      "Train Epoch: 1040 [2100/2589 (81%)]\tLoss: 183.810318\n",
      "Train Epoch: 1040 [2400/2589 (93%)]\tLoss: 188.162933\n",
      "====> Epoch: 1040 Average train loss: 210.4292\n",
      "====> Epoch: 1040 Average test loss: 916.2811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1041 [0/2589 (0%)]\tLoss: 181.526413\n",
      "Train Epoch: 1041 [300/2589 (12%)]\tLoss: 244.603973\n",
      "Train Epoch: 1041 [600/2589 (23%)]\tLoss: 165.771454\n",
      "Train Epoch: 1041 [900/2589 (35%)]\tLoss: 192.483658\n",
      "Train Epoch: 1041 [1200/2589 (46%)]\tLoss: 139.273422\n",
      "Train Epoch: 1041 [1500/2589 (58%)]\tLoss: 190.898193\n",
      "Train Epoch: 1041 [1800/2589 (70%)]\tLoss: 220.319748\n",
      "Train Epoch: 1041 [2100/2589 (81%)]\tLoss: 258.382233\n",
      "Train Epoch: 1041 [2400/2589 (93%)]\tLoss: 298.715179\n",
      "====> Epoch: 1041 Average train loss: 220.3534\n",
      "====> Epoch: 1041 Average test loss: 910.1390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1042 [0/2589 (0%)]\tLoss: 228.017120\n",
      "Train Epoch: 1042 [300/2589 (12%)]\tLoss: 192.266937\n",
      "Train Epoch: 1042 [600/2589 (23%)]\tLoss: 229.708649\n",
      "Train Epoch: 1042 [900/2589 (35%)]\tLoss: 245.358658\n",
      "Train Epoch: 1042 [1200/2589 (46%)]\tLoss: 173.890106\n",
      "Train Epoch: 1042 [1500/2589 (58%)]\tLoss: 202.151581\n",
      "Train Epoch: 1042 [1800/2589 (70%)]\tLoss: 202.030304\n",
      "Train Epoch: 1042 [2100/2589 (81%)]\tLoss: 214.526306\n",
      "Train Epoch: 1042 [2400/2589 (93%)]\tLoss: 243.257324\n",
      "====> Epoch: 1042 Average train loss: 231.4007\n",
      "====> Epoch: 1042 Average test loss: 918.0792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1043 [0/2589 (0%)]\tLoss: 201.224579\n",
      "Train Epoch: 1043 [300/2589 (12%)]\tLoss: 170.067276\n",
      "Train Epoch: 1043 [600/2589 (23%)]\tLoss: 154.531723\n",
      "Train Epoch: 1043 [900/2589 (35%)]\tLoss: 173.576447\n",
      "Train Epoch: 1043 [1200/2589 (46%)]\tLoss: 138.925018\n",
      "Train Epoch: 1043 [1500/2589 (58%)]\tLoss: 164.992249\n",
      "Train Epoch: 1043 [1800/2589 (70%)]\tLoss: 291.395386\n",
      "Train Epoch: 1043 [2100/2589 (81%)]\tLoss: 211.944244\n",
      "Train Epoch: 1043 [2400/2589 (93%)]\tLoss: 228.935654\n",
      "====> Epoch: 1043 Average train loss: 217.2157\n",
      "====> Epoch: 1043 Average test loss: 911.2344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1044 [0/2589 (0%)]\tLoss: 170.521347\n",
      "Train Epoch: 1044 [300/2589 (12%)]\tLoss: 330.646210\n",
      "Train Epoch: 1044 [600/2589 (23%)]\tLoss: 199.282379\n",
      "Train Epoch: 1044 [900/2589 (35%)]\tLoss: 583.670227\n",
      "Train Epoch: 1044 [1200/2589 (46%)]\tLoss: 162.215057\n",
      "Train Epoch: 1044 [1500/2589 (58%)]\tLoss: 271.985229\n",
      "Train Epoch: 1044 [1800/2589 (70%)]\tLoss: 229.380661\n",
      "Train Epoch: 1044 [2100/2589 (81%)]\tLoss: 313.203186\n",
      "Train Epoch: 1044 [2400/2589 (93%)]\tLoss: 177.684418\n",
      "====> Epoch: 1044 Average train loss: 222.3188\n",
      "====> Epoch: 1044 Average test loss: 929.4669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1045 [0/2589 (0%)]\tLoss: 394.590912\n",
      "Train Epoch: 1045 [300/2589 (12%)]\tLoss: 149.808792\n",
      "Train Epoch: 1045 [600/2589 (23%)]\tLoss: 197.875198\n",
      "Train Epoch: 1045 [900/2589 (35%)]\tLoss: 269.152802\n",
      "Train Epoch: 1045 [1200/2589 (46%)]\tLoss: 242.502258\n",
      "Train Epoch: 1045 [1500/2589 (58%)]\tLoss: 240.186356\n",
      "Train Epoch: 1045 [1800/2589 (70%)]\tLoss: 282.137634\n",
      "Train Epoch: 1045 [2100/2589 (81%)]\tLoss: 176.575836\n",
      "Train Epoch: 1045 [2400/2589 (93%)]\tLoss: 258.721436\n",
      "====> Epoch: 1045 Average train loss: 220.9844\n",
      "====> Epoch: 1045 Average test loss: 920.3027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1046 [0/2589 (0%)]\tLoss: 163.004089\n",
      "Train Epoch: 1046 [300/2589 (12%)]\tLoss: 195.660797\n",
      "Train Epoch: 1046 [600/2589 (23%)]\tLoss: 291.398376\n",
      "Train Epoch: 1046 [900/2589 (35%)]\tLoss: 271.935883\n",
      "Train Epoch: 1046 [1200/2589 (46%)]\tLoss: 205.409256\n",
      "Train Epoch: 1046 [1500/2589 (58%)]\tLoss: 157.108597\n",
      "Train Epoch: 1046 [1800/2589 (70%)]\tLoss: 191.796616\n",
      "Train Epoch: 1046 [2100/2589 (81%)]\tLoss: 169.474335\n",
      "Train Epoch: 1046 [2400/2589 (93%)]\tLoss: 186.544296\n",
      "====> Epoch: 1046 Average train loss: 225.4540\n",
      "====> Epoch: 1046 Average test loss: 911.2174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1047 [0/2589 (0%)]\tLoss: 180.246628\n",
      "Train Epoch: 1047 [300/2589 (12%)]\tLoss: 157.443832\n",
      "Train Epoch: 1047 [600/2589 (23%)]\tLoss: 155.859756\n",
      "Train Epoch: 1047 [900/2589 (35%)]\tLoss: 201.536285\n",
      "Train Epoch: 1047 [1200/2589 (46%)]\tLoss: 192.876495\n",
      "Train Epoch: 1047 [1500/2589 (58%)]\tLoss: 192.537292\n",
      "Train Epoch: 1047 [1800/2589 (70%)]\tLoss: 217.034409\n",
      "Train Epoch: 1047 [2100/2589 (81%)]\tLoss: 183.755753\n",
      "Train Epoch: 1047 [2400/2589 (93%)]\tLoss: 239.151718\n",
      "====> Epoch: 1047 Average train loss: 221.2701\n",
      "====> Epoch: 1047 Average test loss: 900.2430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1048 [0/2589 (0%)]\tLoss: 156.118317\n",
      "Train Epoch: 1048 [300/2589 (12%)]\tLoss: 261.849030\n",
      "Train Epoch: 1048 [600/2589 (23%)]\tLoss: 189.345535\n",
      "Train Epoch: 1048 [900/2589 (35%)]\tLoss: 191.343735\n",
      "Train Epoch: 1048 [1200/2589 (46%)]\tLoss: 205.809769\n",
      "Train Epoch: 1048 [1500/2589 (58%)]\tLoss: 378.488403\n",
      "Train Epoch: 1048 [1800/2589 (70%)]\tLoss: 320.373535\n",
      "Train Epoch: 1048 [2100/2589 (81%)]\tLoss: 213.300690\n",
      "Train Epoch: 1048 [2400/2589 (93%)]\tLoss: 182.126953\n",
      "====> Epoch: 1048 Average train loss: 221.2830\n",
      "====> Epoch: 1048 Average test loss: 933.7991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1049 [0/2589 (0%)]\tLoss: 405.805084\n",
      "Train Epoch: 1049 [300/2589 (12%)]\tLoss: 296.194244\n",
      "Train Epoch: 1049 [600/2589 (23%)]\tLoss: 179.342987\n",
      "Train Epoch: 1049 [900/2589 (35%)]\tLoss: 231.519485\n",
      "Train Epoch: 1049 [1200/2589 (46%)]\tLoss: 191.935623\n",
      "Train Epoch: 1049 [1500/2589 (58%)]\tLoss: 209.238632\n",
      "Train Epoch: 1049 [1800/2589 (70%)]\tLoss: 194.382812\n",
      "Train Epoch: 1049 [2100/2589 (81%)]\tLoss: 197.679550\n",
      "Train Epoch: 1049 [2400/2589 (93%)]\tLoss: 186.521790\n",
      "====> Epoch: 1049 Average train loss: 225.8615\n",
      "====> Epoch: 1049 Average test loss: 922.3506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1050 [0/2589 (0%)]\tLoss: 163.442200\n",
      "Train Epoch: 1050 [300/2589 (12%)]\tLoss: 153.331680\n",
      "Train Epoch: 1050 [600/2589 (23%)]\tLoss: 307.686920\n",
      "Train Epoch: 1050 [900/2589 (35%)]\tLoss: 235.887970\n",
      "Train Epoch: 1050 [1200/2589 (46%)]\tLoss: 206.510162\n",
      "Train Epoch: 1050 [1500/2589 (58%)]\tLoss: 213.653122\n",
      "Train Epoch: 1050 [1800/2589 (70%)]\tLoss: 242.290009\n",
      "Train Epoch: 1050 [2100/2589 (81%)]\tLoss: 220.299118\n",
      "Train Epoch: 1050 [2400/2589 (93%)]\tLoss: 166.597122\n",
      "====> Epoch: 1050 Average train loss: 215.5316\n",
      "====> Epoch: 1050 Average test loss: 920.8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1051 [0/2589 (0%)]\tLoss: 356.511139\n",
      "Train Epoch: 1051 [300/2589 (12%)]\tLoss: 179.600021\n",
      "Train Epoch: 1051 [600/2589 (23%)]\tLoss: 260.105896\n",
      "Train Epoch: 1051 [900/2589 (35%)]\tLoss: 344.221710\n",
      "Train Epoch: 1051 [1200/2589 (46%)]\tLoss: 139.934570\n",
      "Train Epoch: 1051 [1500/2589 (58%)]\tLoss: 249.999939\n",
      "Train Epoch: 1051 [1800/2589 (70%)]\tLoss: 196.210297\n",
      "Train Epoch: 1051 [2100/2589 (81%)]\tLoss: 268.196472\n",
      "Train Epoch: 1051 [2400/2589 (93%)]\tLoss: 186.015884\n",
      "====> Epoch: 1051 Average train loss: 215.5685\n",
      "====> Epoch: 1051 Average test loss: 912.6710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1052 [0/2589 (0%)]\tLoss: 170.627182\n",
      "Train Epoch: 1052 [300/2589 (12%)]\tLoss: 166.760147\n",
      "Train Epoch: 1052 [600/2589 (23%)]\tLoss: 174.468567\n",
      "Train Epoch: 1052 [900/2589 (35%)]\tLoss: 228.510666\n",
      "Train Epoch: 1052 [1200/2589 (46%)]\tLoss: 246.509308\n",
      "Train Epoch: 1052 [1500/2589 (58%)]\tLoss: 217.606125\n",
      "Train Epoch: 1052 [1800/2589 (70%)]\tLoss: 160.000214\n",
      "Train Epoch: 1052 [2100/2589 (81%)]\tLoss: 173.738724\n",
      "Train Epoch: 1052 [2400/2589 (93%)]\tLoss: 180.246552\n",
      "====> Epoch: 1052 Average train loss: 218.0487\n",
      "====> Epoch: 1052 Average test loss: 910.4587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1053 [0/2589 (0%)]\tLoss: 212.214111\n",
      "Train Epoch: 1053 [300/2589 (12%)]\tLoss: 264.307709\n",
      "Train Epoch: 1053 [600/2589 (23%)]\tLoss: 164.282608\n",
      "Train Epoch: 1053 [900/2589 (35%)]\tLoss: 166.424744\n",
      "Train Epoch: 1053 [1200/2589 (46%)]\tLoss: 244.612656\n",
      "Train Epoch: 1053 [1500/2589 (58%)]\tLoss: 267.287140\n",
      "Train Epoch: 1053 [1800/2589 (70%)]\tLoss: 303.824280\n",
      "Train Epoch: 1053 [2100/2589 (81%)]\tLoss: 159.377579\n",
      "Train Epoch: 1053 [2400/2589 (93%)]\tLoss: 156.769180\n",
      "====> Epoch: 1053 Average train loss: 214.0392\n",
      "====> Epoch: 1053 Average test loss: 910.2274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1054 [0/2589 (0%)]\tLoss: 260.798309\n",
      "Train Epoch: 1054 [300/2589 (12%)]\tLoss: 215.455994\n",
      "Train Epoch: 1054 [600/2589 (23%)]\tLoss: 120.530342\n",
      "Train Epoch: 1054 [900/2589 (35%)]\tLoss: 160.116760\n",
      "Train Epoch: 1054 [1200/2589 (46%)]\tLoss: 273.351013\n",
      "Train Epoch: 1054 [1500/2589 (58%)]\tLoss: 158.240997\n",
      "Train Epoch: 1054 [1800/2589 (70%)]\tLoss: 359.613068\n",
      "Train Epoch: 1054 [2100/2589 (81%)]\tLoss: 163.822800\n",
      "Train Epoch: 1054 [2400/2589 (93%)]\tLoss: 197.155975\n",
      "====> Epoch: 1054 Average train loss: 220.3637\n",
      "====> Epoch: 1054 Average test loss: 919.7488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1055 [0/2589 (0%)]\tLoss: 253.732880\n",
      "Train Epoch: 1055 [300/2589 (12%)]\tLoss: 214.867477\n",
      "Train Epoch: 1055 [600/2589 (23%)]\tLoss: 220.977585\n",
      "Train Epoch: 1055 [900/2589 (35%)]\tLoss: 262.178925\n",
      "Train Epoch: 1055 [1200/2589 (46%)]\tLoss: 151.294220\n",
      "Train Epoch: 1055 [1500/2589 (58%)]\tLoss: 145.560806\n",
      "Train Epoch: 1055 [1800/2589 (70%)]\tLoss: 257.548370\n",
      "Train Epoch: 1055 [2100/2589 (81%)]\tLoss: 157.556213\n",
      "Train Epoch: 1055 [2400/2589 (93%)]\tLoss: 153.828857\n",
      "====> Epoch: 1055 Average train loss: 217.8396\n",
      "====> Epoch: 1055 Average test loss: 907.1987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1056 [0/2589 (0%)]\tLoss: 94.885498\n",
      "Train Epoch: 1056 [300/2589 (12%)]\tLoss: 206.218460\n",
      "Train Epoch: 1056 [600/2589 (23%)]\tLoss: 144.728424\n",
      "Train Epoch: 1056 [900/2589 (35%)]\tLoss: 218.189209\n",
      "Train Epoch: 1056 [1200/2589 (46%)]\tLoss: 254.257996\n",
      "Train Epoch: 1056 [1500/2589 (58%)]\tLoss: 207.189362\n",
      "Train Epoch: 1056 [1800/2589 (70%)]\tLoss: 206.389603\n",
      "Train Epoch: 1056 [2100/2589 (81%)]\tLoss: 279.921356\n",
      "Train Epoch: 1056 [2400/2589 (93%)]\tLoss: 229.411957\n",
      "====> Epoch: 1056 Average train loss: 216.8410\n",
      "====> Epoch: 1056 Average test loss: 919.5330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1057 [0/2589 (0%)]\tLoss: 181.453445\n",
      "Train Epoch: 1057 [300/2589 (12%)]\tLoss: 154.693344\n",
      "Train Epoch: 1057 [600/2589 (23%)]\tLoss: 184.677307\n",
      "Train Epoch: 1057 [900/2589 (35%)]\tLoss: 154.031113\n",
      "Train Epoch: 1057 [1200/2589 (46%)]\tLoss: 287.709778\n",
      "Train Epoch: 1057 [1500/2589 (58%)]\tLoss: 254.801529\n",
      "Train Epoch: 1057 [1800/2589 (70%)]\tLoss: 158.697235\n",
      "Train Epoch: 1057 [2100/2589 (81%)]\tLoss: 256.397339\n",
      "Train Epoch: 1057 [2400/2589 (93%)]\tLoss: 183.171310\n",
      "====> Epoch: 1057 Average train loss: 220.1996\n",
      "====> Epoch: 1057 Average test loss: 909.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1058 [0/2589 (0%)]\tLoss: 187.509415\n",
      "Train Epoch: 1058 [300/2589 (12%)]\tLoss: 194.655197\n",
      "Train Epoch: 1058 [600/2589 (23%)]\tLoss: 204.103378\n",
      "Train Epoch: 1058 [900/2589 (35%)]\tLoss: 291.638611\n",
      "Train Epoch: 1058 [1200/2589 (46%)]\tLoss: 210.935303\n",
      "Train Epoch: 1058 [1500/2589 (58%)]\tLoss: 167.247559\n",
      "Train Epoch: 1058 [1800/2589 (70%)]\tLoss: 207.722031\n",
      "Train Epoch: 1058 [2100/2589 (81%)]\tLoss: 193.033463\n",
      "Train Epoch: 1058 [2400/2589 (93%)]\tLoss: 207.175919\n",
      "====> Epoch: 1058 Average train loss: 221.8435\n",
      "====> Epoch: 1058 Average test loss: 919.3416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1059 [0/2589 (0%)]\tLoss: 128.721786\n",
      "Train Epoch: 1059 [300/2589 (12%)]\tLoss: 220.543701\n",
      "Train Epoch: 1059 [600/2589 (23%)]\tLoss: 251.204483\n",
      "Train Epoch: 1059 [900/2589 (35%)]\tLoss: 182.186981\n",
      "Train Epoch: 1059 [1200/2589 (46%)]\tLoss: 169.149353\n",
      "Train Epoch: 1059 [1500/2589 (58%)]\tLoss: 182.218246\n",
      "Train Epoch: 1059 [1800/2589 (70%)]\tLoss: 184.831894\n",
      "Train Epoch: 1059 [2100/2589 (81%)]\tLoss: 158.191986\n",
      "Train Epoch: 1059 [2400/2589 (93%)]\tLoss: 192.221680\n",
      "====> Epoch: 1059 Average train loss: 216.6270\n",
      "====> Epoch: 1059 Average test loss: 905.6664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1060 [0/2589 (0%)]\tLoss: 139.603455\n",
      "Train Epoch: 1060 [300/2589 (12%)]\tLoss: 151.359970\n",
      "Train Epoch: 1060 [600/2589 (23%)]\tLoss: 142.524368\n",
      "Train Epoch: 1060 [900/2589 (35%)]\tLoss: 345.071716\n",
      "Train Epoch: 1060 [1200/2589 (46%)]\tLoss: 252.941574\n",
      "Train Epoch: 1060 [1500/2589 (58%)]\tLoss: 145.338135\n",
      "Train Epoch: 1060 [1800/2589 (70%)]\tLoss: 236.713440\n",
      "Train Epoch: 1060 [2100/2589 (81%)]\tLoss: 136.478989\n",
      "Train Epoch: 1060 [2400/2589 (93%)]\tLoss: 176.338776\n",
      "====> Epoch: 1060 Average train loss: 219.3674\n",
      "====> Epoch: 1060 Average test loss: 928.4044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1061 [0/2589 (0%)]\tLoss: 224.142838\n",
      "Train Epoch: 1061 [300/2589 (12%)]\tLoss: 172.258392\n",
      "Train Epoch: 1061 [600/2589 (23%)]\tLoss: 193.961594\n",
      "Train Epoch: 1061 [900/2589 (35%)]\tLoss: 205.285583\n",
      "Train Epoch: 1061 [1200/2589 (46%)]\tLoss: 204.587006\n",
      "Train Epoch: 1061 [1500/2589 (58%)]\tLoss: 290.701630\n",
      "Train Epoch: 1061 [1800/2589 (70%)]\tLoss: 267.747467\n",
      "Train Epoch: 1061 [2100/2589 (81%)]\tLoss: 230.562057\n",
      "Train Epoch: 1061 [2400/2589 (93%)]\tLoss: 140.554947\n",
      "====> Epoch: 1061 Average train loss: 216.7772\n",
      "====> Epoch: 1061 Average test loss: 914.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1062 [0/2589 (0%)]\tLoss: 231.329865\n",
      "Train Epoch: 1062 [300/2589 (12%)]\tLoss: 173.351257\n",
      "Train Epoch: 1062 [600/2589 (23%)]\tLoss: 174.597168\n",
      "Train Epoch: 1062 [900/2589 (35%)]\tLoss: 162.998306\n",
      "Train Epoch: 1062 [1200/2589 (46%)]\tLoss: 233.383560\n",
      "Train Epoch: 1062 [1500/2589 (58%)]\tLoss: 149.390778\n",
      "Train Epoch: 1062 [1800/2589 (70%)]\tLoss: 168.383652\n",
      "Train Epoch: 1062 [2100/2589 (81%)]\tLoss: 136.493500\n",
      "Train Epoch: 1062 [2400/2589 (93%)]\tLoss: 441.885956\n",
      "====> Epoch: 1062 Average train loss: 215.1817\n",
      "====> Epoch: 1062 Average test loss: 918.1205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1063 [0/2589 (0%)]\tLoss: 207.879562\n",
      "Train Epoch: 1063 [300/2589 (12%)]\tLoss: 123.566696\n",
      "Train Epoch: 1063 [600/2589 (23%)]\tLoss: 258.356628\n",
      "Train Epoch: 1063 [900/2589 (35%)]\tLoss: 266.283356\n",
      "Train Epoch: 1063 [1200/2589 (46%)]\tLoss: 183.996826\n",
      "Train Epoch: 1063 [1500/2589 (58%)]\tLoss: 241.989456\n",
      "Train Epoch: 1063 [1800/2589 (70%)]\tLoss: 152.254547\n",
      "Train Epoch: 1063 [2100/2589 (81%)]\tLoss: 167.560699\n",
      "Train Epoch: 1063 [2400/2589 (93%)]\tLoss: 169.118958\n",
      "====> Epoch: 1063 Average train loss: 217.5578\n",
      "====> Epoch: 1063 Average test loss: 934.6569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1064 [0/2589 (0%)]\tLoss: 188.931351\n",
      "Train Epoch: 1064 [300/2589 (12%)]\tLoss: 155.866409\n",
      "Train Epoch: 1064 [600/2589 (23%)]\tLoss: 179.621033\n",
      "Train Epoch: 1064 [900/2589 (35%)]\tLoss: 220.053085\n",
      "Train Epoch: 1064 [1200/2589 (46%)]\tLoss: 240.978867\n",
      "Train Epoch: 1064 [1500/2589 (58%)]\tLoss: 151.474701\n",
      "Train Epoch: 1064 [1800/2589 (70%)]\tLoss: 173.470627\n",
      "Train Epoch: 1064 [2100/2589 (81%)]\tLoss: 195.044785\n",
      "Train Epoch: 1064 [2400/2589 (93%)]\tLoss: 179.121002\n",
      "====> Epoch: 1064 Average train loss: 222.2297\n",
      "====> Epoch: 1064 Average test loss: 921.6987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1065 [0/2589 (0%)]\tLoss: 184.190674\n",
      "Train Epoch: 1065 [300/2589 (12%)]\tLoss: 150.551025\n",
      "Train Epoch: 1065 [600/2589 (23%)]\tLoss: 264.314453\n",
      "Train Epoch: 1065 [900/2589 (35%)]\tLoss: 273.583130\n",
      "Train Epoch: 1065 [1200/2589 (46%)]\tLoss: 218.325714\n",
      "Train Epoch: 1065 [1500/2589 (58%)]\tLoss: 239.340851\n",
      "Train Epoch: 1065 [1800/2589 (70%)]\tLoss: 241.205338\n",
      "Train Epoch: 1065 [2100/2589 (81%)]\tLoss: 238.218567\n",
      "Train Epoch: 1065 [2400/2589 (93%)]\tLoss: 256.097046\n",
      "====> Epoch: 1065 Average train loss: 226.2573\n",
      "====> Epoch: 1065 Average test loss: 913.2901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1066 [0/2589 (0%)]\tLoss: 260.611206\n",
      "Train Epoch: 1066 [300/2589 (12%)]\tLoss: 237.248184\n",
      "Train Epoch: 1066 [600/2589 (23%)]\tLoss: 233.778000\n",
      "Train Epoch: 1066 [900/2589 (35%)]\tLoss: 203.801178\n",
      "Train Epoch: 1066 [1200/2589 (46%)]\tLoss: 182.492767\n",
      "Train Epoch: 1066 [1500/2589 (58%)]\tLoss: 181.116791\n",
      "Train Epoch: 1066 [1800/2589 (70%)]\tLoss: 253.584564\n",
      "Train Epoch: 1066 [2100/2589 (81%)]\tLoss: 231.214584\n",
      "Train Epoch: 1066 [2400/2589 (93%)]\tLoss: 174.986526\n",
      "====> Epoch: 1066 Average train loss: 214.7511\n",
      "====> Epoch: 1066 Average test loss: 915.1304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1067 [0/2589 (0%)]\tLoss: 190.597687\n",
      "Train Epoch: 1067 [300/2589 (12%)]\tLoss: 182.409012\n",
      "Train Epoch: 1067 [600/2589 (23%)]\tLoss: 177.612701\n",
      "Train Epoch: 1067 [900/2589 (35%)]\tLoss: 226.766708\n",
      "Train Epoch: 1067 [1200/2589 (46%)]\tLoss: 197.654221\n",
      "Train Epoch: 1067 [1500/2589 (58%)]\tLoss: 270.900757\n",
      "Train Epoch: 1067 [1800/2589 (70%)]\tLoss: 260.692413\n",
      "Train Epoch: 1067 [2100/2589 (81%)]\tLoss: 150.500839\n",
      "Train Epoch: 1067 [2400/2589 (93%)]\tLoss: 177.798050\n",
      "====> Epoch: 1067 Average train loss: 217.8017\n",
      "====> Epoch: 1067 Average test loss: 920.2634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1068 [0/2589 (0%)]\tLoss: 310.385895\n",
      "Train Epoch: 1068 [300/2589 (12%)]\tLoss: 195.742340\n",
      "Train Epoch: 1068 [600/2589 (23%)]\tLoss: 195.221130\n",
      "Train Epoch: 1068 [900/2589 (35%)]\tLoss: 145.762589\n",
      "Train Epoch: 1068 [1200/2589 (46%)]\tLoss: 178.732101\n",
      "Train Epoch: 1068 [1500/2589 (58%)]\tLoss: 168.243958\n",
      "Train Epoch: 1068 [1800/2589 (70%)]\tLoss: 171.274475\n",
      "Train Epoch: 1068 [2100/2589 (81%)]\tLoss: 212.766693\n",
      "Train Epoch: 1068 [2400/2589 (93%)]\tLoss: 187.844177\n",
      "====> Epoch: 1068 Average train loss: 213.6725\n",
      "====> Epoch: 1068 Average test loss: 923.2130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1069 [0/2589 (0%)]\tLoss: 191.020935\n",
      "Train Epoch: 1069 [300/2589 (12%)]\tLoss: 145.668869\n",
      "Train Epoch: 1069 [600/2589 (23%)]\tLoss: 144.909363\n",
      "Train Epoch: 1069 [900/2589 (35%)]\tLoss: 210.839767\n",
      "Train Epoch: 1069 [1200/2589 (46%)]\tLoss: 236.380829\n",
      "Train Epoch: 1069 [1500/2589 (58%)]\tLoss: 354.398560\n",
      "Train Epoch: 1069 [1800/2589 (70%)]\tLoss: 263.665710\n",
      "Train Epoch: 1069 [2100/2589 (81%)]\tLoss: 321.173248\n",
      "Train Epoch: 1069 [2400/2589 (93%)]\tLoss: 124.782066\n",
      "====> Epoch: 1069 Average train loss: 222.5120\n",
      "====> Epoch: 1069 Average test loss: 909.3232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1070 [0/2589 (0%)]\tLoss: 179.496185\n",
      "Train Epoch: 1070 [300/2589 (12%)]\tLoss: 158.658463\n",
      "Train Epoch: 1070 [600/2589 (23%)]\tLoss: 262.237915\n",
      "Train Epoch: 1070 [900/2589 (35%)]\tLoss: 173.207245\n",
      "Train Epoch: 1070 [1200/2589 (46%)]\tLoss: 184.217056\n",
      "Train Epoch: 1070 [1500/2589 (58%)]\tLoss: 251.305664\n",
      "Train Epoch: 1070 [1800/2589 (70%)]\tLoss: 166.167099\n",
      "Train Epoch: 1070 [2100/2589 (81%)]\tLoss: 207.033936\n",
      "Train Epoch: 1070 [2400/2589 (93%)]\tLoss: 296.129120\n",
      "====> Epoch: 1070 Average train loss: 219.0916\n",
      "====> Epoch: 1070 Average test loss: 912.9412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1071 [0/2589 (0%)]\tLoss: 141.944870\n",
      "Train Epoch: 1071 [300/2589 (12%)]\tLoss: 154.050385\n",
      "Train Epoch: 1071 [600/2589 (23%)]\tLoss: 261.492767\n",
      "Train Epoch: 1071 [900/2589 (35%)]\tLoss: 332.386353\n",
      "Train Epoch: 1071 [1200/2589 (46%)]\tLoss: 351.453827\n",
      "Train Epoch: 1071 [1500/2589 (58%)]\tLoss: 181.026794\n",
      "Train Epoch: 1071 [1800/2589 (70%)]\tLoss: 190.357178\n",
      "Train Epoch: 1071 [2100/2589 (81%)]\tLoss: 229.414230\n",
      "Train Epoch: 1071 [2400/2589 (93%)]\tLoss: 230.934677\n",
      "====> Epoch: 1071 Average train loss: 231.2567\n",
      "====> Epoch: 1071 Average test loss: 907.2104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1072 [0/2589 (0%)]\tLoss: 282.732758\n",
      "Train Epoch: 1072 [300/2589 (12%)]\tLoss: 174.215775\n",
      "Train Epoch: 1072 [600/2589 (23%)]\tLoss: 185.036194\n",
      "Train Epoch: 1072 [900/2589 (35%)]\tLoss: 267.741669\n",
      "Train Epoch: 1072 [1200/2589 (46%)]\tLoss: 173.391113\n",
      "Train Epoch: 1072 [1500/2589 (58%)]\tLoss: 172.665756\n",
      "Train Epoch: 1072 [1800/2589 (70%)]\tLoss: 138.749313\n",
      "Train Epoch: 1072 [2100/2589 (81%)]\tLoss: 195.162369\n",
      "Train Epoch: 1072 [2400/2589 (93%)]\tLoss: 199.863571\n",
      "====> Epoch: 1072 Average train loss: 220.3998\n",
      "====> Epoch: 1072 Average test loss: 914.5233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1073 [0/2589 (0%)]\tLoss: 237.684280\n",
      "Train Epoch: 1073 [300/2589 (12%)]\tLoss: 218.385437\n",
      "Train Epoch: 1073 [600/2589 (23%)]\tLoss: 165.135025\n",
      "Train Epoch: 1073 [900/2589 (35%)]\tLoss: 197.286850\n",
      "Train Epoch: 1073 [1200/2589 (46%)]\tLoss: 224.670074\n",
      "Train Epoch: 1073 [1500/2589 (58%)]\tLoss: 202.137863\n",
      "Train Epoch: 1073 [1800/2589 (70%)]\tLoss: 310.966797\n",
      "Train Epoch: 1073 [2100/2589 (81%)]\tLoss: 202.665726\n",
      "Train Epoch: 1073 [2400/2589 (93%)]\tLoss: 225.332458\n",
      "====> Epoch: 1073 Average train loss: 219.6834\n",
      "====> Epoch: 1073 Average test loss: 925.5251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1074 [0/2589 (0%)]\tLoss: 320.780792\n",
      "Train Epoch: 1074 [300/2589 (12%)]\tLoss: 168.608047\n",
      "Train Epoch: 1074 [600/2589 (23%)]\tLoss: 174.323212\n",
      "Train Epoch: 1074 [900/2589 (35%)]\tLoss: 328.763123\n",
      "Train Epoch: 1074 [1200/2589 (46%)]\tLoss: 200.922150\n",
      "Train Epoch: 1074 [1500/2589 (58%)]\tLoss: 225.685516\n",
      "Train Epoch: 1074 [1800/2589 (70%)]\tLoss: 206.443588\n",
      "Train Epoch: 1074 [2100/2589 (81%)]\tLoss: 213.682449\n",
      "Train Epoch: 1074 [2400/2589 (93%)]\tLoss: 168.883499\n",
      "====> Epoch: 1074 Average train loss: 217.2109\n",
      "====> Epoch: 1074 Average test loss: 922.5439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1075 [0/2589 (0%)]\tLoss: 216.651474\n",
      "Train Epoch: 1075 [300/2589 (12%)]\tLoss: 274.251038\n",
      "Train Epoch: 1075 [600/2589 (23%)]\tLoss: 174.108139\n",
      "Train Epoch: 1075 [900/2589 (35%)]\tLoss: 168.717392\n",
      "Train Epoch: 1075 [1200/2589 (46%)]\tLoss: 237.694351\n",
      "Train Epoch: 1075 [1500/2589 (58%)]\tLoss: 429.428162\n",
      "Train Epoch: 1075 [1800/2589 (70%)]\tLoss: 255.699356\n",
      "Train Epoch: 1075 [2100/2589 (81%)]\tLoss: 228.554230\n",
      "Train Epoch: 1075 [2400/2589 (93%)]\tLoss: 208.542191\n",
      "====> Epoch: 1075 Average train loss: 228.2631\n",
      "====> Epoch: 1075 Average test loss: 908.2079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1076 [0/2589 (0%)]\tLoss: 156.397461\n",
      "Train Epoch: 1076 [300/2589 (12%)]\tLoss: 300.561249\n",
      "Train Epoch: 1076 [600/2589 (23%)]\tLoss: 186.384216\n",
      "Train Epoch: 1076 [900/2589 (35%)]\tLoss: 234.163635\n",
      "Train Epoch: 1076 [1200/2589 (46%)]\tLoss: 197.106796\n",
      "Train Epoch: 1076 [1500/2589 (58%)]\tLoss: 194.383224\n",
      "Train Epoch: 1076 [1800/2589 (70%)]\tLoss: 186.449738\n",
      "Train Epoch: 1076 [2100/2589 (81%)]\tLoss: 183.596817\n",
      "Train Epoch: 1076 [2400/2589 (93%)]\tLoss: 288.029205\n",
      "====> Epoch: 1076 Average train loss: 223.1720\n",
      "====> Epoch: 1076 Average test loss: 907.0842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1077 [0/2589 (0%)]\tLoss: 187.837463\n",
      "Train Epoch: 1077 [300/2589 (12%)]\tLoss: 239.911133\n",
      "Train Epoch: 1077 [600/2589 (23%)]\tLoss: 187.306625\n",
      "Train Epoch: 1077 [900/2589 (35%)]\tLoss: 211.701736\n",
      "Train Epoch: 1077 [1200/2589 (46%)]\tLoss: 275.297974\n",
      "Train Epoch: 1077 [1500/2589 (58%)]\tLoss: 249.668350\n",
      "Train Epoch: 1077 [1800/2589 (70%)]\tLoss: 228.286575\n",
      "Train Epoch: 1077 [2100/2589 (81%)]\tLoss: 217.439514\n",
      "Train Epoch: 1077 [2400/2589 (93%)]\tLoss: 177.629425\n",
      "====> Epoch: 1077 Average train loss: 233.6194\n",
      "====> Epoch: 1077 Average test loss: 922.2958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1078 [0/2589 (0%)]\tLoss: 188.319260\n",
      "Train Epoch: 1078 [300/2589 (12%)]\tLoss: 197.154587\n",
      "Train Epoch: 1078 [600/2589 (23%)]\tLoss: 217.422821\n",
      "Train Epoch: 1078 [900/2589 (35%)]\tLoss: 273.258453\n",
      "Train Epoch: 1078 [1200/2589 (46%)]\tLoss: 140.460968\n",
      "Train Epoch: 1078 [1500/2589 (58%)]\tLoss: 187.742249\n",
      "Train Epoch: 1078 [1800/2589 (70%)]\tLoss: 233.912735\n",
      "Train Epoch: 1078 [2100/2589 (81%)]\tLoss: 236.740921\n",
      "Train Epoch: 1078 [2400/2589 (93%)]\tLoss: 275.934143\n",
      "====> Epoch: 1078 Average train loss: 223.1428\n",
      "====> Epoch: 1078 Average test loss: 916.3698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1079 [0/2589 (0%)]\tLoss: 236.974335\n",
      "Train Epoch: 1079 [300/2589 (12%)]\tLoss: 214.582352\n",
      "Train Epoch: 1079 [600/2589 (23%)]\tLoss: 224.445740\n",
      "Train Epoch: 1079 [900/2589 (35%)]\tLoss: 175.885742\n",
      "Train Epoch: 1079 [1200/2589 (46%)]\tLoss: 203.613480\n",
      "Train Epoch: 1079 [1500/2589 (58%)]\tLoss: 220.487656\n",
      "Train Epoch: 1079 [1800/2589 (70%)]\tLoss: 273.369843\n",
      "Train Epoch: 1079 [2100/2589 (81%)]\tLoss: 178.443832\n",
      "Train Epoch: 1079 [2400/2589 (93%)]\tLoss: 164.094330\n",
      "====> Epoch: 1079 Average train loss: 214.7248\n",
      "====> Epoch: 1079 Average test loss: 901.5741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1080 [0/2589 (0%)]\tLoss: 243.099030\n",
      "Train Epoch: 1080 [300/2589 (12%)]\tLoss: 173.968353\n",
      "Train Epoch: 1080 [600/2589 (23%)]\tLoss: 204.456680\n",
      "Train Epoch: 1080 [900/2589 (35%)]\tLoss: 401.232361\n",
      "Train Epoch: 1080 [1200/2589 (46%)]\tLoss: 292.243378\n",
      "Train Epoch: 1080 [1500/2589 (58%)]\tLoss: 240.706650\n",
      "Train Epoch: 1080 [1800/2589 (70%)]\tLoss: 265.362457\n",
      "Train Epoch: 1080 [2100/2589 (81%)]\tLoss: 181.119980\n",
      "Train Epoch: 1080 [2400/2589 (93%)]\tLoss: 176.842102\n",
      "====> Epoch: 1080 Average train loss: 222.0889\n",
      "====> Epoch: 1080 Average test loss: 920.8863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1081 [0/2589 (0%)]\tLoss: 190.979050\n",
      "Train Epoch: 1081 [300/2589 (12%)]\tLoss: 263.475769\n",
      "Train Epoch: 1081 [600/2589 (23%)]\tLoss: 174.777618\n",
      "Train Epoch: 1081 [900/2589 (35%)]\tLoss: 175.330093\n",
      "Train Epoch: 1081 [1200/2589 (46%)]\tLoss: 231.794006\n",
      "Train Epoch: 1081 [1500/2589 (58%)]\tLoss: 165.355606\n",
      "Train Epoch: 1081 [1800/2589 (70%)]\tLoss: 151.823776\n",
      "Train Epoch: 1081 [2100/2589 (81%)]\tLoss: 165.044998\n",
      "Train Epoch: 1081 [2400/2589 (93%)]\tLoss: 357.177643\n",
      "====> Epoch: 1081 Average train loss: 225.5275\n",
      "====> Epoch: 1081 Average test loss: 903.4791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1082 [0/2589 (0%)]\tLoss: 189.499283\n",
      "Train Epoch: 1082 [300/2589 (12%)]\tLoss: 321.910065\n",
      "Train Epoch: 1082 [600/2589 (23%)]\tLoss: 169.254562\n",
      "Train Epoch: 1082 [900/2589 (35%)]\tLoss: 171.675735\n",
      "Train Epoch: 1082 [1200/2589 (46%)]\tLoss: 195.843094\n",
      "Train Epoch: 1082 [1500/2589 (58%)]\tLoss: 160.445663\n",
      "Train Epoch: 1082 [1800/2589 (70%)]\tLoss: 397.161713\n",
      "Train Epoch: 1082 [2100/2589 (81%)]\tLoss: 230.545441\n",
      "Train Epoch: 1082 [2400/2589 (93%)]\tLoss: 196.250717\n",
      "====> Epoch: 1082 Average train loss: 218.7394\n",
      "====> Epoch: 1082 Average test loss: 906.4920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1083 [0/2589 (0%)]\tLoss: 292.299286\n",
      "Train Epoch: 1083 [300/2589 (12%)]\tLoss: 161.818146\n",
      "Train Epoch: 1083 [600/2589 (23%)]\tLoss: 455.067413\n",
      "Train Epoch: 1083 [900/2589 (35%)]\tLoss: 173.888733\n",
      "Train Epoch: 1083 [1200/2589 (46%)]\tLoss: 318.710602\n",
      "Train Epoch: 1083 [1500/2589 (58%)]\tLoss: 189.195709\n",
      "Train Epoch: 1083 [1800/2589 (70%)]\tLoss: 153.534439\n",
      "Train Epoch: 1083 [2100/2589 (81%)]\tLoss: 225.408463\n",
      "Train Epoch: 1083 [2400/2589 (93%)]\tLoss: 204.928940\n",
      "====> Epoch: 1083 Average train loss: 221.8787\n",
      "====> Epoch: 1083 Average test loss: 922.9387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1084 [0/2589 (0%)]\tLoss: 222.154694\n",
      "Train Epoch: 1084 [300/2589 (12%)]\tLoss: 344.048981\n",
      "Train Epoch: 1084 [600/2589 (23%)]\tLoss: 222.952148\n",
      "Train Epoch: 1084 [900/2589 (35%)]\tLoss: 209.367767\n",
      "Train Epoch: 1084 [1200/2589 (46%)]\tLoss: 223.746521\n",
      "Train Epoch: 1084 [1500/2589 (58%)]\tLoss: 226.198471\n",
      "Train Epoch: 1084 [1800/2589 (70%)]\tLoss: 165.596222\n",
      "Train Epoch: 1084 [2100/2589 (81%)]\tLoss: 166.772141\n",
      "Train Epoch: 1084 [2400/2589 (93%)]\tLoss: 230.248978\n",
      "====> Epoch: 1084 Average train loss: 214.4949\n",
      "====> Epoch: 1084 Average test loss: 915.6390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1085 [0/2589 (0%)]\tLoss: 150.303864\n",
      "Train Epoch: 1085 [300/2589 (12%)]\tLoss: 290.320648\n",
      "Train Epoch: 1085 [600/2589 (23%)]\tLoss: 196.331558\n",
      "Train Epoch: 1085 [900/2589 (35%)]\tLoss: 200.234070\n",
      "Train Epoch: 1085 [1200/2589 (46%)]\tLoss: 189.246368\n",
      "Train Epoch: 1085 [1500/2589 (58%)]\tLoss: 165.885544\n",
      "Train Epoch: 1085 [1800/2589 (70%)]\tLoss: 273.407593\n",
      "Train Epoch: 1085 [2100/2589 (81%)]\tLoss: 248.553238\n",
      "Train Epoch: 1085 [2400/2589 (93%)]\tLoss: 198.788986\n",
      "====> Epoch: 1085 Average train loss: 224.6125\n",
      "====> Epoch: 1085 Average test loss: 929.5264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1086 [0/2589 (0%)]\tLoss: 173.249451\n",
      "Train Epoch: 1086 [300/2589 (12%)]\tLoss: 161.181900\n",
      "Train Epoch: 1086 [600/2589 (23%)]\tLoss: 214.238022\n",
      "Train Epoch: 1086 [900/2589 (35%)]\tLoss: 220.139328\n",
      "Train Epoch: 1086 [1200/2589 (46%)]\tLoss: 209.521210\n",
      "Train Epoch: 1086 [1500/2589 (58%)]\tLoss: 243.235291\n",
      "Train Epoch: 1086 [1800/2589 (70%)]\tLoss: 197.077194\n",
      "Train Epoch: 1086 [2100/2589 (81%)]\tLoss: 216.676300\n",
      "Train Epoch: 1086 [2400/2589 (93%)]\tLoss: 208.239212\n",
      "====> Epoch: 1086 Average train loss: 210.0347\n",
      "====> Epoch: 1086 Average test loss: 920.0171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1087 [0/2589 (0%)]\tLoss: 265.207214\n",
      "Train Epoch: 1087 [300/2589 (12%)]\tLoss: 216.951920\n",
      "Train Epoch: 1087 [600/2589 (23%)]\tLoss: 231.572891\n",
      "Train Epoch: 1087 [900/2589 (35%)]\tLoss: 287.546844\n",
      "Train Epoch: 1087 [1200/2589 (46%)]\tLoss: 248.926926\n",
      "Train Epoch: 1087 [1500/2589 (58%)]\tLoss: 171.676270\n",
      "Train Epoch: 1087 [1800/2589 (70%)]\tLoss: 146.370102\n",
      "Train Epoch: 1087 [2100/2589 (81%)]\tLoss: 264.854858\n",
      "Train Epoch: 1087 [2400/2589 (93%)]\tLoss: 158.158936\n",
      "====> Epoch: 1087 Average train loss: 216.3533\n",
      "====> Epoch: 1087 Average test loss: 915.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1088 [0/2589 (0%)]\tLoss: 238.372513\n",
      "Train Epoch: 1088 [300/2589 (12%)]\tLoss: 162.189651\n",
      "Train Epoch: 1088 [600/2589 (23%)]\tLoss: 212.533844\n",
      "Train Epoch: 1088 [900/2589 (35%)]\tLoss: 194.359390\n",
      "Train Epoch: 1088 [1200/2589 (46%)]\tLoss: 168.001419\n",
      "Train Epoch: 1088 [1500/2589 (58%)]\tLoss: 364.986877\n",
      "Train Epoch: 1088 [1800/2589 (70%)]\tLoss: 139.224747\n",
      "Train Epoch: 1088 [2100/2589 (81%)]\tLoss: 185.362976\n",
      "Train Epoch: 1088 [2400/2589 (93%)]\tLoss: 201.363770\n",
      "====> Epoch: 1088 Average train loss: 222.4883\n",
      "====> Epoch: 1088 Average test loss: 915.9478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1089 [0/2589 (0%)]\tLoss: 217.370956\n",
      "Train Epoch: 1089 [300/2589 (12%)]\tLoss: 211.966904\n",
      "Train Epoch: 1089 [600/2589 (23%)]\tLoss: 216.418930\n",
      "Train Epoch: 1089 [900/2589 (35%)]\tLoss: 167.649582\n",
      "Train Epoch: 1089 [1200/2589 (46%)]\tLoss: 214.838684\n",
      "Train Epoch: 1089 [1500/2589 (58%)]\tLoss: 291.068542\n",
      "Train Epoch: 1089 [1800/2589 (70%)]\tLoss: 147.093796\n",
      "Train Epoch: 1089 [2100/2589 (81%)]\tLoss: 203.270554\n",
      "Train Epoch: 1089 [2400/2589 (93%)]\tLoss: 242.566742\n",
      "====> Epoch: 1089 Average train loss: 219.2415\n",
      "====> Epoch: 1089 Average test loss: 924.6409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1090 [0/2589 (0%)]\tLoss: 146.876602\n",
      "Train Epoch: 1090 [300/2589 (12%)]\tLoss: 257.430084\n",
      "Train Epoch: 1090 [600/2589 (23%)]\tLoss: 204.410706\n",
      "Train Epoch: 1090 [900/2589 (35%)]\tLoss: 143.626907\n",
      "Train Epoch: 1090 [1200/2589 (46%)]\tLoss: 198.485046\n",
      "Train Epoch: 1090 [1500/2589 (58%)]\tLoss: 162.931778\n",
      "Train Epoch: 1090 [1800/2589 (70%)]\tLoss: 225.139709\n",
      "Train Epoch: 1090 [2100/2589 (81%)]\tLoss: 250.923340\n",
      "Train Epoch: 1090 [2400/2589 (93%)]\tLoss: 352.953003\n",
      "====> Epoch: 1090 Average train loss: 229.6966\n",
      "====> Epoch: 1090 Average test loss: 910.0360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1091 [0/2589 (0%)]\tLoss: 214.507309\n",
      "Train Epoch: 1091 [300/2589 (12%)]\tLoss: 334.067902\n",
      "Train Epoch: 1091 [600/2589 (23%)]\tLoss: 293.470856\n",
      "Train Epoch: 1091 [900/2589 (35%)]\tLoss: 196.019989\n",
      "Train Epoch: 1091 [1200/2589 (46%)]\tLoss: 221.916931\n",
      "Train Epoch: 1091 [1500/2589 (58%)]\tLoss: 179.952484\n",
      "Train Epoch: 1091 [1800/2589 (70%)]\tLoss: 140.204651\n",
      "Train Epoch: 1091 [2100/2589 (81%)]\tLoss: 321.387115\n",
      "Train Epoch: 1091 [2400/2589 (93%)]\tLoss: 209.119308\n",
      "====> Epoch: 1091 Average train loss: 218.8495\n",
      "====> Epoch: 1091 Average test loss: 917.1187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1092 [0/2589 (0%)]\tLoss: 189.100616\n",
      "Train Epoch: 1092 [300/2589 (12%)]\tLoss: 238.512100\n",
      "Train Epoch: 1092 [600/2589 (23%)]\tLoss: 286.771515\n",
      "Train Epoch: 1092 [900/2589 (35%)]\tLoss: 150.525726\n",
      "Train Epoch: 1092 [1200/2589 (46%)]\tLoss: 251.563705\n",
      "Train Epoch: 1092 [1500/2589 (58%)]\tLoss: 148.311218\n",
      "Train Epoch: 1092 [1800/2589 (70%)]\tLoss: 169.980667\n",
      "Train Epoch: 1092 [2100/2589 (81%)]\tLoss: 179.833038\n",
      "Train Epoch: 1092 [2400/2589 (93%)]\tLoss: 320.676331\n",
      "====> Epoch: 1092 Average train loss: 197.7843\n",
      "====> Epoch: 1092 Average test loss: 914.8993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1093 [0/2589 (0%)]\tLoss: 365.455933\n",
      "Train Epoch: 1093 [300/2589 (12%)]\tLoss: 183.454590\n",
      "Train Epoch: 1093 [600/2589 (23%)]\tLoss: 190.819397\n",
      "Train Epoch: 1093 [900/2589 (35%)]\tLoss: 186.442093\n",
      "Train Epoch: 1093 [1200/2589 (46%)]\tLoss: 223.661560\n",
      "Train Epoch: 1093 [1500/2589 (58%)]\tLoss: 183.823151\n",
      "Train Epoch: 1093 [1800/2589 (70%)]\tLoss: 242.084381\n",
      "Train Epoch: 1093 [2100/2589 (81%)]\tLoss: 228.119690\n",
      "Train Epoch: 1093 [2400/2589 (93%)]\tLoss: 348.366608\n",
      "====> Epoch: 1093 Average train loss: 214.8135\n",
      "====> Epoch: 1093 Average test loss: 905.4119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1094 [0/2589 (0%)]\tLoss: 206.508621\n",
      "Train Epoch: 1094 [300/2589 (12%)]\tLoss: 204.279724\n",
      "Train Epoch: 1094 [600/2589 (23%)]\tLoss: 131.514313\n",
      "Train Epoch: 1094 [900/2589 (35%)]\tLoss: 190.294342\n",
      "Train Epoch: 1094 [1200/2589 (46%)]\tLoss: 151.335297\n",
      "Train Epoch: 1094 [1500/2589 (58%)]\tLoss: 222.869904\n",
      "Train Epoch: 1094 [1800/2589 (70%)]\tLoss: 196.140137\n",
      "Train Epoch: 1094 [2100/2589 (81%)]\tLoss: 222.086655\n",
      "Train Epoch: 1094 [2400/2589 (93%)]\tLoss: 242.233795\n",
      "====> Epoch: 1094 Average train loss: 214.5133\n",
      "====> Epoch: 1094 Average test loss: 910.5385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1095 [0/2589 (0%)]\tLoss: 128.722092\n",
      "Train Epoch: 1095 [300/2589 (12%)]\tLoss: 193.273666\n",
      "Train Epoch: 1095 [600/2589 (23%)]\tLoss: 224.604004\n",
      "Train Epoch: 1095 [900/2589 (35%)]\tLoss: 233.116501\n",
      "Train Epoch: 1095 [1200/2589 (46%)]\tLoss: 196.918777\n",
      "Train Epoch: 1095 [1500/2589 (58%)]\tLoss: 215.980927\n",
      "Train Epoch: 1095 [1800/2589 (70%)]\tLoss: 214.957062\n",
      "Train Epoch: 1095 [2100/2589 (81%)]\tLoss: 173.592194\n",
      "Train Epoch: 1095 [2400/2589 (93%)]\tLoss: 209.821640\n",
      "====> Epoch: 1095 Average train loss: 218.3235\n",
      "====> Epoch: 1095 Average test loss: 912.6168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1096 [0/2589 (0%)]\tLoss: 193.549515\n",
      "Train Epoch: 1096 [300/2589 (12%)]\tLoss: 358.427917\n",
      "Train Epoch: 1096 [600/2589 (23%)]\tLoss: 202.057938\n",
      "Train Epoch: 1096 [900/2589 (35%)]\tLoss: 167.262619\n",
      "Train Epoch: 1096 [1200/2589 (46%)]\tLoss: 280.569305\n",
      "Train Epoch: 1096 [1500/2589 (58%)]\tLoss: 263.376740\n",
      "Train Epoch: 1096 [1800/2589 (70%)]\tLoss: 214.135513\n",
      "Train Epoch: 1096 [2100/2589 (81%)]\tLoss: 219.476990\n",
      "Train Epoch: 1096 [2400/2589 (93%)]\tLoss: 176.276855\n",
      "====> Epoch: 1096 Average train loss: 221.3790\n",
      "====> Epoch: 1096 Average test loss: 907.9110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1097 [0/2589 (0%)]\tLoss: 268.757172\n",
      "Train Epoch: 1097 [300/2589 (12%)]\tLoss: 456.247345\n",
      "Train Epoch: 1097 [600/2589 (23%)]\tLoss: 230.568222\n",
      "Train Epoch: 1097 [900/2589 (35%)]\tLoss: 194.312973\n",
      "Train Epoch: 1097 [1200/2589 (46%)]\tLoss: 241.108444\n",
      "Train Epoch: 1097 [1500/2589 (58%)]\tLoss: 250.987579\n",
      "Train Epoch: 1097 [1800/2589 (70%)]\tLoss: 155.598221\n",
      "Train Epoch: 1097 [2100/2589 (81%)]\tLoss: 267.031158\n",
      "Train Epoch: 1097 [2400/2589 (93%)]\tLoss: 139.892410\n",
      "====> Epoch: 1097 Average train loss: 235.0329\n",
      "====> Epoch: 1097 Average test loss: 913.0560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1098 [0/2589 (0%)]\tLoss: 204.569992\n",
      "Train Epoch: 1098 [300/2589 (12%)]\tLoss: 147.071274\n",
      "Train Epoch: 1098 [600/2589 (23%)]\tLoss: 218.607285\n",
      "Train Epoch: 1098 [900/2589 (35%)]\tLoss: 188.479507\n",
      "Train Epoch: 1098 [1200/2589 (46%)]\tLoss: 184.850281\n",
      "Train Epoch: 1098 [1500/2589 (58%)]\tLoss: 316.404236\n",
      "Train Epoch: 1098 [1800/2589 (70%)]\tLoss: 205.598038\n",
      "Train Epoch: 1098 [2100/2589 (81%)]\tLoss: 168.734650\n",
      "Train Epoch: 1098 [2400/2589 (93%)]\tLoss: 167.896973\n",
      "====> Epoch: 1098 Average train loss: 223.5503\n",
      "====> Epoch: 1098 Average test loss: 906.9481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1099 [0/2589 (0%)]\tLoss: 199.077927\n",
      "Train Epoch: 1099 [300/2589 (12%)]\tLoss: 250.294205\n",
      "Train Epoch: 1099 [600/2589 (23%)]\tLoss: 198.267853\n",
      "Train Epoch: 1099 [900/2589 (35%)]\tLoss: 257.456970\n",
      "Train Epoch: 1099 [1200/2589 (46%)]\tLoss: 267.599304\n",
      "Train Epoch: 1099 [1500/2589 (58%)]\tLoss: 162.377747\n",
      "Train Epoch: 1099 [1800/2589 (70%)]\tLoss: 212.226562\n",
      "Train Epoch: 1099 [2100/2589 (81%)]\tLoss: 239.325226\n",
      "Train Epoch: 1099 [2400/2589 (93%)]\tLoss: 180.978973\n",
      "====> Epoch: 1099 Average train loss: 220.4117\n",
      "====> Epoch: 1099 Average test loss: 919.9951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1100 [0/2589 (0%)]\tLoss: 195.843842\n",
      "Train Epoch: 1100 [300/2589 (12%)]\tLoss: 192.730927\n",
      "Train Epoch: 1100 [600/2589 (23%)]\tLoss: 163.148926\n",
      "Train Epoch: 1100 [900/2589 (35%)]\tLoss: 197.316299\n",
      "Train Epoch: 1100 [1200/2589 (46%)]\tLoss: 142.364639\n",
      "Train Epoch: 1100 [1500/2589 (58%)]\tLoss: 179.595535\n",
      "Train Epoch: 1100 [1800/2589 (70%)]\tLoss: 205.702362\n",
      "Train Epoch: 1100 [2100/2589 (81%)]\tLoss: 238.917801\n",
      "Train Epoch: 1100 [2400/2589 (93%)]\tLoss: 255.188461\n",
      "====> Epoch: 1100 Average train loss: 209.9811\n",
      "====> Epoch: 1100 Average test loss: 907.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1101 [0/2589 (0%)]\tLoss: 114.440865\n",
      "Train Epoch: 1101 [300/2589 (12%)]\tLoss: 273.969818\n",
      "Train Epoch: 1101 [600/2589 (23%)]\tLoss: 188.889816\n",
      "Train Epoch: 1101 [900/2589 (35%)]\tLoss: 161.062927\n",
      "Train Epoch: 1101 [1200/2589 (46%)]\tLoss: 160.312775\n",
      "Train Epoch: 1101 [1500/2589 (58%)]\tLoss: 237.885544\n",
      "Train Epoch: 1101 [1800/2589 (70%)]\tLoss: 442.273499\n",
      "Train Epoch: 1101 [2100/2589 (81%)]\tLoss: 150.030258\n",
      "Train Epoch: 1101 [2400/2589 (93%)]\tLoss: 161.455414\n",
      "====> Epoch: 1101 Average train loss: 219.0008\n",
      "====> Epoch: 1101 Average test loss: 918.7651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1102 [0/2589 (0%)]\tLoss: 265.677185\n",
      "Train Epoch: 1102 [300/2589 (12%)]\tLoss: 170.494080\n",
      "Train Epoch: 1102 [600/2589 (23%)]\tLoss: 178.133072\n",
      "Train Epoch: 1102 [900/2589 (35%)]\tLoss: 398.735504\n",
      "Train Epoch: 1102 [1200/2589 (46%)]\tLoss: 199.043518\n",
      "Train Epoch: 1102 [1500/2589 (58%)]\tLoss: 251.255447\n",
      "Train Epoch: 1102 [1800/2589 (70%)]\tLoss: 149.248962\n",
      "Train Epoch: 1102 [2100/2589 (81%)]\tLoss: 223.736130\n",
      "Train Epoch: 1102 [2400/2589 (93%)]\tLoss: 347.400574\n",
      "====> Epoch: 1102 Average train loss: 216.3511\n",
      "====> Epoch: 1102 Average test loss: 921.1003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1103 [0/2589 (0%)]\tLoss: 218.972321\n",
      "Train Epoch: 1103 [300/2589 (12%)]\tLoss: 161.359512\n",
      "Train Epoch: 1103 [600/2589 (23%)]\tLoss: 211.040054\n",
      "Train Epoch: 1103 [900/2589 (35%)]\tLoss: 194.933182\n",
      "Train Epoch: 1103 [1200/2589 (46%)]\tLoss: 149.812302\n",
      "Train Epoch: 1103 [1500/2589 (58%)]\tLoss: 178.061920\n",
      "Train Epoch: 1103 [1800/2589 (70%)]\tLoss: 210.984711\n",
      "Train Epoch: 1103 [2100/2589 (81%)]\tLoss: 244.535187\n",
      "Train Epoch: 1103 [2400/2589 (93%)]\tLoss: 298.351837\n",
      "====> Epoch: 1103 Average train loss: 217.5083\n",
      "====> Epoch: 1103 Average test loss: 905.1341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1104 [0/2589 (0%)]\tLoss: 182.815948\n",
      "Train Epoch: 1104 [300/2589 (12%)]\tLoss: 286.205078\n",
      "Train Epoch: 1104 [600/2589 (23%)]\tLoss: 241.752457\n",
      "Train Epoch: 1104 [900/2589 (35%)]\tLoss: 260.205292\n",
      "Train Epoch: 1104 [1200/2589 (46%)]\tLoss: 245.757919\n",
      "Train Epoch: 1104 [1500/2589 (58%)]\tLoss: 156.035873\n",
      "Train Epoch: 1104 [1800/2589 (70%)]\tLoss: 231.506805\n",
      "Train Epoch: 1104 [2100/2589 (81%)]\tLoss: 271.416962\n",
      "Train Epoch: 1104 [2400/2589 (93%)]\tLoss: 212.518585\n",
      "====> Epoch: 1104 Average train loss: 223.0802\n",
      "====> Epoch: 1104 Average test loss: 907.7975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1105 [0/2589 (0%)]\tLoss: 163.561096\n",
      "Train Epoch: 1105 [300/2589 (12%)]\tLoss: 251.178452\n",
      "Train Epoch: 1105 [600/2589 (23%)]\tLoss: 300.582336\n",
      "Train Epoch: 1105 [900/2589 (35%)]\tLoss: 417.166931\n",
      "Train Epoch: 1105 [1200/2589 (46%)]\tLoss: 176.378067\n",
      "Train Epoch: 1105 [1500/2589 (58%)]\tLoss: 213.756256\n",
      "Train Epoch: 1105 [1800/2589 (70%)]\tLoss: 245.953293\n",
      "Train Epoch: 1105 [2100/2589 (81%)]\tLoss: 225.910553\n",
      "Train Epoch: 1105 [2400/2589 (93%)]\tLoss: 151.305115\n",
      "====> Epoch: 1105 Average train loss: 222.3818\n",
      "====> Epoch: 1105 Average test loss: 906.8672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1106 [0/2589 (0%)]\tLoss: 211.323166\n",
      "Train Epoch: 1106 [300/2589 (12%)]\tLoss: 295.959778\n",
      "Train Epoch: 1106 [600/2589 (23%)]\tLoss: 209.163620\n",
      "Train Epoch: 1106 [900/2589 (35%)]\tLoss: 226.725830\n",
      "Train Epoch: 1106 [1200/2589 (46%)]\tLoss: 244.733185\n",
      "Train Epoch: 1106 [1500/2589 (58%)]\tLoss: 153.053604\n",
      "Train Epoch: 1106 [1800/2589 (70%)]\tLoss: 210.982101\n",
      "Train Epoch: 1106 [2100/2589 (81%)]\tLoss: 170.888641\n",
      "Train Epoch: 1106 [2400/2589 (93%)]\tLoss: 233.064194\n",
      "====> Epoch: 1106 Average train loss: 208.6035\n",
      "====> Epoch: 1106 Average test loss: 927.0768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1107 [0/2589 (0%)]\tLoss: 174.047363\n",
      "Train Epoch: 1107 [300/2589 (12%)]\tLoss: 284.742676\n",
      "Train Epoch: 1107 [600/2589 (23%)]\tLoss: 223.505890\n",
      "Train Epoch: 1107 [900/2589 (35%)]\tLoss: 314.490753\n",
      "Train Epoch: 1107 [1200/2589 (46%)]\tLoss: 176.100922\n",
      "Train Epoch: 1107 [1500/2589 (58%)]\tLoss: 198.098572\n",
      "Train Epoch: 1107 [1800/2589 (70%)]\tLoss: 224.825409\n",
      "Train Epoch: 1107 [2100/2589 (81%)]\tLoss: 281.085541\n",
      "Train Epoch: 1107 [2400/2589 (93%)]\tLoss: 164.203873\n",
      "====> Epoch: 1107 Average train loss: 223.5648\n",
      "====> Epoch: 1107 Average test loss: 906.3177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1108 [0/2589 (0%)]\tLoss: 229.463089\n",
      "Train Epoch: 1108 [300/2589 (12%)]\tLoss: 338.431213\n",
      "Train Epoch: 1108 [600/2589 (23%)]\tLoss: 268.844757\n",
      "Train Epoch: 1108 [900/2589 (35%)]\tLoss: 229.400803\n",
      "Train Epoch: 1108 [1200/2589 (46%)]\tLoss: 165.422775\n",
      "Train Epoch: 1108 [1500/2589 (58%)]\tLoss: 171.842804\n",
      "Train Epoch: 1108 [1800/2589 (70%)]\tLoss: 277.031219\n",
      "Train Epoch: 1108 [2100/2589 (81%)]\tLoss: 171.809845\n",
      "Train Epoch: 1108 [2400/2589 (93%)]\tLoss: 208.747452\n",
      "====> Epoch: 1108 Average train loss: 222.8107\n",
      "====> Epoch: 1108 Average test loss: 911.3465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1109 [0/2589 (0%)]\tLoss: 150.939590\n",
      "Train Epoch: 1109 [300/2589 (12%)]\tLoss: 196.081833\n",
      "Train Epoch: 1109 [600/2589 (23%)]\tLoss: 230.903549\n",
      "Train Epoch: 1109 [900/2589 (35%)]\tLoss: 153.377853\n",
      "Train Epoch: 1109 [1200/2589 (46%)]\tLoss: 156.839905\n",
      "Train Epoch: 1109 [1500/2589 (58%)]\tLoss: 178.335190\n",
      "Train Epoch: 1109 [1800/2589 (70%)]\tLoss: 177.981461\n",
      "Train Epoch: 1109 [2100/2589 (81%)]\tLoss: 364.135834\n",
      "Train Epoch: 1109 [2400/2589 (93%)]\tLoss: 213.542892\n",
      "====> Epoch: 1109 Average train loss: 219.5026\n",
      "====> Epoch: 1109 Average test loss: 920.8392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1110 [0/2589 (0%)]\tLoss: 314.827789\n",
      "Train Epoch: 1110 [300/2589 (12%)]\tLoss: 354.481110\n",
      "Train Epoch: 1110 [600/2589 (23%)]\tLoss: 168.151566\n",
      "Train Epoch: 1110 [900/2589 (35%)]\tLoss: 213.599289\n",
      "Train Epoch: 1110 [1200/2589 (46%)]\tLoss: 153.573654\n",
      "Train Epoch: 1110 [1500/2589 (58%)]\tLoss: 224.290146\n",
      "Train Epoch: 1110 [1800/2589 (70%)]\tLoss: 155.313217\n",
      "Train Epoch: 1110 [2100/2589 (81%)]\tLoss: 159.891830\n",
      "Train Epoch: 1110 [2400/2589 (93%)]\tLoss: 272.781677\n",
      "====> Epoch: 1110 Average train loss: 219.7329\n",
      "====> Epoch: 1110 Average test loss: 903.0948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1111 [0/2589 (0%)]\tLoss: 212.223114\n",
      "Train Epoch: 1111 [300/2589 (12%)]\tLoss: 183.981293\n",
      "Train Epoch: 1111 [600/2589 (23%)]\tLoss: 251.313797\n",
      "Train Epoch: 1111 [900/2589 (35%)]\tLoss: 241.093124\n",
      "Train Epoch: 1111 [1200/2589 (46%)]\tLoss: 223.450546\n",
      "Train Epoch: 1111 [1500/2589 (58%)]\tLoss: 241.724518\n",
      "Train Epoch: 1111 [1800/2589 (70%)]\tLoss: 227.159882\n",
      "Train Epoch: 1111 [2100/2589 (81%)]\tLoss: 244.949539\n",
      "Train Epoch: 1111 [2400/2589 (93%)]\tLoss: 192.120407\n",
      "====> Epoch: 1111 Average train loss: 218.1438\n",
      "====> Epoch: 1111 Average test loss: 902.5819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1112 [0/2589 (0%)]\tLoss: 153.628845\n",
      "Train Epoch: 1112 [300/2589 (12%)]\tLoss: 143.329300\n",
      "Train Epoch: 1112 [600/2589 (23%)]\tLoss: 137.861923\n",
      "Train Epoch: 1112 [900/2589 (35%)]\tLoss: 189.065857\n",
      "Train Epoch: 1112 [1200/2589 (46%)]\tLoss: 252.549103\n",
      "Train Epoch: 1112 [1500/2589 (58%)]\tLoss: 180.439880\n",
      "Train Epoch: 1112 [1800/2589 (70%)]\tLoss: 192.282013\n",
      "Train Epoch: 1112 [2100/2589 (81%)]\tLoss: 258.298706\n",
      "Train Epoch: 1112 [2400/2589 (93%)]\tLoss: 249.292801\n",
      "====> Epoch: 1112 Average train loss: 216.1637\n",
      "====> Epoch: 1112 Average test loss: 916.3276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1113 [0/2589 (0%)]\tLoss: 218.935379\n",
      "Train Epoch: 1113 [300/2589 (12%)]\tLoss: 324.567749\n",
      "Train Epoch: 1113 [600/2589 (23%)]\tLoss: 314.562347\n",
      "Train Epoch: 1113 [900/2589 (35%)]\tLoss: 347.612579\n",
      "Train Epoch: 1113 [1200/2589 (46%)]\tLoss: 175.834122\n",
      "Train Epoch: 1113 [1500/2589 (58%)]\tLoss: 152.561111\n",
      "Train Epoch: 1113 [1800/2589 (70%)]\tLoss: 175.677414\n",
      "Train Epoch: 1113 [2100/2589 (81%)]\tLoss: 196.145813\n",
      "Train Epoch: 1113 [2400/2589 (93%)]\tLoss: 181.816559\n",
      "====> Epoch: 1113 Average train loss: 220.3039\n",
      "====> Epoch: 1113 Average test loss: 908.1522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1114 [0/2589 (0%)]\tLoss: 209.080536\n",
      "Train Epoch: 1114 [300/2589 (12%)]\tLoss: 141.487564\n",
      "Train Epoch: 1114 [600/2589 (23%)]\tLoss: 202.336975\n",
      "Train Epoch: 1114 [900/2589 (35%)]\tLoss: 178.657074\n",
      "Train Epoch: 1114 [1200/2589 (46%)]\tLoss: 206.994980\n",
      "Train Epoch: 1114 [1500/2589 (58%)]\tLoss: 178.012695\n",
      "Train Epoch: 1114 [1800/2589 (70%)]\tLoss: 174.438553\n",
      "Train Epoch: 1114 [2100/2589 (81%)]\tLoss: 346.400269\n",
      "Train Epoch: 1114 [2400/2589 (93%)]\tLoss: 145.730469\n",
      "====> Epoch: 1114 Average train loss: 225.7668\n",
      "====> Epoch: 1114 Average test loss: 917.4346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1115 [0/2589 (0%)]\tLoss: 179.506760\n",
      "Train Epoch: 1115 [300/2589 (12%)]\tLoss: 191.670258\n",
      "Train Epoch: 1115 [600/2589 (23%)]\tLoss: 383.442169\n",
      "Train Epoch: 1115 [900/2589 (35%)]\tLoss: 221.417053\n",
      "Train Epoch: 1115 [1200/2589 (46%)]\tLoss: 358.874451\n",
      "Train Epoch: 1115 [1500/2589 (58%)]\tLoss: 217.829300\n",
      "Train Epoch: 1115 [1800/2589 (70%)]\tLoss: 325.249176\n",
      "Train Epoch: 1115 [2100/2589 (81%)]\tLoss: 154.386490\n",
      "Train Epoch: 1115 [2400/2589 (93%)]\tLoss: 187.107086\n",
      "====> Epoch: 1115 Average train loss: 231.6462\n",
      "====> Epoch: 1115 Average test loss: 918.2662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1116 [0/2589 (0%)]\tLoss: 153.647736\n",
      "Train Epoch: 1116 [300/2589 (12%)]\tLoss: 421.132111\n",
      "Train Epoch: 1116 [600/2589 (23%)]\tLoss: 209.684280\n",
      "Train Epoch: 1116 [900/2589 (35%)]\tLoss: 212.799057\n",
      "Train Epoch: 1116 [1200/2589 (46%)]\tLoss: 136.196838\n",
      "Train Epoch: 1116 [1500/2589 (58%)]\tLoss: 241.895081\n",
      "Train Epoch: 1116 [1800/2589 (70%)]\tLoss: 196.762634\n",
      "Train Epoch: 1116 [2100/2589 (81%)]\tLoss: 165.827103\n",
      "Train Epoch: 1116 [2400/2589 (93%)]\tLoss: 140.745697\n",
      "====> Epoch: 1116 Average train loss: 220.0238\n",
      "====> Epoch: 1116 Average test loss: 911.5599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1117 [0/2589 (0%)]\tLoss: 233.522552\n",
      "Train Epoch: 1117 [300/2589 (12%)]\tLoss: 190.696442\n",
      "Train Epoch: 1117 [600/2589 (23%)]\tLoss: 195.410507\n",
      "Train Epoch: 1117 [900/2589 (35%)]\tLoss: 183.526184\n",
      "Train Epoch: 1117 [1200/2589 (46%)]\tLoss: 182.653915\n",
      "Train Epoch: 1117 [1500/2589 (58%)]\tLoss: 231.840302\n",
      "Train Epoch: 1117 [1800/2589 (70%)]\tLoss: 206.654129\n",
      "Train Epoch: 1117 [2100/2589 (81%)]\tLoss: 293.855042\n",
      "Train Epoch: 1117 [2400/2589 (93%)]\tLoss: 207.907455\n",
      "====> Epoch: 1117 Average train loss: 215.9239\n",
      "====> Epoch: 1117 Average test loss: 910.5534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1118 [0/2589 (0%)]\tLoss: 194.110184\n",
      "Train Epoch: 1118 [300/2589 (12%)]\tLoss: 231.810089\n",
      "Train Epoch: 1118 [600/2589 (23%)]\tLoss: 130.436951\n",
      "Train Epoch: 1118 [900/2589 (35%)]\tLoss: 199.092712\n",
      "Train Epoch: 1118 [1200/2589 (46%)]\tLoss: 207.294128\n",
      "Train Epoch: 1118 [1500/2589 (58%)]\tLoss: 208.915421\n",
      "Train Epoch: 1118 [1800/2589 (70%)]\tLoss: 207.994232\n",
      "Train Epoch: 1118 [2100/2589 (81%)]\tLoss: 217.702286\n",
      "Train Epoch: 1118 [2400/2589 (93%)]\tLoss: 179.085281\n",
      "====> Epoch: 1118 Average train loss: 216.1424\n",
      "====> Epoch: 1118 Average test loss: 908.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1119 [0/2589 (0%)]\tLoss: 261.198792\n",
      "Train Epoch: 1119 [300/2589 (12%)]\tLoss: 329.239105\n",
      "Train Epoch: 1119 [600/2589 (23%)]\tLoss: 166.787155\n",
      "Train Epoch: 1119 [900/2589 (35%)]\tLoss: 212.580536\n",
      "Train Epoch: 1119 [1200/2589 (46%)]\tLoss: 164.340775\n",
      "Train Epoch: 1119 [1500/2589 (58%)]\tLoss: 285.813354\n",
      "Train Epoch: 1119 [1800/2589 (70%)]\tLoss: 163.817154\n",
      "Train Epoch: 1119 [2100/2589 (81%)]\tLoss: 307.813934\n",
      "Train Epoch: 1119 [2400/2589 (93%)]\tLoss: 167.986877\n",
      "====> Epoch: 1119 Average train loss: 217.1150\n",
      "====> Epoch: 1119 Average test loss: 917.4935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1120 [0/2589 (0%)]\tLoss: 170.692474\n",
      "Train Epoch: 1120 [300/2589 (12%)]\tLoss: 205.364746\n",
      "Train Epoch: 1120 [600/2589 (23%)]\tLoss: 263.498169\n",
      "Train Epoch: 1120 [900/2589 (35%)]\tLoss: 199.847137\n",
      "Train Epoch: 1120 [1200/2589 (46%)]\tLoss: 139.355698\n",
      "Train Epoch: 1120 [1500/2589 (58%)]\tLoss: 186.972855\n",
      "Train Epoch: 1120 [1800/2589 (70%)]\tLoss: 312.017517\n",
      "Train Epoch: 1120 [2100/2589 (81%)]\tLoss: 203.369415\n",
      "Train Epoch: 1120 [2400/2589 (93%)]\tLoss: 326.691467\n",
      "====> Epoch: 1120 Average train loss: 218.5671\n",
      "====> Epoch: 1120 Average test loss: 914.7826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1121 [0/2589 (0%)]\tLoss: 212.616470\n",
      "Train Epoch: 1121 [300/2589 (12%)]\tLoss: 192.738083\n",
      "Train Epoch: 1121 [600/2589 (23%)]\tLoss: 191.079422\n",
      "Train Epoch: 1121 [900/2589 (35%)]\tLoss: 171.925430\n",
      "Train Epoch: 1121 [1200/2589 (46%)]\tLoss: 179.950623\n",
      "Train Epoch: 1121 [1500/2589 (58%)]\tLoss: 225.728027\n",
      "Train Epoch: 1121 [1800/2589 (70%)]\tLoss: 332.187897\n",
      "Train Epoch: 1121 [2100/2589 (81%)]\tLoss: 323.956818\n",
      "Train Epoch: 1121 [2400/2589 (93%)]\tLoss: 283.965515\n",
      "====> Epoch: 1121 Average train loss: 215.1694\n",
      "====> Epoch: 1121 Average test loss: 905.3579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1122 [0/2589 (0%)]\tLoss: 304.492126\n",
      "Train Epoch: 1122 [300/2589 (12%)]\tLoss: 189.893005\n",
      "Train Epoch: 1122 [600/2589 (23%)]\tLoss: 175.968689\n",
      "Train Epoch: 1122 [900/2589 (35%)]\tLoss: 309.681366\n",
      "Train Epoch: 1122 [1200/2589 (46%)]\tLoss: 232.180344\n",
      "Train Epoch: 1122 [1500/2589 (58%)]\tLoss: 122.348869\n",
      "Train Epoch: 1122 [1800/2589 (70%)]\tLoss: 200.412338\n",
      "Train Epoch: 1122 [2100/2589 (81%)]\tLoss: 166.880463\n",
      "Train Epoch: 1122 [2400/2589 (93%)]\tLoss: 144.472626\n",
      "====> Epoch: 1122 Average train loss: 222.0061\n",
      "====> Epoch: 1122 Average test loss: 905.5162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1123 [0/2589 (0%)]\tLoss: 319.286255\n",
      "Train Epoch: 1123 [300/2589 (12%)]\tLoss: 118.428146\n",
      "Train Epoch: 1123 [600/2589 (23%)]\tLoss: 367.596649\n",
      "Train Epoch: 1123 [900/2589 (35%)]\tLoss: 293.653412\n",
      "Train Epoch: 1123 [1200/2589 (46%)]\tLoss: 183.908188\n",
      "Train Epoch: 1123 [1500/2589 (58%)]\tLoss: 209.618515\n",
      "Train Epoch: 1123 [1800/2589 (70%)]\tLoss: 185.306290\n",
      "Train Epoch: 1123 [2100/2589 (81%)]\tLoss: 194.574188\n",
      "Train Epoch: 1123 [2400/2589 (93%)]\tLoss: 186.709732\n",
      "====> Epoch: 1123 Average train loss: 224.9929\n",
      "====> Epoch: 1123 Average test loss: 904.0728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1124 [0/2589 (0%)]\tLoss: 166.207855\n",
      "Train Epoch: 1124 [300/2589 (12%)]\tLoss: 252.805450\n",
      "Train Epoch: 1124 [600/2589 (23%)]\tLoss: 296.083618\n",
      "Train Epoch: 1124 [900/2589 (35%)]\tLoss: 278.711639\n",
      "Train Epoch: 1124 [1200/2589 (46%)]\tLoss: 202.350006\n",
      "Train Epoch: 1124 [1500/2589 (58%)]\tLoss: 158.106186\n",
      "Train Epoch: 1124 [1800/2589 (70%)]\tLoss: 219.408264\n",
      "Train Epoch: 1124 [2100/2589 (81%)]\tLoss: 153.724564\n",
      "Train Epoch: 1124 [2400/2589 (93%)]\tLoss: 176.346817\n",
      "====> Epoch: 1124 Average train loss: 216.0160\n",
      "====> Epoch: 1124 Average test loss: 910.3226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1125 [0/2589 (0%)]\tLoss: 247.612808\n",
      "Train Epoch: 1125 [300/2589 (12%)]\tLoss: 234.324692\n",
      "Train Epoch: 1125 [600/2589 (23%)]\tLoss: 244.048676\n",
      "Train Epoch: 1125 [900/2589 (35%)]\tLoss: 151.037399\n",
      "Train Epoch: 1125 [1200/2589 (46%)]\tLoss: 251.645004\n",
      "Train Epoch: 1125 [1500/2589 (58%)]\tLoss: 177.322037\n",
      "Train Epoch: 1125 [1800/2589 (70%)]\tLoss: 213.968399\n",
      "Train Epoch: 1125 [2100/2589 (81%)]\tLoss: 202.675980\n",
      "Train Epoch: 1125 [2400/2589 (93%)]\tLoss: 134.243301\n",
      "====> Epoch: 1125 Average train loss: 220.8224\n",
      "====> Epoch: 1125 Average test loss: 922.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1126 [0/2589 (0%)]\tLoss: 215.657288\n",
      "Train Epoch: 1126 [300/2589 (12%)]\tLoss: 205.106522\n",
      "Train Epoch: 1126 [600/2589 (23%)]\tLoss: 147.432083\n",
      "Train Epoch: 1126 [900/2589 (35%)]\tLoss: 204.271255\n",
      "Train Epoch: 1126 [1200/2589 (46%)]\tLoss: 241.642395\n",
      "Train Epoch: 1126 [1500/2589 (58%)]\tLoss: 142.202652\n",
      "Train Epoch: 1126 [1800/2589 (70%)]\tLoss: 254.711517\n",
      "Train Epoch: 1126 [2100/2589 (81%)]\tLoss: 178.496124\n",
      "Train Epoch: 1126 [2400/2589 (93%)]\tLoss: 212.977188\n",
      "====> Epoch: 1126 Average train loss: 227.2134\n",
      "====> Epoch: 1126 Average test loss: 923.1268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1127 [0/2589 (0%)]\tLoss: 206.874741\n",
      "Train Epoch: 1127 [300/2589 (12%)]\tLoss: 192.121780\n",
      "Train Epoch: 1127 [600/2589 (23%)]\tLoss: 203.926575\n",
      "Train Epoch: 1127 [900/2589 (35%)]\tLoss: 259.865631\n",
      "Train Epoch: 1127 [1200/2589 (46%)]\tLoss: 180.589996\n",
      "Train Epoch: 1127 [1500/2589 (58%)]\tLoss: 358.197388\n",
      "Train Epoch: 1127 [1800/2589 (70%)]\tLoss: 207.109329\n",
      "Train Epoch: 1127 [2100/2589 (81%)]\tLoss: 234.533615\n",
      "Train Epoch: 1127 [2400/2589 (93%)]\tLoss: 175.655563\n",
      "====> Epoch: 1127 Average train loss: 225.5583\n",
      "====> Epoch: 1127 Average test loss: 913.8472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1128 [0/2589 (0%)]\tLoss: 207.036530\n",
      "Train Epoch: 1128 [300/2589 (12%)]\tLoss: 163.212143\n",
      "Train Epoch: 1128 [600/2589 (23%)]\tLoss: 300.112274\n",
      "Train Epoch: 1128 [900/2589 (35%)]\tLoss: 196.899765\n",
      "Train Epoch: 1128 [1200/2589 (46%)]\tLoss: 251.746078\n",
      "Train Epoch: 1128 [1500/2589 (58%)]\tLoss: 172.750504\n",
      "Train Epoch: 1128 [1800/2589 (70%)]\tLoss: 192.470413\n",
      "Train Epoch: 1128 [2100/2589 (81%)]\tLoss: 281.637299\n",
      "Train Epoch: 1128 [2400/2589 (93%)]\tLoss: 232.367188\n",
      "====> Epoch: 1128 Average train loss: 210.7707\n",
      "====> Epoch: 1128 Average test loss: 911.7891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1129 [0/2589 (0%)]\tLoss: 184.989349\n",
      "Train Epoch: 1129 [300/2589 (12%)]\tLoss: 196.077850\n",
      "Train Epoch: 1129 [600/2589 (23%)]\tLoss: 440.720581\n",
      "Train Epoch: 1129 [900/2589 (35%)]\tLoss: 216.807816\n",
      "Train Epoch: 1129 [1200/2589 (46%)]\tLoss: 192.479385\n",
      "Train Epoch: 1129 [1500/2589 (58%)]\tLoss: 231.081741\n",
      "Train Epoch: 1129 [1800/2589 (70%)]\tLoss: 203.982605\n",
      "Train Epoch: 1129 [2100/2589 (81%)]\tLoss: 224.597504\n",
      "Train Epoch: 1129 [2400/2589 (93%)]\tLoss: 239.655457\n",
      "====> Epoch: 1129 Average train loss: 212.7316\n",
      "====> Epoch: 1129 Average test loss: 906.2248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1130 [0/2589 (0%)]\tLoss: 199.596741\n",
      "Train Epoch: 1130 [300/2589 (12%)]\tLoss: 150.485580\n",
      "Train Epoch: 1130 [600/2589 (23%)]\tLoss: 187.866241\n",
      "Train Epoch: 1130 [900/2589 (35%)]\tLoss: 235.313187\n",
      "Train Epoch: 1130 [1200/2589 (46%)]\tLoss: 161.886261\n",
      "Train Epoch: 1130 [1500/2589 (58%)]\tLoss: 155.500641\n",
      "Train Epoch: 1130 [1800/2589 (70%)]\tLoss: 396.927765\n",
      "Train Epoch: 1130 [2100/2589 (81%)]\tLoss: 187.562180\n",
      "Train Epoch: 1130 [2400/2589 (93%)]\tLoss: 237.676895\n",
      "====> Epoch: 1130 Average train loss: 207.3011\n",
      "====> Epoch: 1130 Average test loss: 918.0892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1131 [0/2589 (0%)]\tLoss: 245.212494\n",
      "Train Epoch: 1131 [300/2589 (12%)]\tLoss: 258.235779\n",
      "Train Epoch: 1131 [600/2589 (23%)]\tLoss: 202.419342\n",
      "Train Epoch: 1131 [900/2589 (35%)]\tLoss: 197.491989\n",
      "Train Epoch: 1131 [1200/2589 (46%)]\tLoss: 148.552643\n",
      "Train Epoch: 1131 [1500/2589 (58%)]\tLoss: 254.837830\n",
      "Train Epoch: 1131 [1800/2589 (70%)]\tLoss: 227.096252\n",
      "Train Epoch: 1131 [2100/2589 (81%)]\tLoss: 196.511322\n",
      "Train Epoch: 1131 [2400/2589 (93%)]\tLoss: 163.792084\n",
      "====> Epoch: 1131 Average train loss: 204.5425\n",
      "====> Epoch: 1131 Average test loss: 913.6701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1132 [0/2589 (0%)]\tLoss: 228.482620\n",
      "Train Epoch: 1132 [300/2589 (12%)]\tLoss: 213.071609\n",
      "Train Epoch: 1132 [600/2589 (23%)]\tLoss: 270.627777\n",
      "Train Epoch: 1132 [900/2589 (35%)]\tLoss: 335.653290\n",
      "Train Epoch: 1132 [1200/2589 (46%)]\tLoss: 293.318024\n",
      "Train Epoch: 1132 [1500/2589 (58%)]\tLoss: 208.554001\n",
      "Train Epoch: 1132 [1800/2589 (70%)]\tLoss: 390.755920\n",
      "Train Epoch: 1132 [2100/2589 (81%)]\tLoss: 303.947174\n",
      "Train Epoch: 1132 [2400/2589 (93%)]\tLoss: 148.959152\n",
      "====> Epoch: 1132 Average train loss: 214.4225\n",
      "====> Epoch: 1132 Average test loss: 895.8875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1133 [0/2589 (0%)]\tLoss: 170.178650\n",
      "Train Epoch: 1133 [300/2589 (12%)]\tLoss: 190.000778\n",
      "Train Epoch: 1133 [600/2589 (23%)]\tLoss: 299.199280\n",
      "Train Epoch: 1133 [900/2589 (35%)]\tLoss: 237.839172\n",
      "Train Epoch: 1133 [1200/2589 (46%)]\tLoss: 181.692062\n",
      "Train Epoch: 1133 [1500/2589 (58%)]\tLoss: 213.284485\n",
      "Train Epoch: 1133 [1800/2589 (70%)]\tLoss: 249.989029\n",
      "Train Epoch: 1133 [2100/2589 (81%)]\tLoss: 199.531799\n",
      "Train Epoch: 1133 [2400/2589 (93%)]\tLoss: 173.502289\n",
      "====> Epoch: 1133 Average train loss: 214.2695\n",
      "====> Epoch: 1133 Average test loss: 905.2574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1134 [0/2589 (0%)]\tLoss: 202.004578\n",
      "Train Epoch: 1134 [300/2589 (12%)]\tLoss: 207.739899\n",
      "Train Epoch: 1134 [600/2589 (23%)]\tLoss: 291.076660\n",
      "Train Epoch: 1134 [900/2589 (35%)]\tLoss: 208.371811\n",
      "Train Epoch: 1134 [1200/2589 (46%)]\tLoss: 205.746277\n",
      "Train Epoch: 1134 [1500/2589 (58%)]\tLoss: 184.232452\n",
      "Train Epoch: 1134 [1800/2589 (70%)]\tLoss: 128.256989\n",
      "Train Epoch: 1134 [2100/2589 (81%)]\tLoss: 140.036102\n",
      "Train Epoch: 1134 [2400/2589 (93%)]\tLoss: 160.205475\n",
      "====> Epoch: 1134 Average train loss: 209.4213\n",
      "====> Epoch: 1134 Average test loss: 889.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1135 [0/2589 (0%)]\tLoss: 182.382019\n",
      "Train Epoch: 1135 [300/2589 (12%)]\tLoss: 180.384933\n",
      "Train Epoch: 1135 [600/2589 (23%)]\tLoss: 140.875580\n",
      "Train Epoch: 1135 [900/2589 (35%)]\tLoss: 288.612427\n",
      "Train Epoch: 1135 [1200/2589 (46%)]\tLoss: 230.211426\n",
      "Train Epoch: 1135 [1500/2589 (58%)]\tLoss: 187.970612\n",
      "Train Epoch: 1135 [1800/2589 (70%)]\tLoss: 323.865906\n",
      "Train Epoch: 1135 [2100/2589 (81%)]\tLoss: 187.108047\n",
      "Train Epoch: 1135 [2400/2589 (93%)]\tLoss: 211.670853\n",
      "====> Epoch: 1135 Average train loss: 216.4636\n",
      "====> Epoch: 1135 Average test loss: 916.5923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1136 [0/2589 (0%)]\tLoss: 161.452713\n",
      "Train Epoch: 1136 [300/2589 (12%)]\tLoss: 217.711746\n",
      "Train Epoch: 1136 [600/2589 (23%)]\tLoss: 192.719101\n",
      "Train Epoch: 1136 [900/2589 (35%)]\tLoss: 256.787262\n",
      "Train Epoch: 1136 [1200/2589 (46%)]\tLoss: 336.838043\n",
      "Train Epoch: 1136 [1500/2589 (58%)]\tLoss: 344.013306\n",
      "Train Epoch: 1136 [1800/2589 (70%)]\tLoss: 193.233246\n",
      "Train Epoch: 1136 [2100/2589 (81%)]\tLoss: 164.058990\n",
      "Train Epoch: 1136 [2400/2589 (93%)]\tLoss: 214.896042\n",
      "====> Epoch: 1136 Average train loss: 219.8677\n",
      "====> Epoch: 1136 Average test loss: 924.9420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1137 [0/2589 (0%)]\tLoss: 138.566299\n",
      "Train Epoch: 1137 [300/2589 (12%)]\tLoss: 159.847992\n",
      "Train Epoch: 1137 [600/2589 (23%)]\tLoss: 308.025665\n",
      "Train Epoch: 1137 [900/2589 (35%)]\tLoss: 232.982880\n",
      "Train Epoch: 1137 [1200/2589 (46%)]\tLoss: 248.571243\n",
      "Train Epoch: 1137 [1500/2589 (58%)]\tLoss: 174.524979\n",
      "Train Epoch: 1137 [1800/2589 (70%)]\tLoss: 268.327942\n",
      "Train Epoch: 1137 [2100/2589 (81%)]\tLoss: 285.044952\n",
      "Train Epoch: 1137 [2400/2589 (93%)]\tLoss: 356.644409\n",
      "====> Epoch: 1137 Average train loss: 212.4514\n",
      "====> Epoch: 1137 Average test loss: 908.6689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1138 [0/2589 (0%)]\tLoss: 204.738602\n",
      "Train Epoch: 1138 [300/2589 (12%)]\tLoss: 207.259659\n",
      "Train Epoch: 1138 [600/2589 (23%)]\tLoss: 171.561462\n",
      "Train Epoch: 1138 [900/2589 (35%)]\tLoss: 246.039734\n",
      "Train Epoch: 1138 [1200/2589 (46%)]\tLoss: 164.255508\n",
      "Train Epoch: 1138 [1500/2589 (58%)]\tLoss: 223.449951\n",
      "Train Epoch: 1138 [1800/2589 (70%)]\tLoss: 378.765839\n",
      "Train Epoch: 1138 [2100/2589 (81%)]\tLoss: 232.847336\n",
      "Train Epoch: 1138 [2400/2589 (93%)]\tLoss: 150.250168\n",
      "====> Epoch: 1138 Average train loss: 217.3963\n",
      "====> Epoch: 1138 Average test loss: 926.3920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1139 [0/2589 (0%)]\tLoss: 168.817795\n",
      "Train Epoch: 1139 [300/2589 (12%)]\tLoss: 170.354736\n",
      "Train Epoch: 1139 [600/2589 (23%)]\tLoss: 415.936188\n",
      "Train Epoch: 1139 [900/2589 (35%)]\tLoss: 221.117767\n",
      "Train Epoch: 1139 [1200/2589 (46%)]\tLoss: 208.530930\n",
      "Train Epoch: 1139 [1500/2589 (58%)]\tLoss: 352.711121\n",
      "Train Epoch: 1139 [1800/2589 (70%)]\tLoss: 244.420975\n",
      "Train Epoch: 1139 [2100/2589 (81%)]\tLoss: 175.111008\n",
      "Train Epoch: 1139 [2400/2589 (93%)]\tLoss: 137.426727\n",
      "====> Epoch: 1139 Average train loss: 221.5083\n",
      "====> Epoch: 1139 Average test loss: 926.7634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1140 [0/2589 (0%)]\tLoss: 310.353943\n",
      "Train Epoch: 1140 [300/2589 (12%)]\tLoss: 236.983826\n",
      "Train Epoch: 1140 [600/2589 (23%)]\tLoss: 181.508728\n",
      "Train Epoch: 1140 [900/2589 (35%)]\tLoss: 340.730133\n",
      "Train Epoch: 1140 [1200/2589 (46%)]\tLoss: 218.071152\n",
      "Train Epoch: 1140 [1500/2589 (58%)]\tLoss: 273.550690\n",
      "Train Epoch: 1140 [1800/2589 (70%)]\tLoss: 212.157745\n",
      "Train Epoch: 1140 [2100/2589 (81%)]\tLoss: 345.509949\n",
      "Train Epoch: 1140 [2400/2589 (93%)]\tLoss: 177.498749\n",
      "====> Epoch: 1140 Average train loss: 217.9494\n",
      "====> Epoch: 1140 Average test loss: 924.4494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1141 [0/2589 (0%)]\tLoss: 171.713135\n",
      "Train Epoch: 1141 [300/2589 (12%)]\tLoss: 207.288605\n",
      "Train Epoch: 1141 [600/2589 (23%)]\tLoss: 283.477020\n",
      "Train Epoch: 1141 [900/2589 (35%)]\tLoss: 164.127380\n",
      "Train Epoch: 1141 [1200/2589 (46%)]\tLoss: 287.207855\n",
      "Train Epoch: 1141 [1500/2589 (58%)]\tLoss: 154.893280\n",
      "Train Epoch: 1141 [1800/2589 (70%)]\tLoss: 301.746735\n",
      "Train Epoch: 1141 [2100/2589 (81%)]\tLoss: 239.227158\n",
      "Train Epoch: 1141 [2400/2589 (93%)]\tLoss: 228.458588\n",
      "====> Epoch: 1141 Average train loss: 214.2354\n",
      "====> Epoch: 1141 Average test loss: 910.6194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1142 [0/2589 (0%)]\tLoss: 398.173309\n",
      "Train Epoch: 1142 [300/2589 (12%)]\tLoss: 243.077606\n",
      "Train Epoch: 1142 [600/2589 (23%)]\tLoss: 235.884064\n",
      "Train Epoch: 1142 [900/2589 (35%)]\tLoss: 283.550995\n",
      "Train Epoch: 1142 [1200/2589 (46%)]\tLoss: 174.746902\n",
      "Train Epoch: 1142 [1500/2589 (58%)]\tLoss: 191.722656\n",
      "Train Epoch: 1142 [1800/2589 (70%)]\tLoss: 205.105606\n",
      "Train Epoch: 1142 [2100/2589 (81%)]\tLoss: 301.216675\n",
      "Train Epoch: 1142 [2400/2589 (93%)]\tLoss: 278.792511\n",
      "====> Epoch: 1142 Average train loss: 216.6916\n",
      "====> Epoch: 1142 Average test loss: 911.5762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1143 [0/2589 (0%)]\tLoss: 220.493713\n",
      "Train Epoch: 1143 [300/2589 (12%)]\tLoss: 207.804749\n",
      "Train Epoch: 1143 [600/2589 (23%)]\tLoss: 205.084991\n",
      "Train Epoch: 1143 [900/2589 (35%)]\tLoss: 187.067657\n",
      "Train Epoch: 1143 [1200/2589 (46%)]\tLoss: 157.193863\n",
      "Train Epoch: 1143 [1500/2589 (58%)]\tLoss: 331.597076\n",
      "Train Epoch: 1143 [1800/2589 (70%)]\tLoss: 200.866882\n",
      "Train Epoch: 1143 [2100/2589 (81%)]\tLoss: 237.950958\n",
      "Train Epoch: 1143 [2400/2589 (93%)]\tLoss: 252.032425\n",
      "====> Epoch: 1143 Average train loss: 232.6964\n",
      "====> Epoch: 1143 Average test loss: 895.4756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1144 [0/2589 (0%)]\tLoss: 194.842865\n",
      "Train Epoch: 1144 [300/2589 (12%)]\tLoss: 242.376053\n",
      "Train Epoch: 1144 [600/2589 (23%)]\tLoss: 179.265228\n",
      "Train Epoch: 1144 [900/2589 (35%)]\tLoss: 162.009415\n",
      "Train Epoch: 1144 [1200/2589 (46%)]\tLoss: 183.071426\n",
      "Train Epoch: 1144 [1500/2589 (58%)]\tLoss: 217.966965\n",
      "Train Epoch: 1144 [1800/2589 (70%)]\tLoss: 297.115173\n",
      "Train Epoch: 1144 [2100/2589 (81%)]\tLoss: 200.308456\n",
      "Train Epoch: 1144 [2400/2589 (93%)]\tLoss: 166.150345\n",
      "====> Epoch: 1144 Average train loss: 231.7312\n",
      "====> Epoch: 1144 Average test loss: 918.5427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1145 [0/2589 (0%)]\tLoss: 142.655014\n",
      "Train Epoch: 1145 [300/2589 (12%)]\tLoss: 183.082352\n",
      "Train Epoch: 1145 [600/2589 (23%)]\tLoss: 308.347443\n",
      "Train Epoch: 1145 [900/2589 (35%)]\tLoss: 151.029922\n",
      "Train Epoch: 1145 [1200/2589 (46%)]\tLoss: 189.666855\n",
      "Train Epoch: 1145 [1500/2589 (58%)]\tLoss: 273.830658\n",
      "Train Epoch: 1145 [1800/2589 (70%)]\tLoss: 186.132614\n",
      "Train Epoch: 1145 [2100/2589 (81%)]\tLoss: 216.903275\n",
      "Train Epoch: 1145 [2400/2589 (93%)]\tLoss: 186.048676\n",
      "====> Epoch: 1145 Average train loss: 209.7313\n",
      "====> Epoch: 1145 Average test loss: 914.1965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1146 [0/2589 (0%)]\tLoss: 186.141464\n",
      "Train Epoch: 1146 [300/2589 (12%)]\tLoss: 315.177551\n",
      "Train Epoch: 1146 [600/2589 (23%)]\tLoss: 194.435013\n",
      "Train Epoch: 1146 [900/2589 (35%)]\tLoss: 181.236893\n",
      "Train Epoch: 1146 [1200/2589 (46%)]\tLoss: 165.409912\n",
      "Train Epoch: 1146 [1500/2589 (58%)]\tLoss: 141.420059\n",
      "Train Epoch: 1146 [1800/2589 (70%)]\tLoss: 152.338440\n",
      "Train Epoch: 1146 [2100/2589 (81%)]\tLoss: 258.068359\n",
      "Train Epoch: 1146 [2400/2589 (93%)]\tLoss: 242.707657\n",
      "====> Epoch: 1146 Average train loss: 217.5351\n",
      "====> Epoch: 1146 Average test loss: 929.4667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1147 [0/2589 (0%)]\tLoss: 206.503143\n",
      "Train Epoch: 1147 [300/2589 (12%)]\tLoss: 164.481461\n",
      "Train Epoch: 1147 [600/2589 (23%)]\tLoss: 196.952148\n",
      "Train Epoch: 1147 [900/2589 (35%)]\tLoss: 154.643295\n",
      "Train Epoch: 1147 [1200/2589 (46%)]\tLoss: 303.852264\n",
      "Train Epoch: 1147 [1500/2589 (58%)]\tLoss: 135.675995\n",
      "Train Epoch: 1147 [1800/2589 (70%)]\tLoss: 263.449768\n",
      "Train Epoch: 1147 [2100/2589 (81%)]\tLoss: 222.939316\n",
      "Train Epoch: 1147 [2400/2589 (93%)]\tLoss: 229.079758\n",
      "====> Epoch: 1147 Average train loss: 219.0665\n",
      "====> Epoch: 1147 Average test loss: 909.4369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1148 [0/2589 (0%)]\tLoss: 175.473114\n",
      "Train Epoch: 1148 [300/2589 (12%)]\tLoss: 138.931641\n",
      "Train Epoch: 1148 [600/2589 (23%)]\tLoss: 385.222992\n",
      "Train Epoch: 1148 [900/2589 (35%)]\tLoss: 187.560272\n",
      "Train Epoch: 1148 [1200/2589 (46%)]\tLoss: 302.682770\n",
      "Train Epoch: 1148 [1500/2589 (58%)]\tLoss: 157.735901\n",
      "Train Epoch: 1148 [1800/2589 (70%)]\tLoss: 213.466156\n",
      "Train Epoch: 1148 [2100/2589 (81%)]\tLoss: 183.348572\n",
      "Train Epoch: 1148 [2400/2589 (93%)]\tLoss: 160.473785\n",
      "====> Epoch: 1148 Average train loss: 213.5992\n",
      "====> Epoch: 1148 Average test loss: 914.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1149 [0/2589 (0%)]\tLoss: 367.564850\n",
      "Train Epoch: 1149 [300/2589 (12%)]\tLoss: 214.681503\n",
      "Train Epoch: 1149 [600/2589 (23%)]\tLoss: 252.293732\n",
      "Train Epoch: 1149 [900/2589 (35%)]\tLoss: 175.660675\n",
      "Train Epoch: 1149 [1200/2589 (46%)]\tLoss: 187.169083\n",
      "Train Epoch: 1149 [1500/2589 (58%)]\tLoss: 185.719482\n",
      "Train Epoch: 1149 [1800/2589 (70%)]\tLoss: 157.517990\n",
      "Train Epoch: 1149 [2100/2589 (81%)]\tLoss: 195.565079\n",
      "Train Epoch: 1149 [2400/2589 (93%)]\tLoss: 171.555939\n",
      "====> Epoch: 1149 Average train loss: 211.9217\n",
      "====> Epoch: 1149 Average test loss: 911.4259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1150 [0/2589 (0%)]\tLoss: 231.342834\n",
      "Train Epoch: 1150 [300/2589 (12%)]\tLoss: 167.289017\n",
      "Train Epoch: 1150 [600/2589 (23%)]\tLoss: 279.041077\n",
      "Train Epoch: 1150 [900/2589 (35%)]\tLoss: 267.759521\n",
      "Train Epoch: 1150 [1200/2589 (46%)]\tLoss: 177.523682\n",
      "Train Epoch: 1150 [1500/2589 (58%)]\tLoss: 230.888046\n",
      "Train Epoch: 1150 [1800/2589 (70%)]\tLoss: 208.502991\n",
      "Train Epoch: 1150 [2100/2589 (81%)]\tLoss: 223.667709\n",
      "Train Epoch: 1150 [2400/2589 (93%)]\tLoss: 305.422028\n",
      "====> Epoch: 1150 Average train loss: 218.5144\n",
      "====> Epoch: 1150 Average test loss: 913.3232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1151 [0/2589 (0%)]\tLoss: 161.023697\n",
      "Train Epoch: 1151 [300/2589 (12%)]\tLoss: 233.105911\n",
      "Train Epoch: 1151 [600/2589 (23%)]\tLoss: 562.723022\n",
      "Train Epoch: 1151 [900/2589 (35%)]\tLoss: 147.478088\n",
      "Train Epoch: 1151 [1200/2589 (46%)]\tLoss: 215.474899\n",
      "Train Epoch: 1151 [1500/2589 (58%)]\tLoss: 189.146988\n",
      "Train Epoch: 1151 [1800/2589 (70%)]\tLoss: 181.237564\n",
      "Train Epoch: 1151 [2100/2589 (81%)]\tLoss: 147.963959\n",
      "Train Epoch: 1151 [2400/2589 (93%)]\tLoss: 150.950623\n",
      "====> Epoch: 1151 Average train loss: 207.2630\n",
      "====> Epoch: 1151 Average test loss: 903.9553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1152 [0/2589 (0%)]\tLoss: 180.578094\n",
      "Train Epoch: 1152 [300/2589 (12%)]\tLoss: 234.205505\n",
      "Train Epoch: 1152 [600/2589 (23%)]\tLoss: 253.161972\n",
      "Train Epoch: 1152 [900/2589 (35%)]\tLoss: 395.108582\n",
      "Train Epoch: 1152 [1200/2589 (46%)]\tLoss: 183.295959\n",
      "Train Epoch: 1152 [1500/2589 (58%)]\tLoss: 169.954407\n",
      "Train Epoch: 1152 [1800/2589 (70%)]\tLoss: 205.298416\n",
      "Train Epoch: 1152 [2100/2589 (81%)]\tLoss: 243.442078\n",
      "Train Epoch: 1152 [2400/2589 (93%)]\tLoss: 271.863708\n",
      "====> Epoch: 1152 Average train loss: 225.6704\n",
      "====> Epoch: 1152 Average test loss: 907.7095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1153 [0/2589 (0%)]\tLoss: 275.482544\n",
      "Train Epoch: 1153 [300/2589 (12%)]\tLoss: 347.016022\n",
      "Train Epoch: 1153 [600/2589 (23%)]\tLoss: 262.828888\n",
      "Train Epoch: 1153 [900/2589 (35%)]\tLoss: 168.808243\n",
      "Train Epoch: 1153 [1200/2589 (46%)]\tLoss: 219.808823\n",
      "Train Epoch: 1153 [1500/2589 (58%)]\tLoss: 221.478714\n",
      "Train Epoch: 1153 [1800/2589 (70%)]\tLoss: 158.821381\n",
      "Train Epoch: 1153 [2100/2589 (81%)]\tLoss: 155.592453\n",
      "Train Epoch: 1153 [2400/2589 (93%)]\tLoss: 227.931412\n",
      "====> Epoch: 1153 Average train loss: 219.1602\n",
      "====> Epoch: 1153 Average test loss: 916.0449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1154 [0/2589 (0%)]\tLoss: 135.587189\n",
      "Train Epoch: 1154 [300/2589 (12%)]\tLoss: 157.126511\n",
      "Train Epoch: 1154 [600/2589 (23%)]\tLoss: 216.388123\n",
      "Train Epoch: 1154 [900/2589 (35%)]\tLoss: 194.999771\n",
      "Train Epoch: 1154 [1200/2589 (46%)]\tLoss: 266.576935\n",
      "Train Epoch: 1154 [1500/2589 (58%)]\tLoss: 193.929199\n",
      "Train Epoch: 1154 [1800/2589 (70%)]\tLoss: 178.093185\n",
      "Train Epoch: 1154 [2100/2589 (81%)]\tLoss: 228.900101\n",
      "Train Epoch: 1154 [2400/2589 (93%)]\tLoss: 204.377274\n",
      "====> Epoch: 1154 Average train loss: 215.2983\n",
      "====> Epoch: 1154 Average test loss: 896.2120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1155 [0/2589 (0%)]\tLoss: 234.698807\n",
      "Train Epoch: 1155 [300/2589 (12%)]\tLoss: 158.645309\n",
      "Train Epoch: 1155 [600/2589 (23%)]\tLoss: 229.691299\n",
      "Train Epoch: 1155 [900/2589 (35%)]\tLoss: 216.614578\n",
      "Train Epoch: 1155 [1200/2589 (46%)]\tLoss: 227.268967\n",
      "Train Epoch: 1155 [1500/2589 (58%)]\tLoss: 158.615860\n",
      "Train Epoch: 1155 [1800/2589 (70%)]\tLoss: 247.735367\n",
      "Train Epoch: 1155 [2100/2589 (81%)]\tLoss: 186.851761\n",
      "Train Epoch: 1155 [2400/2589 (93%)]\tLoss: 179.904037\n",
      "====> Epoch: 1155 Average train loss: 217.2900\n",
      "====> Epoch: 1155 Average test loss: 908.7238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1156 [0/2589 (0%)]\tLoss: 188.675858\n",
      "Train Epoch: 1156 [300/2589 (12%)]\tLoss: 172.966370\n",
      "Train Epoch: 1156 [600/2589 (23%)]\tLoss: 226.555527\n",
      "Train Epoch: 1156 [900/2589 (35%)]\tLoss: 341.032867\n",
      "Train Epoch: 1156 [1200/2589 (46%)]\tLoss: 268.350708\n",
      "Train Epoch: 1156 [1500/2589 (58%)]\tLoss: 195.684250\n",
      "Train Epoch: 1156 [1800/2589 (70%)]\tLoss: 143.092804\n",
      "Train Epoch: 1156 [2100/2589 (81%)]\tLoss: 258.758240\n",
      "Train Epoch: 1156 [2400/2589 (93%)]\tLoss: 188.368927\n",
      "====> Epoch: 1156 Average train loss: 228.5277\n",
      "====> Epoch: 1156 Average test loss: 916.4539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1157 [0/2589 (0%)]\tLoss: 156.552170\n",
      "Train Epoch: 1157 [300/2589 (12%)]\tLoss: 265.584442\n",
      "Train Epoch: 1157 [600/2589 (23%)]\tLoss: 217.976639\n",
      "Train Epoch: 1157 [900/2589 (35%)]\tLoss: 152.880341\n",
      "Train Epoch: 1157 [1200/2589 (46%)]\tLoss: 175.398666\n",
      "Train Epoch: 1157 [1500/2589 (58%)]\tLoss: 214.120193\n",
      "Train Epoch: 1157 [1800/2589 (70%)]\tLoss: 208.889420\n",
      "Train Epoch: 1157 [2100/2589 (81%)]\tLoss: 174.775162\n",
      "Train Epoch: 1157 [2400/2589 (93%)]\tLoss: 250.154541\n",
      "====> Epoch: 1157 Average train loss: 221.0786\n",
      "====> Epoch: 1157 Average test loss: 905.1876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1158 [0/2589 (0%)]\tLoss: 187.600250\n",
      "Train Epoch: 1158 [300/2589 (12%)]\tLoss: 200.500397\n",
      "Train Epoch: 1158 [600/2589 (23%)]\tLoss: 283.377411\n",
      "Train Epoch: 1158 [900/2589 (35%)]\tLoss: 199.366211\n",
      "Train Epoch: 1158 [1200/2589 (46%)]\tLoss: 277.987183\n",
      "Train Epoch: 1158 [1500/2589 (58%)]\tLoss: 303.629913\n",
      "Train Epoch: 1158 [1800/2589 (70%)]\tLoss: 156.828613\n",
      "Train Epoch: 1158 [2100/2589 (81%)]\tLoss: 230.370117\n",
      "Train Epoch: 1158 [2400/2589 (93%)]\tLoss: 152.836182\n",
      "====> Epoch: 1158 Average train loss: 211.0891\n",
      "====> Epoch: 1158 Average test loss: 912.4119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1159 [0/2589 (0%)]\tLoss: 241.587067\n",
      "Train Epoch: 1159 [300/2589 (12%)]\tLoss: 153.496475\n",
      "Train Epoch: 1159 [600/2589 (23%)]\tLoss: 211.165695\n",
      "Train Epoch: 1159 [900/2589 (35%)]\tLoss: 203.240250\n",
      "Train Epoch: 1159 [1200/2589 (46%)]\tLoss: 157.767166\n",
      "Train Epoch: 1159 [1500/2589 (58%)]\tLoss: 262.783386\n",
      "Train Epoch: 1159 [1800/2589 (70%)]\tLoss: 250.261047\n",
      "Train Epoch: 1159 [2100/2589 (81%)]\tLoss: 261.619507\n",
      "Train Epoch: 1159 [2400/2589 (93%)]\tLoss: 269.321564\n",
      "====> Epoch: 1159 Average train loss: 215.9611\n",
      "====> Epoch: 1159 Average test loss: 911.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1160 [0/2589 (0%)]\tLoss: 142.950745\n",
      "Train Epoch: 1160 [300/2589 (12%)]\tLoss: 302.907776\n",
      "Train Epoch: 1160 [600/2589 (23%)]\tLoss: 168.328659\n",
      "Train Epoch: 1160 [900/2589 (35%)]\tLoss: 217.534317\n",
      "Train Epoch: 1160 [1200/2589 (46%)]\tLoss: 236.735382\n",
      "Train Epoch: 1160 [1500/2589 (58%)]\tLoss: 393.671967\n",
      "Train Epoch: 1160 [1800/2589 (70%)]\tLoss: 149.139633\n",
      "Train Epoch: 1160 [2100/2589 (81%)]\tLoss: 159.194107\n",
      "Train Epoch: 1160 [2400/2589 (93%)]\tLoss: 244.238922\n",
      "====> Epoch: 1160 Average train loss: 221.8297\n",
      "====> Epoch: 1160 Average test loss: 943.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1161 [0/2589 (0%)]\tLoss: 223.836517\n",
      "Train Epoch: 1161 [300/2589 (12%)]\tLoss: 127.099922\n",
      "Train Epoch: 1161 [600/2589 (23%)]\tLoss: 222.564941\n",
      "Train Epoch: 1161 [900/2589 (35%)]\tLoss: 191.713638\n",
      "Train Epoch: 1161 [1200/2589 (46%)]\tLoss: 273.568970\n",
      "Train Epoch: 1161 [1500/2589 (58%)]\tLoss: 213.250473\n",
      "Train Epoch: 1161 [1800/2589 (70%)]\tLoss: 202.947586\n",
      "Train Epoch: 1161 [2100/2589 (81%)]\tLoss: 376.454620\n",
      "Train Epoch: 1161 [2400/2589 (93%)]\tLoss: 219.737656\n",
      "====> Epoch: 1161 Average train loss: 211.9332\n",
      "====> Epoch: 1161 Average test loss: 903.9717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1162 [0/2589 (0%)]\tLoss: 125.578407\n",
      "Train Epoch: 1162 [300/2589 (12%)]\tLoss: 279.100159\n",
      "Train Epoch: 1162 [600/2589 (23%)]\tLoss: 161.398468\n",
      "Train Epoch: 1162 [900/2589 (35%)]\tLoss: 218.008759\n",
      "Train Epoch: 1162 [1200/2589 (46%)]\tLoss: 182.042252\n",
      "Train Epoch: 1162 [1500/2589 (58%)]\tLoss: 214.696426\n",
      "Train Epoch: 1162 [1800/2589 (70%)]\tLoss: 198.574951\n",
      "Train Epoch: 1162 [2100/2589 (81%)]\tLoss: 153.433746\n",
      "Train Epoch: 1162 [2400/2589 (93%)]\tLoss: 161.519073\n",
      "====> Epoch: 1162 Average train loss: 210.6391\n",
      "====> Epoch: 1162 Average test loss: 909.7969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1163 [0/2589 (0%)]\tLoss: 190.338364\n",
      "Train Epoch: 1163 [300/2589 (12%)]\tLoss: 221.892258\n",
      "Train Epoch: 1163 [600/2589 (23%)]\tLoss: 217.502426\n",
      "Train Epoch: 1163 [900/2589 (35%)]\tLoss: 170.071152\n",
      "Train Epoch: 1163 [1200/2589 (46%)]\tLoss: 158.964767\n",
      "Train Epoch: 1163 [1500/2589 (58%)]\tLoss: 217.325455\n",
      "Train Epoch: 1163 [1800/2589 (70%)]\tLoss: 166.832291\n",
      "Train Epoch: 1163 [2100/2589 (81%)]\tLoss: 182.633789\n",
      "Train Epoch: 1163 [2400/2589 (93%)]\tLoss: 192.511688\n",
      "====> Epoch: 1163 Average train loss: 216.4486\n",
      "====> Epoch: 1163 Average test loss: 900.2076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1164 [0/2589 (0%)]\tLoss: 141.592728\n",
      "Train Epoch: 1164 [300/2589 (12%)]\tLoss: 183.457764\n",
      "Train Epoch: 1164 [600/2589 (23%)]\tLoss: 207.234863\n",
      "Train Epoch: 1164 [900/2589 (35%)]\tLoss: 269.015503\n",
      "Train Epoch: 1164 [1200/2589 (46%)]\tLoss: 138.306839\n",
      "Train Epoch: 1164 [1500/2589 (58%)]\tLoss: 206.232452\n",
      "Train Epoch: 1164 [1800/2589 (70%)]\tLoss: 271.707672\n",
      "Train Epoch: 1164 [2100/2589 (81%)]\tLoss: 250.018250\n",
      "Train Epoch: 1164 [2400/2589 (93%)]\tLoss: 175.983612\n",
      "====> Epoch: 1164 Average train loss: 207.5617\n",
      "====> Epoch: 1164 Average test loss: 912.7755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1165 [0/2589 (0%)]\tLoss: 244.483658\n",
      "Train Epoch: 1165 [300/2589 (12%)]\tLoss: 177.307907\n",
      "Train Epoch: 1165 [600/2589 (23%)]\tLoss: 235.365768\n",
      "Train Epoch: 1165 [900/2589 (35%)]\tLoss: 216.755508\n",
      "Train Epoch: 1165 [1200/2589 (46%)]\tLoss: 196.174149\n",
      "Train Epoch: 1165 [1500/2589 (58%)]\tLoss: 150.679581\n",
      "Train Epoch: 1165 [1800/2589 (70%)]\tLoss: 169.460175\n",
      "Train Epoch: 1165 [2100/2589 (81%)]\tLoss: 197.121155\n",
      "Train Epoch: 1165 [2400/2589 (93%)]\tLoss: 174.989517\n",
      "====> Epoch: 1165 Average train loss: 217.5176\n",
      "====> Epoch: 1165 Average test loss: 904.6357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1166 [0/2589 (0%)]\tLoss: 211.287842\n",
      "Train Epoch: 1166 [300/2589 (12%)]\tLoss: 225.013977\n",
      "Train Epoch: 1166 [600/2589 (23%)]\tLoss: 177.973434\n",
      "Train Epoch: 1166 [900/2589 (35%)]\tLoss: 206.699631\n",
      "Train Epoch: 1166 [1200/2589 (46%)]\tLoss: 165.450974\n",
      "Train Epoch: 1166 [1500/2589 (58%)]\tLoss: 231.688339\n",
      "Train Epoch: 1166 [1800/2589 (70%)]\tLoss: 191.643723\n",
      "Train Epoch: 1166 [2100/2589 (81%)]\tLoss: 252.339371\n",
      "Train Epoch: 1166 [2400/2589 (93%)]\tLoss: 166.028351\n",
      "====> Epoch: 1166 Average train loss: 222.2498\n",
      "====> Epoch: 1166 Average test loss: 907.3963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1167 [0/2589 (0%)]\tLoss: 206.501572\n",
      "Train Epoch: 1167 [300/2589 (12%)]\tLoss: 157.075684\n",
      "Train Epoch: 1167 [600/2589 (23%)]\tLoss: 214.319916\n",
      "Train Epoch: 1167 [900/2589 (35%)]\tLoss: 290.681702\n",
      "Train Epoch: 1167 [1200/2589 (46%)]\tLoss: 221.369232\n",
      "Train Epoch: 1167 [1500/2589 (58%)]\tLoss: 291.186859\n",
      "Train Epoch: 1167 [1800/2589 (70%)]\tLoss: 144.083481\n",
      "Train Epoch: 1167 [2100/2589 (81%)]\tLoss: 213.389633\n",
      "Train Epoch: 1167 [2400/2589 (93%)]\tLoss: 287.140137\n",
      "====> Epoch: 1167 Average train loss: 218.9183\n",
      "====> Epoch: 1167 Average test loss: 902.6055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1168 [0/2589 (0%)]\tLoss: 179.215485\n",
      "Train Epoch: 1168 [300/2589 (12%)]\tLoss: 233.205353\n",
      "Train Epoch: 1168 [600/2589 (23%)]\tLoss: 428.583588\n",
      "Train Epoch: 1168 [900/2589 (35%)]\tLoss: 180.833649\n",
      "Train Epoch: 1168 [1200/2589 (46%)]\tLoss: 268.822113\n",
      "Train Epoch: 1168 [1500/2589 (58%)]\tLoss: 186.181137\n",
      "Train Epoch: 1168 [1800/2589 (70%)]\tLoss: 206.211334\n",
      "Train Epoch: 1168 [2100/2589 (81%)]\tLoss: 228.609772\n",
      "Train Epoch: 1168 [2400/2589 (93%)]\tLoss: 228.590424\n",
      "====> Epoch: 1168 Average train loss: 217.8428\n",
      "====> Epoch: 1168 Average test loss: 915.6871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1169 [0/2589 (0%)]\tLoss: 212.766953\n",
      "Train Epoch: 1169 [300/2589 (12%)]\tLoss: 249.957092\n",
      "Train Epoch: 1169 [600/2589 (23%)]\tLoss: 188.871246\n",
      "Train Epoch: 1169 [900/2589 (35%)]\tLoss: 224.732941\n",
      "Train Epoch: 1169 [1200/2589 (46%)]\tLoss: 174.654221\n",
      "Train Epoch: 1169 [1500/2589 (58%)]\tLoss: 179.408142\n",
      "Train Epoch: 1169 [1800/2589 (70%)]\tLoss: 151.903610\n",
      "Train Epoch: 1169 [2100/2589 (81%)]\tLoss: 135.120956\n",
      "Train Epoch: 1169 [2400/2589 (93%)]\tLoss: 182.932327\n",
      "====> Epoch: 1169 Average train loss: 217.8822\n",
      "====> Epoch: 1169 Average test loss: 912.1985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1170 [0/2589 (0%)]\tLoss: 234.502960\n",
      "Train Epoch: 1170 [300/2589 (12%)]\tLoss: 221.115936\n",
      "Train Epoch: 1170 [600/2589 (23%)]\tLoss: 164.088730\n",
      "Train Epoch: 1170 [900/2589 (35%)]\tLoss: 222.874115\n",
      "Train Epoch: 1170 [1200/2589 (46%)]\tLoss: 156.050858\n",
      "Train Epoch: 1170 [1500/2589 (58%)]\tLoss: 185.674789\n",
      "Train Epoch: 1170 [1800/2589 (70%)]\tLoss: 159.155518\n",
      "Train Epoch: 1170 [2100/2589 (81%)]\tLoss: 160.444046\n",
      "Train Epoch: 1170 [2400/2589 (93%)]\tLoss: 204.094666\n",
      "====> Epoch: 1170 Average train loss: 212.9807\n",
      "====> Epoch: 1170 Average test loss: 929.1559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1171 [0/2589 (0%)]\tLoss: 297.472839\n",
      "Train Epoch: 1171 [300/2589 (12%)]\tLoss: 273.293060\n",
      "Train Epoch: 1171 [600/2589 (23%)]\tLoss: 268.976654\n",
      "Train Epoch: 1171 [900/2589 (35%)]\tLoss: 183.605194\n",
      "Train Epoch: 1171 [1200/2589 (46%)]\tLoss: 288.254486\n",
      "Train Epoch: 1171 [1500/2589 (58%)]\tLoss: 179.035126\n",
      "Train Epoch: 1171 [1800/2589 (70%)]\tLoss: 140.266434\n",
      "Train Epoch: 1171 [2100/2589 (81%)]\tLoss: 238.948502\n",
      "Train Epoch: 1171 [2400/2589 (93%)]\tLoss: 236.181320\n",
      "====> Epoch: 1171 Average train loss: 219.2773\n",
      "====> Epoch: 1171 Average test loss: 917.1952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1172 [0/2589 (0%)]\tLoss: 167.555710\n",
      "Train Epoch: 1172 [300/2589 (12%)]\tLoss: 173.267914\n",
      "Train Epoch: 1172 [600/2589 (23%)]\tLoss: 144.775162\n",
      "Train Epoch: 1172 [900/2589 (35%)]\tLoss: 248.173279\n",
      "Train Epoch: 1172 [1200/2589 (46%)]\tLoss: 538.328247\n",
      "Train Epoch: 1172 [1500/2589 (58%)]\tLoss: 216.897888\n",
      "Train Epoch: 1172 [1800/2589 (70%)]\tLoss: 396.901703\n",
      "Train Epoch: 1172 [2100/2589 (81%)]\tLoss: 128.637009\n",
      "Train Epoch: 1172 [2400/2589 (93%)]\tLoss: 149.179688\n",
      "====> Epoch: 1172 Average train loss: 215.5995\n",
      "====> Epoch: 1172 Average test loss: 922.4983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1173 [0/2589 (0%)]\tLoss: 182.436707\n",
      "Train Epoch: 1173 [300/2589 (12%)]\tLoss: 216.205261\n",
      "Train Epoch: 1173 [600/2589 (23%)]\tLoss: 248.955734\n",
      "Train Epoch: 1173 [900/2589 (35%)]\tLoss: 182.760056\n",
      "Train Epoch: 1173 [1200/2589 (46%)]\tLoss: 147.509537\n",
      "Train Epoch: 1173 [1500/2589 (58%)]\tLoss: 219.800568\n",
      "Train Epoch: 1173 [1800/2589 (70%)]\tLoss: 170.186569\n",
      "Train Epoch: 1173 [2100/2589 (81%)]\tLoss: 180.075119\n",
      "Train Epoch: 1173 [2400/2589 (93%)]\tLoss: 307.820984\n",
      "====> Epoch: 1173 Average train loss: 239.5081\n",
      "====> Epoch: 1173 Average test loss: 922.7936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1174 [0/2589 (0%)]\tLoss: 330.035736\n",
      "Train Epoch: 1174 [300/2589 (12%)]\tLoss: 216.833969\n",
      "Train Epoch: 1174 [600/2589 (23%)]\tLoss: 195.107758\n",
      "Train Epoch: 1174 [900/2589 (35%)]\tLoss: 165.591705\n",
      "Train Epoch: 1174 [1200/2589 (46%)]\tLoss: 193.299088\n",
      "Train Epoch: 1174 [1500/2589 (58%)]\tLoss: 250.340378\n",
      "Train Epoch: 1174 [1800/2589 (70%)]\tLoss: 207.676285\n",
      "Train Epoch: 1174 [2100/2589 (81%)]\tLoss: 190.577850\n",
      "Train Epoch: 1174 [2400/2589 (93%)]\tLoss: 148.433823\n",
      "====> Epoch: 1174 Average train loss: 221.9670\n",
      "====> Epoch: 1174 Average test loss: 912.4107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1175 [0/2589 (0%)]\tLoss: 157.687927\n",
      "Train Epoch: 1175 [300/2589 (12%)]\tLoss: 158.459869\n",
      "Train Epoch: 1175 [600/2589 (23%)]\tLoss: 249.504074\n",
      "Train Epoch: 1175 [900/2589 (35%)]\tLoss: 224.042953\n",
      "Train Epoch: 1175 [1200/2589 (46%)]\tLoss: 243.542572\n",
      "Train Epoch: 1175 [1500/2589 (58%)]\tLoss: 201.158035\n",
      "Train Epoch: 1175 [1800/2589 (70%)]\tLoss: 177.130463\n",
      "Train Epoch: 1175 [2100/2589 (81%)]\tLoss: 237.073639\n",
      "Train Epoch: 1175 [2400/2589 (93%)]\tLoss: 156.496124\n",
      "====> Epoch: 1175 Average train loss: 208.2191\n",
      "====> Epoch: 1175 Average test loss: 898.4536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1176 [0/2589 (0%)]\tLoss: 215.203720\n",
      "Train Epoch: 1176 [300/2589 (12%)]\tLoss: 206.485947\n",
      "Train Epoch: 1176 [600/2589 (23%)]\tLoss: 206.209290\n",
      "Train Epoch: 1176 [900/2589 (35%)]\tLoss: 211.786377\n",
      "Train Epoch: 1176 [1200/2589 (46%)]\tLoss: 140.946716\n",
      "Train Epoch: 1176 [1500/2589 (58%)]\tLoss: 501.438385\n",
      "Train Epoch: 1176 [1800/2589 (70%)]\tLoss: 193.022797\n",
      "Train Epoch: 1176 [2100/2589 (81%)]\tLoss: 260.739655\n",
      "Train Epoch: 1176 [2400/2589 (93%)]\tLoss: 207.848129\n",
      "====> Epoch: 1176 Average train loss: 211.7840\n",
      "====> Epoch: 1176 Average test loss: 900.6603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1177 [0/2589 (0%)]\tLoss: 236.523666\n",
      "Train Epoch: 1177 [300/2589 (12%)]\tLoss: 227.470886\n",
      "Train Epoch: 1177 [600/2589 (23%)]\tLoss: 385.845795\n",
      "Train Epoch: 1177 [900/2589 (35%)]\tLoss: 205.432419\n",
      "Train Epoch: 1177 [1200/2589 (46%)]\tLoss: 191.634003\n",
      "Train Epoch: 1177 [1500/2589 (58%)]\tLoss: 134.576569\n",
      "Train Epoch: 1177 [1800/2589 (70%)]\tLoss: 253.484314\n",
      "Train Epoch: 1177 [2100/2589 (81%)]\tLoss: 329.168671\n",
      "Train Epoch: 1177 [2400/2589 (93%)]\tLoss: 161.407913\n",
      "====> Epoch: 1177 Average train loss: 215.4503\n",
      "====> Epoch: 1177 Average test loss: 917.0413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1178 [0/2589 (0%)]\tLoss: 171.785355\n",
      "Train Epoch: 1178 [300/2589 (12%)]\tLoss: 198.035828\n",
      "Train Epoch: 1178 [600/2589 (23%)]\tLoss: 192.216370\n",
      "Train Epoch: 1178 [900/2589 (35%)]\tLoss: 296.604797\n",
      "Train Epoch: 1178 [1200/2589 (46%)]\tLoss: 220.866043\n",
      "Train Epoch: 1178 [1500/2589 (58%)]\tLoss: 172.939102\n",
      "Train Epoch: 1178 [1800/2589 (70%)]\tLoss: 158.366272\n",
      "Train Epoch: 1178 [2100/2589 (81%)]\tLoss: 141.964935\n",
      "Train Epoch: 1178 [2400/2589 (93%)]\tLoss: 164.845123\n",
      "====> Epoch: 1178 Average train loss: 214.8130\n",
      "====> Epoch: 1178 Average test loss: 915.0816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1179 [0/2589 (0%)]\tLoss: 370.273926\n",
      "Train Epoch: 1179 [300/2589 (12%)]\tLoss: 214.416824\n",
      "Train Epoch: 1179 [600/2589 (23%)]\tLoss: 227.098190\n",
      "Train Epoch: 1179 [900/2589 (35%)]\tLoss: 227.387390\n",
      "Train Epoch: 1179 [1200/2589 (46%)]\tLoss: 194.245605\n",
      "Train Epoch: 1179 [1500/2589 (58%)]\tLoss: 279.237579\n",
      "Train Epoch: 1179 [1800/2589 (70%)]\tLoss: 165.980667\n",
      "Train Epoch: 1179 [2100/2589 (81%)]\tLoss: 246.527405\n",
      "Train Epoch: 1179 [2400/2589 (93%)]\tLoss: 301.844818\n",
      "====> Epoch: 1179 Average train loss: 216.1689\n",
      "====> Epoch: 1179 Average test loss: 913.4848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1180 [0/2589 (0%)]\tLoss: 148.070801\n",
      "Train Epoch: 1180 [300/2589 (12%)]\tLoss: 237.772461\n",
      "Train Epoch: 1180 [600/2589 (23%)]\tLoss: 311.829987\n",
      "Train Epoch: 1180 [900/2589 (35%)]\tLoss: 260.081879\n",
      "Train Epoch: 1180 [1200/2589 (46%)]\tLoss: 131.524948\n",
      "Train Epoch: 1180 [1500/2589 (58%)]\tLoss: 169.771652\n",
      "Train Epoch: 1180 [1800/2589 (70%)]\tLoss: 225.691589\n",
      "Train Epoch: 1180 [2100/2589 (81%)]\tLoss: 280.549957\n",
      "Train Epoch: 1180 [2400/2589 (93%)]\tLoss: 177.648499\n",
      "====> Epoch: 1180 Average train loss: 207.1947\n",
      "====> Epoch: 1180 Average test loss: 905.8370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1181 [0/2589 (0%)]\tLoss: 171.615570\n",
      "Train Epoch: 1181 [300/2589 (12%)]\tLoss: 305.391083\n",
      "Train Epoch: 1181 [600/2589 (23%)]\tLoss: 174.526566\n",
      "Train Epoch: 1181 [900/2589 (35%)]\tLoss: 139.598663\n",
      "Train Epoch: 1181 [1200/2589 (46%)]\tLoss: 281.595490\n",
      "Train Epoch: 1181 [1500/2589 (58%)]\tLoss: 168.205002\n",
      "Train Epoch: 1181 [1800/2589 (70%)]\tLoss: 215.251892\n",
      "Train Epoch: 1181 [2100/2589 (81%)]\tLoss: 134.175079\n",
      "Train Epoch: 1181 [2400/2589 (93%)]\tLoss: 155.421692\n",
      "====> Epoch: 1181 Average train loss: 210.8844\n",
      "====> Epoch: 1181 Average test loss: 901.3229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1182 [0/2589 (0%)]\tLoss: 291.915253\n",
      "Train Epoch: 1182 [300/2589 (12%)]\tLoss: 144.138290\n",
      "Train Epoch: 1182 [600/2589 (23%)]\tLoss: 164.336319\n",
      "Train Epoch: 1182 [900/2589 (35%)]\tLoss: 165.403503\n",
      "Train Epoch: 1182 [1200/2589 (46%)]\tLoss: 124.621254\n",
      "Train Epoch: 1182 [1500/2589 (58%)]\tLoss: 187.722702\n",
      "Train Epoch: 1182 [1800/2589 (70%)]\tLoss: 301.697662\n",
      "Train Epoch: 1182 [2100/2589 (81%)]\tLoss: 257.186157\n",
      "Train Epoch: 1182 [2400/2589 (93%)]\tLoss: 173.909271\n",
      "====> Epoch: 1182 Average train loss: 205.9469\n",
      "====> Epoch: 1182 Average test loss: 931.8898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1183 [0/2589 (0%)]\tLoss: 170.764465\n",
      "Train Epoch: 1183 [300/2589 (12%)]\tLoss: 147.241837\n",
      "Train Epoch: 1183 [600/2589 (23%)]\tLoss: 184.581360\n",
      "Train Epoch: 1183 [900/2589 (35%)]\tLoss: 198.261810\n",
      "Train Epoch: 1183 [1200/2589 (46%)]\tLoss: 182.222610\n",
      "Train Epoch: 1183 [1500/2589 (58%)]\tLoss: 197.916000\n",
      "Train Epoch: 1183 [1800/2589 (70%)]\tLoss: 178.941849\n",
      "Train Epoch: 1183 [2100/2589 (81%)]\tLoss: 188.859543\n",
      "Train Epoch: 1183 [2400/2589 (93%)]\tLoss: 160.988724\n",
      "====> Epoch: 1183 Average train loss: 202.1266\n",
      "====> Epoch: 1183 Average test loss: 927.8381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1184 [0/2589 (0%)]\tLoss: 231.801712\n",
      "Train Epoch: 1184 [300/2589 (12%)]\tLoss: 261.125153\n",
      "Train Epoch: 1184 [600/2589 (23%)]\tLoss: 158.518600\n",
      "Train Epoch: 1184 [900/2589 (35%)]\tLoss: 164.767761\n",
      "Train Epoch: 1184 [1200/2589 (46%)]\tLoss: 200.159119\n",
      "Train Epoch: 1184 [1500/2589 (58%)]\tLoss: 236.792648\n",
      "Train Epoch: 1184 [1800/2589 (70%)]\tLoss: 219.506454\n",
      "Train Epoch: 1184 [2100/2589 (81%)]\tLoss: 190.121307\n",
      "Train Epoch: 1184 [2400/2589 (93%)]\tLoss: 394.085358\n",
      "====> Epoch: 1184 Average train loss: 221.9847\n",
      "====> Epoch: 1184 Average test loss: 908.3919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1185 [0/2589 (0%)]\tLoss: 261.571503\n",
      "Train Epoch: 1185 [300/2589 (12%)]\tLoss: 211.589157\n",
      "Train Epoch: 1185 [600/2589 (23%)]\tLoss: 208.021255\n",
      "Train Epoch: 1185 [900/2589 (35%)]\tLoss: 153.030487\n",
      "Train Epoch: 1185 [1200/2589 (46%)]\tLoss: 189.552429\n",
      "Train Epoch: 1185 [1500/2589 (58%)]\tLoss: 138.497910\n",
      "Train Epoch: 1185 [1800/2589 (70%)]\tLoss: 220.675354\n",
      "Train Epoch: 1185 [2100/2589 (81%)]\tLoss: 209.154755\n",
      "Train Epoch: 1185 [2400/2589 (93%)]\tLoss: 248.233673\n",
      "====> Epoch: 1185 Average train loss: 213.3960\n",
      "====> Epoch: 1185 Average test loss: 908.0703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1186 [0/2589 (0%)]\tLoss: 181.314484\n",
      "Train Epoch: 1186 [300/2589 (12%)]\tLoss: 187.238342\n",
      "Train Epoch: 1186 [600/2589 (23%)]\tLoss: 158.167419\n",
      "Train Epoch: 1186 [900/2589 (35%)]\tLoss: 255.357452\n",
      "Train Epoch: 1186 [1200/2589 (46%)]\tLoss: 162.464996\n",
      "Train Epoch: 1186 [1500/2589 (58%)]\tLoss: 166.602844\n",
      "Train Epoch: 1186 [1800/2589 (70%)]\tLoss: 186.866364\n",
      "Train Epoch: 1186 [2100/2589 (81%)]\tLoss: 322.586365\n",
      "Train Epoch: 1186 [2400/2589 (93%)]\tLoss: 299.091156\n",
      "====> Epoch: 1186 Average train loss: 205.4987\n",
      "====> Epoch: 1186 Average test loss: 901.2781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1187 [0/2589 (0%)]\tLoss: 206.843292\n",
      "Train Epoch: 1187 [300/2589 (12%)]\tLoss: 251.725433\n",
      "Train Epoch: 1187 [600/2589 (23%)]\tLoss: 187.828125\n",
      "Train Epoch: 1187 [900/2589 (35%)]\tLoss: 302.033020\n",
      "Train Epoch: 1187 [1200/2589 (46%)]\tLoss: 179.066498\n",
      "Train Epoch: 1187 [1500/2589 (58%)]\tLoss: 230.596573\n",
      "Train Epoch: 1187 [1800/2589 (70%)]\tLoss: 211.324249\n",
      "Train Epoch: 1187 [2100/2589 (81%)]\tLoss: 185.816864\n",
      "Train Epoch: 1187 [2400/2589 (93%)]\tLoss: 262.803040\n",
      "====> Epoch: 1187 Average train loss: 215.7081\n",
      "====> Epoch: 1187 Average test loss: 908.1654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1188 [0/2589 (0%)]\tLoss: 217.073868\n",
      "Train Epoch: 1188 [300/2589 (12%)]\tLoss: 155.149353\n",
      "Train Epoch: 1188 [600/2589 (23%)]\tLoss: 164.701630\n",
      "Train Epoch: 1188 [900/2589 (35%)]\tLoss: 353.472168\n",
      "Train Epoch: 1188 [1200/2589 (46%)]\tLoss: 294.058563\n",
      "Train Epoch: 1188 [1500/2589 (58%)]\tLoss: 213.628128\n",
      "Train Epoch: 1188 [1800/2589 (70%)]\tLoss: 134.880295\n",
      "Train Epoch: 1188 [2100/2589 (81%)]\tLoss: 205.775436\n",
      "Train Epoch: 1188 [2400/2589 (93%)]\tLoss: 371.959351\n",
      "====> Epoch: 1188 Average train loss: 217.2113\n",
      "====> Epoch: 1188 Average test loss: 926.4304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1189 [0/2589 (0%)]\tLoss: 174.818420\n",
      "Train Epoch: 1189 [300/2589 (12%)]\tLoss: 161.591766\n",
      "Train Epoch: 1189 [600/2589 (23%)]\tLoss: 179.394592\n",
      "Train Epoch: 1189 [900/2589 (35%)]\tLoss: 180.740631\n",
      "Train Epoch: 1189 [1200/2589 (46%)]\tLoss: 314.108429\n",
      "Train Epoch: 1189 [1500/2589 (58%)]\tLoss: 221.103714\n",
      "Train Epoch: 1189 [1800/2589 (70%)]\tLoss: 237.163498\n",
      "Train Epoch: 1189 [2100/2589 (81%)]\tLoss: 181.174133\n",
      "Train Epoch: 1189 [2400/2589 (93%)]\tLoss: 262.593140\n",
      "====> Epoch: 1189 Average train loss: 222.0142\n",
      "====> Epoch: 1189 Average test loss: 904.0425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1190 [0/2589 (0%)]\tLoss: 289.511658\n",
      "Train Epoch: 1190 [300/2589 (12%)]\tLoss: 416.636505\n",
      "Train Epoch: 1190 [600/2589 (23%)]\tLoss: 232.974258\n",
      "Train Epoch: 1190 [900/2589 (35%)]\tLoss: 170.289108\n",
      "Train Epoch: 1190 [1200/2589 (46%)]\tLoss: 174.618820\n",
      "Train Epoch: 1190 [1500/2589 (58%)]\tLoss: 279.980530\n",
      "Train Epoch: 1190 [1800/2589 (70%)]\tLoss: 186.564255\n",
      "Train Epoch: 1190 [2100/2589 (81%)]\tLoss: 170.588226\n",
      "Train Epoch: 1190 [2400/2589 (93%)]\tLoss: 232.616623\n",
      "====> Epoch: 1190 Average train loss: 220.0524\n",
      "====> Epoch: 1190 Average test loss: 908.2355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1191 [0/2589 (0%)]\tLoss: 197.535355\n",
      "Train Epoch: 1191 [300/2589 (12%)]\tLoss: 304.917755\n",
      "Train Epoch: 1191 [600/2589 (23%)]\tLoss: 212.407257\n",
      "Train Epoch: 1191 [900/2589 (35%)]\tLoss: 289.336426\n",
      "Train Epoch: 1191 [1200/2589 (46%)]\tLoss: 205.598679\n",
      "Train Epoch: 1191 [1500/2589 (58%)]\tLoss: 186.062561\n",
      "Train Epoch: 1191 [1800/2589 (70%)]\tLoss: 166.372528\n",
      "Train Epoch: 1191 [2100/2589 (81%)]\tLoss: 311.310883\n",
      "Train Epoch: 1191 [2400/2589 (93%)]\tLoss: 328.233490\n",
      "====> Epoch: 1191 Average train loss: 219.6125\n",
      "====> Epoch: 1191 Average test loss: 909.4530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1192 [0/2589 (0%)]\tLoss: 135.747772\n",
      "Train Epoch: 1192 [300/2589 (12%)]\tLoss: 279.247131\n",
      "Train Epoch: 1192 [600/2589 (23%)]\tLoss: 217.588867\n",
      "Train Epoch: 1192 [900/2589 (35%)]\tLoss: 169.602997\n",
      "Train Epoch: 1192 [1200/2589 (46%)]\tLoss: 166.812271\n",
      "Train Epoch: 1192 [1500/2589 (58%)]\tLoss: 156.979736\n",
      "Train Epoch: 1192 [1800/2589 (70%)]\tLoss: 162.940689\n",
      "Train Epoch: 1192 [2100/2589 (81%)]\tLoss: 176.273087\n",
      "Train Epoch: 1192 [2400/2589 (93%)]\tLoss: 155.656433\n",
      "====> Epoch: 1192 Average train loss: 215.8179\n",
      "====> Epoch: 1192 Average test loss: 908.9124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1193 [0/2589 (0%)]\tLoss: 182.177933\n",
      "Train Epoch: 1193 [300/2589 (12%)]\tLoss: 225.099335\n",
      "Train Epoch: 1193 [600/2589 (23%)]\tLoss: 311.026001\n",
      "Train Epoch: 1193 [900/2589 (35%)]\tLoss: 343.229431\n",
      "Train Epoch: 1193 [1200/2589 (46%)]\tLoss: 205.283234\n",
      "Train Epoch: 1193 [1500/2589 (58%)]\tLoss: 151.074203\n",
      "Train Epoch: 1193 [1800/2589 (70%)]\tLoss: 239.245285\n",
      "Train Epoch: 1193 [2100/2589 (81%)]\tLoss: 197.103027\n",
      "Train Epoch: 1193 [2400/2589 (93%)]\tLoss: 157.416656\n",
      "====> Epoch: 1193 Average train loss: 218.6716\n",
      "====> Epoch: 1193 Average test loss: 924.3791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1194 [0/2589 (0%)]\tLoss: 162.483414\n",
      "Train Epoch: 1194 [300/2589 (12%)]\tLoss: 286.210419\n",
      "Train Epoch: 1194 [600/2589 (23%)]\tLoss: 252.108047\n",
      "Train Epoch: 1194 [900/2589 (35%)]\tLoss: 289.443970\n",
      "Train Epoch: 1194 [1200/2589 (46%)]\tLoss: 163.720016\n",
      "Train Epoch: 1194 [1500/2589 (58%)]\tLoss: 649.816711\n",
      "Train Epoch: 1194 [1800/2589 (70%)]\tLoss: 232.234833\n",
      "Train Epoch: 1194 [2100/2589 (81%)]\tLoss: 219.576035\n",
      "Train Epoch: 1194 [2400/2589 (93%)]\tLoss: 274.477814\n",
      "====> Epoch: 1194 Average train loss: 226.7493\n",
      "====> Epoch: 1194 Average test loss: 896.3430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1195 [0/2589 (0%)]\tLoss: 210.463638\n",
      "Train Epoch: 1195 [300/2589 (12%)]\tLoss: 173.021393\n",
      "Train Epoch: 1195 [600/2589 (23%)]\tLoss: 144.623703\n",
      "Train Epoch: 1195 [900/2589 (35%)]\tLoss: 184.816055\n",
      "Train Epoch: 1195 [1200/2589 (46%)]\tLoss: 263.947510\n",
      "Train Epoch: 1195 [1500/2589 (58%)]\tLoss: 161.290619\n",
      "Train Epoch: 1195 [1800/2589 (70%)]\tLoss: 182.397873\n",
      "Train Epoch: 1195 [2100/2589 (81%)]\tLoss: 203.462357\n",
      "Train Epoch: 1195 [2400/2589 (93%)]\tLoss: 250.453186\n",
      "====> Epoch: 1195 Average train loss: 220.9035\n",
      "====> Epoch: 1195 Average test loss: 902.5045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1196 [0/2589 (0%)]\tLoss: 179.289719\n",
      "Train Epoch: 1196 [300/2589 (12%)]\tLoss: 340.822632\n",
      "Train Epoch: 1196 [600/2589 (23%)]\tLoss: 293.041016\n",
      "Train Epoch: 1196 [900/2589 (35%)]\tLoss: 231.193619\n",
      "Train Epoch: 1196 [1200/2589 (46%)]\tLoss: 204.022034\n",
      "Train Epoch: 1196 [1500/2589 (58%)]\tLoss: 161.285477\n",
      "Train Epoch: 1196 [1800/2589 (70%)]\tLoss: 229.906708\n",
      "Train Epoch: 1196 [2100/2589 (81%)]\tLoss: 219.796371\n",
      "Train Epoch: 1196 [2400/2589 (93%)]\tLoss: 159.418686\n",
      "====> Epoch: 1196 Average train loss: 231.8850\n",
      "====> Epoch: 1196 Average test loss: 911.4279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1197 [0/2589 (0%)]\tLoss: 222.947464\n",
      "Train Epoch: 1197 [300/2589 (12%)]\tLoss: 189.321609\n",
      "Train Epoch: 1197 [600/2589 (23%)]\tLoss: 139.124329\n",
      "Train Epoch: 1197 [900/2589 (35%)]\tLoss: 141.799057\n",
      "Train Epoch: 1197 [1200/2589 (46%)]\tLoss: 263.460968\n",
      "Train Epoch: 1197 [1500/2589 (58%)]\tLoss: 242.597107\n",
      "Train Epoch: 1197 [1800/2589 (70%)]\tLoss: 162.504745\n",
      "Train Epoch: 1197 [2100/2589 (81%)]\tLoss: 215.048050\n",
      "Train Epoch: 1197 [2400/2589 (93%)]\tLoss: 170.940567\n",
      "====> Epoch: 1197 Average train loss: 204.6327\n",
      "====> Epoch: 1197 Average test loss: 914.6838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1198 [0/2589 (0%)]\tLoss: 216.770370\n",
      "Train Epoch: 1198 [300/2589 (12%)]\tLoss: 202.357361\n",
      "Train Epoch: 1198 [600/2589 (23%)]\tLoss: 157.098236\n",
      "Train Epoch: 1198 [900/2589 (35%)]\tLoss: 227.736496\n",
      "Train Epoch: 1198 [1200/2589 (46%)]\tLoss: 269.001984\n",
      "Train Epoch: 1198 [1500/2589 (58%)]\tLoss: 217.866318\n",
      "Train Epoch: 1198 [1800/2589 (70%)]\tLoss: 154.276642\n",
      "Train Epoch: 1198 [2100/2589 (81%)]\tLoss: 299.488800\n",
      "Train Epoch: 1198 [2400/2589 (93%)]\tLoss: 185.623810\n",
      "====> Epoch: 1198 Average train loss: 217.7777\n",
      "====> Epoch: 1198 Average test loss: 917.3995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1199 [0/2589 (0%)]\tLoss: 158.172501\n",
      "Train Epoch: 1199 [300/2589 (12%)]\tLoss: 195.176498\n",
      "Train Epoch: 1199 [600/2589 (23%)]\tLoss: 206.991638\n",
      "Train Epoch: 1199 [900/2589 (35%)]\tLoss: 211.696915\n",
      "Train Epoch: 1199 [1200/2589 (46%)]\tLoss: 188.389328\n",
      "Train Epoch: 1199 [1500/2589 (58%)]\tLoss: 169.601425\n",
      "Train Epoch: 1199 [1800/2589 (70%)]\tLoss: 283.244904\n",
      "Train Epoch: 1199 [2100/2589 (81%)]\tLoss: 230.756744\n",
      "Train Epoch: 1199 [2400/2589 (93%)]\tLoss: 307.892151\n",
      "====> Epoch: 1199 Average train loss: 226.7152\n",
      "====> Epoch: 1199 Average test loss: 916.5512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1200 [0/2589 (0%)]\tLoss: 260.356506\n",
      "Train Epoch: 1200 [300/2589 (12%)]\tLoss: 161.978027\n",
      "Train Epoch: 1200 [600/2589 (23%)]\tLoss: 167.787216\n",
      "Train Epoch: 1200 [900/2589 (35%)]\tLoss: 218.935959\n",
      "Train Epoch: 1200 [1200/2589 (46%)]\tLoss: 226.225433\n",
      "Train Epoch: 1200 [1500/2589 (58%)]\tLoss: 153.814438\n",
      "Train Epoch: 1200 [1800/2589 (70%)]\tLoss: 174.512756\n",
      "Train Epoch: 1200 [2100/2589 (81%)]\tLoss: 173.571030\n",
      "Train Epoch: 1200 [2400/2589 (93%)]\tLoss: 191.725189\n",
      "====> Epoch: 1200 Average train loss: 214.6679\n",
      "====> Epoch: 1200 Average test loss: 915.4155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1201 [0/2589 (0%)]\tLoss: 252.133881\n",
      "Train Epoch: 1201 [300/2589 (12%)]\tLoss: 157.314926\n",
      "Train Epoch: 1201 [600/2589 (23%)]\tLoss: 224.889572\n",
      "Train Epoch: 1201 [900/2589 (35%)]\tLoss: 194.848175\n",
      "Train Epoch: 1201 [1200/2589 (46%)]\tLoss: 199.126740\n",
      "Train Epoch: 1201 [1500/2589 (58%)]\tLoss: 336.607483\n",
      "Train Epoch: 1201 [1800/2589 (70%)]\tLoss: 186.698837\n",
      "Train Epoch: 1201 [2100/2589 (81%)]\tLoss: 163.891998\n",
      "Train Epoch: 1201 [2400/2589 (93%)]\tLoss: 169.137787\n",
      "====> Epoch: 1201 Average train loss: 205.0694\n",
      "====> Epoch: 1201 Average test loss: 919.4470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1202 [0/2589 (0%)]\tLoss: 225.194534\n",
      "Train Epoch: 1202 [300/2589 (12%)]\tLoss: 183.432602\n",
      "Train Epoch: 1202 [600/2589 (23%)]\tLoss: 202.554596\n",
      "Train Epoch: 1202 [900/2589 (35%)]\tLoss: 171.837006\n",
      "Train Epoch: 1202 [1200/2589 (46%)]\tLoss: 142.051025\n",
      "Train Epoch: 1202 [1500/2589 (58%)]\tLoss: 150.939835\n",
      "Train Epoch: 1202 [1800/2589 (70%)]\tLoss: 173.793442\n",
      "Train Epoch: 1202 [2100/2589 (81%)]\tLoss: 172.964676\n",
      "Train Epoch: 1202 [2400/2589 (93%)]\tLoss: 157.026749\n",
      "====> Epoch: 1202 Average train loss: 209.1683\n",
      "====> Epoch: 1202 Average test loss: 917.0591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1203 [0/2589 (0%)]\tLoss: 221.605927\n",
      "Train Epoch: 1203 [300/2589 (12%)]\tLoss: 226.713165\n",
      "Train Epoch: 1203 [600/2589 (23%)]\tLoss: 317.575012\n",
      "Train Epoch: 1203 [900/2589 (35%)]\tLoss: 204.738861\n",
      "Train Epoch: 1203 [1200/2589 (46%)]\tLoss: 201.747467\n",
      "Train Epoch: 1203 [1500/2589 (58%)]\tLoss: 166.368118\n",
      "Train Epoch: 1203 [1800/2589 (70%)]\tLoss: 150.885406\n",
      "Train Epoch: 1203 [2100/2589 (81%)]\tLoss: 161.619492\n",
      "Train Epoch: 1203 [2400/2589 (93%)]\tLoss: 156.231522\n",
      "====> Epoch: 1203 Average train loss: 205.9309\n",
      "====> Epoch: 1203 Average test loss: 901.2387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1204 [0/2589 (0%)]\tLoss: 179.240448\n",
      "Train Epoch: 1204 [300/2589 (12%)]\tLoss: 167.886856\n",
      "Train Epoch: 1204 [600/2589 (23%)]\tLoss: 233.851044\n",
      "Train Epoch: 1204 [900/2589 (35%)]\tLoss: 300.080017\n",
      "Train Epoch: 1204 [1200/2589 (46%)]\tLoss: 181.518661\n",
      "Train Epoch: 1204 [1500/2589 (58%)]\tLoss: 331.987457\n",
      "Train Epoch: 1204 [1800/2589 (70%)]\tLoss: 190.114105\n",
      "Train Epoch: 1204 [2100/2589 (81%)]\tLoss: 114.102409\n",
      "Train Epoch: 1204 [2400/2589 (93%)]\tLoss: 138.829758\n",
      "====> Epoch: 1204 Average train loss: 218.2865\n",
      "====> Epoch: 1204 Average test loss: 909.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1205 [0/2589 (0%)]\tLoss: 175.205261\n",
      "Train Epoch: 1205 [300/2589 (12%)]\tLoss: 226.251205\n",
      "Train Epoch: 1205 [600/2589 (23%)]\tLoss: 151.441345\n",
      "Train Epoch: 1205 [900/2589 (35%)]\tLoss: 185.511780\n",
      "Train Epoch: 1205 [1200/2589 (46%)]\tLoss: 195.078629\n",
      "Train Epoch: 1205 [1500/2589 (58%)]\tLoss: 219.948730\n",
      "Train Epoch: 1205 [1800/2589 (70%)]\tLoss: 323.498413\n",
      "Train Epoch: 1205 [2100/2589 (81%)]\tLoss: 193.074066\n",
      "Train Epoch: 1205 [2400/2589 (93%)]\tLoss: 218.477951\n",
      "====> Epoch: 1205 Average train loss: 212.6618\n",
      "====> Epoch: 1205 Average test loss: 908.3267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1206 [0/2589 (0%)]\tLoss: 173.553329\n",
      "Train Epoch: 1206 [300/2589 (12%)]\tLoss: 365.333313\n",
      "Train Epoch: 1206 [600/2589 (23%)]\tLoss: 310.548126\n",
      "Train Epoch: 1206 [900/2589 (35%)]\tLoss: 227.631378\n",
      "Train Epoch: 1206 [1200/2589 (46%)]\tLoss: 209.804581\n",
      "Train Epoch: 1206 [1500/2589 (58%)]\tLoss: 213.713776\n",
      "Train Epoch: 1206 [1800/2589 (70%)]\tLoss: 139.478424\n",
      "Train Epoch: 1206 [2100/2589 (81%)]\tLoss: 193.101624\n",
      "Train Epoch: 1206 [2400/2589 (93%)]\tLoss: 185.929916\n",
      "====> Epoch: 1206 Average train loss: 214.3585\n",
      "====> Epoch: 1206 Average test loss: 908.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1207 [0/2589 (0%)]\tLoss: 148.193436\n",
      "Train Epoch: 1207 [300/2589 (12%)]\tLoss: 161.167053\n",
      "Train Epoch: 1207 [600/2589 (23%)]\tLoss: 236.819565\n",
      "Train Epoch: 1207 [900/2589 (35%)]\tLoss: 158.322754\n",
      "Train Epoch: 1207 [1200/2589 (46%)]\tLoss: 230.400528\n",
      "Train Epoch: 1207 [1500/2589 (58%)]\tLoss: 153.797287\n",
      "Train Epoch: 1207 [1800/2589 (70%)]\tLoss: 194.683319\n",
      "Train Epoch: 1207 [2100/2589 (81%)]\tLoss: 190.986954\n",
      "Train Epoch: 1207 [2400/2589 (93%)]\tLoss: 145.827682\n",
      "====> Epoch: 1207 Average train loss: 212.4245\n",
      "====> Epoch: 1207 Average test loss: 921.6053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1208 [0/2589 (0%)]\tLoss: 180.346146\n",
      "Train Epoch: 1208 [300/2589 (12%)]\tLoss: 136.932083\n",
      "Train Epoch: 1208 [600/2589 (23%)]\tLoss: 199.216537\n",
      "Train Epoch: 1208 [900/2589 (35%)]\tLoss: 184.796524\n",
      "Train Epoch: 1208 [1200/2589 (46%)]\tLoss: 276.087280\n",
      "Train Epoch: 1208 [1500/2589 (58%)]\tLoss: 195.476898\n",
      "Train Epoch: 1208 [1800/2589 (70%)]\tLoss: 177.320129\n",
      "Train Epoch: 1208 [2100/2589 (81%)]\tLoss: 200.831970\n",
      "Train Epoch: 1208 [2400/2589 (93%)]\tLoss: 276.819733\n",
      "====> Epoch: 1208 Average train loss: 218.6627\n",
      "====> Epoch: 1208 Average test loss: 907.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1209 [0/2589 (0%)]\tLoss: 225.833206\n",
      "Train Epoch: 1209 [300/2589 (12%)]\tLoss: 214.569443\n",
      "Train Epoch: 1209 [600/2589 (23%)]\tLoss: 242.511780\n",
      "Train Epoch: 1209 [900/2589 (35%)]\tLoss: 176.633026\n",
      "Train Epoch: 1209 [1200/2589 (46%)]\tLoss: 220.367874\n",
      "Train Epoch: 1209 [1500/2589 (58%)]\tLoss: 260.841309\n",
      "Train Epoch: 1209 [1800/2589 (70%)]\tLoss: 130.669128\n",
      "Train Epoch: 1209 [2100/2589 (81%)]\tLoss: 164.747208\n",
      "Train Epoch: 1209 [2400/2589 (93%)]\tLoss: 208.913757\n",
      "====> Epoch: 1209 Average train loss: 222.5318\n",
      "====> Epoch: 1209 Average test loss: 909.5736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1210 [0/2589 (0%)]\tLoss: 217.910583\n",
      "Train Epoch: 1210 [300/2589 (12%)]\tLoss: 184.995819\n",
      "Train Epoch: 1210 [600/2589 (23%)]\tLoss: 181.842880\n",
      "Train Epoch: 1210 [900/2589 (35%)]\tLoss: 178.452682\n",
      "Train Epoch: 1210 [1200/2589 (46%)]\tLoss: 236.513077\n",
      "Train Epoch: 1210 [1500/2589 (58%)]\tLoss: 213.388382\n",
      "Train Epoch: 1210 [1800/2589 (70%)]\tLoss: 180.510544\n",
      "Train Epoch: 1210 [2100/2589 (81%)]\tLoss: 215.692307\n",
      "Train Epoch: 1210 [2400/2589 (93%)]\tLoss: 207.371185\n",
      "====> Epoch: 1210 Average train loss: 216.3819\n",
      "====> Epoch: 1210 Average test loss: 906.2297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1211 [0/2589 (0%)]\tLoss: 220.898300\n",
      "Train Epoch: 1211 [300/2589 (12%)]\tLoss: 258.437164\n",
      "Train Epoch: 1211 [600/2589 (23%)]\tLoss: 178.312012\n",
      "Train Epoch: 1211 [900/2589 (35%)]\tLoss: 204.633713\n",
      "Train Epoch: 1211 [1200/2589 (46%)]\tLoss: 174.728409\n",
      "Train Epoch: 1211 [1500/2589 (58%)]\tLoss: 242.639648\n",
      "Train Epoch: 1211 [1800/2589 (70%)]\tLoss: 194.613174\n",
      "Train Epoch: 1211 [2100/2589 (81%)]\tLoss: 196.722137\n",
      "Train Epoch: 1211 [2400/2589 (93%)]\tLoss: 251.582520\n",
      "====> Epoch: 1211 Average train loss: 228.5424\n",
      "====> Epoch: 1211 Average test loss: 906.9193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1212 [0/2589 (0%)]\tLoss: 376.396088\n",
      "Train Epoch: 1212 [300/2589 (12%)]\tLoss: 181.478745\n",
      "Train Epoch: 1212 [600/2589 (23%)]\tLoss: 143.887436\n",
      "Train Epoch: 1212 [900/2589 (35%)]\tLoss: 186.735886\n",
      "Train Epoch: 1212 [1200/2589 (46%)]\tLoss: 264.467407\n",
      "Train Epoch: 1212 [1500/2589 (58%)]\tLoss: 247.513351\n",
      "Train Epoch: 1212 [1800/2589 (70%)]\tLoss: 156.647003\n",
      "Train Epoch: 1212 [2100/2589 (81%)]\tLoss: 208.546783\n",
      "Train Epoch: 1212 [2400/2589 (93%)]\tLoss: 187.756348\n",
      "====> Epoch: 1212 Average train loss: 215.0374\n",
      "====> Epoch: 1212 Average test loss: 906.9057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1213 [0/2589 (0%)]\tLoss: 248.918945\n",
      "Train Epoch: 1213 [300/2589 (12%)]\tLoss: 224.397842\n",
      "Train Epoch: 1213 [600/2589 (23%)]\tLoss: 179.398544\n",
      "Train Epoch: 1213 [900/2589 (35%)]\tLoss: 224.218781\n",
      "Train Epoch: 1213 [1200/2589 (46%)]\tLoss: 287.099213\n",
      "Train Epoch: 1213 [1500/2589 (58%)]\tLoss: 187.136169\n",
      "Train Epoch: 1213 [1800/2589 (70%)]\tLoss: 155.589691\n",
      "Train Epoch: 1213 [2100/2589 (81%)]\tLoss: 157.211411\n",
      "Train Epoch: 1213 [2400/2589 (93%)]\tLoss: 543.127686\n",
      "====> Epoch: 1213 Average train loss: 228.6039\n",
      "====> Epoch: 1213 Average test loss: 900.9072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1214 [0/2589 (0%)]\tLoss: 207.239014\n",
      "Train Epoch: 1214 [300/2589 (12%)]\tLoss: 162.416412\n",
      "Train Epoch: 1214 [600/2589 (23%)]\tLoss: 195.763214\n",
      "Train Epoch: 1214 [900/2589 (35%)]\tLoss: 226.860031\n",
      "Train Epoch: 1214 [1200/2589 (46%)]\tLoss: 222.100143\n",
      "Train Epoch: 1214 [1500/2589 (58%)]\tLoss: 256.157654\n",
      "Train Epoch: 1214 [1800/2589 (70%)]\tLoss: 185.115738\n",
      "Train Epoch: 1214 [2100/2589 (81%)]\tLoss: 157.076096\n",
      "Train Epoch: 1214 [2400/2589 (93%)]\tLoss: 167.041702\n",
      "====> Epoch: 1214 Average train loss: 214.2175\n",
      "====> Epoch: 1214 Average test loss: 925.4559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1215 [0/2589 (0%)]\tLoss: 211.031036\n",
      "Train Epoch: 1215 [300/2589 (12%)]\tLoss: 206.864578\n",
      "Train Epoch: 1215 [600/2589 (23%)]\tLoss: 196.850327\n",
      "Train Epoch: 1215 [900/2589 (35%)]\tLoss: 207.779617\n",
      "Train Epoch: 1215 [1200/2589 (46%)]\tLoss: 181.501358\n",
      "Train Epoch: 1215 [1500/2589 (58%)]\tLoss: 236.866714\n",
      "Train Epoch: 1215 [1800/2589 (70%)]\tLoss: 136.015381\n",
      "Train Epoch: 1215 [2100/2589 (81%)]\tLoss: 191.019745\n",
      "Train Epoch: 1215 [2400/2589 (93%)]\tLoss: 224.381577\n",
      "====> Epoch: 1215 Average train loss: 220.4879\n",
      "====> Epoch: 1215 Average test loss: 909.5928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1216 [0/2589 (0%)]\tLoss: 227.596237\n",
      "Train Epoch: 1216 [300/2589 (12%)]\tLoss: 236.196686\n",
      "Train Epoch: 1216 [600/2589 (23%)]\tLoss: 229.844696\n",
      "Train Epoch: 1216 [900/2589 (35%)]\tLoss: 341.315826\n",
      "Train Epoch: 1216 [1200/2589 (46%)]\tLoss: 162.957703\n",
      "Train Epoch: 1216 [1500/2589 (58%)]\tLoss: 282.500275\n",
      "Train Epoch: 1216 [1800/2589 (70%)]\tLoss: 159.567123\n",
      "Train Epoch: 1216 [2100/2589 (81%)]\tLoss: 286.340027\n",
      "Train Epoch: 1216 [2400/2589 (93%)]\tLoss: 219.184235\n",
      "====> Epoch: 1216 Average train loss: 220.1415\n",
      "====> Epoch: 1216 Average test loss: 916.2633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1217 [0/2589 (0%)]\tLoss: 177.867676\n",
      "Train Epoch: 1217 [300/2589 (12%)]\tLoss: 134.999619\n",
      "Train Epoch: 1217 [600/2589 (23%)]\tLoss: 225.203461\n",
      "Train Epoch: 1217 [900/2589 (35%)]\tLoss: 210.533524\n",
      "Train Epoch: 1217 [1200/2589 (46%)]\tLoss: 128.132874\n",
      "Train Epoch: 1217 [1500/2589 (58%)]\tLoss: 278.728394\n",
      "Train Epoch: 1217 [1800/2589 (70%)]\tLoss: 231.240234\n",
      "Train Epoch: 1217 [2100/2589 (81%)]\tLoss: 224.966522\n",
      "Train Epoch: 1217 [2400/2589 (93%)]\tLoss: 219.438538\n",
      "====> Epoch: 1217 Average train loss: 209.0546\n",
      "====> Epoch: 1217 Average test loss: 913.7908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1218 [0/2589 (0%)]\tLoss: 139.061569\n",
      "Train Epoch: 1218 [300/2589 (12%)]\tLoss: 208.070465\n",
      "Train Epoch: 1218 [600/2589 (23%)]\tLoss: 158.976669\n",
      "Train Epoch: 1218 [900/2589 (35%)]\tLoss: 137.920181\n",
      "Train Epoch: 1218 [1200/2589 (46%)]\tLoss: 172.050354\n",
      "Train Epoch: 1218 [1500/2589 (58%)]\tLoss: 165.891144\n",
      "Train Epoch: 1218 [1800/2589 (70%)]\tLoss: 228.711884\n",
      "Train Epoch: 1218 [2100/2589 (81%)]\tLoss: 404.377228\n",
      "Train Epoch: 1218 [2400/2589 (93%)]\tLoss: 216.006927\n",
      "====> Epoch: 1218 Average train loss: 224.2113\n",
      "====> Epoch: 1218 Average test loss: 918.3066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1219 [0/2589 (0%)]\tLoss: 160.135101\n",
      "Train Epoch: 1219 [300/2589 (12%)]\tLoss: 143.071030\n",
      "Train Epoch: 1219 [600/2589 (23%)]\tLoss: 235.961670\n",
      "Train Epoch: 1219 [900/2589 (35%)]\tLoss: 202.805206\n",
      "Train Epoch: 1219 [1200/2589 (46%)]\tLoss: 207.036667\n",
      "Train Epoch: 1219 [1500/2589 (58%)]\tLoss: 173.855133\n",
      "Train Epoch: 1219 [1800/2589 (70%)]\tLoss: 276.842133\n",
      "Train Epoch: 1219 [2100/2589 (81%)]\tLoss: 156.655930\n",
      "Train Epoch: 1219 [2400/2589 (93%)]\tLoss: 170.188705\n",
      "====> Epoch: 1219 Average train loss: 210.7130\n",
      "====> Epoch: 1219 Average test loss: 912.8926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1220 [0/2589 (0%)]\tLoss: 218.757416\n",
      "Train Epoch: 1220 [300/2589 (12%)]\tLoss: 208.596252\n",
      "Train Epoch: 1220 [600/2589 (23%)]\tLoss: 175.956253\n",
      "Train Epoch: 1220 [900/2589 (35%)]\tLoss: 207.597641\n",
      "Train Epoch: 1220 [1200/2589 (46%)]\tLoss: 185.520950\n",
      "Train Epoch: 1220 [1500/2589 (58%)]\tLoss: 237.831146\n",
      "Train Epoch: 1220 [1800/2589 (70%)]\tLoss: 180.213470\n",
      "Train Epoch: 1220 [2100/2589 (81%)]\tLoss: 198.555618\n",
      "Train Epoch: 1220 [2400/2589 (93%)]\tLoss: 126.042946\n",
      "====> Epoch: 1220 Average train loss: 213.1779\n",
      "====> Epoch: 1220 Average test loss: 925.3486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1221 [0/2589 (0%)]\tLoss: 285.097656\n",
      "Train Epoch: 1221 [300/2589 (12%)]\tLoss: 194.608566\n",
      "Train Epoch: 1221 [600/2589 (23%)]\tLoss: 272.552399\n",
      "Train Epoch: 1221 [900/2589 (35%)]\tLoss: 273.660522\n",
      "Train Epoch: 1221 [1200/2589 (46%)]\tLoss: 203.029602\n",
      "Train Epoch: 1221 [1500/2589 (58%)]\tLoss: 283.911194\n",
      "Train Epoch: 1221 [1800/2589 (70%)]\tLoss: 363.120880\n",
      "Train Epoch: 1221 [2100/2589 (81%)]\tLoss: 208.416504\n",
      "Train Epoch: 1221 [2400/2589 (93%)]\tLoss: 154.310577\n",
      "====> Epoch: 1221 Average train loss: 230.3683\n",
      "====> Epoch: 1221 Average test loss: 934.4963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1222 [0/2589 (0%)]\tLoss: 229.574158\n",
      "Train Epoch: 1222 [300/2589 (12%)]\tLoss: 193.643845\n",
      "Train Epoch: 1222 [600/2589 (23%)]\tLoss: 201.375488\n",
      "Train Epoch: 1222 [900/2589 (35%)]\tLoss: 251.189682\n",
      "Train Epoch: 1222 [1200/2589 (46%)]\tLoss: 257.950165\n",
      "Train Epoch: 1222 [1500/2589 (58%)]\tLoss: 154.833298\n",
      "Train Epoch: 1222 [1800/2589 (70%)]\tLoss: 150.043411\n",
      "Train Epoch: 1222 [2100/2589 (81%)]\tLoss: 317.333160\n",
      "Train Epoch: 1222 [2400/2589 (93%)]\tLoss: 200.382538\n",
      "====> Epoch: 1222 Average train loss: 204.2730\n",
      "====> Epoch: 1222 Average test loss: 918.3066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1223 [0/2589 (0%)]\tLoss: 293.776031\n",
      "Train Epoch: 1223 [300/2589 (12%)]\tLoss: 202.728897\n",
      "Train Epoch: 1223 [600/2589 (23%)]\tLoss: 311.660706\n",
      "Train Epoch: 1223 [900/2589 (35%)]\tLoss: 166.574753\n",
      "Train Epoch: 1223 [1200/2589 (46%)]\tLoss: 244.832870\n",
      "Train Epoch: 1223 [1500/2589 (58%)]\tLoss: 164.739166\n",
      "Train Epoch: 1223 [1800/2589 (70%)]\tLoss: 280.297638\n",
      "Train Epoch: 1223 [2100/2589 (81%)]\tLoss: 210.900101\n",
      "Train Epoch: 1223 [2400/2589 (93%)]\tLoss: 184.417725\n",
      "====> Epoch: 1223 Average train loss: 219.7703\n",
      "====> Epoch: 1223 Average test loss: 898.8526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1224 [0/2589 (0%)]\tLoss: 205.913910\n",
      "Train Epoch: 1224 [300/2589 (12%)]\tLoss: 197.103088\n",
      "Train Epoch: 1224 [600/2589 (23%)]\tLoss: 367.522339\n",
      "Train Epoch: 1224 [900/2589 (35%)]\tLoss: 191.179062\n",
      "Train Epoch: 1224 [1200/2589 (46%)]\tLoss: 158.226349\n",
      "Train Epoch: 1224 [1500/2589 (58%)]\tLoss: 175.812531\n",
      "Train Epoch: 1224 [1800/2589 (70%)]\tLoss: 258.493103\n",
      "Train Epoch: 1224 [2100/2589 (81%)]\tLoss: 173.989960\n",
      "Train Epoch: 1224 [2400/2589 (93%)]\tLoss: 168.530701\n",
      "====> Epoch: 1224 Average train loss: 211.2814\n",
      "====> Epoch: 1224 Average test loss: 894.5742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1225 [0/2589 (0%)]\tLoss: 161.332428\n",
      "Train Epoch: 1225 [300/2589 (12%)]\tLoss: 334.280365\n",
      "Train Epoch: 1225 [600/2589 (23%)]\tLoss: 262.909027\n",
      "Train Epoch: 1225 [900/2589 (35%)]\tLoss: 183.307175\n",
      "Train Epoch: 1225 [1200/2589 (46%)]\tLoss: 130.305008\n",
      "Train Epoch: 1225 [1500/2589 (58%)]\tLoss: 271.736420\n",
      "Train Epoch: 1225 [1800/2589 (70%)]\tLoss: 264.158905\n",
      "Train Epoch: 1225 [2100/2589 (81%)]\tLoss: 210.075714\n",
      "Train Epoch: 1225 [2400/2589 (93%)]\tLoss: 348.333344\n",
      "====> Epoch: 1225 Average train loss: 213.5240\n",
      "====> Epoch: 1225 Average test loss: 902.8580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1226 [0/2589 (0%)]\tLoss: 170.299347\n",
      "Train Epoch: 1226 [300/2589 (12%)]\tLoss: 239.539581\n",
      "Train Epoch: 1226 [600/2589 (23%)]\tLoss: 211.323196\n",
      "Train Epoch: 1226 [900/2589 (35%)]\tLoss: 163.940018\n",
      "Train Epoch: 1226 [1200/2589 (46%)]\tLoss: 171.036026\n",
      "Train Epoch: 1226 [1500/2589 (58%)]\tLoss: 190.913879\n",
      "Train Epoch: 1226 [1800/2589 (70%)]\tLoss: 196.867676\n",
      "Train Epoch: 1226 [2100/2589 (81%)]\tLoss: 252.820328\n",
      "Train Epoch: 1226 [2400/2589 (93%)]\tLoss: 208.401016\n",
      "====> Epoch: 1226 Average train loss: 209.2702\n",
      "====> Epoch: 1226 Average test loss: 909.9229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1227 [0/2589 (0%)]\tLoss: 119.674576\n",
      "Train Epoch: 1227 [300/2589 (12%)]\tLoss: 183.266342\n",
      "Train Epoch: 1227 [600/2589 (23%)]\tLoss: 202.593536\n",
      "Train Epoch: 1227 [900/2589 (35%)]\tLoss: 235.557129\n",
      "Train Epoch: 1227 [1200/2589 (46%)]\tLoss: 216.004471\n",
      "Train Epoch: 1227 [1500/2589 (58%)]\tLoss: 231.017776\n",
      "Train Epoch: 1227 [1800/2589 (70%)]\tLoss: 395.220795\n",
      "Train Epoch: 1227 [2100/2589 (81%)]\tLoss: 215.486816\n",
      "Train Epoch: 1227 [2400/2589 (93%)]\tLoss: 224.889252\n",
      "====> Epoch: 1227 Average train loss: 218.9742\n",
      "====> Epoch: 1227 Average test loss: 905.5924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1228 [0/2589 (0%)]\tLoss: 166.800110\n",
      "Train Epoch: 1228 [300/2589 (12%)]\tLoss: 132.789902\n",
      "Train Epoch: 1228 [600/2589 (23%)]\tLoss: 348.070770\n",
      "Train Epoch: 1228 [900/2589 (35%)]\tLoss: 248.219238\n",
      "Train Epoch: 1228 [1200/2589 (46%)]\tLoss: 171.973236\n",
      "Train Epoch: 1228 [1500/2589 (58%)]\tLoss: 135.789337\n",
      "Train Epoch: 1228 [1800/2589 (70%)]\tLoss: 301.767700\n",
      "Train Epoch: 1228 [2100/2589 (81%)]\tLoss: 219.387802\n",
      "Train Epoch: 1228 [2400/2589 (93%)]\tLoss: 163.475296\n",
      "====> Epoch: 1228 Average train loss: 204.5415\n",
      "====> Epoch: 1228 Average test loss: 903.0668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1229 [0/2589 (0%)]\tLoss: 232.990234\n",
      "Train Epoch: 1229 [300/2589 (12%)]\tLoss: 285.616516\n",
      "Train Epoch: 1229 [600/2589 (23%)]\tLoss: 162.325500\n",
      "Train Epoch: 1229 [900/2589 (35%)]\tLoss: 201.295883\n",
      "Train Epoch: 1229 [1200/2589 (46%)]\tLoss: 201.643448\n",
      "Train Epoch: 1229 [1500/2589 (58%)]\tLoss: 215.999222\n",
      "Train Epoch: 1229 [1800/2589 (70%)]\tLoss: 175.820618\n",
      "Train Epoch: 1229 [2100/2589 (81%)]\tLoss: 200.439209\n",
      "Train Epoch: 1229 [2400/2589 (93%)]\tLoss: 172.757645\n",
      "====> Epoch: 1229 Average train loss: 219.6499\n",
      "====> Epoch: 1229 Average test loss: 925.1350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1230 [0/2589 (0%)]\tLoss: 152.026230\n",
      "Train Epoch: 1230 [300/2589 (12%)]\tLoss: 264.230316\n",
      "Train Epoch: 1230 [600/2589 (23%)]\tLoss: 199.230209\n",
      "Train Epoch: 1230 [900/2589 (35%)]\tLoss: 270.501678\n",
      "Train Epoch: 1230 [1200/2589 (46%)]\tLoss: 153.882614\n",
      "Train Epoch: 1230 [1500/2589 (58%)]\tLoss: 220.714890\n",
      "Train Epoch: 1230 [1800/2589 (70%)]\tLoss: 227.411713\n",
      "Train Epoch: 1230 [2100/2589 (81%)]\tLoss: 185.065826\n",
      "Train Epoch: 1230 [2400/2589 (93%)]\tLoss: 218.141251\n",
      "====> Epoch: 1230 Average train loss: 218.8970\n",
      "====> Epoch: 1230 Average test loss: 917.8808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1231 [0/2589 (0%)]\tLoss: 168.593033\n",
      "Train Epoch: 1231 [300/2589 (12%)]\tLoss: 220.246765\n",
      "Train Epoch: 1231 [600/2589 (23%)]\tLoss: 176.839752\n",
      "Train Epoch: 1231 [900/2589 (35%)]\tLoss: 156.989822\n",
      "Train Epoch: 1231 [1200/2589 (46%)]\tLoss: 147.631516\n",
      "Train Epoch: 1231 [1500/2589 (58%)]\tLoss: 146.598923\n",
      "Train Epoch: 1231 [1800/2589 (70%)]\tLoss: 288.425598\n",
      "Train Epoch: 1231 [2100/2589 (81%)]\tLoss: 166.919739\n",
      "Train Epoch: 1231 [2400/2589 (93%)]\tLoss: 158.443069\n",
      "====> Epoch: 1231 Average train loss: 204.5854\n",
      "====> Epoch: 1231 Average test loss: 927.6287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1232 [0/2589 (0%)]\tLoss: 212.002365\n",
      "Train Epoch: 1232 [300/2589 (12%)]\tLoss: 183.658386\n",
      "Train Epoch: 1232 [600/2589 (23%)]\tLoss: 209.048752\n",
      "Train Epoch: 1232 [900/2589 (35%)]\tLoss: 282.714050\n",
      "Train Epoch: 1232 [1200/2589 (46%)]\tLoss: 207.880127\n",
      "Train Epoch: 1232 [1500/2589 (58%)]\tLoss: 197.808929\n",
      "Train Epoch: 1232 [1800/2589 (70%)]\tLoss: 155.041336\n",
      "Train Epoch: 1232 [2100/2589 (81%)]\tLoss: 196.857224\n",
      "Train Epoch: 1232 [2400/2589 (93%)]\tLoss: 165.073746\n",
      "====> Epoch: 1232 Average train loss: 213.0379\n",
      "====> Epoch: 1232 Average test loss: 898.6111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1233 [0/2589 (0%)]\tLoss: 177.261948\n",
      "Train Epoch: 1233 [300/2589 (12%)]\tLoss: 168.550339\n",
      "Train Epoch: 1233 [600/2589 (23%)]\tLoss: 182.988541\n",
      "Train Epoch: 1233 [900/2589 (35%)]\tLoss: 292.339417\n",
      "Train Epoch: 1233 [1200/2589 (46%)]\tLoss: 255.845810\n",
      "Train Epoch: 1233 [1500/2589 (58%)]\tLoss: 166.035904\n",
      "Train Epoch: 1233 [1800/2589 (70%)]\tLoss: 203.108734\n",
      "Train Epoch: 1233 [2100/2589 (81%)]\tLoss: 183.200134\n",
      "Train Epoch: 1233 [2400/2589 (93%)]\tLoss: 147.065521\n",
      "====> Epoch: 1233 Average train loss: 215.7338\n",
      "====> Epoch: 1233 Average test loss: 916.9429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1234 [0/2589 (0%)]\tLoss: 186.623276\n",
      "Train Epoch: 1234 [300/2589 (12%)]\tLoss: 194.507050\n",
      "Train Epoch: 1234 [600/2589 (23%)]\tLoss: 144.736298\n",
      "Train Epoch: 1234 [900/2589 (35%)]\tLoss: 227.191635\n",
      "Train Epoch: 1234 [1200/2589 (46%)]\tLoss: 318.507629\n",
      "Train Epoch: 1234 [1500/2589 (58%)]\tLoss: 217.182724\n",
      "Train Epoch: 1234 [1800/2589 (70%)]\tLoss: 175.845200\n",
      "Train Epoch: 1234 [2100/2589 (81%)]\tLoss: 169.593170\n",
      "Train Epoch: 1234 [2400/2589 (93%)]\tLoss: 154.041962\n",
      "====> Epoch: 1234 Average train loss: 219.6324\n",
      "====> Epoch: 1234 Average test loss: 900.2224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1235 [0/2589 (0%)]\tLoss: 214.021210\n",
      "Train Epoch: 1235 [300/2589 (12%)]\tLoss: 217.646973\n",
      "Train Epoch: 1235 [600/2589 (23%)]\tLoss: 240.192215\n",
      "Train Epoch: 1235 [900/2589 (35%)]\tLoss: 232.305359\n",
      "Train Epoch: 1235 [1200/2589 (46%)]\tLoss: 234.094376\n",
      "Train Epoch: 1235 [1500/2589 (58%)]\tLoss: 259.183807\n",
      "Train Epoch: 1235 [1800/2589 (70%)]\tLoss: 285.987183\n",
      "Train Epoch: 1235 [2100/2589 (81%)]\tLoss: 340.479065\n",
      "Train Epoch: 1235 [2400/2589 (93%)]\tLoss: 245.488846\n",
      "====> Epoch: 1235 Average train loss: 212.6762\n",
      "====> Epoch: 1235 Average test loss: 902.8791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1236 [0/2589 (0%)]\tLoss: 267.814331\n",
      "Train Epoch: 1236 [300/2589 (12%)]\tLoss: 251.071533\n",
      "Train Epoch: 1236 [600/2589 (23%)]\tLoss: 210.605270\n",
      "Train Epoch: 1236 [900/2589 (35%)]\tLoss: 253.388840\n",
      "Train Epoch: 1236 [1200/2589 (46%)]\tLoss: 195.137878\n",
      "Train Epoch: 1236 [1500/2589 (58%)]\tLoss: 306.575195\n",
      "Train Epoch: 1236 [1800/2589 (70%)]\tLoss: 318.285217\n",
      "Train Epoch: 1236 [2100/2589 (81%)]\tLoss: 186.079605\n",
      "Train Epoch: 1236 [2400/2589 (93%)]\tLoss: 206.447495\n",
      "====> Epoch: 1236 Average train loss: 222.4252\n",
      "====> Epoch: 1236 Average test loss: 911.0941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1237 [0/2589 (0%)]\tLoss: 191.930557\n",
      "Train Epoch: 1237 [300/2589 (12%)]\tLoss: 197.878738\n",
      "Train Epoch: 1237 [600/2589 (23%)]\tLoss: 295.758789\n",
      "Train Epoch: 1237 [900/2589 (35%)]\tLoss: 222.872589\n",
      "Train Epoch: 1237 [1200/2589 (46%)]\tLoss: 194.452896\n",
      "Train Epoch: 1237 [1500/2589 (58%)]\tLoss: 257.539276\n",
      "Train Epoch: 1237 [1800/2589 (70%)]\tLoss: 277.733215\n",
      "Train Epoch: 1237 [2100/2589 (81%)]\tLoss: 195.416122\n",
      "Train Epoch: 1237 [2400/2589 (93%)]\tLoss: 280.325073\n",
      "====> Epoch: 1237 Average train loss: 215.9398\n",
      "====> Epoch: 1237 Average test loss: 920.8320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1238 [0/2589 (0%)]\tLoss: 186.521042\n",
      "Train Epoch: 1238 [300/2589 (12%)]\tLoss: 170.620590\n",
      "Train Epoch: 1238 [600/2589 (23%)]\tLoss: 168.587936\n",
      "Train Epoch: 1238 [900/2589 (35%)]\tLoss: 140.258377\n",
      "Train Epoch: 1238 [1200/2589 (46%)]\tLoss: 177.871643\n",
      "Train Epoch: 1238 [1500/2589 (58%)]\tLoss: 156.921173\n",
      "Train Epoch: 1238 [1800/2589 (70%)]\tLoss: 308.109863\n",
      "Train Epoch: 1238 [2100/2589 (81%)]\tLoss: 220.410065\n",
      "Train Epoch: 1238 [2400/2589 (93%)]\tLoss: 261.586426\n",
      "====> Epoch: 1238 Average train loss: 210.1503\n",
      "====> Epoch: 1238 Average test loss: 906.8809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1239 [0/2589 (0%)]\tLoss: 167.463318\n",
      "Train Epoch: 1239 [300/2589 (12%)]\tLoss: 254.151016\n",
      "Train Epoch: 1239 [600/2589 (23%)]\tLoss: 177.003235\n",
      "Train Epoch: 1239 [900/2589 (35%)]\tLoss: 155.701859\n",
      "Train Epoch: 1239 [1200/2589 (46%)]\tLoss: 236.812805\n",
      "Train Epoch: 1239 [1500/2589 (58%)]\tLoss: 182.689514\n",
      "Train Epoch: 1239 [1800/2589 (70%)]\tLoss: 194.417816\n",
      "Train Epoch: 1239 [2100/2589 (81%)]\tLoss: 172.900482\n",
      "Train Epoch: 1239 [2400/2589 (93%)]\tLoss: 175.209732\n",
      "====> Epoch: 1239 Average train loss: 211.9923\n",
      "====> Epoch: 1239 Average test loss: 925.1055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1240 [0/2589 (0%)]\tLoss: 409.703003\n",
      "Train Epoch: 1240 [300/2589 (12%)]\tLoss: 143.275818\n",
      "Train Epoch: 1240 [600/2589 (23%)]\tLoss: 195.984619\n",
      "Train Epoch: 1240 [900/2589 (35%)]\tLoss: 229.438782\n",
      "Train Epoch: 1240 [1200/2589 (46%)]\tLoss: 214.742889\n",
      "Train Epoch: 1240 [1500/2589 (58%)]\tLoss: 179.857971\n",
      "Train Epoch: 1240 [1800/2589 (70%)]\tLoss: 188.980682\n",
      "Train Epoch: 1240 [2100/2589 (81%)]\tLoss: 165.332947\n",
      "Train Epoch: 1240 [2400/2589 (93%)]\tLoss: 206.722763\n",
      "====> Epoch: 1240 Average train loss: 214.7938\n",
      "====> Epoch: 1240 Average test loss: 913.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1241 [0/2589 (0%)]\tLoss: 205.955322\n",
      "Train Epoch: 1241 [300/2589 (12%)]\tLoss: 172.979553\n",
      "Train Epoch: 1241 [600/2589 (23%)]\tLoss: 249.974533\n",
      "Train Epoch: 1241 [900/2589 (35%)]\tLoss: 222.057281\n",
      "Train Epoch: 1241 [1200/2589 (46%)]\tLoss: 193.582520\n",
      "Train Epoch: 1241 [1500/2589 (58%)]\tLoss: 163.762726\n",
      "Train Epoch: 1241 [1800/2589 (70%)]\tLoss: 207.733261\n",
      "Train Epoch: 1241 [2100/2589 (81%)]\tLoss: 204.059555\n",
      "Train Epoch: 1241 [2400/2589 (93%)]\tLoss: 291.494843\n",
      "====> Epoch: 1241 Average train loss: 215.8367\n",
      "====> Epoch: 1241 Average test loss: 913.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1242 [0/2589 (0%)]\tLoss: 143.980148\n",
      "Train Epoch: 1242 [300/2589 (12%)]\tLoss: 276.251068\n",
      "Train Epoch: 1242 [600/2589 (23%)]\tLoss: 192.626526\n",
      "Train Epoch: 1242 [900/2589 (35%)]\tLoss: 222.383835\n",
      "Train Epoch: 1242 [1200/2589 (46%)]\tLoss: 140.120438\n",
      "Train Epoch: 1242 [1500/2589 (58%)]\tLoss: 148.366638\n",
      "Train Epoch: 1242 [1800/2589 (70%)]\tLoss: 197.599457\n",
      "Train Epoch: 1242 [2100/2589 (81%)]\tLoss: 356.878693\n",
      "Train Epoch: 1242 [2400/2589 (93%)]\tLoss: 137.802246\n",
      "====> Epoch: 1242 Average train loss: 222.7693\n",
      "====> Epoch: 1242 Average test loss: 899.2357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1243 [0/2589 (0%)]\tLoss: 128.002762\n",
      "Train Epoch: 1243 [300/2589 (12%)]\tLoss: 402.349335\n",
      "Train Epoch: 1243 [600/2589 (23%)]\tLoss: 241.008041\n",
      "Train Epoch: 1243 [900/2589 (35%)]\tLoss: 168.754349\n",
      "Train Epoch: 1243 [1200/2589 (46%)]\tLoss: 278.955200\n",
      "Train Epoch: 1243 [1500/2589 (58%)]\tLoss: 159.118423\n",
      "Train Epoch: 1243 [1800/2589 (70%)]\tLoss: 251.130554\n",
      "Train Epoch: 1243 [2100/2589 (81%)]\tLoss: 182.724518\n",
      "Train Epoch: 1243 [2400/2589 (93%)]\tLoss: 291.500336\n",
      "====> Epoch: 1243 Average train loss: 218.1728\n",
      "====> Epoch: 1243 Average test loss: 909.8685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1244 [0/2589 (0%)]\tLoss: 215.533279\n",
      "Train Epoch: 1244 [300/2589 (12%)]\tLoss: 167.376160\n",
      "Train Epoch: 1244 [600/2589 (23%)]\tLoss: 192.115326\n",
      "Train Epoch: 1244 [900/2589 (35%)]\tLoss: 181.202469\n",
      "Train Epoch: 1244 [1200/2589 (46%)]\tLoss: 197.188538\n",
      "Train Epoch: 1244 [1500/2589 (58%)]\tLoss: 169.808105\n",
      "Train Epoch: 1244 [1800/2589 (70%)]\tLoss: 168.294495\n",
      "Train Epoch: 1244 [2100/2589 (81%)]\tLoss: 215.569031\n",
      "Train Epoch: 1244 [2400/2589 (93%)]\tLoss: 183.434311\n",
      "====> Epoch: 1244 Average train loss: 210.3592\n",
      "====> Epoch: 1244 Average test loss: 915.6969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1245 [0/2589 (0%)]\tLoss: 182.558075\n",
      "Train Epoch: 1245 [300/2589 (12%)]\tLoss: 194.747360\n",
      "Train Epoch: 1245 [600/2589 (23%)]\tLoss: 132.848328\n",
      "Train Epoch: 1245 [900/2589 (35%)]\tLoss: 199.767044\n",
      "Train Epoch: 1245 [1200/2589 (46%)]\tLoss: 214.622772\n",
      "Train Epoch: 1245 [1500/2589 (58%)]\tLoss: 185.404358\n",
      "Train Epoch: 1245 [1800/2589 (70%)]\tLoss: 128.739487\n",
      "Train Epoch: 1245 [2100/2589 (81%)]\tLoss: 194.333954\n",
      "Train Epoch: 1245 [2400/2589 (93%)]\tLoss: 173.748764\n",
      "====> Epoch: 1245 Average train loss: 217.5847\n",
      "====> Epoch: 1245 Average test loss: 909.1470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1246 [0/2589 (0%)]\tLoss: 155.684006\n",
      "Train Epoch: 1246 [300/2589 (12%)]\tLoss: 227.377029\n",
      "Train Epoch: 1246 [600/2589 (23%)]\tLoss: 147.282135\n",
      "Train Epoch: 1246 [900/2589 (35%)]\tLoss: 405.496643\n",
      "Train Epoch: 1246 [1200/2589 (46%)]\tLoss: 133.606537\n",
      "Train Epoch: 1246 [1500/2589 (58%)]\tLoss: 161.459183\n",
      "Train Epoch: 1246 [1800/2589 (70%)]\tLoss: 140.701279\n",
      "Train Epoch: 1246 [2100/2589 (81%)]\tLoss: 128.072037\n",
      "Train Epoch: 1246 [2400/2589 (93%)]\tLoss: 198.595871\n",
      "====> Epoch: 1246 Average train loss: 205.7680\n",
      "====> Epoch: 1246 Average test loss: 917.1198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1247 [0/2589 (0%)]\tLoss: 230.742905\n",
      "Train Epoch: 1247 [300/2589 (12%)]\tLoss: 149.171616\n",
      "Train Epoch: 1247 [600/2589 (23%)]\tLoss: 234.342102\n",
      "Train Epoch: 1247 [900/2589 (35%)]\tLoss: 313.319305\n",
      "Train Epoch: 1247 [1200/2589 (46%)]\tLoss: 179.249695\n",
      "Train Epoch: 1247 [1500/2589 (58%)]\tLoss: 286.834686\n",
      "Train Epoch: 1247 [1800/2589 (70%)]\tLoss: 224.519882\n",
      "Train Epoch: 1247 [2100/2589 (81%)]\tLoss: 285.332153\n",
      "Train Epoch: 1247 [2400/2589 (93%)]\tLoss: 230.386566\n",
      "====> Epoch: 1247 Average train loss: 230.8785\n",
      "====> Epoch: 1247 Average test loss: 911.2286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1248 [0/2589 (0%)]\tLoss: 180.586761\n",
      "Train Epoch: 1248 [300/2589 (12%)]\tLoss: 135.406998\n",
      "Train Epoch: 1248 [600/2589 (23%)]\tLoss: 222.712265\n",
      "Train Epoch: 1248 [900/2589 (35%)]\tLoss: 204.391312\n",
      "Train Epoch: 1248 [1200/2589 (46%)]\tLoss: 255.056900\n",
      "Train Epoch: 1248 [1500/2589 (58%)]\tLoss: 331.811127\n",
      "Train Epoch: 1248 [1800/2589 (70%)]\tLoss: 145.042023\n",
      "Train Epoch: 1248 [2100/2589 (81%)]\tLoss: 193.377197\n",
      "Train Epoch: 1248 [2400/2589 (93%)]\tLoss: 193.889130\n",
      "====> Epoch: 1248 Average train loss: 224.8026\n",
      "====> Epoch: 1248 Average test loss: 909.7205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1249 [0/2589 (0%)]\tLoss: 164.850540\n",
      "Train Epoch: 1249 [300/2589 (12%)]\tLoss: 182.148834\n",
      "Train Epoch: 1249 [600/2589 (23%)]\tLoss: 214.769791\n",
      "Train Epoch: 1249 [900/2589 (35%)]\tLoss: 165.045898\n",
      "Train Epoch: 1249 [1200/2589 (46%)]\tLoss: 216.336044\n",
      "Train Epoch: 1249 [1500/2589 (58%)]\tLoss: 216.837250\n",
      "Train Epoch: 1249 [1800/2589 (70%)]\tLoss: 170.808121\n",
      "Train Epoch: 1249 [2100/2589 (81%)]\tLoss: 193.246979\n",
      "Train Epoch: 1249 [2400/2589 (93%)]\tLoss: 187.853653\n",
      "====> Epoch: 1249 Average train loss: 206.1137\n",
      "====> Epoch: 1249 Average test loss: 912.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1250 [0/2589 (0%)]\tLoss: 211.979095\n",
      "Train Epoch: 1250 [300/2589 (12%)]\tLoss: 158.716843\n",
      "Train Epoch: 1250 [600/2589 (23%)]\tLoss: 202.422226\n",
      "Train Epoch: 1250 [900/2589 (35%)]\tLoss: 209.819717\n",
      "Train Epoch: 1250 [1200/2589 (46%)]\tLoss: 312.281067\n",
      "Train Epoch: 1250 [1500/2589 (58%)]\tLoss: 184.549881\n",
      "Train Epoch: 1250 [1800/2589 (70%)]\tLoss: 260.341003\n",
      "Train Epoch: 1250 [2100/2589 (81%)]\tLoss: 196.186310\n",
      "Train Epoch: 1250 [2400/2589 (93%)]\tLoss: 226.924622\n",
      "====> Epoch: 1250 Average train loss: 216.3401\n",
      "====> Epoch: 1250 Average test loss: 921.8092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1251 [0/2589 (0%)]\tLoss: 142.014984\n",
      "Train Epoch: 1251 [300/2589 (12%)]\tLoss: 188.124207\n",
      "Train Epoch: 1251 [600/2589 (23%)]\tLoss: 155.099396\n",
      "Train Epoch: 1251 [900/2589 (35%)]\tLoss: 315.649292\n",
      "Train Epoch: 1251 [1200/2589 (46%)]\tLoss: 349.334198\n",
      "Train Epoch: 1251 [1500/2589 (58%)]\tLoss: 193.257385\n",
      "Train Epoch: 1251 [1800/2589 (70%)]\tLoss: 184.815002\n",
      "Train Epoch: 1251 [2100/2589 (81%)]\tLoss: 170.979553\n",
      "Train Epoch: 1251 [2400/2589 (93%)]\tLoss: 374.764984\n",
      "====> Epoch: 1251 Average train loss: 211.5718\n",
      "====> Epoch: 1251 Average test loss: 905.3424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1252 [0/2589 (0%)]\tLoss: 159.689423\n",
      "Train Epoch: 1252 [300/2589 (12%)]\tLoss: 234.783051\n",
      "Train Epoch: 1252 [600/2589 (23%)]\tLoss: 262.187225\n",
      "Train Epoch: 1252 [900/2589 (35%)]\tLoss: 327.621277\n",
      "Train Epoch: 1252 [1200/2589 (46%)]\tLoss: 269.542633\n",
      "Train Epoch: 1252 [1500/2589 (58%)]\tLoss: 206.672623\n",
      "Train Epoch: 1252 [1800/2589 (70%)]\tLoss: 193.222382\n",
      "Train Epoch: 1252 [2100/2589 (81%)]\tLoss: 287.141449\n",
      "Train Epoch: 1252 [2400/2589 (93%)]\tLoss: 214.013351\n",
      "====> Epoch: 1252 Average train loss: 218.9892\n",
      "====> Epoch: 1252 Average test loss: 917.4673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1253 [0/2589 (0%)]\tLoss: 259.654388\n",
      "Train Epoch: 1253 [300/2589 (12%)]\tLoss: 195.763443\n",
      "Train Epoch: 1253 [600/2589 (23%)]\tLoss: 134.661774\n",
      "Train Epoch: 1253 [900/2589 (35%)]\tLoss: 193.471619\n",
      "Train Epoch: 1253 [1200/2589 (46%)]\tLoss: 155.299408\n",
      "Train Epoch: 1253 [1500/2589 (58%)]\tLoss: 153.230270\n",
      "Train Epoch: 1253 [1800/2589 (70%)]\tLoss: 189.059784\n",
      "Train Epoch: 1253 [2100/2589 (81%)]\tLoss: 198.873306\n",
      "Train Epoch: 1253 [2400/2589 (93%)]\tLoss: 170.796127\n",
      "====> Epoch: 1253 Average train loss: 208.0155\n",
      "====> Epoch: 1253 Average test loss: 902.0306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1254 [0/2589 (0%)]\tLoss: 223.392227\n",
      "Train Epoch: 1254 [300/2589 (12%)]\tLoss: 149.107330\n",
      "Train Epoch: 1254 [600/2589 (23%)]\tLoss: 170.666504\n",
      "Train Epoch: 1254 [900/2589 (35%)]\tLoss: 184.678741\n",
      "Train Epoch: 1254 [1200/2589 (46%)]\tLoss: 239.156250\n",
      "Train Epoch: 1254 [1500/2589 (58%)]\tLoss: 364.150482\n",
      "Train Epoch: 1254 [1800/2589 (70%)]\tLoss: 196.708420\n",
      "Train Epoch: 1254 [2100/2589 (81%)]\tLoss: 220.604462\n",
      "Train Epoch: 1254 [2400/2589 (93%)]\tLoss: 194.046127\n",
      "====> Epoch: 1254 Average train loss: 218.6085\n",
      "====> Epoch: 1254 Average test loss: 903.1187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1255 [0/2589 (0%)]\tLoss: 287.295319\n",
      "Train Epoch: 1255 [300/2589 (12%)]\tLoss: 122.826874\n",
      "Train Epoch: 1255 [600/2589 (23%)]\tLoss: 171.685806\n",
      "Train Epoch: 1255 [900/2589 (35%)]\tLoss: 217.489746\n",
      "Train Epoch: 1255 [1200/2589 (46%)]\tLoss: 175.062363\n",
      "Train Epoch: 1255 [1500/2589 (58%)]\tLoss: 284.936646\n",
      "Train Epoch: 1255 [1800/2589 (70%)]\tLoss: 247.604172\n",
      "Train Epoch: 1255 [2100/2589 (81%)]\tLoss: 180.515884\n",
      "Train Epoch: 1255 [2400/2589 (93%)]\tLoss: 202.245697\n",
      "====> Epoch: 1255 Average train loss: 204.5875\n",
      "====> Epoch: 1255 Average test loss: 914.6878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1256 [0/2589 (0%)]\tLoss: 215.597321\n",
      "Train Epoch: 1256 [300/2589 (12%)]\tLoss: 115.483353\n",
      "Train Epoch: 1256 [600/2589 (23%)]\tLoss: 149.058289\n",
      "Train Epoch: 1256 [900/2589 (35%)]\tLoss: 216.152130\n",
      "Train Epoch: 1256 [1200/2589 (46%)]\tLoss: 305.160248\n",
      "Train Epoch: 1256 [1500/2589 (58%)]\tLoss: 228.450851\n",
      "Train Epoch: 1256 [1800/2589 (70%)]\tLoss: 167.550919\n",
      "Train Epoch: 1256 [2100/2589 (81%)]\tLoss: 174.683762\n",
      "Train Epoch: 1256 [2400/2589 (93%)]\tLoss: 282.637726\n",
      "====> Epoch: 1256 Average train loss: 205.2929\n",
      "====> Epoch: 1256 Average test loss: 919.5715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1257 [0/2589 (0%)]\tLoss: 225.026215\n",
      "Train Epoch: 1257 [300/2589 (12%)]\tLoss: 200.125427\n",
      "Train Epoch: 1257 [600/2589 (23%)]\tLoss: 176.679840\n",
      "Train Epoch: 1257 [900/2589 (35%)]\tLoss: 212.682022\n",
      "Train Epoch: 1257 [1200/2589 (46%)]\tLoss: 162.678970\n",
      "Train Epoch: 1257 [1500/2589 (58%)]\tLoss: 238.486603\n",
      "Train Epoch: 1257 [1800/2589 (70%)]\tLoss: 212.793121\n",
      "Train Epoch: 1257 [2100/2589 (81%)]\tLoss: 276.442841\n",
      "Train Epoch: 1257 [2400/2589 (93%)]\tLoss: 263.719696\n",
      "====> Epoch: 1257 Average train loss: 232.7640\n",
      "====> Epoch: 1257 Average test loss: 919.6274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1258 [0/2589 (0%)]\tLoss: 208.522797\n",
      "Train Epoch: 1258 [300/2589 (12%)]\tLoss: 190.083221\n",
      "Train Epoch: 1258 [600/2589 (23%)]\tLoss: 170.014893\n",
      "Train Epoch: 1258 [900/2589 (35%)]\tLoss: 120.682259\n",
      "Train Epoch: 1258 [1200/2589 (46%)]\tLoss: 146.171707\n",
      "Train Epoch: 1258 [1500/2589 (58%)]\tLoss: 159.433502\n",
      "Train Epoch: 1258 [1800/2589 (70%)]\tLoss: 209.821777\n",
      "Train Epoch: 1258 [2100/2589 (81%)]\tLoss: 241.180603\n",
      "Train Epoch: 1258 [2400/2589 (93%)]\tLoss: 155.423920\n",
      "====> Epoch: 1258 Average train loss: 213.2103\n",
      "====> Epoch: 1258 Average test loss: 918.1117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1259 [0/2589 (0%)]\tLoss: 183.469681\n",
      "Train Epoch: 1259 [300/2589 (12%)]\tLoss: 242.200302\n",
      "Train Epoch: 1259 [600/2589 (23%)]\tLoss: 236.166901\n",
      "Train Epoch: 1259 [900/2589 (35%)]\tLoss: 152.960617\n",
      "Train Epoch: 1259 [1200/2589 (46%)]\tLoss: 201.233688\n",
      "Train Epoch: 1259 [1500/2589 (58%)]\tLoss: 246.402451\n",
      "Train Epoch: 1259 [1800/2589 (70%)]\tLoss: 200.803299\n",
      "Train Epoch: 1259 [2100/2589 (81%)]\tLoss: 204.345520\n",
      "Train Epoch: 1259 [2400/2589 (93%)]\tLoss: 280.152252\n",
      "====> Epoch: 1259 Average train loss: 209.0842\n",
      "====> Epoch: 1259 Average test loss: 915.6785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1260 [0/2589 (0%)]\tLoss: 228.901886\n",
      "Train Epoch: 1260 [300/2589 (12%)]\tLoss: 226.162125\n",
      "Train Epoch: 1260 [600/2589 (23%)]\tLoss: 195.425507\n",
      "Train Epoch: 1260 [900/2589 (35%)]\tLoss: 150.821320\n",
      "Train Epoch: 1260 [1200/2589 (46%)]\tLoss: 208.241119\n",
      "Train Epoch: 1260 [1500/2589 (58%)]\tLoss: 189.714081\n",
      "Train Epoch: 1260 [1800/2589 (70%)]\tLoss: 295.137848\n",
      "Train Epoch: 1260 [2100/2589 (81%)]\tLoss: 150.524994\n",
      "Train Epoch: 1260 [2400/2589 (93%)]\tLoss: 191.206512\n",
      "====> Epoch: 1260 Average train loss: 203.6871\n",
      "====> Epoch: 1260 Average test loss: 928.3250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1261 [0/2589 (0%)]\tLoss: 266.344086\n",
      "Train Epoch: 1261 [300/2589 (12%)]\tLoss: 254.187027\n",
      "Train Epoch: 1261 [600/2589 (23%)]\tLoss: 170.288574\n",
      "Train Epoch: 1261 [900/2589 (35%)]\tLoss: 203.152908\n",
      "Train Epoch: 1261 [1200/2589 (46%)]\tLoss: 139.505325\n",
      "Train Epoch: 1261 [1500/2589 (58%)]\tLoss: 197.021500\n",
      "Train Epoch: 1261 [1800/2589 (70%)]\tLoss: 240.435516\n",
      "Train Epoch: 1261 [2100/2589 (81%)]\tLoss: 216.786865\n",
      "Train Epoch: 1261 [2400/2589 (93%)]\tLoss: 245.394333\n",
      "====> Epoch: 1261 Average train loss: 214.6859\n",
      "====> Epoch: 1261 Average test loss: 927.0337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1262 [0/2589 (0%)]\tLoss: 222.076202\n",
      "Train Epoch: 1262 [300/2589 (12%)]\tLoss: 182.771652\n",
      "Train Epoch: 1262 [600/2589 (23%)]\tLoss: 235.304352\n",
      "Train Epoch: 1262 [900/2589 (35%)]\tLoss: 286.809784\n",
      "Train Epoch: 1262 [1200/2589 (46%)]\tLoss: 239.484589\n",
      "Train Epoch: 1262 [1500/2589 (58%)]\tLoss: 210.991440\n",
      "Train Epoch: 1262 [1800/2589 (70%)]\tLoss: 277.025024\n",
      "Train Epoch: 1262 [2100/2589 (81%)]\tLoss: 182.657516\n",
      "Train Epoch: 1262 [2400/2589 (93%)]\tLoss: 209.523163\n",
      "====> Epoch: 1262 Average train loss: 215.5023\n",
      "====> Epoch: 1262 Average test loss: 915.1425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1263 [0/2589 (0%)]\tLoss: 200.602615\n",
      "Train Epoch: 1263 [300/2589 (12%)]\tLoss: 215.485046\n",
      "Train Epoch: 1263 [600/2589 (23%)]\tLoss: 302.193695\n",
      "Train Epoch: 1263 [900/2589 (35%)]\tLoss: 163.908005\n",
      "Train Epoch: 1263 [1200/2589 (46%)]\tLoss: 198.772354\n",
      "Train Epoch: 1263 [1500/2589 (58%)]\tLoss: 127.804977\n",
      "Train Epoch: 1263 [1800/2589 (70%)]\tLoss: 209.015793\n",
      "Train Epoch: 1263 [2100/2589 (81%)]\tLoss: 288.552032\n",
      "Train Epoch: 1263 [2400/2589 (93%)]\tLoss: 214.024063\n",
      "====> Epoch: 1263 Average train loss: 208.5476\n",
      "====> Epoch: 1263 Average test loss: 901.2120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1264 [0/2589 (0%)]\tLoss: 226.460770\n",
      "Train Epoch: 1264 [300/2589 (12%)]\tLoss: 173.335892\n",
      "Train Epoch: 1264 [600/2589 (23%)]\tLoss: 177.362595\n",
      "Train Epoch: 1264 [900/2589 (35%)]\tLoss: 159.741959\n",
      "Train Epoch: 1264 [1200/2589 (46%)]\tLoss: 191.934662\n",
      "Train Epoch: 1264 [1500/2589 (58%)]\tLoss: 220.814072\n",
      "Train Epoch: 1264 [1800/2589 (70%)]\tLoss: 199.842117\n",
      "Train Epoch: 1264 [2100/2589 (81%)]\tLoss: 287.975494\n",
      "Train Epoch: 1264 [2400/2589 (93%)]\tLoss: 187.575287\n",
      "====> Epoch: 1264 Average train loss: 213.4654\n",
      "====> Epoch: 1264 Average test loss: 921.4462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1265 [0/2589 (0%)]\tLoss: 130.707733\n",
      "Train Epoch: 1265 [300/2589 (12%)]\tLoss: 219.927628\n",
      "Train Epoch: 1265 [600/2589 (23%)]\tLoss: 232.242294\n",
      "Train Epoch: 1265 [900/2589 (35%)]\tLoss: 201.027359\n",
      "Train Epoch: 1265 [1200/2589 (46%)]\tLoss: 215.684479\n",
      "Train Epoch: 1265 [1500/2589 (58%)]\tLoss: 149.087128\n",
      "Train Epoch: 1265 [1800/2589 (70%)]\tLoss: 241.458603\n",
      "Train Epoch: 1265 [2100/2589 (81%)]\tLoss: 149.770477\n",
      "Train Epoch: 1265 [2400/2589 (93%)]\tLoss: 216.874023\n",
      "====> Epoch: 1265 Average train loss: 213.3689\n",
      "====> Epoch: 1265 Average test loss: 905.0690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1266 [0/2589 (0%)]\tLoss: 399.372070\n",
      "Train Epoch: 1266 [300/2589 (12%)]\tLoss: 228.160904\n",
      "Train Epoch: 1266 [600/2589 (23%)]\tLoss: 369.741913\n",
      "Train Epoch: 1266 [900/2589 (35%)]\tLoss: 174.450287\n",
      "Train Epoch: 1266 [1200/2589 (46%)]\tLoss: 181.534348\n",
      "Train Epoch: 1266 [1500/2589 (58%)]\tLoss: 170.598877\n",
      "Train Epoch: 1266 [1800/2589 (70%)]\tLoss: 140.416946\n",
      "Train Epoch: 1266 [2100/2589 (81%)]\tLoss: 179.948517\n",
      "Train Epoch: 1266 [2400/2589 (93%)]\tLoss: 170.265213\n",
      "====> Epoch: 1266 Average train loss: 211.4338\n",
      "====> Epoch: 1266 Average test loss: 913.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1267 [0/2589 (0%)]\tLoss: 178.671539\n",
      "Train Epoch: 1267 [300/2589 (12%)]\tLoss: 121.851608\n",
      "Train Epoch: 1267 [600/2589 (23%)]\tLoss: 128.314117\n",
      "Train Epoch: 1267 [900/2589 (35%)]\tLoss: 136.345459\n",
      "Train Epoch: 1267 [1200/2589 (46%)]\tLoss: 157.155548\n",
      "Train Epoch: 1267 [1500/2589 (58%)]\tLoss: 199.289215\n",
      "Train Epoch: 1267 [1800/2589 (70%)]\tLoss: 329.020172\n",
      "Train Epoch: 1267 [2100/2589 (81%)]\tLoss: 213.867386\n",
      "Train Epoch: 1267 [2400/2589 (93%)]\tLoss: 201.335709\n",
      "====> Epoch: 1267 Average train loss: 217.3816\n",
      "====> Epoch: 1267 Average test loss: 909.7316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1268 [0/2589 (0%)]\tLoss: 206.856979\n",
      "Train Epoch: 1268 [300/2589 (12%)]\tLoss: 239.696869\n",
      "Train Epoch: 1268 [600/2589 (23%)]\tLoss: 136.917389\n",
      "Train Epoch: 1268 [900/2589 (35%)]\tLoss: 195.987061\n",
      "Train Epoch: 1268 [1200/2589 (46%)]\tLoss: 193.180450\n",
      "Train Epoch: 1268 [1500/2589 (58%)]\tLoss: 150.818390\n",
      "Train Epoch: 1268 [1800/2589 (70%)]\tLoss: 211.725632\n",
      "Train Epoch: 1268 [2100/2589 (81%)]\tLoss: 180.039352\n",
      "Train Epoch: 1268 [2400/2589 (93%)]\tLoss: 194.480301\n",
      "====> Epoch: 1268 Average train loss: 204.7272\n",
      "====> Epoch: 1268 Average test loss: 905.4624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1269 [0/2589 (0%)]\tLoss: 152.207581\n",
      "Train Epoch: 1269 [300/2589 (12%)]\tLoss: 177.643463\n",
      "Train Epoch: 1269 [600/2589 (23%)]\tLoss: 219.642258\n",
      "Train Epoch: 1269 [900/2589 (35%)]\tLoss: 188.909348\n",
      "Train Epoch: 1269 [1200/2589 (46%)]\tLoss: 214.719986\n",
      "Train Epoch: 1269 [1500/2589 (58%)]\tLoss: 143.018875\n",
      "Train Epoch: 1269 [1800/2589 (70%)]\tLoss: 267.857941\n",
      "Train Epoch: 1269 [2100/2589 (81%)]\tLoss: 223.040436\n",
      "Train Epoch: 1269 [2400/2589 (93%)]\tLoss: 228.236588\n",
      "====> Epoch: 1269 Average train loss: 228.7065\n",
      "====> Epoch: 1269 Average test loss: 914.5992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1270 [0/2589 (0%)]\tLoss: 171.853714\n",
      "Train Epoch: 1270 [300/2589 (12%)]\tLoss: 156.666702\n",
      "Train Epoch: 1270 [600/2589 (23%)]\tLoss: 234.002670\n",
      "Train Epoch: 1270 [900/2589 (35%)]\tLoss: 185.966797\n",
      "Train Epoch: 1270 [1200/2589 (46%)]\tLoss: 229.722443\n",
      "Train Epoch: 1270 [1500/2589 (58%)]\tLoss: 262.500702\n",
      "Train Epoch: 1270 [1800/2589 (70%)]\tLoss: 265.947021\n",
      "Train Epoch: 1270 [2100/2589 (81%)]\tLoss: 497.446136\n",
      "Train Epoch: 1270 [2400/2589 (93%)]\tLoss: 161.228745\n",
      "====> Epoch: 1270 Average train loss: 217.5579\n",
      "====> Epoch: 1270 Average test loss: 919.3353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1271 [0/2589 (0%)]\tLoss: 250.343430\n",
      "Train Epoch: 1271 [300/2589 (12%)]\tLoss: 253.009369\n",
      "Train Epoch: 1271 [600/2589 (23%)]\tLoss: 196.371109\n",
      "Train Epoch: 1271 [900/2589 (35%)]\tLoss: 180.314377\n",
      "Train Epoch: 1271 [1200/2589 (46%)]\tLoss: 240.297653\n",
      "Train Epoch: 1271 [1500/2589 (58%)]\tLoss: 225.334045\n",
      "Train Epoch: 1271 [1800/2589 (70%)]\tLoss: 240.231598\n",
      "Train Epoch: 1271 [2100/2589 (81%)]\tLoss: 166.566101\n",
      "Train Epoch: 1271 [2400/2589 (93%)]\tLoss: 216.198624\n",
      "====> Epoch: 1271 Average train loss: 208.2749\n",
      "====> Epoch: 1271 Average test loss: 921.7581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1272 [0/2589 (0%)]\tLoss: 182.937927\n",
      "Train Epoch: 1272 [300/2589 (12%)]\tLoss: 147.700272\n",
      "Train Epoch: 1272 [600/2589 (23%)]\tLoss: 202.300964\n",
      "Train Epoch: 1272 [900/2589 (35%)]\tLoss: 162.584091\n",
      "Train Epoch: 1272 [1200/2589 (46%)]\tLoss: 165.023712\n",
      "Train Epoch: 1272 [1500/2589 (58%)]\tLoss: 185.167572\n",
      "Train Epoch: 1272 [1800/2589 (70%)]\tLoss: 301.740173\n",
      "Train Epoch: 1272 [2100/2589 (81%)]\tLoss: 213.513077\n",
      "Train Epoch: 1272 [2400/2589 (93%)]\tLoss: 224.656158\n",
      "====> Epoch: 1272 Average train loss: 211.6463\n",
      "====> Epoch: 1272 Average test loss: 892.0352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1273 [0/2589 (0%)]\tLoss: 292.873199\n",
      "Train Epoch: 1273 [300/2589 (12%)]\tLoss: 181.696289\n",
      "Train Epoch: 1273 [600/2589 (23%)]\tLoss: 331.698334\n",
      "Train Epoch: 1273 [900/2589 (35%)]\tLoss: 181.838974\n",
      "Train Epoch: 1273 [1200/2589 (46%)]\tLoss: 171.239685\n",
      "Train Epoch: 1273 [1500/2589 (58%)]\tLoss: 134.053299\n",
      "Train Epoch: 1273 [1800/2589 (70%)]\tLoss: 246.419266\n",
      "Train Epoch: 1273 [2100/2589 (81%)]\tLoss: 298.395050\n",
      "Train Epoch: 1273 [2400/2589 (93%)]\tLoss: 156.921005\n",
      "====> Epoch: 1273 Average train loss: 217.3202\n",
      "====> Epoch: 1273 Average test loss: 907.6953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1274 [0/2589 (0%)]\tLoss: 265.497009\n",
      "Train Epoch: 1274 [300/2589 (12%)]\tLoss: 218.083984\n",
      "Train Epoch: 1274 [600/2589 (23%)]\tLoss: 184.746338\n",
      "Train Epoch: 1274 [900/2589 (35%)]\tLoss: 213.168549\n",
      "Train Epoch: 1274 [1200/2589 (46%)]\tLoss: 296.246399\n",
      "Train Epoch: 1274 [1500/2589 (58%)]\tLoss: 170.357361\n",
      "Train Epoch: 1274 [1800/2589 (70%)]\tLoss: 265.641052\n",
      "Train Epoch: 1274 [2100/2589 (81%)]\tLoss: 218.501923\n",
      "Train Epoch: 1274 [2400/2589 (93%)]\tLoss: 235.504715\n",
      "====> Epoch: 1274 Average train loss: 222.6901\n",
      "====> Epoch: 1274 Average test loss: 904.0939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1275 [0/2589 (0%)]\tLoss: 241.592255\n",
      "Train Epoch: 1275 [300/2589 (12%)]\tLoss: 222.422318\n",
      "Train Epoch: 1275 [600/2589 (23%)]\tLoss: 482.374878\n",
      "Train Epoch: 1275 [900/2589 (35%)]\tLoss: 250.054260\n",
      "Train Epoch: 1275 [1200/2589 (46%)]\tLoss: 193.815598\n",
      "Train Epoch: 1275 [1500/2589 (58%)]\tLoss: 226.409973\n",
      "Train Epoch: 1275 [1800/2589 (70%)]\tLoss: 212.790039\n",
      "Train Epoch: 1275 [2100/2589 (81%)]\tLoss: 199.537048\n",
      "Train Epoch: 1275 [2400/2589 (93%)]\tLoss: 224.048767\n",
      "====> Epoch: 1275 Average train loss: 223.7702\n",
      "====> Epoch: 1275 Average test loss: 923.2372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1276 [0/2589 (0%)]\tLoss: 231.095795\n",
      "Train Epoch: 1276 [300/2589 (12%)]\tLoss: 459.098907\n",
      "Train Epoch: 1276 [600/2589 (23%)]\tLoss: 136.907272\n",
      "Train Epoch: 1276 [900/2589 (35%)]\tLoss: 185.278229\n",
      "Train Epoch: 1276 [1200/2589 (46%)]\tLoss: 220.853516\n",
      "Train Epoch: 1276 [1500/2589 (58%)]\tLoss: 228.437332\n",
      "Train Epoch: 1276 [1800/2589 (70%)]\tLoss: 137.484314\n",
      "Train Epoch: 1276 [2100/2589 (81%)]\tLoss: 157.706894\n",
      "Train Epoch: 1276 [2400/2589 (93%)]\tLoss: 170.741074\n",
      "====> Epoch: 1276 Average train loss: 211.0336\n",
      "====> Epoch: 1276 Average test loss: 915.1769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1277 [0/2589 (0%)]\tLoss: 134.121994\n",
      "Train Epoch: 1277 [300/2589 (12%)]\tLoss: 226.127396\n",
      "Train Epoch: 1277 [600/2589 (23%)]\tLoss: 234.192688\n",
      "Train Epoch: 1277 [900/2589 (35%)]\tLoss: 354.963196\n",
      "Train Epoch: 1277 [1200/2589 (46%)]\tLoss: 256.303925\n",
      "Train Epoch: 1277 [1500/2589 (58%)]\tLoss: 244.421829\n",
      "Train Epoch: 1277 [1800/2589 (70%)]\tLoss: 183.164124\n",
      "Train Epoch: 1277 [2100/2589 (81%)]\tLoss: 169.446869\n",
      "Train Epoch: 1277 [2400/2589 (93%)]\tLoss: 294.604828\n",
      "====> Epoch: 1277 Average train loss: 213.6789\n",
      "====> Epoch: 1277 Average test loss: 912.9178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1278 [0/2589 (0%)]\tLoss: 206.636063\n",
      "Train Epoch: 1278 [300/2589 (12%)]\tLoss: 189.877731\n",
      "Train Epoch: 1278 [600/2589 (23%)]\tLoss: 212.403107\n",
      "Train Epoch: 1278 [900/2589 (35%)]\tLoss: 180.572037\n",
      "Train Epoch: 1278 [1200/2589 (46%)]\tLoss: 179.244598\n",
      "Train Epoch: 1278 [1500/2589 (58%)]\tLoss: 312.212708\n",
      "Train Epoch: 1278 [1800/2589 (70%)]\tLoss: 245.021164\n",
      "Train Epoch: 1278 [2100/2589 (81%)]\tLoss: 195.368866\n",
      "Train Epoch: 1278 [2400/2589 (93%)]\tLoss: 158.538483\n",
      "====> Epoch: 1278 Average train loss: 219.0080\n",
      "====> Epoch: 1278 Average test loss: 917.1943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1279 [0/2589 (0%)]\tLoss: 182.224991\n",
      "Train Epoch: 1279 [300/2589 (12%)]\tLoss: 195.888092\n",
      "Train Epoch: 1279 [600/2589 (23%)]\tLoss: 188.933014\n",
      "Train Epoch: 1279 [900/2589 (35%)]\tLoss: 179.424637\n",
      "Train Epoch: 1279 [1200/2589 (46%)]\tLoss: 166.392593\n",
      "Train Epoch: 1279 [1500/2589 (58%)]\tLoss: 231.211700\n",
      "Train Epoch: 1279 [1800/2589 (70%)]\tLoss: 202.336685\n",
      "Train Epoch: 1279 [2100/2589 (81%)]\tLoss: 162.962341\n",
      "Train Epoch: 1279 [2400/2589 (93%)]\tLoss: 151.587784\n",
      "====> Epoch: 1279 Average train loss: 225.0483\n",
      "====> Epoch: 1279 Average test loss: 920.0447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1280 [0/2589 (0%)]\tLoss: 249.270126\n",
      "Train Epoch: 1280 [300/2589 (12%)]\tLoss: 201.323471\n",
      "Train Epoch: 1280 [600/2589 (23%)]\tLoss: 258.968597\n",
      "Train Epoch: 1280 [900/2589 (35%)]\tLoss: 273.706818\n",
      "Train Epoch: 1280 [1200/2589 (46%)]\tLoss: 333.569000\n",
      "Train Epoch: 1280 [1500/2589 (58%)]\tLoss: 182.451401\n",
      "Train Epoch: 1280 [1800/2589 (70%)]\tLoss: 219.185013\n",
      "Train Epoch: 1280 [2100/2589 (81%)]\tLoss: 257.347229\n",
      "Train Epoch: 1280 [2400/2589 (93%)]\tLoss: 251.274765\n",
      "====> Epoch: 1280 Average train loss: 207.4097\n",
      "====> Epoch: 1280 Average test loss: 923.0521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1281 [0/2589 (0%)]\tLoss: 250.495026\n",
      "Train Epoch: 1281 [300/2589 (12%)]\tLoss: 242.145508\n",
      "Train Epoch: 1281 [600/2589 (23%)]\tLoss: 369.636780\n",
      "Train Epoch: 1281 [900/2589 (35%)]\tLoss: 217.816849\n",
      "Train Epoch: 1281 [1200/2589 (46%)]\tLoss: 172.945389\n",
      "Train Epoch: 1281 [1500/2589 (58%)]\tLoss: 254.435547\n",
      "Train Epoch: 1281 [1800/2589 (70%)]\tLoss: 222.272354\n",
      "Train Epoch: 1281 [2100/2589 (81%)]\tLoss: 169.323166\n",
      "Train Epoch: 1281 [2400/2589 (93%)]\tLoss: 144.907272\n",
      "====> Epoch: 1281 Average train loss: 223.5734\n",
      "====> Epoch: 1281 Average test loss: 900.3535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1282 [0/2589 (0%)]\tLoss: 237.827805\n",
      "Train Epoch: 1282 [300/2589 (12%)]\tLoss: 286.781372\n",
      "Train Epoch: 1282 [600/2589 (23%)]\tLoss: 149.339401\n",
      "Train Epoch: 1282 [900/2589 (35%)]\tLoss: 178.092468\n",
      "Train Epoch: 1282 [1200/2589 (46%)]\tLoss: 186.667953\n",
      "Train Epoch: 1282 [1500/2589 (58%)]\tLoss: 138.004883\n",
      "Train Epoch: 1282 [1800/2589 (70%)]\tLoss: 184.659332\n",
      "Train Epoch: 1282 [2100/2589 (81%)]\tLoss: 359.090363\n",
      "Train Epoch: 1282 [2400/2589 (93%)]\tLoss: 264.766968\n",
      "====> Epoch: 1282 Average train loss: 221.3055\n",
      "====> Epoch: 1282 Average test loss: 932.7073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1283 [0/2589 (0%)]\tLoss: 123.581100\n",
      "Train Epoch: 1283 [300/2589 (12%)]\tLoss: 164.086685\n",
      "Train Epoch: 1283 [600/2589 (23%)]\tLoss: 245.581009\n",
      "Train Epoch: 1283 [900/2589 (35%)]\tLoss: 207.878464\n",
      "Train Epoch: 1283 [1200/2589 (46%)]\tLoss: 237.283875\n",
      "Train Epoch: 1283 [1500/2589 (58%)]\tLoss: 174.657898\n",
      "Train Epoch: 1283 [1800/2589 (70%)]\tLoss: 197.092392\n",
      "Train Epoch: 1283 [2100/2589 (81%)]\tLoss: 163.778854\n",
      "Train Epoch: 1283 [2400/2589 (93%)]\tLoss: 192.663116\n",
      "====> Epoch: 1283 Average train loss: 219.4012\n",
      "====> Epoch: 1283 Average test loss: 902.1036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1284 [0/2589 (0%)]\tLoss: 243.826279\n",
      "Train Epoch: 1284 [300/2589 (12%)]\tLoss: 229.760056\n",
      "Train Epoch: 1284 [600/2589 (23%)]\tLoss: 229.926697\n",
      "Train Epoch: 1284 [900/2589 (35%)]\tLoss: 186.020981\n",
      "Train Epoch: 1284 [1200/2589 (46%)]\tLoss: 177.029266\n",
      "Train Epoch: 1284 [1500/2589 (58%)]\tLoss: 166.530594\n",
      "Train Epoch: 1284 [1800/2589 (70%)]\tLoss: 174.366867\n",
      "Train Epoch: 1284 [2100/2589 (81%)]\tLoss: 214.573502\n",
      "Train Epoch: 1284 [2400/2589 (93%)]\tLoss: 247.407181\n",
      "====> Epoch: 1284 Average train loss: 204.6064\n",
      "====> Epoch: 1284 Average test loss: 911.5746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1285 [0/2589 (0%)]\tLoss: 163.262360\n",
      "Train Epoch: 1285 [300/2589 (12%)]\tLoss: 183.275726\n",
      "Train Epoch: 1285 [600/2589 (23%)]\tLoss: 288.447723\n",
      "Train Epoch: 1285 [900/2589 (35%)]\tLoss: 184.800964\n",
      "Train Epoch: 1285 [1200/2589 (46%)]\tLoss: 162.330505\n",
      "Train Epoch: 1285 [1500/2589 (58%)]\tLoss: 224.843964\n",
      "Train Epoch: 1285 [1800/2589 (70%)]\tLoss: 198.291275\n",
      "Train Epoch: 1285 [2100/2589 (81%)]\tLoss: 208.795380\n",
      "Train Epoch: 1285 [2400/2589 (93%)]\tLoss: 153.108795\n",
      "====> Epoch: 1285 Average train loss: 212.1815\n",
      "====> Epoch: 1285 Average test loss: 912.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1286 [0/2589 (0%)]\tLoss: 150.013992\n",
      "Train Epoch: 1286 [300/2589 (12%)]\tLoss: 493.349579\n",
      "Train Epoch: 1286 [600/2589 (23%)]\tLoss: 231.314072\n",
      "Train Epoch: 1286 [900/2589 (35%)]\tLoss: 173.735168\n",
      "Train Epoch: 1286 [1200/2589 (46%)]\tLoss: 296.945587\n",
      "Train Epoch: 1286 [1500/2589 (58%)]\tLoss: 180.697266\n",
      "Train Epoch: 1286 [1800/2589 (70%)]\tLoss: 221.951797\n",
      "Train Epoch: 1286 [2100/2589 (81%)]\tLoss: 222.269150\n",
      "Train Epoch: 1286 [2400/2589 (93%)]\tLoss: 157.840668\n",
      "====> Epoch: 1286 Average train loss: 226.5700\n",
      "====> Epoch: 1286 Average test loss: 905.2536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1287 [0/2589 (0%)]\tLoss: 184.843262\n",
      "Train Epoch: 1287 [300/2589 (12%)]\tLoss: 132.824051\n",
      "Train Epoch: 1287 [600/2589 (23%)]\tLoss: 225.291260\n",
      "Train Epoch: 1287 [900/2589 (35%)]\tLoss: 267.166656\n",
      "Train Epoch: 1287 [1200/2589 (46%)]\tLoss: 202.217941\n",
      "Train Epoch: 1287 [1500/2589 (58%)]\tLoss: 211.037781\n",
      "Train Epoch: 1287 [1800/2589 (70%)]\tLoss: 228.994202\n",
      "Train Epoch: 1287 [2100/2589 (81%)]\tLoss: 298.451324\n",
      "Train Epoch: 1287 [2400/2589 (93%)]\tLoss: 259.596130\n",
      "====> Epoch: 1287 Average train loss: 216.0582\n",
      "====> Epoch: 1287 Average test loss: 925.8672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1288 [0/2589 (0%)]\tLoss: 195.404236\n",
      "Train Epoch: 1288 [300/2589 (12%)]\tLoss: 272.120483\n",
      "Train Epoch: 1288 [600/2589 (23%)]\tLoss: 187.943649\n",
      "Train Epoch: 1288 [900/2589 (35%)]\tLoss: 157.074539\n",
      "Train Epoch: 1288 [1200/2589 (46%)]\tLoss: 204.476074\n",
      "Train Epoch: 1288 [1500/2589 (58%)]\tLoss: 184.886780\n",
      "Train Epoch: 1288 [1800/2589 (70%)]\tLoss: 166.070343\n",
      "Train Epoch: 1288 [2100/2589 (81%)]\tLoss: 188.861984\n",
      "Train Epoch: 1288 [2400/2589 (93%)]\tLoss: 220.923798\n",
      "====> Epoch: 1288 Average train loss: 213.2931\n",
      "====> Epoch: 1288 Average test loss: 919.1207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1289 [0/2589 (0%)]\tLoss: 192.937927\n",
      "Train Epoch: 1289 [300/2589 (12%)]\tLoss: 160.948944\n",
      "Train Epoch: 1289 [600/2589 (23%)]\tLoss: 173.425964\n",
      "Train Epoch: 1289 [900/2589 (35%)]\tLoss: 208.860275\n",
      "Train Epoch: 1289 [1200/2589 (46%)]\tLoss: 190.013702\n",
      "Train Epoch: 1289 [1500/2589 (58%)]\tLoss: 188.835861\n",
      "Train Epoch: 1289 [1800/2589 (70%)]\tLoss: 236.032272\n",
      "Train Epoch: 1289 [2100/2589 (81%)]\tLoss: 322.781616\n",
      "Train Epoch: 1289 [2400/2589 (93%)]\tLoss: 320.526825\n",
      "====> Epoch: 1289 Average train loss: 206.9805\n",
      "====> Epoch: 1289 Average test loss: 906.7927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1290 [0/2589 (0%)]\tLoss: 163.477997\n",
      "Train Epoch: 1290 [300/2589 (12%)]\tLoss: 241.661850\n",
      "Train Epoch: 1290 [600/2589 (23%)]\tLoss: 203.400742\n",
      "Train Epoch: 1290 [900/2589 (35%)]\tLoss: 317.563354\n",
      "Train Epoch: 1290 [1200/2589 (46%)]\tLoss: 182.177002\n",
      "Train Epoch: 1290 [1500/2589 (58%)]\tLoss: 227.045914\n",
      "Train Epoch: 1290 [1800/2589 (70%)]\tLoss: 207.298431\n",
      "Train Epoch: 1290 [2100/2589 (81%)]\tLoss: 152.869720\n",
      "Train Epoch: 1290 [2400/2589 (93%)]\tLoss: 355.058105\n",
      "====> Epoch: 1290 Average train loss: 217.3199\n",
      "====> Epoch: 1290 Average test loss: 910.3049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1291 [0/2589 (0%)]\tLoss: 195.036682\n",
      "Train Epoch: 1291 [300/2589 (12%)]\tLoss: 213.111725\n",
      "Train Epoch: 1291 [600/2589 (23%)]\tLoss: 227.622360\n",
      "Train Epoch: 1291 [900/2589 (35%)]\tLoss: 198.861984\n",
      "Train Epoch: 1291 [1200/2589 (46%)]\tLoss: 310.698059\n",
      "Train Epoch: 1291 [1500/2589 (58%)]\tLoss: 186.757019\n",
      "Train Epoch: 1291 [1800/2589 (70%)]\tLoss: 165.666595\n",
      "Train Epoch: 1291 [2100/2589 (81%)]\tLoss: 277.279022\n",
      "Train Epoch: 1291 [2400/2589 (93%)]\tLoss: 305.762543\n",
      "====> Epoch: 1291 Average train loss: 221.7490\n",
      "====> Epoch: 1291 Average test loss: 914.0403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1292 [0/2589 (0%)]\tLoss: 220.479095\n",
      "Train Epoch: 1292 [300/2589 (12%)]\tLoss: 219.464569\n",
      "Train Epoch: 1292 [600/2589 (23%)]\tLoss: 151.397415\n",
      "Train Epoch: 1292 [900/2589 (35%)]\tLoss: 164.795898\n",
      "Train Epoch: 1292 [1200/2589 (46%)]\tLoss: 179.731430\n",
      "Train Epoch: 1292 [1500/2589 (58%)]\tLoss: 183.523712\n",
      "Train Epoch: 1292 [1800/2589 (70%)]\tLoss: 184.126755\n",
      "Train Epoch: 1292 [2100/2589 (81%)]\tLoss: 402.820679\n",
      "Train Epoch: 1292 [2400/2589 (93%)]\tLoss: 249.329361\n",
      "====> Epoch: 1292 Average train loss: 209.4254\n",
      "====> Epoch: 1292 Average test loss: 917.1908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1293 [0/2589 (0%)]\tLoss: 169.509430\n",
      "Train Epoch: 1293 [300/2589 (12%)]\tLoss: 188.325516\n",
      "Train Epoch: 1293 [600/2589 (23%)]\tLoss: 407.223419\n",
      "Train Epoch: 1293 [900/2589 (35%)]\tLoss: 154.614685\n",
      "Train Epoch: 1293 [1200/2589 (46%)]\tLoss: 182.934128\n",
      "Train Epoch: 1293 [1500/2589 (58%)]\tLoss: 167.005081\n",
      "Train Epoch: 1293 [1800/2589 (70%)]\tLoss: 210.784317\n",
      "Train Epoch: 1293 [2100/2589 (81%)]\tLoss: 193.095871\n",
      "Train Epoch: 1293 [2400/2589 (93%)]\tLoss: 178.257126\n",
      "====> Epoch: 1293 Average train loss: 222.3002\n",
      "====> Epoch: 1293 Average test loss: 910.0659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1294 [0/2589 (0%)]\tLoss: 156.433380\n",
      "Train Epoch: 1294 [300/2589 (12%)]\tLoss: 211.172272\n",
      "Train Epoch: 1294 [600/2589 (23%)]\tLoss: 198.617645\n",
      "Train Epoch: 1294 [900/2589 (35%)]\tLoss: 150.679596\n",
      "Train Epoch: 1294 [1200/2589 (46%)]\tLoss: 198.683380\n",
      "Train Epoch: 1294 [1500/2589 (58%)]\tLoss: 184.089417\n",
      "Train Epoch: 1294 [1800/2589 (70%)]\tLoss: 217.069519\n",
      "Train Epoch: 1294 [2100/2589 (81%)]\tLoss: 327.883331\n",
      "Train Epoch: 1294 [2400/2589 (93%)]\tLoss: 203.624588\n",
      "====> Epoch: 1294 Average train loss: 218.2846\n",
      "====> Epoch: 1294 Average test loss: 901.1776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1295 [0/2589 (0%)]\tLoss: 251.785507\n",
      "Train Epoch: 1295 [300/2589 (12%)]\tLoss: 144.670731\n",
      "Train Epoch: 1295 [600/2589 (23%)]\tLoss: 191.876633\n",
      "Train Epoch: 1295 [900/2589 (35%)]\tLoss: 172.040726\n",
      "Train Epoch: 1295 [1200/2589 (46%)]\tLoss: 133.056137\n",
      "Train Epoch: 1295 [1500/2589 (58%)]\tLoss: 228.679230\n",
      "Train Epoch: 1295 [1800/2589 (70%)]\tLoss: 225.421158\n",
      "Train Epoch: 1295 [2100/2589 (81%)]\tLoss: 211.737259\n",
      "Train Epoch: 1295 [2400/2589 (93%)]\tLoss: 253.026428\n",
      "====> Epoch: 1295 Average train loss: 219.5314\n",
      "====> Epoch: 1295 Average test loss: 907.4528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1296 [0/2589 (0%)]\tLoss: 167.312500\n",
      "Train Epoch: 1296 [300/2589 (12%)]\tLoss: 260.642700\n",
      "Train Epoch: 1296 [600/2589 (23%)]\tLoss: 237.380615\n",
      "Train Epoch: 1296 [900/2589 (35%)]\tLoss: 243.949753\n",
      "Train Epoch: 1296 [1200/2589 (46%)]\tLoss: 225.972870\n",
      "Train Epoch: 1296 [1500/2589 (58%)]\tLoss: 223.942780\n",
      "Train Epoch: 1296 [1800/2589 (70%)]\tLoss: 257.951965\n",
      "Train Epoch: 1296 [2100/2589 (81%)]\tLoss: 179.927017\n",
      "Train Epoch: 1296 [2400/2589 (93%)]\tLoss: 230.802399\n",
      "====> Epoch: 1296 Average train loss: 219.0184\n",
      "====> Epoch: 1296 Average test loss: 920.0654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1297 [0/2589 (0%)]\tLoss: 271.329498\n",
      "Train Epoch: 1297 [300/2589 (12%)]\tLoss: 262.450623\n",
      "Train Epoch: 1297 [600/2589 (23%)]\tLoss: 166.275101\n",
      "Train Epoch: 1297 [900/2589 (35%)]\tLoss: 200.313461\n",
      "Train Epoch: 1297 [1200/2589 (46%)]\tLoss: 214.762344\n",
      "Train Epoch: 1297 [1500/2589 (58%)]\tLoss: 244.855301\n",
      "Train Epoch: 1297 [1800/2589 (70%)]\tLoss: 196.334213\n",
      "Train Epoch: 1297 [2100/2589 (81%)]\tLoss: 170.546783\n",
      "Train Epoch: 1297 [2400/2589 (93%)]\tLoss: 122.553711\n",
      "====> Epoch: 1297 Average train loss: 216.1348\n",
      "====> Epoch: 1297 Average test loss: 930.8022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1298 [0/2589 (0%)]\tLoss: 242.292618\n",
      "Train Epoch: 1298 [300/2589 (12%)]\tLoss: 162.273880\n",
      "Train Epoch: 1298 [600/2589 (23%)]\tLoss: 299.935669\n",
      "Train Epoch: 1298 [900/2589 (35%)]\tLoss: 232.705719\n",
      "Train Epoch: 1298 [1200/2589 (46%)]\tLoss: 284.923126\n",
      "Train Epoch: 1298 [1500/2589 (58%)]\tLoss: 289.784576\n",
      "Train Epoch: 1298 [1800/2589 (70%)]\tLoss: 235.339401\n",
      "Train Epoch: 1298 [2100/2589 (81%)]\tLoss: 172.245560\n",
      "Train Epoch: 1298 [2400/2589 (93%)]\tLoss: 258.616882\n",
      "====> Epoch: 1298 Average train loss: 233.1716\n",
      "====> Epoch: 1298 Average test loss: 891.1516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1299 [0/2589 (0%)]\tLoss: 166.315964\n",
      "Train Epoch: 1299 [300/2589 (12%)]\tLoss: 226.034805\n",
      "Train Epoch: 1299 [600/2589 (23%)]\tLoss: 172.546844\n",
      "Train Epoch: 1299 [900/2589 (35%)]\tLoss: 308.797211\n",
      "Train Epoch: 1299 [1200/2589 (46%)]\tLoss: 257.911621\n",
      "Train Epoch: 1299 [1500/2589 (58%)]\tLoss: 187.127304\n",
      "Train Epoch: 1299 [1800/2589 (70%)]\tLoss: 261.300842\n",
      "Train Epoch: 1299 [2100/2589 (81%)]\tLoss: 229.609604\n",
      "Train Epoch: 1299 [2400/2589 (93%)]\tLoss: 238.808807\n",
      "====> Epoch: 1299 Average train loss: 227.5396\n",
      "====> Epoch: 1299 Average test loss: 914.0822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1300 [0/2589 (0%)]\tLoss: 224.877304\n",
      "Train Epoch: 1300 [300/2589 (12%)]\tLoss: 247.779434\n",
      "Train Epoch: 1300 [600/2589 (23%)]\tLoss: 157.977768\n",
      "Train Epoch: 1300 [900/2589 (35%)]\tLoss: 189.117737\n",
      "Train Epoch: 1300 [1200/2589 (46%)]\tLoss: 236.496613\n",
      "Train Epoch: 1300 [1500/2589 (58%)]\tLoss: 182.111359\n",
      "Train Epoch: 1300 [1800/2589 (70%)]\tLoss: 177.535431\n",
      "Train Epoch: 1300 [2100/2589 (81%)]\tLoss: 189.115128\n",
      "Train Epoch: 1300 [2400/2589 (93%)]\tLoss: 256.744385\n",
      "====> Epoch: 1300 Average train loss: 217.6460\n",
      "====> Epoch: 1300 Average test loss: 906.0562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1301 [0/2589 (0%)]\tLoss: 328.175354\n",
      "Train Epoch: 1301 [300/2589 (12%)]\tLoss: 210.103088\n",
      "Train Epoch: 1301 [600/2589 (23%)]\tLoss: 206.471329\n",
      "Train Epoch: 1301 [900/2589 (35%)]\tLoss: 158.006271\n",
      "Train Epoch: 1301 [1200/2589 (46%)]\tLoss: 193.341293\n",
      "Train Epoch: 1301 [1500/2589 (58%)]\tLoss: 175.686035\n",
      "Train Epoch: 1301 [1800/2589 (70%)]\tLoss: 168.278992\n",
      "Train Epoch: 1301 [2100/2589 (81%)]\tLoss: 206.367493\n",
      "Train Epoch: 1301 [2400/2589 (93%)]\tLoss: 201.966629\n",
      "====> Epoch: 1301 Average train loss: 212.7278\n",
      "====> Epoch: 1301 Average test loss: 913.6382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1302 [0/2589 (0%)]\tLoss: 164.648102\n",
      "Train Epoch: 1302 [300/2589 (12%)]\tLoss: 239.731186\n",
      "Train Epoch: 1302 [600/2589 (23%)]\tLoss: 252.686676\n",
      "Train Epoch: 1302 [900/2589 (35%)]\tLoss: 251.296219\n",
      "Train Epoch: 1302 [1200/2589 (46%)]\tLoss: 250.003510\n",
      "Train Epoch: 1302 [1500/2589 (58%)]\tLoss: 185.084015\n",
      "Train Epoch: 1302 [1800/2589 (70%)]\tLoss: 177.979889\n",
      "Train Epoch: 1302 [2100/2589 (81%)]\tLoss: 156.165985\n",
      "Train Epoch: 1302 [2400/2589 (93%)]\tLoss: 210.041977\n",
      "====> Epoch: 1302 Average train loss: 227.8250\n",
      "====> Epoch: 1302 Average test loss: 920.0951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1303 [0/2589 (0%)]\tLoss: 165.017670\n",
      "Train Epoch: 1303 [300/2589 (12%)]\tLoss: 123.812172\n",
      "Train Epoch: 1303 [600/2589 (23%)]\tLoss: 209.753677\n",
      "Train Epoch: 1303 [900/2589 (35%)]\tLoss: 148.855240\n",
      "Train Epoch: 1303 [1200/2589 (46%)]\tLoss: 211.009140\n",
      "Train Epoch: 1303 [1500/2589 (58%)]\tLoss: 224.059784\n",
      "Train Epoch: 1303 [1800/2589 (70%)]\tLoss: 185.318329\n",
      "Train Epoch: 1303 [2100/2589 (81%)]\tLoss: 316.060272\n",
      "Train Epoch: 1303 [2400/2589 (93%)]\tLoss: 166.599213\n",
      "====> Epoch: 1303 Average train loss: 209.8057\n",
      "====> Epoch: 1303 Average test loss: 899.6584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1304 [0/2589 (0%)]\tLoss: 300.091156\n",
      "Train Epoch: 1304 [300/2589 (12%)]\tLoss: 292.318359\n",
      "Train Epoch: 1304 [600/2589 (23%)]\tLoss: 254.956573\n",
      "Train Epoch: 1304 [900/2589 (35%)]\tLoss: 190.713028\n",
      "Train Epoch: 1304 [1200/2589 (46%)]\tLoss: 191.309708\n",
      "Train Epoch: 1304 [1500/2589 (58%)]\tLoss: 201.695358\n",
      "Train Epoch: 1304 [1800/2589 (70%)]\tLoss: 209.670456\n",
      "Train Epoch: 1304 [2100/2589 (81%)]\tLoss: 190.056686\n",
      "Train Epoch: 1304 [2400/2589 (93%)]\tLoss: 371.802307\n",
      "====> Epoch: 1304 Average train loss: 210.2201\n",
      "====> Epoch: 1304 Average test loss: 917.8395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1305 [0/2589 (0%)]\tLoss: 178.769180\n",
      "Train Epoch: 1305 [300/2589 (12%)]\tLoss: 158.833649\n",
      "Train Epoch: 1305 [600/2589 (23%)]\tLoss: 153.957901\n",
      "Train Epoch: 1305 [900/2589 (35%)]\tLoss: 158.290482\n",
      "Train Epoch: 1305 [1200/2589 (46%)]\tLoss: 125.115265\n",
      "Train Epoch: 1305 [1500/2589 (58%)]\tLoss: 201.710205\n",
      "Train Epoch: 1305 [1800/2589 (70%)]\tLoss: 228.903610\n",
      "Train Epoch: 1305 [2100/2589 (81%)]\tLoss: 183.161224\n",
      "Train Epoch: 1305 [2400/2589 (93%)]\tLoss: 156.999039\n",
      "====> Epoch: 1305 Average train loss: 219.3935\n",
      "====> Epoch: 1305 Average test loss: 908.2874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1306 [0/2589 (0%)]\tLoss: 203.441025\n",
      "Train Epoch: 1306 [300/2589 (12%)]\tLoss: 187.162567\n",
      "Train Epoch: 1306 [600/2589 (23%)]\tLoss: 204.294601\n",
      "Train Epoch: 1306 [900/2589 (35%)]\tLoss: 132.131195\n",
      "Train Epoch: 1306 [1200/2589 (46%)]\tLoss: 175.866165\n",
      "Train Epoch: 1306 [1500/2589 (58%)]\tLoss: 190.479904\n",
      "Train Epoch: 1306 [1800/2589 (70%)]\tLoss: 165.843582\n",
      "Train Epoch: 1306 [2100/2589 (81%)]\tLoss: 160.385513\n",
      "Train Epoch: 1306 [2400/2589 (93%)]\tLoss: 219.496506\n",
      "====> Epoch: 1306 Average train loss: 212.9668\n",
      "====> Epoch: 1306 Average test loss: 909.9427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1307 [0/2589 (0%)]\tLoss: 199.087784\n",
      "Train Epoch: 1307 [300/2589 (12%)]\tLoss: 168.287064\n",
      "Train Epoch: 1307 [600/2589 (23%)]\tLoss: 177.547424\n",
      "Train Epoch: 1307 [900/2589 (35%)]\tLoss: 139.306122\n",
      "Train Epoch: 1307 [1200/2589 (46%)]\tLoss: 255.552597\n",
      "Train Epoch: 1307 [1500/2589 (58%)]\tLoss: 134.711945\n",
      "Train Epoch: 1307 [1800/2589 (70%)]\tLoss: 462.848083\n",
      "Train Epoch: 1307 [2100/2589 (81%)]\tLoss: 159.142838\n",
      "Train Epoch: 1307 [2400/2589 (93%)]\tLoss: 208.575882\n",
      "====> Epoch: 1307 Average train loss: 220.5139\n",
      "====> Epoch: 1307 Average test loss: 920.8601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1308 [0/2589 (0%)]\tLoss: 203.550781\n",
      "Train Epoch: 1308 [300/2589 (12%)]\tLoss: 232.737442\n",
      "Train Epoch: 1308 [600/2589 (23%)]\tLoss: 298.752136\n",
      "Train Epoch: 1308 [900/2589 (35%)]\tLoss: 256.310181\n",
      "Train Epoch: 1308 [1200/2589 (46%)]\tLoss: 285.641602\n",
      "Train Epoch: 1308 [1500/2589 (58%)]\tLoss: 191.125259\n",
      "Train Epoch: 1308 [1800/2589 (70%)]\tLoss: 197.612564\n",
      "Train Epoch: 1308 [2100/2589 (81%)]\tLoss: 219.116959\n",
      "Train Epoch: 1308 [2400/2589 (93%)]\tLoss: 214.702484\n",
      "====> Epoch: 1308 Average train loss: 221.6163\n",
      "====> Epoch: 1308 Average test loss: 911.2828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1309 [0/2589 (0%)]\tLoss: 216.311615\n",
      "Train Epoch: 1309 [300/2589 (12%)]\tLoss: 169.527267\n",
      "Train Epoch: 1309 [600/2589 (23%)]\tLoss: 163.429214\n",
      "Train Epoch: 1309 [900/2589 (35%)]\tLoss: 174.601379\n",
      "Train Epoch: 1309 [1200/2589 (46%)]\tLoss: 165.141907\n",
      "Train Epoch: 1309 [1500/2589 (58%)]\tLoss: 164.790054\n",
      "Train Epoch: 1309 [1800/2589 (70%)]\tLoss: 201.761520\n",
      "Train Epoch: 1309 [2100/2589 (81%)]\tLoss: 221.071365\n",
      "Train Epoch: 1309 [2400/2589 (93%)]\tLoss: 279.896881\n",
      "====> Epoch: 1309 Average train loss: 215.3194\n",
      "====> Epoch: 1309 Average test loss: 913.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1310 [0/2589 (0%)]\tLoss: 587.273987\n",
      "Train Epoch: 1310 [300/2589 (12%)]\tLoss: 180.731033\n",
      "Train Epoch: 1310 [600/2589 (23%)]\tLoss: 240.522369\n",
      "Train Epoch: 1310 [900/2589 (35%)]\tLoss: 394.759125\n",
      "Train Epoch: 1310 [1200/2589 (46%)]\tLoss: 165.082489\n",
      "Train Epoch: 1310 [1500/2589 (58%)]\tLoss: 250.359512\n",
      "Train Epoch: 1310 [1800/2589 (70%)]\tLoss: 195.225723\n",
      "Train Epoch: 1310 [2100/2589 (81%)]\tLoss: 154.248520\n",
      "Train Epoch: 1310 [2400/2589 (93%)]\tLoss: 200.597977\n",
      "====> Epoch: 1310 Average train loss: 219.4884\n",
      "====> Epoch: 1310 Average test loss: 906.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1311 [0/2589 (0%)]\tLoss: 341.320038\n",
      "Train Epoch: 1311 [300/2589 (12%)]\tLoss: 222.588486\n",
      "Train Epoch: 1311 [600/2589 (23%)]\tLoss: 185.554901\n",
      "Train Epoch: 1311 [900/2589 (35%)]\tLoss: 380.259644\n",
      "Train Epoch: 1311 [1200/2589 (46%)]\tLoss: 152.356125\n",
      "Train Epoch: 1311 [1500/2589 (58%)]\tLoss: 278.835449\n",
      "Train Epoch: 1311 [1800/2589 (70%)]\tLoss: 216.649933\n",
      "Train Epoch: 1311 [2100/2589 (81%)]\tLoss: 306.210297\n",
      "Train Epoch: 1311 [2400/2589 (93%)]\tLoss: 134.409821\n",
      "====> Epoch: 1311 Average train loss: 222.8653\n",
      "====> Epoch: 1311 Average test loss: 931.6483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1312 [0/2589 (0%)]\tLoss: 127.424919\n",
      "Train Epoch: 1312 [300/2589 (12%)]\tLoss: 169.147354\n",
      "Train Epoch: 1312 [600/2589 (23%)]\tLoss: 230.419342\n",
      "Train Epoch: 1312 [900/2589 (35%)]\tLoss: 283.072693\n",
      "Train Epoch: 1312 [1200/2589 (46%)]\tLoss: 156.558044\n",
      "Train Epoch: 1312 [1500/2589 (58%)]\tLoss: 224.954056\n",
      "Train Epoch: 1312 [1800/2589 (70%)]\tLoss: 154.611481\n",
      "Train Epoch: 1312 [2100/2589 (81%)]\tLoss: 241.440125\n",
      "Train Epoch: 1312 [2400/2589 (93%)]\tLoss: 257.827698\n",
      "====> Epoch: 1312 Average train loss: 220.9731\n",
      "====> Epoch: 1312 Average test loss: 908.2575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1313 [0/2589 (0%)]\tLoss: 132.759979\n",
      "Train Epoch: 1313 [300/2589 (12%)]\tLoss: 403.921783\n",
      "Train Epoch: 1313 [600/2589 (23%)]\tLoss: 358.822144\n",
      "Train Epoch: 1313 [900/2589 (35%)]\tLoss: 133.557419\n",
      "Train Epoch: 1313 [1200/2589 (46%)]\tLoss: 248.293854\n",
      "Train Epoch: 1313 [1500/2589 (58%)]\tLoss: 160.796417\n",
      "Train Epoch: 1313 [1800/2589 (70%)]\tLoss: 209.988495\n",
      "Train Epoch: 1313 [2100/2589 (81%)]\tLoss: 176.965637\n",
      "Train Epoch: 1313 [2400/2589 (93%)]\tLoss: 207.028839\n",
      "====> Epoch: 1313 Average train loss: 199.8969\n",
      "====> Epoch: 1313 Average test loss: 900.0134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1314 [0/2589 (0%)]\tLoss: 213.943497\n",
      "Train Epoch: 1314 [300/2589 (12%)]\tLoss: 246.686188\n",
      "Train Epoch: 1314 [600/2589 (23%)]\tLoss: 202.824142\n",
      "Train Epoch: 1314 [900/2589 (35%)]\tLoss: 188.922104\n",
      "Train Epoch: 1314 [1200/2589 (46%)]\tLoss: 187.382797\n",
      "Train Epoch: 1314 [1500/2589 (58%)]\tLoss: 209.883484\n",
      "Train Epoch: 1314 [1800/2589 (70%)]\tLoss: 131.480606\n",
      "Train Epoch: 1314 [2100/2589 (81%)]\tLoss: 168.367401\n",
      "Train Epoch: 1314 [2400/2589 (93%)]\tLoss: 134.261475\n",
      "====> Epoch: 1314 Average train loss: 206.9659\n",
      "====> Epoch: 1314 Average test loss: 918.5962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1315 [0/2589 (0%)]\tLoss: 356.779205\n",
      "Train Epoch: 1315 [300/2589 (12%)]\tLoss: 215.096420\n",
      "Train Epoch: 1315 [600/2589 (23%)]\tLoss: 166.525650\n",
      "Train Epoch: 1315 [900/2589 (35%)]\tLoss: 166.076447\n",
      "Train Epoch: 1315 [1200/2589 (46%)]\tLoss: 193.358795\n",
      "Train Epoch: 1315 [1500/2589 (58%)]\tLoss: 195.159088\n",
      "Train Epoch: 1315 [1800/2589 (70%)]\tLoss: 151.075653\n",
      "Train Epoch: 1315 [2100/2589 (81%)]\tLoss: 223.191467\n",
      "Train Epoch: 1315 [2400/2589 (93%)]\tLoss: 204.133530\n",
      "====> Epoch: 1315 Average train loss: 214.9056\n",
      "====> Epoch: 1315 Average test loss: 906.5292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1316 [0/2589 (0%)]\tLoss: 278.873901\n",
      "Train Epoch: 1316 [300/2589 (12%)]\tLoss: 214.663635\n",
      "Train Epoch: 1316 [600/2589 (23%)]\tLoss: 232.465149\n",
      "Train Epoch: 1316 [900/2589 (35%)]\tLoss: 205.331650\n",
      "Train Epoch: 1316 [1200/2589 (46%)]\tLoss: 174.799377\n",
      "Train Epoch: 1316 [1500/2589 (58%)]\tLoss: 112.477097\n",
      "Train Epoch: 1316 [1800/2589 (70%)]\tLoss: 210.398666\n",
      "Train Epoch: 1316 [2100/2589 (81%)]\tLoss: 263.488373\n",
      "Train Epoch: 1316 [2400/2589 (93%)]\tLoss: 198.557693\n",
      "====> Epoch: 1316 Average train loss: 207.5907\n",
      "====> Epoch: 1316 Average test loss: 897.5696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1317 [0/2589 (0%)]\tLoss: 169.709793\n",
      "Train Epoch: 1317 [300/2589 (12%)]\tLoss: 298.745575\n",
      "Train Epoch: 1317 [600/2589 (23%)]\tLoss: 261.521942\n",
      "Train Epoch: 1317 [900/2589 (35%)]\tLoss: 183.008774\n",
      "Train Epoch: 1317 [1200/2589 (46%)]\tLoss: 155.247940\n",
      "Train Epoch: 1317 [1500/2589 (58%)]\tLoss: 344.186340\n",
      "Train Epoch: 1317 [1800/2589 (70%)]\tLoss: 193.140045\n",
      "Train Epoch: 1317 [2100/2589 (81%)]\tLoss: 193.198013\n",
      "Train Epoch: 1317 [2400/2589 (93%)]\tLoss: 237.670853\n",
      "====> Epoch: 1317 Average train loss: 212.9716\n",
      "====> Epoch: 1317 Average test loss: 911.0349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1318 [0/2589 (0%)]\tLoss: 168.888321\n",
      "Train Epoch: 1318 [300/2589 (12%)]\tLoss: 175.857239\n",
      "Train Epoch: 1318 [600/2589 (23%)]\tLoss: 220.415756\n",
      "Train Epoch: 1318 [900/2589 (35%)]\tLoss: 235.399933\n",
      "Train Epoch: 1318 [1200/2589 (46%)]\tLoss: 198.547409\n",
      "Train Epoch: 1318 [1500/2589 (58%)]\tLoss: 167.885468\n",
      "Train Epoch: 1318 [1800/2589 (70%)]\tLoss: 194.546356\n",
      "Train Epoch: 1318 [2100/2589 (81%)]\tLoss: 181.973740\n",
      "Train Epoch: 1318 [2400/2589 (93%)]\tLoss: 230.674500\n",
      "====> Epoch: 1318 Average train loss: 209.9961\n",
      "====> Epoch: 1318 Average test loss: 912.1936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1319 [0/2589 (0%)]\tLoss: 127.256477\n",
      "Train Epoch: 1319 [300/2589 (12%)]\tLoss: 155.050705\n",
      "Train Epoch: 1319 [600/2589 (23%)]\tLoss: 227.758331\n",
      "Train Epoch: 1319 [900/2589 (35%)]\tLoss: 170.352936\n",
      "Train Epoch: 1319 [1200/2589 (46%)]\tLoss: 201.050568\n",
      "Train Epoch: 1319 [1500/2589 (58%)]\tLoss: 201.383362\n",
      "Train Epoch: 1319 [1800/2589 (70%)]\tLoss: 134.007629\n",
      "Train Epoch: 1319 [2100/2589 (81%)]\tLoss: 200.964584\n",
      "Train Epoch: 1319 [2400/2589 (93%)]\tLoss: 180.357513\n",
      "====> Epoch: 1319 Average train loss: 215.2998\n",
      "====> Epoch: 1319 Average test loss: 910.1201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1320 [0/2589 (0%)]\tLoss: 235.993927\n",
      "Train Epoch: 1320 [300/2589 (12%)]\tLoss: 170.671097\n",
      "Train Epoch: 1320 [600/2589 (23%)]\tLoss: 187.506622\n",
      "Train Epoch: 1320 [900/2589 (35%)]\tLoss: 173.049072\n",
      "Train Epoch: 1320 [1200/2589 (46%)]\tLoss: 337.577148\n",
      "Train Epoch: 1320 [1500/2589 (58%)]\tLoss: 175.796967\n",
      "Train Epoch: 1320 [1800/2589 (70%)]\tLoss: 228.835281\n",
      "Train Epoch: 1320 [2100/2589 (81%)]\tLoss: 175.208679\n",
      "Train Epoch: 1320 [2400/2589 (93%)]\tLoss: 221.024368\n",
      "====> Epoch: 1320 Average train loss: 203.4274\n",
      "====> Epoch: 1320 Average test loss: 908.2040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1321 [0/2589 (0%)]\tLoss: 223.851700\n",
      "Train Epoch: 1321 [300/2589 (12%)]\tLoss: 163.361542\n",
      "Train Epoch: 1321 [600/2589 (23%)]\tLoss: 181.258804\n",
      "Train Epoch: 1321 [900/2589 (35%)]\tLoss: 315.016876\n",
      "Train Epoch: 1321 [1200/2589 (46%)]\tLoss: 161.485565\n",
      "Train Epoch: 1321 [1500/2589 (58%)]\tLoss: 204.927277\n",
      "Train Epoch: 1321 [1800/2589 (70%)]\tLoss: 246.937317\n",
      "Train Epoch: 1321 [2100/2589 (81%)]\tLoss: 244.437805\n",
      "Train Epoch: 1321 [2400/2589 (93%)]\tLoss: 146.003174\n",
      "====> Epoch: 1321 Average train loss: 204.4051\n",
      "====> Epoch: 1321 Average test loss: 906.0715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1322 [0/2589 (0%)]\tLoss: 163.914978\n",
      "Train Epoch: 1322 [300/2589 (12%)]\tLoss: 203.833405\n",
      "Train Epoch: 1322 [600/2589 (23%)]\tLoss: 281.076843\n",
      "Train Epoch: 1322 [900/2589 (35%)]\tLoss: 261.228607\n",
      "Train Epoch: 1322 [1200/2589 (46%)]\tLoss: 210.412735\n",
      "Train Epoch: 1322 [1500/2589 (58%)]\tLoss: 176.785141\n",
      "Train Epoch: 1322 [1800/2589 (70%)]\tLoss: 219.838699\n",
      "Train Epoch: 1322 [2100/2589 (81%)]\tLoss: 208.149857\n",
      "Train Epoch: 1322 [2400/2589 (93%)]\tLoss: 186.251190\n",
      "====> Epoch: 1322 Average train loss: 207.7068\n",
      "====> Epoch: 1322 Average test loss: 910.2469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1323 [0/2589 (0%)]\tLoss: 255.167343\n",
      "Train Epoch: 1323 [300/2589 (12%)]\tLoss: 176.233459\n",
      "Train Epoch: 1323 [600/2589 (23%)]\tLoss: 171.192368\n",
      "Train Epoch: 1323 [900/2589 (35%)]\tLoss: 205.547577\n",
      "Train Epoch: 1323 [1200/2589 (46%)]\tLoss: 183.085876\n",
      "Train Epoch: 1323 [1500/2589 (58%)]\tLoss: 240.651169\n",
      "Train Epoch: 1323 [1800/2589 (70%)]\tLoss: 203.428940\n",
      "Train Epoch: 1323 [2100/2589 (81%)]\tLoss: 161.102859\n",
      "Train Epoch: 1323 [2400/2589 (93%)]\tLoss: 205.367279\n",
      "====> Epoch: 1323 Average train loss: 206.5878\n",
      "====> Epoch: 1323 Average test loss: 915.1330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1324 [0/2589 (0%)]\tLoss: 196.656021\n",
      "Train Epoch: 1324 [300/2589 (12%)]\tLoss: 162.474579\n",
      "Train Epoch: 1324 [600/2589 (23%)]\tLoss: 218.237396\n",
      "Train Epoch: 1324 [900/2589 (35%)]\tLoss: 180.849579\n",
      "Train Epoch: 1324 [1200/2589 (46%)]\tLoss: 295.430603\n",
      "Train Epoch: 1324 [1500/2589 (58%)]\tLoss: 192.323593\n",
      "Train Epoch: 1324 [1800/2589 (70%)]\tLoss: 118.098511\n",
      "Train Epoch: 1324 [2100/2589 (81%)]\tLoss: 154.450882\n",
      "Train Epoch: 1324 [2400/2589 (93%)]\tLoss: 180.008041\n",
      "====> Epoch: 1324 Average train loss: 209.4559\n",
      "====> Epoch: 1324 Average test loss: 926.3699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1325 [0/2589 (0%)]\tLoss: 300.170593\n",
      "Train Epoch: 1325 [300/2589 (12%)]\tLoss: 214.039841\n",
      "Train Epoch: 1325 [600/2589 (23%)]\tLoss: 143.064514\n",
      "Train Epoch: 1325 [900/2589 (35%)]\tLoss: 181.927628\n",
      "Train Epoch: 1325 [1200/2589 (46%)]\tLoss: 181.027893\n",
      "Train Epoch: 1325 [1500/2589 (58%)]\tLoss: 159.044006\n",
      "Train Epoch: 1325 [1800/2589 (70%)]\tLoss: 214.487122\n",
      "Train Epoch: 1325 [2100/2589 (81%)]\tLoss: 299.555267\n",
      "Train Epoch: 1325 [2400/2589 (93%)]\tLoss: 253.553879\n",
      "====> Epoch: 1325 Average train loss: 220.5319\n",
      "====> Epoch: 1325 Average test loss: 916.7516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1326 [0/2589 (0%)]\tLoss: 199.538025\n",
      "Train Epoch: 1326 [300/2589 (12%)]\tLoss: 233.458679\n",
      "Train Epoch: 1326 [600/2589 (23%)]\tLoss: 201.359848\n",
      "Train Epoch: 1326 [900/2589 (35%)]\tLoss: 225.960739\n",
      "Train Epoch: 1326 [1200/2589 (46%)]\tLoss: 221.174866\n",
      "Train Epoch: 1326 [1500/2589 (58%)]\tLoss: 220.646057\n",
      "Train Epoch: 1326 [1800/2589 (70%)]\tLoss: 189.209991\n",
      "Train Epoch: 1326 [2100/2589 (81%)]\tLoss: 147.177017\n",
      "Train Epoch: 1326 [2400/2589 (93%)]\tLoss: 228.806122\n",
      "====> Epoch: 1326 Average train loss: 210.5234\n",
      "====> Epoch: 1326 Average test loss: 915.1612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1327 [0/2589 (0%)]\tLoss: 165.528061\n",
      "Train Epoch: 1327 [300/2589 (12%)]\tLoss: 261.061920\n",
      "Train Epoch: 1327 [600/2589 (23%)]\tLoss: 160.236237\n",
      "Train Epoch: 1327 [900/2589 (35%)]\tLoss: 324.534607\n",
      "Train Epoch: 1327 [1200/2589 (46%)]\tLoss: 247.526291\n",
      "Train Epoch: 1327 [1500/2589 (58%)]\tLoss: 174.001663\n",
      "Train Epoch: 1327 [1800/2589 (70%)]\tLoss: 230.961487\n",
      "Train Epoch: 1327 [2100/2589 (81%)]\tLoss: 196.381638\n",
      "Train Epoch: 1327 [2400/2589 (93%)]\tLoss: 254.425705\n",
      "====> Epoch: 1327 Average train loss: 208.1798\n",
      "====> Epoch: 1327 Average test loss: 914.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1328 [0/2589 (0%)]\tLoss: 268.611023\n",
      "Train Epoch: 1328 [300/2589 (12%)]\tLoss: 195.883072\n",
      "Train Epoch: 1328 [600/2589 (23%)]\tLoss: 157.134262\n",
      "Train Epoch: 1328 [900/2589 (35%)]\tLoss: 183.224762\n",
      "Train Epoch: 1328 [1200/2589 (46%)]\tLoss: 225.377640\n",
      "Train Epoch: 1328 [1500/2589 (58%)]\tLoss: 248.542007\n",
      "Train Epoch: 1328 [1800/2589 (70%)]\tLoss: 178.598602\n",
      "Train Epoch: 1328 [2100/2589 (81%)]\tLoss: 148.686676\n",
      "Train Epoch: 1328 [2400/2589 (93%)]\tLoss: 319.148468\n",
      "====> Epoch: 1328 Average train loss: 218.3135\n",
      "====> Epoch: 1328 Average test loss: 916.5531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1329 [0/2589 (0%)]\tLoss: 207.649948\n",
      "Train Epoch: 1329 [300/2589 (12%)]\tLoss: 201.903229\n",
      "Train Epoch: 1329 [600/2589 (23%)]\tLoss: 201.612595\n",
      "Train Epoch: 1329 [900/2589 (35%)]\tLoss: 162.739426\n",
      "Train Epoch: 1329 [1200/2589 (46%)]\tLoss: 232.655365\n",
      "Train Epoch: 1329 [1500/2589 (58%)]\tLoss: 221.091690\n",
      "Train Epoch: 1329 [1800/2589 (70%)]\tLoss: 207.514191\n",
      "Train Epoch: 1329 [2100/2589 (81%)]\tLoss: 160.205063\n",
      "Train Epoch: 1329 [2400/2589 (93%)]\tLoss: 200.748688\n",
      "====> Epoch: 1329 Average train loss: 214.3262\n",
      "====> Epoch: 1329 Average test loss: 925.6796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1330 [0/2589 (0%)]\tLoss: 181.869217\n",
      "Train Epoch: 1330 [300/2589 (12%)]\tLoss: 204.067474\n",
      "Train Epoch: 1330 [600/2589 (23%)]\tLoss: 123.537811\n",
      "Train Epoch: 1330 [900/2589 (35%)]\tLoss: 356.545105\n",
      "Train Epoch: 1330 [1200/2589 (46%)]\tLoss: 293.304657\n",
      "Train Epoch: 1330 [1500/2589 (58%)]\tLoss: 168.812119\n",
      "Train Epoch: 1330 [1800/2589 (70%)]\tLoss: 191.254990\n",
      "Train Epoch: 1330 [2100/2589 (81%)]\tLoss: 186.593979\n",
      "Train Epoch: 1330 [2400/2589 (93%)]\tLoss: 160.945221\n",
      "====> Epoch: 1330 Average train loss: 214.7426\n",
      "====> Epoch: 1330 Average test loss: 909.5245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1331 [0/2589 (0%)]\tLoss: 165.842865\n",
      "Train Epoch: 1331 [300/2589 (12%)]\tLoss: 236.271820\n",
      "Train Epoch: 1331 [600/2589 (23%)]\tLoss: 232.609146\n",
      "Train Epoch: 1331 [900/2589 (35%)]\tLoss: 227.743256\n",
      "Train Epoch: 1331 [1200/2589 (46%)]\tLoss: 142.526520\n",
      "Train Epoch: 1331 [1500/2589 (58%)]\tLoss: 116.463760\n",
      "Train Epoch: 1331 [1800/2589 (70%)]\tLoss: 273.940796\n",
      "Train Epoch: 1331 [2100/2589 (81%)]\tLoss: 215.493164\n",
      "Train Epoch: 1331 [2400/2589 (93%)]\tLoss: 182.858368\n",
      "====> Epoch: 1331 Average train loss: 218.6662\n",
      "====> Epoch: 1331 Average test loss: 895.3786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1332 [0/2589 (0%)]\tLoss: 205.685333\n",
      "Train Epoch: 1332 [300/2589 (12%)]\tLoss: 238.220795\n",
      "Train Epoch: 1332 [600/2589 (23%)]\tLoss: 145.627731\n",
      "Train Epoch: 1332 [900/2589 (35%)]\tLoss: 178.442093\n",
      "Train Epoch: 1332 [1200/2589 (46%)]\tLoss: 201.138046\n",
      "Train Epoch: 1332 [1500/2589 (58%)]\tLoss: 213.997391\n",
      "Train Epoch: 1332 [1800/2589 (70%)]\tLoss: 202.210739\n",
      "Train Epoch: 1332 [2100/2589 (81%)]\tLoss: 280.136261\n",
      "Train Epoch: 1332 [2400/2589 (93%)]\tLoss: 302.003906\n",
      "====> Epoch: 1332 Average train loss: 218.6929\n",
      "====> Epoch: 1332 Average test loss: 911.2773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1333 [0/2589 (0%)]\tLoss: 209.474091\n",
      "Train Epoch: 1333 [300/2589 (12%)]\tLoss: 197.439026\n",
      "Train Epoch: 1333 [600/2589 (23%)]\tLoss: 215.865158\n",
      "Train Epoch: 1333 [900/2589 (35%)]\tLoss: 129.965836\n",
      "Train Epoch: 1333 [1200/2589 (46%)]\tLoss: 132.686707\n",
      "Train Epoch: 1333 [1500/2589 (58%)]\tLoss: 215.836517\n",
      "Train Epoch: 1333 [1800/2589 (70%)]\tLoss: 220.142822\n",
      "Train Epoch: 1333 [2100/2589 (81%)]\tLoss: 171.163666\n",
      "Train Epoch: 1333 [2400/2589 (93%)]\tLoss: 215.997040\n",
      "====> Epoch: 1333 Average train loss: 206.1535\n",
      "====> Epoch: 1333 Average test loss: 894.6317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1334 [0/2589 (0%)]\tLoss: 190.899826\n",
      "Train Epoch: 1334 [300/2589 (12%)]\tLoss: 175.492874\n",
      "Train Epoch: 1334 [600/2589 (23%)]\tLoss: 160.184052\n",
      "Train Epoch: 1334 [900/2589 (35%)]\tLoss: 153.387589\n",
      "Train Epoch: 1334 [1200/2589 (46%)]\tLoss: 181.231354\n",
      "Train Epoch: 1334 [1500/2589 (58%)]\tLoss: 270.703949\n",
      "Train Epoch: 1334 [1800/2589 (70%)]\tLoss: 245.144684\n",
      "Train Epoch: 1334 [2100/2589 (81%)]\tLoss: 176.474350\n",
      "Train Epoch: 1334 [2400/2589 (93%)]\tLoss: 214.069275\n",
      "====> Epoch: 1334 Average train loss: 214.0333\n",
      "====> Epoch: 1334 Average test loss: 910.4078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1335 [0/2589 (0%)]\tLoss: 139.194687\n",
      "Train Epoch: 1335 [300/2589 (12%)]\tLoss: 153.137299\n",
      "Train Epoch: 1335 [600/2589 (23%)]\tLoss: 144.072800\n",
      "Train Epoch: 1335 [900/2589 (35%)]\tLoss: 281.507172\n",
      "Train Epoch: 1335 [1200/2589 (46%)]\tLoss: 204.630310\n",
      "Train Epoch: 1335 [1500/2589 (58%)]\tLoss: 235.856873\n",
      "Train Epoch: 1335 [1800/2589 (70%)]\tLoss: 168.377609\n",
      "Train Epoch: 1335 [2100/2589 (81%)]\tLoss: 209.439285\n",
      "Train Epoch: 1335 [2400/2589 (93%)]\tLoss: 140.875320\n",
      "====> Epoch: 1335 Average train loss: 217.2511\n",
      "====> Epoch: 1335 Average test loss: 927.4312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1336 [0/2589 (0%)]\tLoss: 174.458206\n",
      "Train Epoch: 1336 [300/2589 (12%)]\tLoss: 152.356888\n",
      "Train Epoch: 1336 [600/2589 (23%)]\tLoss: 201.297943\n",
      "Train Epoch: 1336 [900/2589 (35%)]\tLoss: 185.358215\n",
      "Train Epoch: 1336 [1200/2589 (46%)]\tLoss: 174.452011\n",
      "Train Epoch: 1336 [1500/2589 (58%)]\tLoss: 152.796219\n",
      "Train Epoch: 1336 [1800/2589 (70%)]\tLoss: 285.693054\n",
      "Train Epoch: 1336 [2100/2589 (81%)]\tLoss: 123.483261\n",
      "Train Epoch: 1336 [2400/2589 (93%)]\tLoss: 203.513885\n",
      "====> Epoch: 1336 Average train loss: 205.0893\n",
      "====> Epoch: 1336 Average test loss: 907.5847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1337 [0/2589 (0%)]\tLoss: 258.984467\n",
      "Train Epoch: 1337 [300/2589 (12%)]\tLoss: 208.231308\n",
      "Train Epoch: 1337 [600/2589 (23%)]\tLoss: 168.684265\n",
      "Train Epoch: 1337 [900/2589 (35%)]\tLoss: 205.178192\n",
      "Train Epoch: 1337 [1200/2589 (46%)]\tLoss: 198.009186\n",
      "Train Epoch: 1337 [1500/2589 (58%)]\tLoss: 162.142960\n",
      "Train Epoch: 1337 [1800/2589 (70%)]\tLoss: 133.824051\n",
      "Train Epoch: 1337 [2100/2589 (81%)]\tLoss: 171.646973\n",
      "Train Epoch: 1337 [2400/2589 (93%)]\tLoss: 151.725281\n",
      "====> Epoch: 1337 Average train loss: 212.5687\n",
      "====> Epoch: 1337 Average test loss: 909.2666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1338 [0/2589 (0%)]\tLoss: 176.660248\n",
      "Train Epoch: 1338 [300/2589 (12%)]\tLoss: 179.006561\n",
      "Train Epoch: 1338 [600/2589 (23%)]\tLoss: 214.079163\n",
      "Train Epoch: 1338 [900/2589 (35%)]\tLoss: 201.057266\n",
      "Train Epoch: 1338 [1200/2589 (46%)]\tLoss: 173.115143\n",
      "Train Epoch: 1338 [1500/2589 (58%)]\tLoss: 335.858582\n",
      "Train Epoch: 1338 [1800/2589 (70%)]\tLoss: 206.057068\n",
      "Train Epoch: 1338 [2100/2589 (81%)]\tLoss: 184.486801\n",
      "Train Epoch: 1338 [2400/2589 (93%)]\tLoss: 237.203461\n",
      "====> Epoch: 1338 Average train loss: 211.0824\n",
      "====> Epoch: 1338 Average test loss: 912.1191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1339 [0/2589 (0%)]\tLoss: 114.237862\n",
      "Train Epoch: 1339 [300/2589 (12%)]\tLoss: 153.564255\n",
      "Train Epoch: 1339 [600/2589 (23%)]\tLoss: 166.037643\n",
      "Train Epoch: 1339 [900/2589 (35%)]\tLoss: 106.350670\n",
      "Train Epoch: 1339 [1200/2589 (46%)]\tLoss: 218.331894\n",
      "Train Epoch: 1339 [1500/2589 (58%)]\tLoss: 154.785645\n",
      "Train Epoch: 1339 [1800/2589 (70%)]\tLoss: 201.876816\n",
      "Train Epoch: 1339 [2100/2589 (81%)]\tLoss: 245.598221\n",
      "Train Epoch: 1339 [2400/2589 (93%)]\tLoss: 196.212677\n",
      "====> Epoch: 1339 Average train loss: 207.0082\n",
      "====> Epoch: 1339 Average test loss: 901.4183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1340 [0/2589 (0%)]\tLoss: 213.578354\n",
      "Train Epoch: 1340 [300/2589 (12%)]\tLoss: 179.641388\n",
      "Train Epoch: 1340 [600/2589 (23%)]\tLoss: 169.530945\n",
      "Train Epoch: 1340 [900/2589 (35%)]\tLoss: 180.555725\n",
      "Train Epoch: 1340 [1200/2589 (46%)]\tLoss: 186.450439\n",
      "Train Epoch: 1340 [1500/2589 (58%)]\tLoss: 295.932098\n",
      "Train Epoch: 1340 [1800/2589 (70%)]\tLoss: 200.118332\n",
      "Train Epoch: 1340 [2100/2589 (81%)]\tLoss: 160.235123\n",
      "Train Epoch: 1340 [2400/2589 (93%)]\tLoss: 239.175644\n",
      "====> Epoch: 1340 Average train loss: 214.4487\n",
      "====> Epoch: 1340 Average test loss: 913.7297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1341 [0/2589 (0%)]\tLoss: 207.599701\n",
      "Train Epoch: 1341 [300/2589 (12%)]\tLoss: 147.472107\n",
      "Train Epoch: 1341 [600/2589 (23%)]\tLoss: 179.851868\n",
      "Train Epoch: 1341 [900/2589 (35%)]\tLoss: 154.603043\n",
      "Train Epoch: 1341 [1200/2589 (46%)]\tLoss: 174.804123\n",
      "Train Epoch: 1341 [1500/2589 (58%)]\tLoss: 231.701309\n",
      "Train Epoch: 1341 [1800/2589 (70%)]\tLoss: 174.220322\n",
      "Train Epoch: 1341 [2100/2589 (81%)]\tLoss: 117.263580\n",
      "Train Epoch: 1341 [2400/2589 (93%)]\tLoss: 125.096794\n",
      "====> Epoch: 1341 Average train loss: 222.3809\n",
      "====> Epoch: 1341 Average test loss: 908.1785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1342 [0/2589 (0%)]\tLoss: 339.184204\n",
      "Train Epoch: 1342 [300/2589 (12%)]\tLoss: 139.867188\n",
      "Train Epoch: 1342 [600/2589 (23%)]\tLoss: 206.799652\n",
      "Train Epoch: 1342 [900/2589 (35%)]\tLoss: 141.753159\n",
      "Train Epoch: 1342 [1200/2589 (46%)]\tLoss: 273.553223\n",
      "Train Epoch: 1342 [1500/2589 (58%)]\tLoss: 151.797806\n",
      "Train Epoch: 1342 [1800/2589 (70%)]\tLoss: 218.186005\n",
      "Train Epoch: 1342 [2100/2589 (81%)]\tLoss: 183.470932\n",
      "Train Epoch: 1342 [2400/2589 (93%)]\tLoss: 341.528107\n",
      "====> Epoch: 1342 Average train loss: 209.9364\n",
      "====> Epoch: 1342 Average test loss: 922.3617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1343 [0/2589 (0%)]\tLoss: 194.767258\n",
      "Train Epoch: 1343 [300/2589 (12%)]\tLoss: 293.557739\n",
      "Train Epoch: 1343 [600/2589 (23%)]\tLoss: 207.533691\n",
      "Train Epoch: 1343 [900/2589 (35%)]\tLoss: 159.511093\n",
      "Train Epoch: 1343 [1200/2589 (46%)]\tLoss: 229.985703\n",
      "Train Epoch: 1343 [1500/2589 (58%)]\tLoss: 293.031036\n",
      "Train Epoch: 1343 [1800/2589 (70%)]\tLoss: 153.531342\n",
      "Train Epoch: 1343 [2100/2589 (81%)]\tLoss: 249.412659\n",
      "Train Epoch: 1343 [2400/2589 (93%)]\tLoss: 165.769669\n",
      "====> Epoch: 1343 Average train loss: 214.9073\n",
      "====> Epoch: 1343 Average test loss: 919.6777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1344 [0/2589 (0%)]\tLoss: 118.230713\n",
      "Train Epoch: 1344 [300/2589 (12%)]\tLoss: 149.829987\n",
      "Train Epoch: 1344 [600/2589 (23%)]\tLoss: 210.411270\n",
      "Train Epoch: 1344 [900/2589 (35%)]\tLoss: 232.907974\n",
      "Train Epoch: 1344 [1200/2589 (46%)]\tLoss: 243.878311\n",
      "Train Epoch: 1344 [1500/2589 (58%)]\tLoss: 271.182953\n",
      "Train Epoch: 1344 [1800/2589 (70%)]\tLoss: 239.865616\n",
      "Train Epoch: 1344 [2100/2589 (81%)]\tLoss: 159.285126\n",
      "Train Epoch: 1344 [2400/2589 (93%)]\tLoss: 241.724335\n",
      "====> Epoch: 1344 Average train loss: 211.6924\n",
      "====> Epoch: 1344 Average test loss: 917.5554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1345 [0/2589 (0%)]\tLoss: 180.886093\n",
      "Train Epoch: 1345 [300/2589 (12%)]\tLoss: 287.018280\n",
      "Train Epoch: 1345 [600/2589 (23%)]\tLoss: 287.416626\n",
      "Train Epoch: 1345 [900/2589 (35%)]\tLoss: 205.390076\n",
      "Train Epoch: 1345 [1200/2589 (46%)]\tLoss: 204.821152\n",
      "Train Epoch: 1345 [1500/2589 (58%)]\tLoss: 241.838806\n",
      "Train Epoch: 1345 [1800/2589 (70%)]\tLoss: 254.378876\n",
      "Train Epoch: 1345 [2100/2589 (81%)]\tLoss: 377.691132\n",
      "Train Epoch: 1345 [2400/2589 (93%)]\tLoss: 158.641495\n",
      "====> Epoch: 1345 Average train loss: 212.0046\n",
      "====> Epoch: 1345 Average test loss: 914.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1346 [0/2589 (0%)]\tLoss: 171.515488\n",
      "Train Epoch: 1346 [300/2589 (12%)]\tLoss: 201.041092\n",
      "Train Epoch: 1346 [600/2589 (23%)]\tLoss: 167.526230\n",
      "Train Epoch: 1346 [900/2589 (35%)]\tLoss: 138.855774\n",
      "Train Epoch: 1346 [1200/2589 (46%)]\tLoss: 234.605972\n",
      "Train Epoch: 1346 [1500/2589 (58%)]\tLoss: 196.651779\n",
      "Train Epoch: 1346 [1800/2589 (70%)]\tLoss: 249.922379\n",
      "Train Epoch: 1346 [2100/2589 (81%)]\tLoss: 233.847168\n",
      "Train Epoch: 1346 [2400/2589 (93%)]\tLoss: 298.553070\n",
      "====> Epoch: 1346 Average train loss: 208.4857\n",
      "====> Epoch: 1346 Average test loss: 911.5255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1347 [0/2589 (0%)]\tLoss: 179.752686\n",
      "Train Epoch: 1347 [300/2589 (12%)]\tLoss: 176.024384\n",
      "Train Epoch: 1347 [600/2589 (23%)]\tLoss: 298.388397\n",
      "Train Epoch: 1347 [900/2589 (35%)]\tLoss: 301.713837\n",
      "Train Epoch: 1347 [1200/2589 (46%)]\tLoss: 173.501511\n",
      "Train Epoch: 1347 [1500/2589 (58%)]\tLoss: 145.458755\n",
      "Train Epoch: 1347 [1800/2589 (70%)]\tLoss: 151.372910\n",
      "Train Epoch: 1347 [2100/2589 (81%)]\tLoss: 222.643021\n",
      "Train Epoch: 1347 [2400/2589 (93%)]\tLoss: 175.590317\n",
      "====> Epoch: 1347 Average train loss: 197.9052\n",
      "====> Epoch: 1347 Average test loss: 904.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1348 [0/2589 (0%)]\tLoss: 229.003265\n",
      "Train Epoch: 1348 [300/2589 (12%)]\tLoss: 191.554962\n",
      "Train Epoch: 1348 [600/2589 (23%)]\tLoss: 212.956451\n",
      "Train Epoch: 1348 [900/2589 (35%)]\tLoss: 174.045563\n",
      "Train Epoch: 1348 [1200/2589 (46%)]\tLoss: 148.393906\n",
      "Train Epoch: 1348 [1500/2589 (58%)]\tLoss: 295.262482\n",
      "Train Epoch: 1348 [1800/2589 (70%)]\tLoss: 172.270081\n",
      "Train Epoch: 1348 [2100/2589 (81%)]\tLoss: 187.550598\n",
      "Train Epoch: 1348 [2400/2589 (93%)]\tLoss: 257.367218\n",
      "====> Epoch: 1348 Average train loss: 220.0661\n",
      "====> Epoch: 1348 Average test loss: 901.9365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1349 [0/2589 (0%)]\tLoss: 136.209610\n",
      "Train Epoch: 1349 [300/2589 (12%)]\tLoss: 209.503662\n",
      "Train Epoch: 1349 [600/2589 (23%)]\tLoss: 184.596939\n",
      "Train Epoch: 1349 [900/2589 (35%)]\tLoss: 188.968353\n",
      "Train Epoch: 1349 [1200/2589 (46%)]\tLoss: 185.197159\n",
      "Train Epoch: 1349 [1500/2589 (58%)]\tLoss: 217.481140\n",
      "Train Epoch: 1349 [1800/2589 (70%)]\tLoss: 233.185013\n",
      "Train Epoch: 1349 [2100/2589 (81%)]\tLoss: 183.182861\n",
      "Train Epoch: 1349 [2400/2589 (93%)]\tLoss: 189.273361\n",
      "====> Epoch: 1349 Average train loss: 206.5160\n",
      "====> Epoch: 1349 Average test loss: 908.6552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1350 [0/2589 (0%)]\tLoss: 212.967926\n",
      "Train Epoch: 1350 [300/2589 (12%)]\tLoss: 207.842209\n",
      "Train Epoch: 1350 [600/2589 (23%)]\tLoss: 237.027008\n",
      "Train Epoch: 1350 [900/2589 (35%)]\tLoss: 210.871262\n",
      "Train Epoch: 1350 [1200/2589 (46%)]\tLoss: 190.719269\n",
      "Train Epoch: 1350 [1500/2589 (58%)]\tLoss: 162.212387\n",
      "Train Epoch: 1350 [1800/2589 (70%)]\tLoss: 269.809814\n",
      "Train Epoch: 1350 [2100/2589 (81%)]\tLoss: 153.853287\n",
      "Train Epoch: 1350 [2400/2589 (93%)]\tLoss: 166.339890\n",
      "====> Epoch: 1350 Average train loss: 216.7648\n",
      "====> Epoch: 1350 Average test loss: 919.8423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1351 [0/2589 (0%)]\tLoss: 171.473862\n",
      "Train Epoch: 1351 [300/2589 (12%)]\tLoss: 144.358658\n",
      "Train Epoch: 1351 [600/2589 (23%)]\tLoss: 177.885117\n",
      "Train Epoch: 1351 [900/2589 (35%)]\tLoss: 223.603851\n",
      "Train Epoch: 1351 [1200/2589 (46%)]\tLoss: 186.617844\n",
      "Train Epoch: 1351 [1500/2589 (58%)]\tLoss: 250.475189\n",
      "Train Epoch: 1351 [1800/2589 (70%)]\tLoss: 249.099518\n",
      "Train Epoch: 1351 [2100/2589 (81%)]\tLoss: 132.852310\n",
      "Train Epoch: 1351 [2400/2589 (93%)]\tLoss: 355.082092\n",
      "====> Epoch: 1351 Average train loss: 220.7943\n",
      "====> Epoch: 1351 Average test loss: 916.1259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1352 [0/2589 (0%)]\tLoss: 187.245209\n",
      "Train Epoch: 1352 [300/2589 (12%)]\tLoss: 123.597252\n",
      "Train Epoch: 1352 [600/2589 (23%)]\tLoss: 246.440155\n",
      "Train Epoch: 1352 [900/2589 (35%)]\tLoss: 160.799286\n",
      "Train Epoch: 1352 [1200/2589 (46%)]\tLoss: 191.119980\n",
      "Train Epoch: 1352 [1500/2589 (58%)]\tLoss: 152.901108\n",
      "Train Epoch: 1352 [1800/2589 (70%)]\tLoss: 243.585846\n",
      "Train Epoch: 1352 [2100/2589 (81%)]\tLoss: 208.803329\n",
      "Train Epoch: 1352 [2400/2589 (93%)]\tLoss: 327.651489\n",
      "====> Epoch: 1352 Average train loss: 209.0647\n",
      "====> Epoch: 1352 Average test loss: 921.7619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1353 [0/2589 (0%)]\tLoss: 183.347672\n",
      "Train Epoch: 1353 [300/2589 (12%)]\tLoss: 129.170044\n",
      "Train Epoch: 1353 [600/2589 (23%)]\tLoss: 194.490677\n",
      "Train Epoch: 1353 [900/2589 (35%)]\tLoss: 214.581009\n",
      "Train Epoch: 1353 [1200/2589 (46%)]\tLoss: 248.518555\n",
      "Train Epoch: 1353 [1500/2589 (58%)]\tLoss: 195.798233\n",
      "Train Epoch: 1353 [1800/2589 (70%)]\tLoss: 339.052734\n",
      "Train Epoch: 1353 [2100/2589 (81%)]\tLoss: 159.717377\n",
      "Train Epoch: 1353 [2400/2589 (93%)]\tLoss: 205.462509\n",
      "====> Epoch: 1353 Average train loss: 216.8316\n",
      "====> Epoch: 1353 Average test loss: 900.4395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1354 [0/2589 (0%)]\tLoss: 168.672928\n",
      "Train Epoch: 1354 [300/2589 (12%)]\tLoss: 296.459900\n",
      "Train Epoch: 1354 [600/2589 (23%)]\tLoss: 185.305176\n",
      "Train Epoch: 1354 [900/2589 (35%)]\tLoss: 194.683807\n",
      "Train Epoch: 1354 [1200/2589 (46%)]\tLoss: 184.724518\n",
      "Train Epoch: 1354 [1500/2589 (58%)]\tLoss: 168.180130\n",
      "Train Epoch: 1354 [1800/2589 (70%)]\tLoss: 184.048920\n",
      "Train Epoch: 1354 [2100/2589 (81%)]\tLoss: 176.009872\n",
      "Train Epoch: 1354 [2400/2589 (93%)]\tLoss: 228.186951\n",
      "====> Epoch: 1354 Average train loss: 215.3907\n",
      "====> Epoch: 1354 Average test loss: 917.0959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1355 [0/2589 (0%)]\tLoss: 178.261780\n",
      "Train Epoch: 1355 [300/2589 (12%)]\tLoss: 162.645004\n",
      "Train Epoch: 1355 [600/2589 (23%)]\tLoss: 252.959869\n",
      "Train Epoch: 1355 [900/2589 (35%)]\tLoss: 145.797531\n",
      "Train Epoch: 1355 [1200/2589 (46%)]\tLoss: 296.722076\n",
      "Train Epoch: 1355 [1500/2589 (58%)]\tLoss: 139.979065\n",
      "Train Epoch: 1355 [1800/2589 (70%)]\tLoss: 280.890106\n",
      "Train Epoch: 1355 [2100/2589 (81%)]\tLoss: 283.021271\n",
      "Train Epoch: 1355 [2400/2589 (93%)]\tLoss: 253.917084\n",
      "====> Epoch: 1355 Average train loss: 200.2082\n",
      "====> Epoch: 1355 Average test loss: 910.4774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1356 [0/2589 (0%)]\tLoss: 150.253906\n",
      "Train Epoch: 1356 [300/2589 (12%)]\tLoss: 221.489273\n",
      "Train Epoch: 1356 [600/2589 (23%)]\tLoss: 174.585312\n",
      "Train Epoch: 1356 [900/2589 (35%)]\tLoss: 224.027115\n",
      "Train Epoch: 1356 [1200/2589 (46%)]\tLoss: 203.871490\n",
      "Train Epoch: 1356 [1500/2589 (58%)]\tLoss: 157.442703\n",
      "Train Epoch: 1356 [1800/2589 (70%)]\tLoss: 190.562790\n",
      "Train Epoch: 1356 [2100/2589 (81%)]\tLoss: 243.910965\n",
      "Train Epoch: 1356 [2400/2589 (93%)]\tLoss: 222.740417\n",
      "====> Epoch: 1356 Average train loss: 214.4039\n",
      "====> Epoch: 1356 Average test loss: 909.0898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1357 [0/2589 (0%)]\tLoss: 177.561493\n",
      "Train Epoch: 1357 [300/2589 (12%)]\tLoss: 253.225647\n",
      "Train Epoch: 1357 [600/2589 (23%)]\tLoss: 164.064301\n",
      "Train Epoch: 1357 [900/2589 (35%)]\tLoss: 274.978577\n",
      "Train Epoch: 1357 [1200/2589 (46%)]\tLoss: 494.127991\n",
      "Train Epoch: 1357 [1500/2589 (58%)]\tLoss: 183.652237\n",
      "Train Epoch: 1357 [1800/2589 (70%)]\tLoss: 233.213043\n",
      "Train Epoch: 1357 [2100/2589 (81%)]\tLoss: 160.900009\n",
      "Train Epoch: 1357 [2400/2589 (93%)]\tLoss: 200.120514\n",
      "====> Epoch: 1357 Average train loss: 209.1449\n",
      "====> Epoch: 1357 Average test loss: 913.2333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1358 [0/2589 (0%)]\tLoss: 221.209427\n",
      "Train Epoch: 1358 [300/2589 (12%)]\tLoss: 249.197723\n",
      "Train Epoch: 1358 [600/2589 (23%)]\tLoss: 134.842148\n",
      "Train Epoch: 1358 [900/2589 (35%)]\tLoss: 247.993454\n",
      "Train Epoch: 1358 [1200/2589 (46%)]\tLoss: 244.672272\n",
      "Train Epoch: 1358 [1500/2589 (58%)]\tLoss: 191.791153\n",
      "Train Epoch: 1358 [1800/2589 (70%)]\tLoss: 160.302582\n",
      "Train Epoch: 1358 [2100/2589 (81%)]\tLoss: 214.776596\n",
      "Train Epoch: 1358 [2400/2589 (93%)]\tLoss: 188.389648\n",
      "====> Epoch: 1358 Average train loss: 214.1861\n",
      "====> Epoch: 1358 Average test loss: 906.9106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1359 [0/2589 (0%)]\tLoss: 182.321701\n",
      "Train Epoch: 1359 [300/2589 (12%)]\tLoss: 210.676010\n",
      "Train Epoch: 1359 [600/2589 (23%)]\tLoss: 162.203156\n",
      "Train Epoch: 1359 [900/2589 (35%)]\tLoss: 171.016510\n",
      "Train Epoch: 1359 [1200/2589 (46%)]\tLoss: 145.622101\n",
      "Train Epoch: 1359 [1500/2589 (58%)]\tLoss: 254.370193\n",
      "Train Epoch: 1359 [1800/2589 (70%)]\tLoss: 230.959335\n",
      "Train Epoch: 1359 [2100/2589 (81%)]\tLoss: 192.331573\n",
      "Train Epoch: 1359 [2400/2589 (93%)]\tLoss: 280.991821\n",
      "====> Epoch: 1359 Average train loss: 205.0768\n",
      "====> Epoch: 1359 Average test loss: 929.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1360 [0/2589 (0%)]\tLoss: 371.442780\n",
      "Train Epoch: 1360 [300/2589 (12%)]\tLoss: 180.357773\n",
      "Train Epoch: 1360 [600/2589 (23%)]\tLoss: 204.345947\n",
      "Train Epoch: 1360 [900/2589 (35%)]\tLoss: 180.163773\n",
      "Train Epoch: 1360 [1200/2589 (46%)]\tLoss: 253.492706\n",
      "Train Epoch: 1360 [1500/2589 (58%)]\tLoss: 215.134277\n",
      "Train Epoch: 1360 [1800/2589 (70%)]\tLoss: 265.409485\n",
      "Train Epoch: 1360 [2100/2589 (81%)]\tLoss: 142.533722\n",
      "Train Epoch: 1360 [2400/2589 (93%)]\tLoss: 305.976440\n",
      "====> Epoch: 1360 Average train loss: 215.3167\n",
      "====> Epoch: 1360 Average test loss: 923.4826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1361 [0/2589 (0%)]\tLoss: 205.241226\n",
      "Train Epoch: 1361 [300/2589 (12%)]\tLoss: 178.315353\n",
      "Train Epoch: 1361 [600/2589 (23%)]\tLoss: 199.536453\n",
      "Train Epoch: 1361 [900/2589 (35%)]\tLoss: 181.473877\n",
      "Train Epoch: 1361 [1200/2589 (46%)]\tLoss: 266.771851\n",
      "Train Epoch: 1361 [1500/2589 (58%)]\tLoss: 257.722290\n",
      "Train Epoch: 1361 [1800/2589 (70%)]\tLoss: 136.805450\n",
      "Train Epoch: 1361 [2100/2589 (81%)]\tLoss: 177.251495\n",
      "Train Epoch: 1361 [2400/2589 (93%)]\tLoss: 148.877640\n",
      "====> Epoch: 1361 Average train loss: 213.7432\n",
      "====> Epoch: 1361 Average test loss: 907.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1362 [0/2589 (0%)]\tLoss: 248.374512\n",
      "Train Epoch: 1362 [300/2589 (12%)]\tLoss: 211.780060\n",
      "Train Epoch: 1362 [600/2589 (23%)]\tLoss: 252.382492\n",
      "Train Epoch: 1362 [900/2589 (35%)]\tLoss: 284.795959\n",
      "Train Epoch: 1362 [1200/2589 (46%)]\tLoss: 289.309113\n",
      "Train Epoch: 1362 [1500/2589 (58%)]\tLoss: 358.092590\n",
      "Train Epoch: 1362 [1800/2589 (70%)]\tLoss: 190.974579\n",
      "Train Epoch: 1362 [2100/2589 (81%)]\tLoss: 351.516174\n",
      "Train Epoch: 1362 [2400/2589 (93%)]\tLoss: 217.666351\n",
      "====> Epoch: 1362 Average train loss: 215.4155\n",
      "====> Epoch: 1362 Average test loss: 898.5664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1363 [0/2589 (0%)]\tLoss: 200.409271\n",
      "Train Epoch: 1363 [300/2589 (12%)]\tLoss: 148.255432\n",
      "Train Epoch: 1363 [600/2589 (23%)]\tLoss: 189.206497\n",
      "Train Epoch: 1363 [900/2589 (35%)]\tLoss: 203.769760\n",
      "Train Epoch: 1363 [1200/2589 (46%)]\tLoss: 128.105606\n",
      "Train Epoch: 1363 [1500/2589 (58%)]\tLoss: 185.683212\n",
      "Train Epoch: 1363 [1800/2589 (70%)]\tLoss: 167.445068\n",
      "Train Epoch: 1363 [2100/2589 (81%)]\tLoss: 221.882523\n",
      "Train Epoch: 1363 [2400/2589 (93%)]\tLoss: 227.841354\n",
      "====> Epoch: 1363 Average train loss: 206.0410\n",
      "====> Epoch: 1363 Average test loss: 915.2264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1364 [0/2589 (0%)]\tLoss: 175.705780\n",
      "Train Epoch: 1364 [300/2589 (12%)]\tLoss: 231.371445\n",
      "Train Epoch: 1364 [600/2589 (23%)]\tLoss: 171.701736\n",
      "Train Epoch: 1364 [900/2589 (35%)]\tLoss: 352.766968\n",
      "Train Epoch: 1364 [1200/2589 (46%)]\tLoss: 345.837311\n",
      "Train Epoch: 1364 [1500/2589 (58%)]\tLoss: 208.946106\n",
      "Train Epoch: 1364 [1800/2589 (70%)]\tLoss: 189.743729\n",
      "Train Epoch: 1364 [2100/2589 (81%)]\tLoss: 247.178085\n",
      "Train Epoch: 1364 [2400/2589 (93%)]\tLoss: 327.284698\n",
      "====> Epoch: 1364 Average train loss: 214.1460\n",
      "====> Epoch: 1364 Average test loss: 919.0020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1365 [0/2589 (0%)]\tLoss: 274.673828\n",
      "Train Epoch: 1365 [300/2589 (12%)]\tLoss: 193.506180\n",
      "Train Epoch: 1365 [600/2589 (23%)]\tLoss: 335.392548\n",
      "Train Epoch: 1365 [900/2589 (35%)]\tLoss: 136.820770\n",
      "Train Epoch: 1365 [1200/2589 (46%)]\tLoss: 228.389664\n",
      "Train Epoch: 1365 [1500/2589 (58%)]\tLoss: 250.719666\n",
      "Train Epoch: 1365 [1800/2589 (70%)]\tLoss: 145.450027\n",
      "Train Epoch: 1365 [2100/2589 (81%)]\tLoss: 205.581863\n",
      "Train Epoch: 1365 [2400/2589 (93%)]\tLoss: 143.462418\n",
      "====> Epoch: 1365 Average train loss: 215.2634\n",
      "====> Epoch: 1365 Average test loss: 903.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1366 [0/2589 (0%)]\tLoss: 183.934921\n",
      "Train Epoch: 1366 [300/2589 (12%)]\tLoss: 148.849411\n",
      "Train Epoch: 1366 [600/2589 (23%)]\tLoss: 284.205719\n",
      "Train Epoch: 1366 [900/2589 (35%)]\tLoss: 120.548080\n",
      "Train Epoch: 1366 [1200/2589 (46%)]\tLoss: 241.792130\n",
      "Train Epoch: 1366 [1500/2589 (58%)]\tLoss: 199.735367\n",
      "Train Epoch: 1366 [1800/2589 (70%)]\tLoss: 244.647400\n",
      "Train Epoch: 1366 [2100/2589 (81%)]\tLoss: 285.564575\n",
      "Train Epoch: 1366 [2400/2589 (93%)]\tLoss: 199.351639\n",
      "====> Epoch: 1366 Average train loss: 217.2162\n",
      "====> Epoch: 1366 Average test loss: 916.5538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1367 [0/2589 (0%)]\tLoss: 249.561020\n",
      "Train Epoch: 1367 [300/2589 (12%)]\tLoss: 227.275223\n",
      "Train Epoch: 1367 [600/2589 (23%)]\tLoss: 228.248856\n",
      "Train Epoch: 1367 [900/2589 (35%)]\tLoss: 207.098648\n",
      "Train Epoch: 1367 [1200/2589 (46%)]\tLoss: 247.791275\n",
      "Train Epoch: 1367 [1500/2589 (58%)]\tLoss: 165.755341\n",
      "Train Epoch: 1367 [1800/2589 (70%)]\tLoss: 183.600754\n",
      "Train Epoch: 1367 [2100/2589 (81%)]\tLoss: 154.383652\n",
      "Train Epoch: 1367 [2400/2589 (93%)]\tLoss: 225.936020\n",
      "====> Epoch: 1367 Average train loss: 222.7299\n",
      "====> Epoch: 1367 Average test loss: 930.2834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1368 [0/2589 (0%)]\tLoss: 173.302582\n",
      "Train Epoch: 1368 [300/2589 (12%)]\tLoss: 207.617523\n",
      "Train Epoch: 1368 [600/2589 (23%)]\tLoss: 170.269196\n",
      "Train Epoch: 1368 [900/2589 (35%)]\tLoss: 124.516594\n",
      "Train Epoch: 1368 [1200/2589 (46%)]\tLoss: 233.716385\n",
      "Train Epoch: 1368 [1500/2589 (58%)]\tLoss: 342.468811\n",
      "Train Epoch: 1368 [1800/2589 (70%)]\tLoss: 193.054398\n",
      "Train Epoch: 1368 [2100/2589 (81%)]\tLoss: 204.843521\n",
      "Train Epoch: 1368 [2400/2589 (93%)]\tLoss: 183.142380\n",
      "====> Epoch: 1368 Average train loss: 207.9151\n",
      "====> Epoch: 1368 Average test loss: 920.8546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1369 [0/2589 (0%)]\tLoss: 248.693863\n",
      "Train Epoch: 1369 [300/2589 (12%)]\tLoss: 188.498459\n",
      "Train Epoch: 1369 [600/2589 (23%)]\tLoss: 405.644592\n",
      "Train Epoch: 1369 [900/2589 (35%)]\tLoss: 177.166214\n",
      "Train Epoch: 1369 [1200/2589 (46%)]\tLoss: 264.856720\n",
      "Train Epoch: 1369 [1500/2589 (58%)]\tLoss: 232.766510\n",
      "Train Epoch: 1369 [1800/2589 (70%)]\tLoss: 151.332581\n",
      "Train Epoch: 1369 [2100/2589 (81%)]\tLoss: 208.216827\n",
      "Train Epoch: 1369 [2400/2589 (93%)]\tLoss: 179.785477\n",
      "====> Epoch: 1369 Average train loss: 223.9672\n",
      "====> Epoch: 1369 Average test loss: 931.0255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1370 [0/2589 (0%)]\tLoss: 263.804749\n",
      "Train Epoch: 1370 [300/2589 (12%)]\tLoss: 373.634583\n",
      "Train Epoch: 1370 [600/2589 (23%)]\tLoss: 240.162537\n",
      "Train Epoch: 1370 [900/2589 (35%)]\tLoss: 309.854980\n",
      "Train Epoch: 1370 [1200/2589 (46%)]\tLoss: 223.087112\n",
      "Train Epoch: 1370 [1500/2589 (58%)]\tLoss: 200.599197\n",
      "Train Epoch: 1370 [1800/2589 (70%)]\tLoss: 135.717941\n",
      "Train Epoch: 1370 [2100/2589 (81%)]\tLoss: 191.870087\n",
      "Train Epoch: 1370 [2400/2589 (93%)]\tLoss: 172.716263\n",
      "====> Epoch: 1370 Average train loss: 224.5812\n",
      "====> Epoch: 1370 Average test loss: 923.7693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1371 [0/2589 (0%)]\tLoss: 218.458664\n",
      "Train Epoch: 1371 [300/2589 (12%)]\tLoss: 168.260849\n",
      "Train Epoch: 1371 [600/2589 (23%)]\tLoss: 216.782501\n",
      "Train Epoch: 1371 [900/2589 (35%)]\tLoss: 265.063416\n",
      "Train Epoch: 1371 [1200/2589 (46%)]\tLoss: 190.201569\n",
      "Train Epoch: 1371 [1500/2589 (58%)]\tLoss: 162.281067\n",
      "Train Epoch: 1371 [1800/2589 (70%)]\tLoss: 157.548889\n",
      "Train Epoch: 1371 [2100/2589 (81%)]\tLoss: 182.266632\n",
      "Train Epoch: 1371 [2400/2589 (93%)]\tLoss: 299.335846\n",
      "====> Epoch: 1371 Average train loss: 211.0393\n",
      "====> Epoch: 1371 Average test loss: 907.8286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1372 [0/2589 (0%)]\tLoss: 211.722702\n",
      "Train Epoch: 1372 [300/2589 (12%)]\tLoss: 244.330475\n",
      "Train Epoch: 1372 [600/2589 (23%)]\tLoss: 273.428192\n",
      "Train Epoch: 1372 [900/2589 (35%)]\tLoss: 305.348846\n",
      "Train Epoch: 1372 [1200/2589 (46%)]\tLoss: 160.861023\n",
      "Train Epoch: 1372 [1500/2589 (58%)]\tLoss: 284.239624\n",
      "Train Epoch: 1372 [1800/2589 (70%)]\tLoss: 250.969269\n",
      "Train Epoch: 1372 [2100/2589 (81%)]\tLoss: 213.841324\n",
      "Train Epoch: 1372 [2400/2589 (93%)]\tLoss: 343.633820\n",
      "====> Epoch: 1372 Average train loss: 212.6378\n",
      "====> Epoch: 1372 Average test loss: 901.4932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1373 [0/2589 (0%)]\tLoss: 171.892899\n",
      "Train Epoch: 1373 [300/2589 (12%)]\tLoss: 196.031448\n",
      "Train Epoch: 1373 [600/2589 (23%)]\tLoss: 186.393143\n",
      "Train Epoch: 1373 [900/2589 (35%)]\tLoss: 412.002472\n",
      "Train Epoch: 1373 [1200/2589 (46%)]\tLoss: 191.149109\n",
      "Train Epoch: 1373 [1500/2589 (58%)]\tLoss: 160.623398\n",
      "Train Epoch: 1373 [1800/2589 (70%)]\tLoss: 184.957321\n",
      "Train Epoch: 1373 [2100/2589 (81%)]\tLoss: 335.174683\n",
      "Train Epoch: 1373 [2400/2589 (93%)]\tLoss: 264.686523\n",
      "====> Epoch: 1373 Average train loss: 219.6734\n",
      "====> Epoch: 1373 Average test loss: 927.0579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1374 [0/2589 (0%)]\tLoss: 186.050766\n",
      "Train Epoch: 1374 [300/2589 (12%)]\tLoss: 147.155304\n",
      "Train Epoch: 1374 [600/2589 (23%)]\tLoss: 160.430939\n",
      "Train Epoch: 1374 [900/2589 (35%)]\tLoss: 160.097000\n",
      "Train Epoch: 1374 [1200/2589 (46%)]\tLoss: 248.822433\n",
      "Train Epoch: 1374 [1500/2589 (58%)]\tLoss: 248.631134\n",
      "Train Epoch: 1374 [1800/2589 (70%)]\tLoss: 283.762817\n",
      "Train Epoch: 1374 [2100/2589 (81%)]\tLoss: 226.608734\n",
      "Train Epoch: 1374 [2400/2589 (93%)]\tLoss: 175.073105\n",
      "====> Epoch: 1374 Average train loss: 198.2127\n",
      "====> Epoch: 1374 Average test loss: 913.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1375 [0/2589 (0%)]\tLoss: 256.971466\n",
      "Train Epoch: 1375 [300/2589 (12%)]\tLoss: 195.217819\n",
      "Train Epoch: 1375 [600/2589 (23%)]\tLoss: 202.749191\n",
      "Train Epoch: 1375 [900/2589 (35%)]\tLoss: 240.413361\n",
      "Train Epoch: 1375 [1200/2589 (46%)]\tLoss: 178.329819\n",
      "Train Epoch: 1375 [1500/2589 (58%)]\tLoss: 184.990555\n",
      "Train Epoch: 1375 [1800/2589 (70%)]\tLoss: 143.117462\n",
      "Train Epoch: 1375 [2100/2589 (81%)]\tLoss: 187.136398\n",
      "Train Epoch: 1375 [2400/2589 (93%)]\tLoss: 255.021149\n",
      "====> Epoch: 1375 Average train loss: 215.1362\n",
      "====> Epoch: 1375 Average test loss: 912.5325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1376 [0/2589 (0%)]\tLoss: 188.815582\n",
      "Train Epoch: 1376 [300/2589 (12%)]\tLoss: 164.028076\n",
      "Train Epoch: 1376 [600/2589 (23%)]\tLoss: 178.810028\n",
      "Train Epoch: 1376 [900/2589 (35%)]\tLoss: 243.601868\n",
      "Train Epoch: 1376 [1200/2589 (46%)]\tLoss: 173.396408\n",
      "Train Epoch: 1376 [1500/2589 (58%)]\tLoss: 204.683563\n",
      "Train Epoch: 1376 [1800/2589 (70%)]\tLoss: 212.620209\n",
      "Train Epoch: 1376 [2100/2589 (81%)]\tLoss: 292.355530\n",
      "Train Epoch: 1376 [2400/2589 (93%)]\tLoss: 310.543884\n",
      "====> Epoch: 1376 Average train loss: 237.0298\n",
      "====> Epoch: 1376 Average test loss: 919.3135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1377 [0/2589 (0%)]\tLoss: 194.971283\n",
      "Train Epoch: 1377 [300/2589 (12%)]\tLoss: 393.849335\n",
      "Train Epoch: 1377 [600/2589 (23%)]\tLoss: 172.804459\n",
      "Train Epoch: 1377 [900/2589 (35%)]\tLoss: 190.839676\n",
      "Train Epoch: 1377 [1200/2589 (46%)]\tLoss: 288.586426\n",
      "Train Epoch: 1377 [1500/2589 (58%)]\tLoss: 247.504425\n",
      "Train Epoch: 1377 [1800/2589 (70%)]\tLoss: 161.582214\n",
      "Train Epoch: 1377 [2100/2589 (81%)]\tLoss: 343.072205\n",
      "Train Epoch: 1377 [2400/2589 (93%)]\tLoss: 290.788452\n",
      "====> Epoch: 1377 Average train loss: 224.6638\n",
      "====> Epoch: 1377 Average test loss: 899.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1378 [0/2589 (0%)]\tLoss: 202.891556\n",
      "Train Epoch: 1378 [300/2589 (12%)]\tLoss: 192.770538\n",
      "Train Epoch: 1378 [600/2589 (23%)]\tLoss: 156.630356\n",
      "Train Epoch: 1378 [900/2589 (35%)]\tLoss: 184.791031\n",
      "Train Epoch: 1378 [1200/2589 (46%)]\tLoss: 218.409180\n",
      "Train Epoch: 1378 [1500/2589 (58%)]\tLoss: 125.947105\n",
      "Train Epoch: 1378 [1800/2589 (70%)]\tLoss: 181.994202\n",
      "Train Epoch: 1378 [2100/2589 (81%)]\tLoss: 282.011383\n",
      "Train Epoch: 1378 [2400/2589 (93%)]\tLoss: 231.009369\n",
      "====> Epoch: 1378 Average train loss: 217.7197\n",
      "====> Epoch: 1378 Average test loss: 904.5421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1379 [0/2589 (0%)]\tLoss: 177.012650\n",
      "Train Epoch: 1379 [300/2589 (12%)]\tLoss: 128.790344\n",
      "Train Epoch: 1379 [600/2589 (23%)]\tLoss: 214.140579\n",
      "Train Epoch: 1379 [900/2589 (35%)]\tLoss: 189.440231\n",
      "Train Epoch: 1379 [1200/2589 (46%)]\tLoss: 134.174210\n",
      "Train Epoch: 1379 [1500/2589 (58%)]\tLoss: 209.623764\n",
      "Train Epoch: 1379 [1800/2589 (70%)]\tLoss: 224.838974\n",
      "Train Epoch: 1379 [2100/2589 (81%)]\tLoss: 263.745667\n",
      "Train Epoch: 1379 [2400/2589 (93%)]\tLoss: 219.503754\n",
      "====> Epoch: 1379 Average train loss: 200.9643\n",
      "====> Epoch: 1379 Average test loss: 913.4443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1380 [0/2589 (0%)]\tLoss: 264.752045\n",
      "Train Epoch: 1380 [300/2589 (12%)]\tLoss: 194.378769\n",
      "Train Epoch: 1380 [600/2589 (23%)]\tLoss: 233.441818\n",
      "Train Epoch: 1380 [900/2589 (35%)]\tLoss: 439.722015\n",
      "Train Epoch: 1380 [1200/2589 (46%)]\tLoss: 222.139557\n",
      "Train Epoch: 1380 [1500/2589 (58%)]\tLoss: 196.810944\n",
      "Train Epoch: 1380 [1800/2589 (70%)]\tLoss: 146.403503\n",
      "Train Epoch: 1380 [2100/2589 (81%)]\tLoss: 254.618561\n",
      "Train Epoch: 1380 [2400/2589 (93%)]\tLoss: 222.862152\n",
      "====> Epoch: 1380 Average train loss: 209.9914\n",
      "====> Epoch: 1380 Average test loss: 907.3576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1381 [0/2589 (0%)]\tLoss: 235.089752\n",
      "Train Epoch: 1381 [300/2589 (12%)]\tLoss: 162.497833\n",
      "Train Epoch: 1381 [600/2589 (23%)]\tLoss: 224.040176\n",
      "Train Epoch: 1381 [900/2589 (35%)]\tLoss: 265.180786\n",
      "Train Epoch: 1381 [1200/2589 (46%)]\tLoss: 214.464447\n",
      "Train Epoch: 1381 [1500/2589 (58%)]\tLoss: 196.234207\n",
      "Train Epoch: 1381 [1800/2589 (70%)]\tLoss: 156.626328\n",
      "Train Epoch: 1381 [2100/2589 (81%)]\tLoss: 173.888275\n",
      "Train Epoch: 1381 [2400/2589 (93%)]\tLoss: 178.593369\n",
      "====> Epoch: 1381 Average train loss: 209.2952\n",
      "====> Epoch: 1381 Average test loss: 909.0562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1382 [0/2589 (0%)]\tLoss: 147.916473\n",
      "Train Epoch: 1382 [300/2589 (12%)]\tLoss: 240.208466\n",
      "Train Epoch: 1382 [600/2589 (23%)]\tLoss: 190.539536\n",
      "Train Epoch: 1382 [900/2589 (35%)]\tLoss: 109.284309\n",
      "Train Epoch: 1382 [1200/2589 (46%)]\tLoss: 283.518433\n",
      "Train Epoch: 1382 [1500/2589 (58%)]\tLoss: 154.517334\n",
      "Train Epoch: 1382 [1800/2589 (70%)]\tLoss: 141.926346\n",
      "Train Epoch: 1382 [2100/2589 (81%)]\tLoss: 183.881699\n",
      "Train Epoch: 1382 [2400/2589 (93%)]\tLoss: 517.082458\n",
      "====> Epoch: 1382 Average train loss: 205.7175\n",
      "====> Epoch: 1382 Average test loss: 910.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1383 [0/2589 (0%)]\tLoss: 262.481110\n",
      "Train Epoch: 1383 [300/2589 (12%)]\tLoss: 185.275177\n",
      "Train Epoch: 1383 [600/2589 (23%)]\tLoss: 147.205566\n",
      "Train Epoch: 1383 [900/2589 (35%)]\tLoss: 218.218781\n",
      "Train Epoch: 1383 [1200/2589 (46%)]\tLoss: 179.230515\n",
      "Train Epoch: 1383 [1500/2589 (58%)]\tLoss: 155.948990\n",
      "Train Epoch: 1383 [1800/2589 (70%)]\tLoss: 137.345673\n",
      "Train Epoch: 1383 [2100/2589 (81%)]\tLoss: 207.987732\n",
      "Train Epoch: 1383 [2400/2589 (93%)]\tLoss: 277.887817\n",
      "====> Epoch: 1383 Average train loss: 217.9320\n",
      "====> Epoch: 1383 Average test loss: 912.5736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1384 [0/2589 (0%)]\tLoss: 164.161163\n",
      "Train Epoch: 1384 [300/2589 (12%)]\tLoss: 157.293304\n",
      "Train Epoch: 1384 [600/2589 (23%)]\tLoss: 247.700531\n",
      "Train Epoch: 1384 [900/2589 (35%)]\tLoss: 210.979584\n",
      "Train Epoch: 1384 [1200/2589 (46%)]\tLoss: 215.342789\n",
      "Train Epoch: 1384 [1500/2589 (58%)]\tLoss: 145.729263\n",
      "Train Epoch: 1384 [1800/2589 (70%)]\tLoss: 180.414551\n",
      "Train Epoch: 1384 [2100/2589 (81%)]\tLoss: 271.474335\n",
      "Train Epoch: 1384 [2400/2589 (93%)]\tLoss: 238.800720\n",
      "====> Epoch: 1384 Average train loss: 213.3012\n",
      "====> Epoch: 1384 Average test loss: 924.7802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1385 [0/2589 (0%)]\tLoss: 251.576752\n",
      "Train Epoch: 1385 [300/2589 (12%)]\tLoss: 162.294785\n",
      "Train Epoch: 1385 [600/2589 (23%)]\tLoss: 132.766418\n",
      "Train Epoch: 1385 [900/2589 (35%)]\tLoss: 348.252228\n",
      "Train Epoch: 1385 [1200/2589 (46%)]\tLoss: 198.919724\n",
      "Train Epoch: 1385 [1500/2589 (58%)]\tLoss: 151.774002\n",
      "Train Epoch: 1385 [1800/2589 (70%)]\tLoss: 371.094360\n",
      "Train Epoch: 1385 [2100/2589 (81%)]\tLoss: 202.541595\n",
      "Train Epoch: 1385 [2400/2589 (93%)]\tLoss: 289.638702\n",
      "====> Epoch: 1385 Average train loss: 219.3931\n",
      "====> Epoch: 1385 Average test loss: 895.7175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1386 [0/2589 (0%)]\tLoss: 182.126694\n",
      "Train Epoch: 1386 [300/2589 (12%)]\tLoss: 145.172989\n",
      "Train Epoch: 1386 [600/2589 (23%)]\tLoss: 145.000198\n",
      "Train Epoch: 1386 [900/2589 (35%)]\tLoss: 204.822693\n",
      "Train Epoch: 1386 [1200/2589 (46%)]\tLoss: 225.811142\n",
      "Train Epoch: 1386 [1500/2589 (58%)]\tLoss: 307.260895\n",
      "Train Epoch: 1386 [1800/2589 (70%)]\tLoss: 255.597610\n",
      "Train Epoch: 1386 [2100/2589 (81%)]\tLoss: 208.938187\n",
      "Train Epoch: 1386 [2400/2589 (93%)]\tLoss: 167.392990\n",
      "====> Epoch: 1386 Average train loss: 207.2393\n",
      "====> Epoch: 1386 Average test loss: 910.7138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1387 [0/2589 (0%)]\tLoss: 193.746231\n",
      "Train Epoch: 1387 [300/2589 (12%)]\tLoss: 243.555176\n",
      "Train Epoch: 1387 [600/2589 (23%)]\tLoss: 194.382248\n",
      "Train Epoch: 1387 [900/2589 (35%)]\tLoss: 138.047226\n",
      "Train Epoch: 1387 [1200/2589 (46%)]\tLoss: 195.493301\n",
      "Train Epoch: 1387 [1500/2589 (58%)]\tLoss: 222.566147\n",
      "Train Epoch: 1387 [1800/2589 (70%)]\tLoss: 302.524719\n",
      "Train Epoch: 1387 [2100/2589 (81%)]\tLoss: 239.326218\n",
      "Train Epoch: 1387 [2400/2589 (93%)]\tLoss: 139.340881\n",
      "====> Epoch: 1387 Average train loss: 219.2257\n",
      "====> Epoch: 1387 Average test loss: 904.8890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1388 [0/2589 (0%)]\tLoss: 161.433197\n",
      "Train Epoch: 1388 [300/2589 (12%)]\tLoss: 158.470123\n",
      "Train Epoch: 1388 [600/2589 (23%)]\tLoss: 448.424133\n",
      "Train Epoch: 1388 [900/2589 (35%)]\tLoss: 212.364670\n",
      "Train Epoch: 1388 [1200/2589 (46%)]\tLoss: 158.755951\n",
      "Train Epoch: 1388 [1500/2589 (58%)]\tLoss: 199.567047\n",
      "Train Epoch: 1388 [1800/2589 (70%)]\tLoss: 193.827866\n",
      "Train Epoch: 1388 [2100/2589 (81%)]\tLoss: 282.186432\n",
      "Train Epoch: 1388 [2400/2589 (93%)]\tLoss: 145.906158\n",
      "====> Epoch: 1388 Average train loss: 209.0054\n",
      "====> Epoch: 1388 Average test loss: 913.8724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1389 [0/2589 (0%)]\tLoss: 191.174026\n",
      "Train Epoch: 1389 [300/2589 (12%)]\tLoss: 200.525345\n",
      "Train Epoch: 1389 [600/2589 (23%)]\tLoss: 138.946518\n",
      "Train Epoch: 1389 [900/2589 (35%)]\tLoss: 249.184479\n",
      "Train Epoch: 1389 [1200/2589 (46%)]\tLoss: 221.004288\n",
      "Train Epoch: 1389 [1500/2589 (58%)]\tLoss: 211.479813\n",
      "Train Epoch: 1389 [1800/2589 (70%)]\tLoss: 191.293198\n",
      "Train Epoch: 1389 [2100/2589 (81%)]\tLoss: 202.817398\n",
      "Train Epoch: 1389 [2400/2589 (93%)]\tLoss: 254.370255\n",
      "====> Epoch: 1389 Average train loss: 208.9784\n",
      "====> Epoch: 1389 Average test loss: 910.3113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1390 [0/2589 (0%)]\tLoss: 254.530533\n",
      "Train Epoch: 1390 [300/2589 (12%)]\tLoss: 199.777740\n",
      "Train Epoch: 1390 [600/2589 (23%)]\tLoss: 259.071228\n",
      "Train Epoch: 1390 [900/2589 (35%)]\tLoss: 161.985931\n",
      "Train Epoch: 1390 [1200/2589 (46%)]\tLoss: 218.806503\n",
      "Train Epoch: 1390 [1500/2589 (58%)]\tLoss: 168.256348\n",
      "Train Epoch: 1390 [1800/2589 (70%)]\tLoss: 213.156342\n",
      "Train Epoch: 1390 [2100/2589 (81%)]\tLoss: 264.417053\n",
      "Train Epoch: 1390 [2400/2589 (93%)]\tLoss: 155.915222\n",
      "====> Epoch: 1390 Average train loss: 218.0219\n",
      "====> Epoch: 1390 Average test loss: 921.8783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1391 [0/2589 (0%)]\tLoss: 166.628204\n",
      "Train Epoch: 1391 [300/2589 (12%)]\tLoss: 264.925385\n",
      "Train Epoch: 1391 [600/2589 (23%)]\tLoss: 176.970993\n",
      "Train Epoch: 1391 [900/2589 (35%)]\tLoss: 172.915665\n",
      "Train Epoch: 1391 [1200/2589 (46%)]\tLoss: 185.755859\n",
      "Train Epoch: 1391 [1500/2589 (58%)]\tLoss: 191.532196\n",
      "Train Epoch: 1391 [1800/2589 (70%)]\tLoss: 172.186600\n",
      "Train Epoch: 1391 [2100/2589 (81%)]\tLoss: 203.332779\n",
      "Train Epoch: 1391 [2400/2589 (93%)]\tLoss: 196.542709\n",
      "====> Epoch: 1391 Average train loss: 218.4514\n",
      "====> Epoch: 1391 Average test loss: 906.0060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1392 [0/2589 (0%)]\tLoss: 171.856995\n",
      "Train Epoch: 1392 [300/2589 (12%)]\tLoss: 269.199127\n",
      "Train Epoch: 1392 [600/2589 (23%)]\tLoss: 191.832047\n",
      "Train Epoch: 1392 [900/2589 (35%)]\tLoss: 234.663742\n",
      "Train Epoch: 1392 [1200/2589 (46%)]\tLoss: 139.724197\n",
      "Train Epoch: 1392 [1500/2589 (58%)]\tLoss: 212.892776\n",
      "Train Epoch: 1392 [1800/2589 (70%)]\tLoss: 296.171448\n",
      "Train Epoch: 1392 [2100/2589 (81%)]\tLoss: 216.847244\n",
      "Train Epoch: 1392 [2400/2589 (93%)]\tLoss: 165.161926\n",
      "====> Epoch: 1392 Average train loss: 208.2368\n",
      "====> Epoch: 1392 Average test loss: 918.4696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1393 [0/2589 (0%)]\tLoss: 375.444397\n",
      "Train Epoch: 1393 [300/2589 (12%)]\tLoss: 327.569061\n",
      "Train Epoch: 1393 [600/2589 (23%)]\tLoss: 266.320648\n",
      "Train Epoch: 1393 [900/2589 (35%)]\tLoss: 276.221313\n",
      "Train Epoch: 1393 [1200/2589 (46%)]\tLoss: 205.258545\n",
      "Train Epoch: 1393 [1500/2589 (58%)]\tLoss: 131.723221\n",
      "Train Epoch: 1393 [1800/2589 (70%)]\tLoss: 289.618866\n",
      "Train Epoch: 1393 [2100/2589 (81%)]\tLoss: 186.711227\n",
      "Train Epoch: 1393 [2400/2589 (93%)]\tLoss: 203.676849\n",
      "====> Epoch: 1393 Average train loss: 230.4057\n",
      "====> Epoch: 1393 Average test loss: 906.5436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1394 [0/2589 (0%)]\tLoss: 240.617004\n",
      "Train Epoch: 1394 [300/2589 (12%)]\tLoss: 188.012787\n",
      "Train Epoch: 1394 [600/2589 (23%)]\tLoss: 136.098679\n",
      "Train Epoch: 1394 [900/2589 (35%)]\tLoss: 220.837982\n",
      "Train Epoch: 1394 [1200/2589 (46%)]\tLoss: 351.747284\n",
      "Train Epoch: 1394 [1500/2589 (58%)]\tLoss: 309.517365\n",
      "Train Epoch: 1394 [1800/2589 (70%)]\tLoss: 171.885712\n",
      "Train Epoch: 1394 [2100/2589 (81%)]\tLoss: 196.173630\n",
      "Train Epoch: 1394 [2400/2589 (93%)]\tLoss: 263.313080\n",
      "====> Epoch: 1394 Average train loss: 220.4672\n",
      "====> Epoch: 1394 Average test loss: 905.1273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1395 [0/2589 (0%)]\tLoss: 230.824615\n",
      "Train Epoch: 1395 [300/2589 (12%)]\tLoss: 171.057617\n",
      "Train Epoch: 1395 [600/2589 (23%)]\tLoss: 203.593094\n",
      "Train Epoch: 1395 [900/2589 (35%)]\tLoss: 293.629028\n",
      "Train Epoch: 1395 [1200/2589 (46%)]\tLoss: 145.151718\n",
      "Train Epoch: 1395 [1500/2589 (58%)]\tLoss: 252.764786\n",
      "Train Epoch: 1395 [1800/2589 (70%)]\tLoss: 340.565369\n",
      "Train Epoch: 1395 [2100/2589 (81%)]\tLoss: 188.434296\n",
      "Train Epoch: 1395 [2400/2589 (93%)]\tLoss: 451.965881\n",
      "====> Epoch: 1395 Average train loss: 208.5091\n",
      "====> Epoch: 1395 Average test loss: 901.0622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1396 [0/2589 (0%)]\tLoss: 185.758652\n",
      "Train Epoch: 1396 [300/2589 (12%)]\tLoss: 213.058456\n",
      "Train Epoch: 1396 [600/2589 (23%)]\tLoss: 146.831894\n",
      "Train Epoch: 1396 [900/2589 (35%)]\tLoss: 214.943939\n",
      "Train Epoch: 1396 [1200/2589 (46%)]\tLoss: 202.603500\n",
      "Train Epoch: 1396 [1500/2589 (58%)]\tLoss: 261.525696\n",
      "Train Epoch: 1396 [1800/2589 (70%)]\tLoss: 161.769699\n",
      "Train Epoch: 1396 [2100/2589 (81%)]\tLoss: 158.770004\n",
      "Train Epoch: 1396 [2400/2589 (93%)]\tLoss: 193.823196\n",
      "====> Epoch: 1396 Average train loss: 210.3920\n",
      "====> Epoch: 1396 Average test loss: 908.1920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1397 [0/2589 (0%)]\tLoss: 213.456009\n",
      "Train Epoch: 1397 [300/2589 (12%)]\tLoss: 210.016312\n",
      "Train Epoch: 1397 [600/2589 (23%)]\tLoss: 177.178085\n",
      "Train Epoch: 1397 [900/2589 (35%)]\tLoss: 150.569260\n",
      "Train Epoch: 1397 [1200/2589 (46%)]\tLoss: 153.298859\n",
      "Train Epoch: 1397 [1500/2589 (58%)]\tLoss: 195.083389\n",
      "Train Epoch: 1397 [1800/2589 (70%)]\tLoss: 171.764938\n",
      "Train Epoch: 1397 [2100/2589 (81%)]\tLoss: 148.092941\n",
      "Train Epoch: 1397 [2400/2589 (93%)]\tLoss: 230.128510\n",
      "====> Epoch: 1397 Average train loss: 209.8516\n",
      "====> Epoch: 1397 Average test loss: 916.4760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1398 [0/2589 (0%)]\tLoss: 181.619736\n",
      "Train Epoch: 1398 [300/2589 (12%)]\tLoss: 193.246780\n",
      "Train Epoch: 1398 [600/2589 (23%)]\tLoss: 262.957184\n",
      "Train Epoch: 1398 [900/2589 (35%)]\tLoss: 223.634872\n",
      "Train Epoch: 1398 [1200/2589 (46%)]\tLoss: 228.910416\n",
      "Train Epoch: 1398 [1500/2589 (58%)]\tLoss: 171.173111\n",
      "Train Epoch: 1398 [1800/2589 (70%)]\tLoss: 265.978210\n",
      "Train Epoch: 1398 [2100/2589 (81%)]\tLoss: 211.468430\n",
      "Train Epoch: 1398 [2400/2589 (93%)]\tLoss: 191.128311\n",
      "====> Epoch: 1398 Average train loss: 212.7584\n",
      "====> Epoch: 1398 Average test loss: 901.5223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1399 [0/2589 (0%)]\tLoss: 163.425720\n",
      "Train Epoch: 1399 [300/2589 (12%)]\tLoss: 159.636169\n",
      "Train Epoch: 1399 [600/2589 (23%)]\tLoss: 148.267487\n",
      "Train Epoch: 1399 [900/2589 (35%)]\tLoss: 323.963715\n",
      "Train Epoch: 1399 [1200/2589 (46%)]\tLoss: 352.009796\n",
      "Train Epoch: 1399 [1500/2589 (58%)]\tLoss: 273.373535\n",
      "Train Epoch: 1399 [1800/2589 (70%)]\tLoss: 180.107925\n",
      "Train Epoch: 1399 [2100/2589 (81%)]\tLoss: 148.449814\n",
      "Train Epoch: 1399 [2400/2589 (93%)]\tLoss: 208.456802\n",
      "====> Epoch: 1399 Average train loss: 218.6628\n",
      "====> Epoch: 1399 Average test loss: 917.5444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1400 [0/2589 (0%)]\tLoss: 135.360321\n",
      "Train Epoch: 1400 [300/2589 (12%)]\tLoss: 206.029251\n",
      "Train Epoch: 1400 [600/2589 (23%)]\tLoss: 373.406677\n",
      "Train Epoch: 1400 [900/2589 (35%)]\tLoss: 256.175781\n",
      "Train Epoch: 1400 [1200/2589 (46%)]\tLoss: 209.636688\n",
      "Train Epoch: 1400 [1500/2589 (58%)]\tLoss: 146.239990\n",
      "Train Epoch: 1400 [1800/2589 (70%)]\tLoss: 203.470032\n",
      "Train Epoch: 1400 [2100/2589 (81%)]\tLoss: 181.350159\n",
      "Train Epoch: 1400 [2400/2589 (93%)]\tLoss: 274.792633\n",
      "====> Epoch: 1400 Average train loss: 216.7192\n",
      "====> Epoch: 1400 Average test loss: 916.7739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1401 [0/2589 (0%)]\tLoss: 200.958069\n",
      "Train Epoch: 1401 [300/2589 (12%)]\tLoss: 177.893768\n",
      "Train Epoch: 1401 [600/2589 (23%)]\tLoss: 177.338638\n",
      "Train Epoch: 1401 [900/2589 (35%)]\tLoss: 282.154816\n",
      "Train Epoch: 1401 [1200/2589 (46%)]\tLoss: 218.308807\n",
      "Train Epoch: 1401 [1500/2589 (58%)]\tLoss: 262.582703\n",
      "Train Epoch: 1401 [1800/2589 (70%)]\tLoss: 260.217255\n",
      "Train Epoch: 1401 [2100/2589 (81%)]\tLoss: 160.773117\n",
      "Train Epoch: 1401 [2400/2589 (93%)]\tLoss: 192.656723\n",
      "====> Epoch: 1401 Average train loss: 222.0978\n",
      "====> Epoch: 1401 Average test loss: 898.8932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1402 [0/2589 (0%)]\tLoss: 258.028748\n",
      "Train Epoch: 1402 [300/2589 (12%)]\tLoss: 173.046326\n",
      "Train Epoch: 1402 [600/2589 (23%)]\tLoss: 136.589890\n",
      "Train Epoch: 1402 [900/2589 (35%)]\tLoss: 158.233536\n",
      "Train Epoch: 1402 [1200/2589 (46%)]\tLoss: 223.862534\n",
      "Train Epoch: 1402 [1500/2589 (58%)]\tLoss: 196.932281\n",
      "Train Epoch: 1402 [1800/2589 (70%)]\tLoss: 199.931107\n",
      "Train Epoch: 1402 [2100/2589 (81%)]\tLoss: 175.676208\n",
      "Train Epoch: 1402 [2400/2589 (93%)]\tLoss: 193.231689\n",
      "====> Epoch: 1402 Average train loss: 203.5750\n",
      "====> Epoch: 1402 Average test loss: 910.6295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1403 [0/2589 (0%)]\tLoss: 175.338959\n",
      "Train Epoch: 1403 [300/2589 (12%)]\tLoss: 169.510406\n",
      "Train Epoch: 1403 [600/2589 (23%)]\tLoss: 133.435028\n",
      "Train Epoch: 1403 [900/2589 (35%)]\tLoss: 139.723862\n",
      "Train Epoch: 1403 [1200/2589 (46%)]\tLoss: 300.633148\n",
      "Train Epoch: 1403 [1500/2589 (58%)]\tLoss: 158.043808\n",
      "Train Epoch: 1403 [1800/2589 (70%)]\tLoss: 142.997787\n",
      "Train Epoch: 1403 [2100/2589 (81%)]\tLoss: 167.979874\n",
      "Train Epoch: 1403 [2400/2589 (93%)]\tLoss: 185.524246\n",
      "====> Epoch: 1403 Average train loss: 207.3345\n",
      "====> Epoch: 1403 Average test loss: 911.9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1404 [0/2589 (0%)]\tLoss: 163.296356\n",
      "Train Epoch: 1404 [300/2589 (12%)]\tLoss: 180.161469\n",
      "Train Epoch: 1404 [600/2589 (23%)]\tLoss: 190.871750\n",
      "Train Epoch: 1404 [900/2589 (35%)]\tLoss: 261.097229\n",
      "Train Epoch: 1404 [1200/2589 (46%)]\tLoss: 168.189102\n",
      "Train Epoch: 1404 [1500/2589 (58%)]\tLoss: 177.534241\n",
      "Train Epoch: 1404 [1800/2589 (70%)]\tLoss: 476.367950\n",
      "Train Epoch: 1404 [2100/2589 (81%)]\tLoss: 313.126007\n",
      "Train Epoch: 1404 [2400/2589 (93%)]\tLoss: 331.319672\n",
      "====> Epoch: 1404 Average train loss: 217.6249\n",
      "====> Epoch: 1404 Average test loss: 906.8270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1405 [0/2589 (0%)]\tLoss: 289.718475\n",
      "Train Epoch: 1405 [300/2589 (12%)]\tLoss: 295.996429\n",
      "Train Epoch: 1405 [600/2589 (23%)]\tLoss: 205.594833\n",
      "Train Epoch: 1405 [900/2589 (35%)]\tLoss: 155.660202\n",
      "Train Epoch: 1405 [1200/2589 (46%)]\tLoss: 347.685822\n",
      "Train Epoch: 1405 [1500/2589 (58%)]\tLoss: 472.281708\n",
      "Train Epoch: 1405 [1800/2589 (70%)]\tLoss: 180.743195\n",
      "Train Epoch: 1405 [2100/2589 (81%)]\tLoss: 168.071121\n",
      "Train Epoch: 1405 [2400/2589 (93%)]\tLoss: 198.250565\n",
      "====> Epoch: 1405 Average train loss: 213.5370\n",
      "====> Epoch: 1405 Average test loss: 910.3656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1406 [0/2589 (0%)]\tLoss: 169.483322\n",
      "Train Epoch: 1406 [300/2589 (12%)]\tLoss: 215.451584\n",
      "Train Epoch: 1406 [600/2589 (23%)]\tLoss: 201.448410\n",
      "Train Epoch: 1406 [900/2589 (35%)]\tLoss: 176.530304\n",
      "Train Epoch: 1406 [1200/2589 (46%)]\tLoss: 176.801895\n",
      "Train Epoch: 1406 [1500/2589 (58%)]\tLoss: 284.181366\n",
      "Train Epoch: 1406 [1800/2589 (70%)]\tLoss: 176.768875\n",
      "Train Epoch: 1406 [2100/2589 (81%)]\tLoss: 192.267105\n",
      "Train Epoch: 1406 [2400/2589 (93%)]\tLoss: 236.578705\n",
      "====> Epoch: 1406 Average train loss: 206.4703\n",
      "====> Epoch: 1406 Average test loss: 920.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1407 [0/2589 (0%)]\tLoss: 161.182709\n",
      "Train Epoch: 1407 [300/2589 (12%)]\tLoss: 183.002426\n",
      "Train Epoch: 1407 [600/2589 (23%)]\tLoss: 224.174942\n",
      "Train Epoch: 1407 [900/2589 (35%)]\tLoss: 187.200378\n",
      "Train Epoch: 1407 [1200/2589 (46%)]\tLoss: 313.848358\n",
      "Train Epoch: 1407 [1500/2589 (58%)]\tLoss: 184.947296\n",
      "Train Epoch: 1407 [1800/2589 (70%)]\tLoss: 234.688965\n",
      "Train Epoch: 1407 [2100/2589 (81%)]\tLoss: 162.642410\n",
      "Train Epoch: 1407 [2400/2589 (93%)]\tLoss: 254.803299\n",
      "====> Epoch: 1407 Average train loss: 221.5781\n",
      "====> Epoch: 1407 Average test loss: 896.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1408 [0/2589 (0%)]\tLoss: 366.003448\n",
      "Train Epoch: 1408 [300/2589 (12%)]\tLoss: 246.101486\n",
      "Train Epoch: 1408 [600/2589 (23%)]\tLoss: 138.408264\n",
      "Train Epoch: 1408 [900/2589 (35%)]\tLoss: 207.007553\n",
      "Train Epoch: 1408 [1200/2589 (46%)]\tLoss: 234.476501\n",
      "Train Epoch: 1408 [1500/2589 (58%)]\tLoss: 175.368378\n",
      "Train Epoch: 1408 [1800/2589 (70%)]\tLoss: 179.598038\n",
      "Train Epoch: 1408 [2100/2589 (81%)]\tLoss: 168.749313\n",
      "Train Epoch: 1408 [2400/2589 (93%)]\tLoss: 183.193756\n",
      "====> Epoch: 1408 Average train loss: 214.6755\n",
      "====> Epoch: 1408 Average test loss: 918.5875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1409 [0/2589 (0%)]\tLoss: 248.952972\n",
      "Train Epoch: 1409 [300/2589 (12%)]\tLoss: 215.012619\n",
      "Train Epoch: 1409 [600/2589 (23%)]\tLoss: 222.961655\n",
      "Train Epoch: 1409 [900/2589 (35%)]\tLoss: 340.511780\n",
      "Train Epoch: 1409 [1200/2589 (46%)]\tLoss: 151.395935\n",
      "Train Epoch: 1409 [1500/2589 (58%)]\tLoss: 149.885101\n",
      "Train Epoch: 1409 [1800/2589 (70%)]\tLoss: 191.732208\n",
      "Train Epoch: 1409 [2100/2589 (81%)]\tLoss: 268.304291\n",
      "Train Epoch: 1409 [2400/2589 (93%)]\tLoss: 304.319458\n",
      "====> Epoch: 1409 Average train loss: 213.8582\n",
      "====> Epoch: 1409 Average test loss: 904.2280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1410 [0/2589 (0%)]\tLoss: 205.239929\n",
      "Train Epoch: 1410 [300/2589 (12%)]\tLoss: 147.554672\n",
      "Train Epoch: 1410 [600/2589 (23%)]\tLoss: 200.144714\n",
      "Train Epoch: 1410 [900/2589 (35%)]\tLoss: 206.345474\n",
      "Train Epoch: 1410 [1200/2589 (46%)]\tLoss: 213.459213\n",
      "Train Epoch: 1410 [1500/2589 (58%)]\tLoss: 169.319107\n",
      "Train Epoch: 1410 [1800/2589 (70%)]\tLoss: 151.716492\n",
      "Train Epoch: 1410 [2100/2589 (81%)]\tLoss: 340.669067\n",
      "Train Epoch: 1410 [2400/2589 (93%)]\tLoss: 349.258667\n",
      "====> Epoch: 1410 Average train loss: 208.3732\n",
      "====> Epoch: 1410 Average test loss: 922.9054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1411 [0/2589 (0%)]\tLoss: 200.533112\n",
      "Train Epoch: 1411 [300/2589 (12%)]\tLoss: 320.113464\n",
      "Train Epoch: 1411 [600/2589 (23%)]\tLoss: 195.944794\n",
      "Train Epoch: 1411 [900/2589 (35%)]\tLoss: 237.593857\n",
      "Train Epoch: 1411 [1200/2589 (46%)]\tLoss: 140.617050\n",
      "Train Epoch: 1411 [1500/2589 (58%)]\tLoss: 154.836746\n",
      "Train Epoch: 1411 [1800/2589 (70%)]\tLoss: 197.377701\n",
      "Train Epoch: 1411 [2100/2589 (81%)]\tLoss: 183.281693\n",
      "Train Epoch: 1411 [2400/2589 (93%)]\tLoss: 202.376892\n",
      "====> Epoch: 1411 Average train loss: 206.9828\n",
      "====> Epoch: 1411 Average test loss: 906.0845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1412 [0/2589 (0%)]\tLoss: 187.054825\n",
      "Train Epoch: 1412 [300/2589 (12%)]\tLoss: 244.168762\n",
      "Train Epoch: 1412 [600/2589 (23%)]\tLoss: 181.855484\n",
      "Train Epoch: 1412 [900/2589 (35%)]\tLoss: 206.865555\n",
      "Train Epoch: 1412 [1200/2589 (46%)]\tLoss: 206.503952\n",
      "Train Epoch: 1412 [1500/2589 (58%)]\tLoss: 206.459564\n",
      "Train Epoch: 1412 [1800/2589 (70%)]\tLoss: 263.192749\n",
      "Train Epoch: 1412 [2100/2589 (81%)]\tLoss: 178.792999\n",
      "Train Epoch: 1412 [2400/2589 (93%)]\tLoss: 173.142303\n",
      "====> Epoch: 1412 Average train loss: 216.7118\n",
      "====> Epoch: 1412 Average test loss: 912.0261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1413 [0/2589 (0%)]\tLoss: 130.203201\n",
      "Train Epoch: 1413 [300/2589 (12%)]\tLoss: 310.660858\n",
      "Train Epoch: 1413 [600/2589 (23%)]\tLoss: 261.250763\n",
      "Train Epoch: 1413 [900/2589 (35%)]\tLoss: 200.567734\n",
      "Train Epoch: 1413 [1200/2589 (46%)]\tLoss: 262.369202\n",
      "Train Epoch: 1413 [1500/2589 (58%)]\tLoss: 241.979019\n",
      "Train Epoch: 1413 [1800/2589 (70%)]\tLoss: 152.495178\n",
      "Train Epoch: 1413 [2100/2589 (81%)]\tLoss: 145.116699\n",
      "Train Epoch: 1413 [2400/2589 (93%)]\tLoss: 237.300262\n",
      "====> Epoch: 1413 Average train loss: 207.4574\n",
      "====> Epoch: 1413 Average test loss: 920.1363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1414 [0/2589 (0%)]\tLoss: 190.406784\n",
      "Train Epoch: 1414 [300/2589 (12%)]\tLoss: 163.902008\n",
      "Train Epoch: 1414 [600/2589 (23%)]\tLoss: 166.265228\n",
      "Train Epoch: 1414 [900/2589 (35%)]\tLoss: 234.960648\n",
      "Train Epoch: 1414 [1200/2589 (46%)]\tLoss: 183.134552\n",
      "Train Epoch: 1414 [1500/2589 (58%)]\tLoss: 158.956970\n",
      "Train Epoch: 1414 [1800/2589 (70%)]\tLoss: 191.775040\n",
      "Train Epoch: 1414 [2100/2589 (81%)]\tLoss: 183.704025\n",
      "Train Epoch: 1414 [2400/2589 (93%)]\tLoss: 245.010605\n",
      "====> Epoch: 1414 Average train loss: 213.3823\n",
      "====> Epoch: 1414 Average test loss: 905.8950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1415 [0/2589 (0%)]\tLoss: 179.241211\n",
      "Train Epoch: 1415 [300/2589 (12%)]\tLoss: 246.461929\n",
      "Train Epoch: 1415 [600/2589 (23%)]\tLoss: 165.331436\n",
      "Train Epoch: 1415 [900/2589 (35%)]\tLoss: 236.816696\n",
      "Train Epoch: 1415 [1200/2589 (46%)]\tLoss: 197.968521\n",
      "Train Epoch: 1415 [1500/2589 (58%)]\tLoss: 163.171555\n",
      "Train Epoch: 1415 [1800/2589 (70%)]\tLoss: 145.339996\n",
      "Train Epoch: 1415 [2100/2589 (81%)]\tLoss: 226.434708\n",
      "Train Epoch: 1415 [2400/2589 (93%)]\tLoss: 144.787521\n",
      "====> Epoch: 1415 Average train loss: 207.7936\n",
      "====> Epoch: 1415 Average test loss: 923.2740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1416 [0/2589 (0%)]\tLoss: 173.574203\n",
      "Train Epoch: 1416 [300/2589 (12%)]\tLoss: 174.922760\n",
      "Train Epoch: 1416 [600/2589 (23%)]\tLoss: 238.013199\n",
      "Train Epoch: 1416 [900/2589 (35%)]\tLoss: 270.839203\n",
      "Train Epoch: 1416 [1200/2589 (46%)]\tLoss: 271.309235\n",
      "Train Epoch: 1416 [1500/2589 (58%)]\tLoss: 342.500214\n",
      "Train Epoch: 1416 [1800/2589 (70%)]\tLoss: 185.046906\n",
      "Train Epoch: 1416 [2100/2589 (81%)]\tLoss: 356.367249\n",
      "Train Epoch: 1416 [2400/2589 (93%)]\tLoss: 182.694275\n",
      "====> Epoch: 1416 Average train loss: 222.1230\n",
      "====> Epoch: 1416 Average test loss: 913.7445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1417 [0/2589 (0%)]\tLoss: 210.837723\n",
      "Train Epoch: 1417 [300/2589 (12%)]\tLoss: 195.723114\n",
      "Train Epoch: 1417 [600/2589 (23%)]\tLoss: 284.930206\n",
      "Train Epoch: 1417 [900/2589 (35%)]\tLoss: 219.512405\n",
      "Train Epoch: 1417 [1200/2589 (46%)]\tLoss: 139.280426\n",
      "Train Epoch: 1417 [1500/2589 (58%)]\tLoss: 145.156189\n",
      "Train Epoch: 1417 [1800/2589 (70%)]\tLoss: 239.767242\n",
      "Train Epoch: 1417 [2100/2589 (81%)]\tLoss: 139.547073\n",
      "Train Epoch: 1417 [2400/2589 (93%)]\tLoss: 242.006485\n",
      "====> Epoch: 1417 Average train loss: 214.6639\n",
      "====> Epoch: 1417 Average test loss: 901.4100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1418 [0/2589 (0%)]\tLoss: 193.197800\n",
      "Train Epoch: 1418 [300/2589 (12%)]\tLoss: 192.786194\n",
      "Train Epoch: 1418 [600/2589 (23%)]\tLoss: 183.250458\n",
      "Train Epoch: 1418 [900/2589 (35%)]\tLoss: 263.021637\n",
      "Train Epoch: 1418 [1200/2589 (46%)]\tLoss: 225.367737\n",
      "Train Epoch: 1418 [1500/2589 (58%)]\tLoss: 235.050766\n",
      "Train Epoch: 1418 [1800/2589 (70%)]\tLoss: 191.344498\n",
      "Train Epoch: 1418 [2100/2589 (81%)]\tLoss: 201.063492\n",
      "Train Epoch: 1418 [2400/2589 (93%)]\tLoss: 139.894730\n",
      "====> Epoch: 1418 Average train loss: 221.6584\n",
      "====> Epoch: 1418 Average test loss: 904.3271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1419 [0/2589 (0%)]\tLoss: 425.076691\n",
      "Train Epoch: 1419 [300/2589 (12%)]\tLoss: 247.134079\n",
      "Train Epoch: 1419 [600/2589 (23%)]\tLoss: 168.638474\n",
      "Train Epoch: 1419 [900/2589 (35%)]\tLoss: 140.087311\n",
      "Train Epoch: 1419 [1200/2589 (46%)]\tLoss: 128.682892\n",
      "Train Epoch: 1419 [1500/2589 (58%)]\tLoss: 188.703430\n",
      "Train Epoch: 1419 [1800/2589 (70%)]\tLoss: 189.939255\n",
      "Train Epoch: 1419 [2100/2589 (81%)]\tLoss: 214.716843\n",
      "Train Epoch: 1419 [2400/2589 (93%)]\tLoss: 213.961945\n",
      "====> Epoch: 1419 Average train loss: 208.1646\n",
      "====> Epoch: 1419 Average test loss: 908.7705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1420 [0/2589 (0%)]\tLoss: 199.654587\n",
      "Train Epoch: 1420 [300/2589 (12%)]\tLoss: 166.978607\n",
      "Train Epoch: 1420 [600/2589 (23%)]\tLoss: 184.837540\n",
      "Train Epoch: 1420 [900/2589 (35%)]\tLoss: 203.388458\n",
      "Train Epoch: 1420 [1200/2589 (46%)]\tLoss: 194.541397\n",
      "Train Epoch: 1420 [1500/2589 (58%)]\tLoss: 193.069885\n",
      "Train Epoch: 1420 [1800/2589 (70%)]\tLoss: 206.258759\n",
      "Train Epoch: 1420 [2100/2589 (81%)]\tLoss: 212.991364\n",
      "Train Epoch: 1420 [2400/2589 (93%)]\tLoss: 194.632492\n",
      "====> Epoch: 1420 Average train loss: 213.6693\n",
      "====> Epoch: 1420 Average test loss: 910.4132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1421 [0/2589 (0%)]\tLoss: 169.595718\n",
      "Train Epoch: 1421 [300/2589 (12%)]\tLoss: 168.695450\n",
      "Train Epoch: 1421 [600/2589 (23%)]\tLoss: 167.995575\n",
      "Train Epoch: 1421 [900/2589 (35%)]\tLoss: 196.911163\n",
      "Train Epoch: 1421 [1200/2589 (46%)]\tLoss: 214.185822\n",
      "Train Epoch: 1421 [1500/2589 (58%)]\tLoss: 172.805359\n",
      "Train Epoch: 1421 [1800/2589 (70%)]\tLoss: 200.574997\n",
      "Train Epoch: 1421 [2100/2589 (81%)]\tLoss: 155.454544\n",
      "Train Epoch: 1421 [2400/2589 (93%)]\tLoss: 323.253296\n",
      "====> Epoch: 1421 Average train loss: 211.0753\n",
      "====> Epoch: 1421 Average test loss: 916.4963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1422 [0/2589 (0%)]\tLoss: 174.980637\n",
      "Train Epoch: 1422 [300/2589 (12%)]\tLoss: 187.155579\n",
      "Train Epoch: 1422 [600/2589 (23%)]\tLoss: 143.807632\n",
      "Train Epoch: 1422 [900/2589 (35%)]\tLoss: 293.521210\n",
      "Train Epoch: 1422 [1200/2589 (46%)]\tLoss: 175.121796\n",
      "Train Epoch: 1422 [1500/2589 (58%)]\tLoss: 152.345398\n",
      "Train Epoch: 1422 [1800/2589 (70%)]\tLoss: 196.878693\n",
      "Train Epoch: 1422 [2100/2589 (81%)]\tLoss: 238.307053\n",
      "Train Epoch: 1422 [2400/2589 (93%)]\tLoss: 159.062729\n",
      "====> Epoch: 1422 Average train loss: 213.7776\n",
      "====> Epoch: 1422 Average test loss: 909.8947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1423 [0/2589 (0%)]\tLoss: 206.740494\n",
      "Train Epoch: 1423 [300/2589 (12%)]\tLoss: 178.619324\n",
      "Train Epoch: 1423 [600/2589 (23%)]\tLoss: 385.263550\n",
      "Train Epoch: 1423 [900/2589 (35%)]\tLoss: 197.689453\n",
      "Train Epoch: 1423 [1200/2589 (46%)]\tLoss: 243.454285\n",
      "Train Epoch: 1423 [1500/2589 (58%)]\tLoss: 179.536819\n",
      "Train Epoch: 1423 [1800/2589 (70%)]\tLoss: 143.654434\n",
      "Train Epoch: 1423 [2100/2589 (81%)]\tLoss: 259.863739\n",
      "Train Epoch: 1423 [2400/2589 (93%)]\tLoss: 182.372299\n",
      "====> Epoch: 1423 Average train loss: 212.5351\n",
      "====> Epoch: 1423 Average test loss: 911.1443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1424 [0/2589 (0%)]\tLoss: 250.335541\n",
      "Train Epoch: 1424 [300/2589 (12%)]\tLoss: 198.642807\n",
      "Train Epoch: 1424 [600/2589 (23%)]\tLoss: 211.149078\n",
      "Train Epoch: 1424 [900/2589 (35%)]\tLoss: 139.815109\n",
      "Train Epoch: 1424 [1200/2589 (46%)]\tLoss: 168.263733\n",
      "Train Epoch: 1424 [1500/2589 (58%)]\tLoss: 285.720123\n",
      "Train Epoch: 1424 [1800/2589 (70%)]\tLoss: 208.248596\n",
      "Train Epoch: 1424 [2100/2589 (81%)]\tLoss: 214.131790\n",
      "Train Epoch: 1424 [2400/2589 (93%)]\tLoss: 181.765472\n",
      "====> Epoch: 1424 Average train loss: 209.1004\n",
      "====> Epoch: 1424 Average test loss: 927.8410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1425 [0/2589 (0%)]\tLoss: 183.739517\n",
      "Train Epoch: 1425 [300/2589 (12%)]\tLoss: 181.929779\n",
      "Train Epoch: 1425 [600/2589 (23%)]\tLoss: 253.095154\n",
      "Train Epoch: 1425 [900/2589 (35%)]\tLoss: 214.420441\n",
      "Train Epoch: 1425 [1200/2589 (46%)]\tLoss: 230.842804\n",
      "Train Epoch: 1425 [1500/2589 (58%)]\tLoss: 211.072784\n",
      "Train Epoch: 1425 [1800/2589 (70%)]\tLoss: 144.350739\n",
      "Train Epoch: 1425 [2100/2589 (81%)]\tLoss: 206.298019\n",
      "Train Epoch: 1425 [2400/2589 (93%)]\tLoss: 212.657303\n",
      "====> Epoch: 1425 Average train loss: 213.2506\n",
      "====> Epoch: 1425 Average test loss: 905.1759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1426 [0/2589 (0%)]\tLoss: 191.940170\n",
      "Train Epoch: 1426 [300/2589 (12%)]\tLoss: 235.216171\n",
      "Train Epoch: 1426 [600/2589 (23%)]\tLoss: 178.947983\n",
      "Train Epoch: 1426 [900/2589 (35%)]\tLoss: 213.124771\n",
      "Train Epoch: 1426 [1200/2589 (46%)]\tLoss: 201.203049\n",
      "Train Epoch: 1426 [1500/2589 (58%)]\tLoss: 312.541473\n",
      "Train Epoch: 1426 [1800/2589 (70%)]\tLoss: 163.183014\n",
      "Train Epoch: 1426 [2100/2589 (81%)]\tLoss: 142.484787\n",
      "Train Epoch: 1426 [2400/2589 (93%)]\tLoss: 153.176239\n",
      "====> Epoch: 1426 Average train loss: 211.7119\n",
      "====> Epoch: 1426 Average test loss: 898.4475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1427 [0/2589 (0%)]\tLoss: 257.477570\n",
      "Train Epoch: 1427 [300/2589 (12%)]\tLoss: 170.959900\n",
      "Train Epoch: 1427 [600/2589 (23%)]\tLoss: 151.637833\n",
      "Train Epoch: 1427 [900/2589 (35%)]\tLoss: 148.759445\n",
      "Train Epoch: 1427 [1200/2589 (46%)]\tLoss: 278.770996\n",
      "Train Epoch: 1427 [1500/2589 (58%)]\tLoss: 150.262146\n",
      "Train Epoch: 1427 [1800/2589 (70%)]\tLoss: 165.807205\n",
      "Train Epoch: 1427 [2100/2589 (81%)]\tLoss: 225.861572\n",
      "Train Epoch: 1427 [2400/2589 (93%)]\tLoss: 201.003220\n",
      "====> Epoch: 1427 Average train loss: 205.1096\n",
      "====> Epoch: 1427 Average test loss: 923.0214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1428 [0/2589 (0%)]\tLoss: 160.294998\n",
      "Train Epoch: 1428 [300/2589 (12%)]\tLoss: 182.658203\n",
      "Train Epoch: 1428 [600/2589 (23%)]\tLoss: 201.982529\n",
      "Train Epoch: 1428 [900/2589 (35%)]\tLoss: 173.382614\n",
      "Train Epoch: 1428 [1200/2589 (46%)]\tLoss: 377.327942\n",
      "Train Epoch: 1428 [1500/2589 (58%)]\tLoss: 265.774780\n",
      "Train Epoch: 1428 [1800/2589 (70%)]\tLoss: 232.099503\n",
      "Train Epoch: 1428 [2100/2589 (81%)]\tLoss: 204.054276\n",
      "Train Epoch: 1428 [2400/2589 (93%)]\tLoss: 277.558899\n",
      "====> Epoch: 1428 Average train loss: 221.7549\n",
      "====> Epoch: 1428 Average test loss: 916.8376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1429 [0/2589 (0%)]\tLoss: 213.492737\n",
      "Train Epoch: 1429 [300/2589 (12%)]\tLoss: 181.320145\n",
      "Train Epoch: 1429 [600/2589 (23%)]\tLoss: 299.521118\n",
      "Train Epoch: 1429 [900/2589 (35%)]\tLoss: 198.797928\n",
      "Train Epoch: 1429 [1200/2589 (46%)]\tLoss: 186.130341\n",
      "Train Epoch: 1429 [1500/2589 (58%)]\tLoss: 240.925674\n",
      "Train Epoch: 1429 [1800/2589 (70%)]\tLoss: 211.377884\n",
      "Train Epoch: 1429 [2100/2589 (81%)]\tLoss: 178.669250\n",
      "Train Epoch: 1429 [2400/2589 (93%)]\tLoss: 227.896393\n",
      "====> Epoch: 1429 Average train loss: 217.1862\n",
      "====> Epoch: 1429 Average test loss: 923.2717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1430 [0/2589 (0%)]\tLoss: 224.176758\n",
      "Train Epoch: 1430 [300/2589 (12%)]\tLoss: 152.255585\n",
      "Train Epoch: 1430 [600/2589 (23%)]\tLoss: 281.783722\n",
      "Train Epoch: 1430 [900/2589 (35%)]\tLoss: 256.619202\n",
      "Train Epoch: 1430 [1200/2589 (46%)]\tLoss: 215.077728\n",
      "Train Epoch: 1430 [1500/2589 (58%)]\tLoss: 214.529449\n",
      "Train Epoch: 1430 [1800/2589 (70%)]\tLoss: 218.072052\n",
      "Train Epoch: 1430 [2100/2589 (81%)]\tLoss: 227.851028\n",
      "Train Epoch: 1430 [2400/2589 (93%)]\tLoss: 222.333664\n",
      "====> Epoch: 1430 Average train loss: 218.1082\n",
      "====> Epoch: 1430 Average test loss: 907.6987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1431 [0/2589 (0%)]\tLoss: 147.653000\n",
      "Train Epoch: 1431 [300/2589 (12%)]\tLoss: 149.121353\n",
      "Train Epoch: 1431 [600/2589 (23%)]\tLoss: 188.554001\n",
      "Train Epoch: 1431 [900/2589 (35%)]\tLoss: 164.684280\n",
      "Train Epoch: 1431 [1200/2589 (46%)]\tLoss: 167.767029\n",
      "Train Epoch: 1431 [1500/2589 (58%)]\tLoss: 203.324905\n",
      "Train Epoch: 1431 [1800/2589 (70%)]\tLoss: 175.716751\n",
      "Train Epoch: 1431 [2100/2589 (81%)]\tLoss: 189.256821\n",
      "Train Epoch: 1431 [2400/2589 (93%)]\tLoss: 264.682190\n",
      "====> Epoch: 1431 Average train loss: 214.7712\n",
      "====> Epoch: 1431 Average test loss: 920.5618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1432 [0/2589 (0%)]\tLoss: 149.987289\n",
      "Train Epoch: 1432 [300/2589 (12%)]\tLoss: 249.237274\n",
      "Train Epoch: 1432 [600/2589 (23%)]\tLoss: 191.323471\n",
      "Train Epoch: 1432 [900/2589 (35%)]\tLoss: 204.198074\n",
      "Train Epoch: 1432 [1200/2589 (46%)]\tLoss: 250.565887\n",
      "Train Epoch: 1432 [1500/2589 (58%)]\tLoss: 216.143463\n",
      "Train Epoch: 1432 [1800/2589 (70%)]\tLoss: 192.434738\n",
      "Train Epoch: 1432 [2100/2589 (81%)]\tLoss: 196.259583\n",
      "Train Epoch: 1432 [2400/2589 (93%)]\tLoss: 173.984940\n",
      "====> Epoch: 1432 Average train loss: 219.9937\n",
      "====> Epoch: 1432 Average test loss: 913.4715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1433 [0/2589 (0%)]\tLoss: 161.074509\n",
      "Train Epoch: 1433 [300/2589 (12%)]\tLoss: 148.309952\n",
      "Train Epoch: 1433 [600/2589 (23%)]\tLoss: 408.725647\n",
      "Train Epoch: 1433 [900/2589 (35%)]\tLoss: 243.046799\n",
      "Train Epoch: 1433 [1200/2589 (46%)]\tLoss: 248.745453\n",
      "Train Epoch: 1433 [1500/2589 (58%)]\tLoss: 190.448273\n",
      "Train Epoch: 1433 [1800/2589 (70%)]\tLoss: 250.923584\n",
      "Train Epoch: 1433 [2100/2589 (81%)]\tLoss: 317.692108\n",
      "Train Epoch: 1433 [2400/2589 (93%)]\tLoss: 232.826157\n",
      "====> Epoch: 1433 Average train loss: 208.3962\n",
      "====> Epoch: 1433 Average test loss: 896.9473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1434 [0/2589 (0%)]\tLoss: 153.307236\n",
      "Train Epoch: 1434 [300/2589 (12%)]\tLoss: 151.817566\n",
      "Train Epoch: 1434 [600/2589 (23%)]\tLoss: 263.273254\n",
      "Train Epoch: 1434 [900/2589 (35%)]\tLoss: 253.593018\n",
      "Train Epoch: 1434 [1200/2589 (46%)]\tLoss: 192.664154\n",
      "Train Epoch: 1434 [1500/2589 (58%)]\tLoss: 199.395584\n",
      "Train Epoch: 1434 [1800/2589 (70%)]\tLoss: 281.769043\n",
      "Train Epoch: 1434 [2100/2589 (81%)]\tLoss: 156.943451\n",
      "Train Epoch: 1434 [2400/2589 (93%)]\tLoss: 237.863220\n",
      "====> Epoch: 1434 Average train loss: 216.7667\n",
      "====> Epoch: 1434 Average test loss: 915.7562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1435 [0/2589 (0%)]\tLoss: 157.561920\n",
      "Train Epoch: 1435 [300/2589 (12%)]\tLoss: 242.932648\n",
      "Train Epoch: 1435 [600/2589 (23%)]\tLoss: 196.793427\n",
      "Train Epoch: 1435 [900/2589 (35%)]\tLoss: 402.739197\n",
      "Train Epoch: 1435 [1200/2589 (46%)]\tLoss: 185.093613\n",
      "Train Epoch: 1435 [1500/2589 (58%)]\tLoss: 149.481964\n",
      "Train Epoch: 1435 [1800/2589 (70%)]\tLoss: 171.898499\n",
      "Train Epoch: 1435 [2100/2589 (81%)]\tLoss: 145.112900\n",
      "Train Epoch: 1435 [2400/2589 (93%)]\tLoss: 114.077080\n",
      "====> Epoch: 1435 Average train loss: 216.3784\n",
      "====> Epoch: 1435 Average test loss: 918.2155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1436 [0/2589 (0%)]\tLoss: 222.416641\n",
      "Train Epoch: 1436 [300/2589 (12%)]\tLoss: 136.250565\n",
      "Train Epoch: 1436 [600/2589 (23%)]\tLoss: 208.673569\n",
      "Train Epoch: 1436 [900/2589 (35%)]\tLoss: 158.973007\n",
      "Train Epoch: 1436 [1200/2589 (46%)]\tLoss: 154.198395\n",
      "Train Epoch: 1436 [1500/2589 (58%)]\tLoss: 142.066437\n",
      "Train Epoch: 1436 [1800/2589 (70%)]\tLoss: 210.073029\n",
      "Train Epoch: 1436 [2100/2589 (81%)]\tLoss: 227.970306\n",
      "Train Epoch: 1436 [2400/2589 (93%)]\tLoss: 190.829559\n",
      "====> Epoch: 1436 Average train loss: 215.6498\n",
      "====> Epoch: 1436 Average test loss: 917.8436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1437 [0/2589 (0%)]\tLoss: 163.059860\n",
      "Train Epoch: 1437 [300/2589 (12%)]\tLoss: 215.633255\n",
      "Train Epoch: 1437 [600/2589 (23%)]\tLoss: 209.296127\n",
      "Train Epoch: 1437 [900/2589 (35%)]\tLoss: 185.646088\n",
      "Train Epoch: 1437 [1200/2589 (46%)]\tLoss: 169.189392\n",
      "Train Epoch: 1437 [1500/2589 (58%)]\tLoss: 188.727859\n",
      "Train Epoch: 1437 [1800/2589 (70%)]\tLoss: 142.049072\n",
      "Train Epoch: 1437 [2100/2589 (81%)]\tLoss: 149.114182\n",
      "Train Epoch: 1437 [2400/2589 (93%)]\tLoss: 151.097076\n",
      "====> Epoch: 1437 Average train loss: 205.5007\n",
      "====> Epoch: 1437 Average test loss: 897.8238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1438 [0/2589 (0%)]\tLoss: 193.722626\n",
      "Train Epoch: 1438 [300/2589 (12%)]\tLoss: 243.248077\n",
      "Train Epoch: 1438 [600/2589 (23%)]\tLoss: 173.415298\n",
      "Train Epoch: 1438 [900/2589 (35%)]\tLoss: 160.586426\n",
      "Train Epoch: 1438 [1200/2589 (46%)]\tLoss: 257.715393\n",
      "Train Epoch: 1438 [1500/2589 (58%)]\tLoss: 220.287140\n",
      "Train Epoch: 1438 [1800/2589 (70%)]\tLoss: 164.086823\n",
      "Train Epoch: 1438 [2100/2589 (81%)]\tLoss: 217.616791\n",
      "Train Epoch: 1438 [2400/2589 (93%)]\tLoss: 211.589935\n",
      "====> Epoch: 1438 Average train loss: 222.1218\n",
      "====> Epoch: 1438 Average test loss: 904.2692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1439 [0/2589 (0%)]\tLoss: 134.092880\n",
      "Train Epoch: 1439 [300/2589 (12%)]\tLoss: 142.053055\n",
      "Train Epoch: 1439 [600/2589 (23%)]\tLoss: 226.740891\n",
      "Train Epoch: 1439 [900/2589 (35%)]\tLoss: 221.962326\n",
      "Train Epoch: 1439 [1200/2589 (46%)]\tLoss: 204.689560\n",
      "Train Epoch: 1439 [1500/2589 (58%)]\tLoss: 189.012161\n",
      "Train Epoch: 1439 [1800/2589 (70%)]\tLoss: 197.483261\n",
      "Train Epoch: 1439 [2100/2589 (81%)]\tLoss: 210.655121\n",
      "Train Epoch: 1439 [2400/2589 (93%)]\tLoss: 243.257675\n",
      "====> Epoch: 1439 Average train loss: 204.9027\n",
      "====> Epoch: 1439 Average test loss: 905.8063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1440 [0/2589 (0%)]\tLoss: 192.812836\n",
      "Train Epoch: 1440 [300/2589 (12%)]\tLoss: 208.159775\n",
      "Train Epoch: 1440 [600/2589 (23%)]\tLoss: 200.424713\n",
      "Train Epoch: 1440 [900/2589 (35%)]\tLoss: 180.045822\n",
      "Train Epoch: 1440 [1200/2589 (46%)]\tLoss: 226.542023\n",
      "Train Epoch: 1440 [1500/2589 (58%)]\tLoss: 212.595688\n",
      "Train Epoch: 1440 [1800/2589 (70%)]\tLoss: 186.457260\n",
      "Train Epoch: 1440 [2100/2589 (81%)]\tLoss: 292.144928\n",
      "Train Epoch: 1440 [2400/2589 (93%)]\tLoss: 156.991882\n",
      "====> Epoch: 1440 Average train loss: 220.9584\n",
      "====> Epoch: 1440 Average test loss: 891.3346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1441 [0/2589 (0%)]\tLoss: 228.241013\n",
      "Train Epoch: 1441 [300/2589 (12%)]\tLoss: 310.121155\n",
      "Train Epoch: 1441 [600/2589 (23%)]\tLoss: 309.015045\n",
      "Train Epoch: 1441 [900/2589 (35%)]\tLoss: 183.911453\n",
      "Train Epoch: 1441 [1200/2589 (46%)]\tLoss: 215.980316\n",
      "Train Epoch: 1441 [1500/2589 (58%)]\tLoss: 191.400192\n",
      "Train Epoch: 1441 [1800/2589 (70%)]\tLoss: 154.911469\n",
      "Train Epoch: 1441 [2100/2589 (81%)]\tLoss: 258.684204\n",
      "Train Epoch: 1441 [2400/2589 (93%)]\tLoss: 193.061768\n",
      "====> Epoch: 1441 Average train loss: 206.2469\n",
      "====> Epoch: 1441 Average test loss: 909.3947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1442 [0/2589 (0%)]\tLoss: 288.324371\n",
      "Train Epoch: 1442 [300/2589 (12%)]\tLoss: 156.525635\n",
      "Train Epoch: 1442 [600/2589 (23%)]\tLoss: 231.549072\n",
      "Train Epoch: 1442 [900/2589 (35%)]\tLoss: 157.093063\n",
      "Train Epoch: 1442 [1200/2589 (46%)]\tLoss: 426.547150\n",
      "Train Epoch: 1442 [1500/2589 (58%)]\tLoss: 123.629601\n",
      "Train Epoch: 1442 [1800/2589 (70%)]\tLoss: 162.383041\n",
      "Train Epoch: 1442 [2100/2589 (81%)]\tLoss: 305.791290\n",
      "Train Epoch: 1442 [2400/2589 (93%)]\tLoss: 210.226715\n",
      "====> Epoch: 1442 Average train loss: 224.3235\n",
      "====> Epoch: 1442 Average test loss: 895.7112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1443 [0/2589 (0%)]\tLoss: 207.329697\n",
      "Train Epoch: 1443 [300/2589 (12%)]\tLoss: 162.775803\n",
      "Train Epoch: 1443 [600/2589 (23%)]\tLoss: 156.416809\n",
      "Train Epoch: 1443 [900/2589 (35%)]\tLoss: 197.777695\n",
      "Train Epoch: 1443 [1200/2589 (46%)]\tLoss: 170.818573\n",
      "Train Epoch: 1443 [1500/2589 (58%)]\tLoss: 173.576431\n",
      "Train Epoch: 1443 [1800/2589 (70%)]\tLoss: 178.435898\n",
      "Train Epoch: 1443 [2100/2589 (81%)]\tLoss: 205.304489\n",
      "Train Epoch: 1443 [2400/2589 (93%)]\tLoss: 282.929321\n",
      "====> Epoch: 1443 Average train loss: 213.4050\n",
      "====> Epoch: 1443 Average test loss: 906.9503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1444 [0/2589 (0%)]\tLoss: 161.642776\n",
      "Train Epoch: 1444 [300/2589 (12%)]\tLoss: 137.936447\n",
      "Train Epoch: 1444 [600/2589 (23%)]\tLoss: 189.192352\n",
      "Train Epoch: 1444 [900/2589 (35%)]\tLoss: 127.463600\n",
      "Train Epoch: 1444 [1200/2589 (46%)]\tLoss: 152.672028\n",
      "Train Epoch: 1444 [1500/2589 (58%)]\tLoss: 271.260986\n",
      "Train Epoch: 1444 [1800/2589 (70%)]\tLoss: 186.839584\n",
      "Train Epoch: 1444 [2100/2589 (81%)]\tLoss: 295.802277\n",
      "Train Epoch: 1444 [2400/2589 (93%)]\tLoss: 171.671738\n",
      "====> Epoch: 1444 Average train loss: 214.8202\n",
      "====> Epoch: 1444 Average test loss: 919.0355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1445 [0/2589 (0%)]\tLoss: 388.559174\n",
      "Train Epoch: 1445 [300/2589 (12%)]\tLoss: 259.378876\n",
      "Train Epoch: 1445 [600/2589 (23%)]\tLoss: 152.672455\n",
      "Train Epoch: 1445 [900/2589 (35%)]\tLoss: 208.738968\n",
      "Train Epoch: 1445 [1200/2589 (46%)]\tLoss: 276.209320\n",
      "Train Epoch: 1445 [1500/2589 (58%)]\tLoss: 230.818115\n",
      "Train Epoch: 1445 [1800/2589 (70%)]\tLoss: 190.455612\n",
      "Train Epoch: 1445 [2100/2589 (81%)]\tLoss: 273.607391\n",
      "Train Epoch: 1445 [2400/2589 (93%)]\tLoss: 164.780838\n",
      "====> Epoch: 1445 Average train loss: 227.5269\n",
      "====> Epoch: 1445 Average test loss: 915.5471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1446 [0/2589 (0%)]\tLoss: 108.627609\n",
      "Train Epoch: 1446 [300/2589 (12%)]\tLoss: 176.027740\n",
      "Train Epoch: 1446 [600/2589 (23%)]\tLoss: 215.525879\n",
      "Train Epoch: 1446 [900/2589 (35%)]\tLoss: 205.879593\n",
      "Train Epoch: 1446 [1200/2589 (46%)]\tLoss: 209.844528\n",
      "Train Epoch: 1446 [1500/2589 (58%)]\tLoss: 210.855331\n",
      "Train Epoch: 1446 [1800/2589 (70%)]\tLoss: 210.139511\n",
      "Train Epoch: 1446 [2100/2589 (81%)]\tLoss: 214.930771\n",
      "Train Epoch: 1446 [2400/2589 (93%)]\tLoss: 225.801666\n",
      "====> Epoch: 1446 Average train loss: 206.1232\n",
      "====> Epoch: 1446 Average test loss: 908.1426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1447 [0/2589 (0%)]\tLoss: 232.140198\n",
      "Train Epoch: 1447 [300/2589 (12%)]\tLoss: 227.488953\n",
      "Train Epoch: 1447 [600/2589 (23%)]\tLoss: 213.499893\n",
      "Train Epoch: 1447 [900/2589 (35%)]\tLoss: 186.612747\n",
      "Train Epoch: 1447 [1200/2589 (46%)]\tLoss: 184.257187\n",
      "Train Epoch: 1447 [1500/2589 (58%)]\tLoss: 126.818588\n",
      "Train Epoch: 1447 [1800/2589 (70%)]\tLoss: 278.568726\n",
      "Train Epoch: 1447 [2100/2589 (81%)]\tLoss: 394.597076\n",
      "Train Epoch: 1447 [2400/2589 (93%)]\tLoss: 179.679016\n",
      "====> Epoch: 1447 Average train loss: 211.3628\n",
      "====> Epoch: 1447 Average test loss: 920.5349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1448 [0/2589 (0%)]\tLoss: 185.480301\n",
      "Train Epoch: 1448 [300/2589 (12%)]\tLoss: 197.758301\n",
      "Train Epoch: 1448 [600/2589 (23%)]\tLoss: 168.472412\n",
      "Train Epoch: 1448 [900/2589 (35%)]\tLoss: 176.155106\n",
      "Train Epoch: 1448 [1200/2589 (46%)]\tLoss: 151.158554\n",
      "Train Epoch: 1448 [1500/2589 (58%)]\tLoss: 180.841888\n",
      "Train Epoch: 1448 [1800/2589 (70%)]\tLoss: 217.035736\n",
      "Train Epoch: 1448 [2100/2589 (81%)]\tLoss: 214.309860\n",
      "Train Epoch: 1448 [2400/2589 (93%)]\tLoss: 243.260406\n",
      "====> Epoch: 1448 Average train loss: 217.5109\n",
      "====> Epoch: 1448 Average test loss: 913.0712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1449 [0/2589 (0%)]\tLoss: 197.738297\n",
      "Train Epoch: 1449 [300/2589 (12%)]\tLoss: 237.835907\n",
      "Train Epoch: 1449 [600/2589 (23%)]\tLoss: 151.496643\n",
      "Train Epoch: 1449 [900/2589 (35%)]\tLoss: 221.754105\n",
      "Train Epoch: 1449 [1200/2589 (46%)]\tLoss: 253.284286\n",
      "Train Epoch: 1449 [1500/2589 (58%)]\tLoss: 153.667252\n",
      "Train Epoch: 1449 [1800/2589 (70%)]\tLoss: 243.428711\n",
      "Train Epoch: 1449 [2100/2589 (81%)]\tLoss: 145.402893\n",
      "Train Epoch: 1449 [2400/2589 (93%)]\tLoss: 172.675507\n",
      "====> Epoch: 1449 Average train loss: 206.5945\n",
      "====> Epoch: 1449 Average test loss: 921.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1450 [0/2589 (0%)]\tLoss: 163.937775\n",
      "Train Epoch: 1450 [300/2589 (12%)]\tLoss: 167.751816\n",
      "Train Epoch: 1450 [600/2589 (23%)]\tLoss: 158.795990\n",
      "Train Epoch: 1450 [900/2589 (35%)]\tLoss: 330.376495\n",
      "Train Epoch: 1450 [1200/2589 (46%)]\tLoss: 190.577682\n",
      "Train Epoch: 1450 [1500/2589 (58%)]\tLoss: 171.920837\n",
      "Train Epoch: 1450 [1800/2589 (70%)]\tLoss: 233.006927\n",
      "Train Epoch: 1450 [2100/2589 (81%)]\tLoss: 152.026932\n",
      "Train Epoch: 1450 [2400/2589 (93%)]\tLoss: 203.125290\n",
      "====> Epoch: 1450 Average train loss: 223.6500\n",
      "====> Epoch: 1450 Average test loss: 920.6451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1451 [0/2589 (0%)]\tLoss: 116.835365\n",
      "Train Epoch: 1451 [300/2589 (12%)]\tLoss: 170.964447\n",
      "Train Epoch: 1451 [600/2589 (23%)]\tLoss: 173.560211\n",
      "Train Epoch: 1451 [900/2589 (35%)]\tLoss: 171.056015\n",
      "Train Epoch: 1451 [1200/2589 (46%)]\tLoss: 167.849472\n",
      "Train Epoch: 1451 [1500/2589 (58%)]\tLoss: 236.273300\n",
      "Train Epoch: 1451 [1800/2589 (70%)]\tLoss: 175.896942\n",
      "Train Epoch: 1451 [2100/2589 (81%)]\tLoss: 242.098389\n",
      "Train Epoch: 1451 [2400/2589 (93%)]\tLoss: 173.130798\n",
      "====> Epoch: 1451 Average train loss: 203.9570\n",
      "====> Epoch: 1451 Average test loss: 897.6209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1452 [0/2589 (0%)]\tLoss: 357.934906\n",
      "Train Epoch: 1452 [300/2589 (12%)]\tLoss: 237.754211\n",
      "Train Epoch: 1452 [600/2589 (23%)]\tLoss: 381.284943\n",
      "Train Epoch: 1452 [900/2589 (35%)]\tLoss: 155.639053\n",
      "Train Epoch: 1452 [1200/2589 (46%)]\tLoss: 167.320953\n",
      "Train Epoch: 1452 [1500/2589 (58%)]\tLoss: 291.698151\n",
      "Train Epoch: 1452 [1800/2589 (70%)]\tLoss: 189.643982\n",
      "Train Epoch: 1452 [2100/2589 (81%)]\tLoss: 177.021378\n",
      "Train Epoch: 1452 [2400/2589 (93%)]\tLoss: 217.849762\n",
      "====> Epoch: 1452 Average train loss: 215.5532\n",
      "====> Epoch: 1452 Average test loss: 904.0662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1453 [0/2589 (0%)]\tLoss: 194.970322\n",
      "Train Epoch: 1453 [300/2589 (12%)]\tLoss: 421.596588\n",
      "Train Epoch: 1453 [600/2589 (23%)]\tLoss: 152.282364\n",
      "Train Epoch: 1453 [900/2589 (35%)]\tLoss: 201.034149\n",
      "Train Epoch: 1453 [1200/2589 (46%)]\tLoss: 223.278000\n",
      "Train Epoch: 1453 [1500/2589 (58%)]\tLoss: 165.613052\n",
      "Train Epoch: 1453 [1800/2589 (70%)]\tLoss: 216.393204\n",
      "Train Epoch: 1453 [2100/2589 (81%)]\tLoss: 155.834152\n",
      "Train Epoch: 1453 [2400/2589 (93%)]\tLoss: 200.971680\n",
      "====> Epoch: 1453 Average train loss: 210.1685\n",
      "====> Epoch: 1453 Average test loss: 894.1457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1454 [0/2589 (0%)]\tLoss: 192.156967\n",
      "Train Epoch: 1454 [300/2589 (12%)]\tLoss: 412.513184\n",
      "Train Epoch: 1454 [600/2589 (23%)]\tLoss: 237.520859\n",
      "Train Epoch: 1454 [900/2589 (35%)]\tLoss: 218.830399\n",
      "Train Epoch: 1454 [1200/2589 (46%)]\tLoss: 293.211426\n",
      "Train Epoch: 1454 [1500/2589 (58%)]\tLoss: 231.877701\n",
      "Train Epoch: 1454 [1800/2589 (70%)]\tLoss: 208.228455\n",
      "Train Epoch: 1454 [2100/2589 (81%)]\tLoss: 228.389709\n",
      "Train Epoch: 1454 [2400/2589 (93%)]\tLoss: 144.950241\n",
      "====> Epoch: 1454 Average train loss: 220.0118\n",
      "====> Epoch: 1454 Average test loss: 902.7946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1455 [0/2589 (0%)]\tLoss: 196.089188\n",
      "Train Epoch: 1455 [300/2589 (12%)]\tLoss: 210.736359\n",
      "Train Epoch: 1455 [600/2589 (23%)]\tLoss: 178.237885\n",
      "Train Epoch: 1455 [900/2589 (35%)]\tLoss: 221.847610\n",
      "Train Epoch: 1455 [1200/2589 (46%)]\tLoss: 144.661423\n",
      "Train Epoch: 1455 [1500/2589 (58%)]\tLoss: 234.709122\n",
      "Train Epoch: 1455 [1800/2589 (70%)]\tLoss: 162.475540\n",
      "Train Epoch: 1455 [2100/2589 (81%)]\tLoss: 235.170364\n",
      "Train Epoch: 1455 [2400/2589 (93%)]\tLoss: 163.785187\n",
      "====> Epoch: 1455 Average train loss: 208.1782\n",
      "====> Epoch: 1455 Average test loss: 912.7096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1456 [0/2589 (0%)]\tLoss: 152.015076\n",
      "Train Epoch: 1456 [300/2589 (12%)]\tLoss: 190.533691\n",
      "Train Epoch: 1456 [600/2589 (23%)]\tLoss: 162.455704\n",
      "Train Epoch: 1456 [900/2589 (35%)]\tLoss: 177.048126\n",
      "Train Epoch: 1456 [1200/2589 (46%)]\tLoss: 214.137436\n",
      "Train Epoch: 1456 [1500/2589 (58%)]\tLoss: 269.026550\n",
      "Train Epoch: 1456 [1800/2589 (70%)]\tLoss: 147.300919\n",
      "Train Epoch: 1456 [2100/2589 (81%)]\tLoss: 149.344254\n",
      "Train Epoch: 1456 [2400/2589 (93%)]\tLoss: 230.091660\n",
      "====> Epoch: 1456 Average train loss: 206.4258\n",
      "====> Epoch: 1456 Average test loss: 932.2389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1457 [0/2589 (0%)]\tLoss: 168.545792\n",
      "Train Epoch: 1457 [300/2589 (12%)]\tLoss: 174.085480\n",
      "Train Epoch: 1457 [600/2589 (23%)]\tLoss: 179.282608\n",
      "Train Epoch: 1457 [900/2589 (35%)]\tLoss: 339.951721\n",
      "Train Epoch: 1457 [1200/2589 (46%)]\tLoss: 163.975601\n",
      "Train Epoch: 1457 [1500/2589 (58%)]\tLoss: 132.832047\n",
      "Train Epoch: 1457 [1800/2589 (70%)]\tLoss: 245.068802\n",
      "Train Epoch: 1457 [2100/2589 (81%)]\tLoss: 242.539566\n",
      "Train Epoch: 1457 [2400/2589 (93%)]\tLoss: 231.806290\n",
      "====> Epoch: 1457 Average train loss: 214.7742\n",
      "====> Epoch: 1457 Average test loss: 914.6718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1458 [0/2589 (0%)]\tLoss: 233.735062\n",
      "Train Epoch: 1458 [300/2589 (12%)]\tLoss: 225.589767\n",
      "Train Epoch: 1458 [600/2589 (23%)]\tLoss: 151.777695\n",
      "Train Epoch: 1458 [900/2589 (35%)]\tLoss: 358.667053\n",
      "Train Epoch: 1458 [1200/2589 (46%)]\tLoss: 178.766357\n",
      "Train Epoch: 1458 [1500/2589 (58%)]\tLoss: 208.323959\n",
      "Train Epoch: 1458 [1800/2589 (70%)]\tLoss: 167.384125\n",
      "Train Epoch: 1458 [2100/2589 (81%)]\tLoss: 120.377441\n",
      "Train Epoch: 1458 [2400/2589 (93%)]\tLoss: 254.249588\n",
      "====> Epoch: 1458 Average train loss: 209.4740\n",
      "====> Epoch: 1458 Average test loss: 899.1043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1459 [0/2589 (0%)]\tLoss: 123.543159\n",
      "Train Epoch: 1459 [300/2589 (12%)]\tLoss: 192.678177\n",
      "Train Epoch: 1459 [600/2589 (23%)]\tLoss: 329.852905\n",
      "Train Epoch: 1459 [900/2589 (35%)]\tLoss: 194.845703\n",
      "Train Epoch: 1459 [1200/2589 (46%)]\tLoss: 175.902878\n",
      "Train Epoch: 1459 [1500/2589 (58%)]\tLoss: 258.339081\n",
      "Train Epoch: 1459 [1800/2589 (70%)]\tLoss: 158.771072\n",
      "Train Epoch: 1459 [2100/2589 (81%)]\tLoss: 330.026062\n",
      "Train Epoch: 1459 [2400/2589 (93%)]\tLoss: 241.369949\n",
      "====> Epoch: 1459 Average train loss: 213.7412\n",
      "====> Epoch: 1459 Average test loss: 903.8161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1460 [0/2589 (0%)]\tLoss: 221.671295\n",
      "Train Epoch: 1460 [300/2589 (12%)]\tLoss: 217.327560\n",
      "Train Epoch: 1460 [600/2589 (23%)]\tLoss: 267.134735\n",
      "Train Epoch: 1460 [900/2589 (35%)]\tLoss: 229.627869\n",
      "Train Epoch: 1460 [1200/2589 (46%)]\tLoss: 400.441254\n",
      "Train Epoch: 1460 [1500/2589 (58%)]\tLoss: 160.607025\n",
      "Train Epoch: 1460 [1800/2589 (70%)]\tLoss: 130.565186\n",
      "Train Epoch: 1460 [2100/2589 (81%)]\tLoss: 228.697769\n",
      "Train Epoch: 1460 [2400/2589 (93%)]\tLoss: 282.696808\n",
      "====> Epoch: 1460 Average train loss: 209.6780\n",
      "====> Epoch: 1460 Average test loss: 913.2316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1461 [0/2589 (0%)]\tLoss: 213.102158\n",
      "Train Epoch: 1461 [300/2589 (12%)]\tLoss: 193.558914\n",
      "Train Epoch: 1461 [600/2589 (23%)]\tLoss: 319.712280\n",
      "Train Epoch: 1461 [900/2589 (35%)]\tLoss: 359.668976\n",
      "Train Epoch: 1461 [1200/2589 (46%)]\tLoss: 236.725067\n",
      "Train Epoch: 1461 [1500/2589 (58%)]\tLoss: 303.266663\n",
      "Train Epoch: 1461 [1800/2589 (70%)]\tLoss: 168.785080\n",
      "Train Epoch: 1461 [2100/2589 (81%)]\tLoss: 295.989594\n",
      "Train Epoch: 1461 [2400/2589 (93%)]\tLoss: 236.563065\n",
      "====> Epoch: 1461 Average train loss: 223.6973\n",
      "====> Epoch: 1461 Average test loss: 911.9061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1462 [0/2589 (0%)]\tLoss: 202.315231\n",
      "Train Epoch: 1462 [300/2589 (12%)]\tLoss: 177.991135\n",
      "Train Epoch: 1462 [600/2589 (23%)]\tLoss: 147.432098\n",
      "Train Epoch: 1462 [900/2589 (35%)]\tLoss: 196.110016\n",
      "Train Epoch: 1462 [1200/2589 (46%)]\tLoss: 211.778214\n",
      "Train Epoch: 1462 [1500/2589 (58%)]\tLoss: 193.385254\n",
      "Train Epoch: 1462 [1800/2589 (70%)]\tLoss: 232.996735\n",
      "Train Epoch: 1462 [2100/2589 (81%)]\tLoss: 193.376892\n",
      "Train Epoch: 1462 [2400/2589 (93%)]\tLoss: 199.120438\n",
      "====> Epoch: 1462 Average train loss: 212.2250\n",
      "====> Epoch: 1462 Average test loss: 896.8035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1463 [0/2589 (0%)]\tLoss: 230.150970\n",
      "Train Epoch: 1463 [300/2589 (12%)]\tLoss: 208.460922\n",
      "Train Epoch: 1463 [600/2589 (23%)]\tLoss: 150.872910\n",
      "Train Epoch: 1463 [900/2589 (35%)]\tLoss: 164.877502\n",
      "Train Epoch: 1463 [1200/2589 (46%)]\tLoss: 160.475357\n",
      "Train Epoch: 1463 [1500/2589 (58%)]\tLoss: 189.631699\n",
      "Train Epoch: 1463 [1800/2589 (70%)]\tLoss: 218.727982\n",
      "Train Epoch: 1463 [2100/2589 (81%)]\tLoss: 226.438858\n",
      "Train Epoch: 1463 [2400/2589 (93%)]\tLoss: 177.338089\n",
      "====> Epoch: 1463 Average train loss: 206.2860\n",
      "====> Epoch: 1463 Average test loss: 902.3177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1464 [0/2589 (0%)]\tLoss: 159.332062\n",
      "Train Epoch: 1464 [300/2589 (12%)]\tLoss: 338.735687\n",
      "Train Epoch: 1464 [600/2589 (23%)]\tLoss: 218.605316\n",
      "Train Epoch: 1464 [900/2589 (35%)]\tLoss: 216.604584\n",
      "Train Epoch: 1464 [1200/2589 (46%)]\tLoss: 240.019669\n",
      "Train Epoch: 1464 [1500/2589 (58%)]\tLoss: 124.055740\n",
      "Train Epoch: 1464 [1800/2589 (70%)]\tLoss: 337.223633\n",
      "Train Epoch: 1464 [2100/2589 (81%)]\tLoss: 188.735779\n",
      "Train Epoch: 1464 [2400/2589 (93%)]\tLoss: 256.093811\n",
      "====> Epoch: 1464 Average train loss: 203.3076\n",
      "====> Epoch: 1464 Average test loss: 918.2004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1465 [0/2589 (0%)]\tLoss: 167.194901\n",
      "Train Epoch: 1465 [300/2589 (12%)]\tLoss: 118.600479\n",
      "Train Epoch: 1465 [600/2589 (23%)]\tLoss: 253.433350\n",
      "Train Epoch: 1465 [900/2589 (35%)]\tLoss: 247.354630\n",
      "Train Epoch: 1465 [1200/2589 (46%)]\tLoss: 206.781174\n",
      "Train Epoch: 1465 [1500/2589 (58%)]\tLoss: 197.123535\n",
      "Train Epoch: 1465 [1800/2589 (70%)]\tLoss: 118.913071\n",
      "Train Epoch: 1465 [2100/2589 (81%)]\tLoss: 228.884552\n",
      "Train Epoch: 1465 [2400/2589 (93%)]\tLoss: 303.295990\n",
      "====> Epoch: 1465 Average train loss: 203.8434\n",
      "====> Epoch: 1465 Average test loss: 908.3611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1466 [0/2589 (0%)]\tLoss: 223.820251\n",
      "Train Epoch: 1466 [300/2589 (12%)]\tLoss: 392.870087\n",
      "Train Epoch: 1466 [600/2589 (23%)]\tLoss: 174.473175\n",
      "Train Epoch: 1466 [900/2589 (35%)]\tLoss: 217.073212\n",
      "Train Epoch: 1466 [1200/2589 (46%)]\tLoss: 134.369980\n",
      "Train Epoch: 1466 [1500/2589 (58%)]\tLoss: 237.687119\n",
      "Train Epoch: 1466 [1800/2589 (70%)]\tLoss: 250.718430\n",
      "Train Epoch: 1466 [2100/2589 (81%)]\tLoss: 173.438995\n",
      "Train Epoch: 1466 [2400/2589 (93%)]\tLoss: 285.991638\n",
      "====> Epoch: 1466 Average train loss: 220.6085\n",
      "====> Epoch: 1466 Average test loss: 910.4421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1467 [0/2589 (0%)]\tLoss: 165.206528\n",
      "Train Epoch: 1467 [300/2589 (12%)]\tLoss: 180.506638\n",
      "Train Epoch: 1467 [600/2589 (23%)]\tLoss: 242.032715\n",
      "Train Epoch: 1467 [900/2589 (35%)]\tLoss: 203.663330\n",
      "Train Epoch: 1467 [1200/2589 (46%)]\tLoss: 227.314362\n",
      "Train Epoch: 1467 [1500/2589 (58%)]\tLoss: 329.352112\n",
      "Train Epoch: 1467 [1800/2589 (70%)]\tLoss: 152.119797\n",
      "Train Epoch: 1467 [2100/2589 (81%)]\tLoss: 125.150864\n",
      "Train Epoch: 1467 [2400/2589 (93%)]\tLoss: 233.305038\n",
      "====> Epoch: 1467 Average train loss: 201.5981\n",
      "====> Epoch: 1467 Average test loss: 901.2969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1468 [0/2589 (0%)]\tLoss: 237.577667\n",
      "Train Epoch: 1468 [300/2589 (12%)]\tLoss: 182.403824\n",
      "Train Epoch: 1468 [600/2589 (23%)]\tLoss: 174.825836\n",
      "Train Epoch: 1468 [900/2589 (35%)]\tLoss: 164.267075\n",
      "Train Epoch: 1468 [1200/2589 (46%)]\tLoss: 175.972794\n",
      "Train Epoch: 1468 [1500/2589 (58%)]\tLoss: 224.767868\n",
      "Train Epoch: 1468 [1800/2589 (70%)]\tLoss: 197.090576\n",
      "Train Epoch: 1468 [2100/2589 (81%)]\tLoss: 237.838806\n",
      "Train Epoch: 1468 [2400/2589 (93%)]\tLoss: 194.122864\n",
      "====> Epoch: 1468 Average train loss: 214.5497\n",
      "====> Epoch: 1468 Average test loss: 900.1143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1469 [0/2589 (0%)]\tLoss: 164.164032\n",
      "Train Epoch: 1469 [300/2589 (12%)]\tLoss: 195.972717\n",
      "Train Epoch: 1469 [600/2589 (23%)]\tLoss: 186.977356\n",
      "Train Epoch: 1469 [900/2589 (35%)]\tLoss: 191.540924\n",
      "Train Epoch: 1469 [1200/2589 (46%)]\tLoss: 212.229889\n",
      "Train Epoch: 1469 [1500/2589 (58%)]\tLoss: 244.288223\n",
      "Train Epoch: 1469 [1800/2589 (70%)]\tLoss: 151.867523\n",
      "Train Epoch: 1469 [2100/2589 (81%)]\tLoss: 155.196091\n",
      "Train Epoch: 1469 [2400/2589 (93%)]\tLoss: 303.233704\n",
      "====> Epoch: 1469 Average train loss: 218.0797\n",
      "====> Epoch: 1469 Average test loss: 920.6897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1470 [0/2589 (0%)]\tLoss: 177.722931\n",
      "Train Epoch: 1470 [300/2589 (12%)]\tLoss: 178.358688\n",
      "Train Epoch: 1470 [600/2589 (23%)]\tLoss: 218.150650\n",
      "Train Epoch: 1470 [900/2589 (35%)]\tLoss: 293.251953\n",
      "Train Epoch: 1470 [1200/2589 (46%)]\tLoss: 204.236618\n",
      "Train Epoch: 1470 [1500/2589 (58%)]\tLoss: 223.049973\n",
      "Train Epoch: 1470 [1800/2589 (70%)]\tLoss: 175.682068\n",
      "Train Epoch: 1470 [2100/2589 (81%)]\tLoss: 204.305038\n",
      "Train Epoch: 1470 [2400/2589 (93%)]\tLoss: 182.424576\n",
      "====> Epoch: 1470 Average train loss: 213.4843\n",
      "====> Epoch: 1470 Average test loss: 915.8486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1471 [0/2589 (0%)]\tLoss: 184.863007\n",
      "Train Epoch: 1471 [300/2589 (12%)]\tLoss: 255.820175\n",
      "Train Epoch: 1471 [600/2589 (23%)]\tLoss: 192.525543\n",
      "Train Epoch: 1471 [900/2589 (35%)]\tLoss: 232.231552\n",
      "Train Epoch: 1471 [1200/2589 (46%)]\tLoss: 182.138809\n",
      "Train Epoch: 1471 [1500/2589 (58%)]\tLoss: 235.100845\n",
      "Train Epoch: 1471 [1800/2589 (70%)]\tLoss: 168.774017\n",
      "Train Epoch: 1471 [2100/2589 (81%)]\tLoss: 229.741745\n",
      "Train Epoch: 1471 [2400/2589 (93%)]\tLoss: 216.425140\n",
      "====> Epoch: 1471 Average train loss: 214.4830\n",
      "====> Epoch: 1471 Average test loss: 914.7524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1472 [0/2589 (0%)]\tLoss: 205.941315\n",
      "Train Epoch: 1472 [300/2589 (12%)]\tLoss: 211.190170\n",
      "Train Epoch: 1472 [600/2589 (23%)]\tLoss: 149.814697\n",
      "Train Epoch: 1472 [900/2589 (35%)]\tLoss: 197.590607\n",
      "Train Epoch: 1472 [1200/2589 (46%)]\tLoss: 189.159775\n",
      "Train Epoch: 1472 [1500/2589 (58%)]\tLoss: 149.257263\n",
      "Train Epoch: 1472 [1800/2589 (70%)]\tLoss: 175.196091\n",
      "Train Epoch: 1472 [2100/2589 (81%)]\tLoss: 223.596329\n",
      "Train Epoch: 1472 [2400/2589 (93%)]\tLoss: 179.195862\n",
      "====> Epoch: 1472 Average train loss: 210.1167\n",
      "====> Epoch: 1472 Average test loss: 917.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1473 [0/2589 (0%)]\tLoss: 216.153091\n",
      "Train Epoch: 1473 [300/2589 (12%)]\tLoss: 170.079727\n",
      "Train Epoch: 1473 [600/2589 (23%)]\tLoss: 204.197296\n",
      "Train Epoch: 1473 [900/2589 (35%)]\tLoss: 237.577179\n",
      "Train Epoch: 1473 [1200/2589 (46%)]\tLoss: 182.565430\n",
      "Train Epoch: 1473 [1500/2589 (58%)]\tLoss: 331.429260\n",
      "Train Epoch: 1473 [1800/2589 (70%)]\tLoss: 192.235382\n",
      "Train Epoch: 1473 [2100/2589 (81%)]\tLoss: 213.030014\n",
      "Train Epoch: 1473 [2400/2589 (93%)]\tLoss: 226.373062\n",
      "====> Epoch: 1473 Average train loss: 212.9797\n",
      "====> Epoch: 1473 Average test loss: 919.6091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1474 [0/2589 (0%)]\tLoss: 262.047821\n",
      "Train Epoch: 1474 [300/2589 (12%)]\tLoss: 175.303253\n",
      "Train Epoch: 1474 [600/2589 (23%)]\tLoss: 156.285431\n",
      "Train Epoch: 1474 [900/2589 (35%)]\tLoss: 227.755157\n",
      "Train Epoch: 1474 [1200/2589 (46%)]\tLoss: 178.332428\n",
      "Train Epoch: 1474 [1500/2589 (58%)]\tLoss: 123.897697\n",
      "Train Epoch: 1474 [1800/2589 (70%)]\tLoss: 215.396683\n",
      "Train Epoch: 1474 [2100/2589 (81%)]\tLoss: 216.693359\n",
      "Train Epoch: 1474 [2400/2589 (93%)]\tLoss: 202.536041\n",
      "====> Epoch: 1474 Average train loss: 211.1454\n",
      "====> Epoch: 1474 Average test loss: 905.6671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1475 [0/2589 (0%)]\tLoss: 214.467499\n",
      "Train Epoch: 1475 [300/2589 (12%)]\tLoss: 238.310074\n",
      "Train Epoch: 1475 [600/2589 (23%)]\tLoss: 248.192719\n",
      "Train Epoch: 1475 [900/2589 (35%)]\tLoss: 130.928864\n",
      "Train Epoch: 1475 [1200/2589 (46%)]\tLoss: 156.639587\n",
      "Train Epoch: 1475 [1500/2589 (58%)]\tLoss: 243.714142\n",
      "Train Epoch: 1475 [1800/2589 (70%)]\tLoss: 248.468719\n",
      "Train Epoch: 1475 [2100/2589 (81%)]\tLoss: 260.230682\n",
      "Train Epoch: 1475 [2400/2589 (93%)]\tLoss: 437.244690\n",
      "====> Epoch: 1475 Average train loss: 210.2318\n",
      "====> Epoch: 1475 Average test loss: 921.0486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1476 [0/2589 (0%)]\tLoss: 246.610809\n",
      "Train Epoch: 1476 [300/2589 (12%)]\tLoss: 162.035919\n",
      "Train Epoch: 1476 [600/2589 (23%)]\tLoss: 148.000946\n",
      "Train Epoch: 1476 [900/2589 (35%)]\tLoss: 192.849777\n",
      "Train Epoch: 1476 [1200/2589 (46%)]\tLoss: 152.576431\n",
      "Train Epoch: 1476 [1500/2589 (58%)]\tLoss: 178.081604\n",
      "Train Epoch: 1476 [1800/2589 (70%)]\tLoss: 177.170868\n",
      "Train Epoch: 1476 [2100/2589 (81%)]\tLoss: 191.266327\n",
      "Train Epoch: 1476 [2400/2589 (93%)]\tLoss: 166.907516\n",
      "====> Epoch: 1476 Average train loss: 210.2001\n",
      "====> Epoch: 1476 Average test loss: 930.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1477 [0/2589 (0%)]\tLoss: 203.487473\n",
      "Train Epoch: 1477 [300/2589 (12%)]\tLoss: 255.950821\n",
      "Train Epoch: 1477 [600/2589 (23%)]\tLoss: 182.950775\n",
      "Train Epoch: 1477 [900/2589 (35%)]\tLoss: 167.949356\n",
      "Train Epoch: 1477 [1200/2589 (46%)]\tLoss: 223.588669\n",
      "Train Epoch: 1477 [1500/2589 (58%)]\tLoss: 190.073547\n",
      "Train Epoch: 1477 [1800/2589 (70%)]\tLoss: 252.186981\n",
      "Train Epoch: 1477 [2100/2589 (81%)]\tLoss: 236.030594\n",
      "Train Epoch: 1477 [2400/2589 (93%)]\tLoss: 165.362503\n",
      "====> Epoch: 1477 Average train loss: 226.7930\n",
      "====> Epoch: 1477 Average test loss: 908.4858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1478 [0/2589 (0%)]\tLoss: 236.752365\n",
      "Train Epoch: 1478 [300/2589 (12%)]\tLoss: 230.195007\n",
      "Train Epoch: 1478 [600/2589 (23%)]\tLoss: 149.778214\n",
      "Train Epoch: 1478 [900/2589 (35%)]\tLoss: 175.990631\n",
      "Train Epoch: 1478 [1200/2589 (46%)]\tLoss: 188.609024\n",
      "Train Epoch: 1478 [1500/2589 (58%)]\tLoss: 216.783005\n",
      "Train Epoch: 1478 [1800/2589 (70%)]\tLoss: 236.262939\n",
      "Train Epoch: 1478 [2100/2589 (81%)]\tLoss: 131.809479\n",
      "Train Epoch: 1478 [2400/2589 (93%)]\tLoss: 195.972656\n",
      "====> Epoch: 1478 Average train loss: 206.7516\n",
      "====> Epoch: 1478 Average test loss: 920.5707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1479 [0/2589 (0%)]\tLoss: 191.815628\n",
      "Train Epoch: 1479 [300/2589 (12%)]\tLoss: 182.668716\n",
      "Train Epoch: 1479 [600/2589 (23%)]\tLoss: 218.738022\n",
      "Train Epoch: 1479 [900/2589 (35%)]\tLoss: 136.503922\n",
      "Train Epoch: 1479 [1200/2589 (46%)]\tLoss: 189.497772\n",
      "Train Epoch: 1479 [1500/2589 (58%)]\tLoss: 203.371414\n",
      "Train Epoch: 1479 [1800/2589 (70%)]\tLoss: 332.783386\n",
      "Train Epoch: 1479 [2100/2589 (81%)]\tLoss: 123.976646\n",
      "Train Epoch: 1479 [2400/2589 (93%)]\tLoss: 217.275070\n",
      "====> Epoch: 1479 Average train loss: 207.7157\n",
      "====> Epoch: 1479 Average test loss: 901.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1480 [0/2589 (0%)]\tLoss: 151.991638\n",
      "Train Epoch: 1480 [300/2589 (12%)]\tLoss: 187.921127\n",
      "Train Epoch: 1480 [600/2589 (23%)]\tLoss: 210.285919\n",
      "Train Epoch: 1480 [900/2589 (35%)]\tLoss: 210.291733\n",
      "Train Epoch: 1480 [1200/2589 (46%)]\tLoss: 293.027557\n",
      "Train Epoch: 1480 [1500/2589 (58%)]\tLoss: 220.042068\n",
      "Train Epoch: 1480 [1800/2589 (70%)]\tLoss: 184.339157\n",
      "Train Epoch: 1480 [2100/2589 (81%)]\tLoss: 188.287125\n",
      "Train Epoch: 1480 [2400/2589 (93%)]\tLoss: 174.223526\n",
      "====> Epoch: 1480 Average train loss: 208.1644\n",
      "====> Epoch: 1480 Average test loss: 915.2607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1481 [0/2589 (0%)]\tLoss: 178.154556\n",
      "Train Epoch: 1481 [300/2589 (12%)]\tLoss: 311.852966\n",
      "Train Epoch: 1481 [600/2589 (23%)]\tLoss: 220.875031\n",
      "Train Epoch: 1481 [900/2589 (35%)]\tLoss: 272.333984\n",
      "Train Epoch: 1481 [1200/2589 (46%)]\tLoss: 176.128067\n",
      "Train Epoch: 1481 [1500/2589 (58%)]\tLoss: 181.780823\n",
      "Train Epoch: 1481 [1800/2589 (70%)]\tLoss: 341.204010\n",
      "Train Epoch: 1481 [2100/2589 (81%)]\tLoss: 254.275528\n",
      "Train Epoch: 1481 [2400/2589 (93%)]\tLoss: 313.569733\n",
      "====> Epoch: 1481 Average train loss: 210.6750\n",
      "====> Epoch: 1481 Average test loss: 924.0295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1482 [0/2589 (0%)]\tLoss: 130.369232\n",
      "Train Epoch: 1482 [300/2589 (12%)]\tLoss: 129.464767\n",
      "Train Epoch: 1482 [600/2589 (23%)]\tLoss: 323.251099\n",
      "Train Epoch: 1482 [900/2589 (35%)]\tLoss: 211.865814\n",
      "Train Epoch: 1482 [1200/2589 (46%)]\tLoss: 183.064194\n",
      "Train Epoch: 1482 [1500/2589 (58%)]\tLoss: 187.689301\n",
      "Train Epoch: 1482 [1800/2589 (70%)]\tLoss: 183.711990\n",
      "Train Epoch: 1482 [2100/2589 (81%)]\tLoss: 159.879166\n",
      "Train Epoch: 1482 [2400/2589 (93%)]\tLoss: 161.061234\n",
      "====> Epoch: 1482 Average train loss: 210.4252\n",
      "====> Epoch: 1482 Average test loss: 927.1725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1483 [0/2589 (0%)]\tLoss: 283.726624\n",
      "Train Epoch: 1483 [300/2589 (12%)]\tLoss: 171.226868\n",
      "Train Epoch: 1483 [600/2589 (23%)]\tLoss: 203.963837\n",
      "Train Epoch: 1483 [900/2589 (35%)]\tLoss: 225.954193\n",
      "Train Epoch: 1483 [1200/2589 (46%)]\tLoss: 208.523392\n",
      "Train Epoch: 1483 [1500/2589 (58%)]\tLoss: 294.790558\n",
      "Train Epoch: 1483 [1800/2589 (70%)]\tLoss: 189.599716\n",
      "Train Epoch: 1483 [2100/2589 (81%)]\tLoss: 147.162506\n",
      "Train Epoch: 1483 [2400/2589 (93%)]\tLoss: 253.454391\n",
      "====> Epoch: 1483 Average train loss: 216.4605\n",
      "====> Epoch: 1483 Average test loss: 913.4595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1484 [0/2589 (0%)]\tLoss: 180.894470\n",
      "Train Epoch: 1484 [300/2589 (12%)]\tLoss: 174.628342\n",
      "Train Epoch: 1484 [600/2589 (23%)]\tLoss: 225.383041\n",
      "Train Epoch: 1484 [900/2589 (35%)]\tLoss: 197.225388\n",
      "Train Epoch: 1484 [1200/2589 (46%)]\tLoss: 171.784653\n",
      "Train Epoch: 1484 [1500/2589 (58%)]\tLoss: 105.018105\n",
      "Train Epoch: 1484 [1800/2589 (70%)]\tLoss: 216.556244\n",
      "Train Epoch: 1484 [2100/2589 (81%)]\tLoss: 200.833923\n",
      "Train Epoch: 1484 [2400/2589 (93%)]\tLoss: 250.067184\n",
      "====> Epoch: 1484 Average train loss: 196.2788\n",
      "====> Epoch: 1484 Average test loss: 925.6933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1485 [0/2589 (0%)]\tLoss: 160.760544\n",
      "Train Epoch: 1485 [300/2589 (12%)]\tLoss: 244.206741\n",
      "Train Epoch: 1485 [600/2589 (23%)]\tLoss: 221.351105\n",
      "Train Epoch: 1485 [900/2589 (35%)]\tLoss: 163.164093\n",
      "Train Epoch: 1485 [1200/2589 (46%)]\tLoss: 184.348389\n",
      "Train Epoch: 1485 [1500/2589 (58%)]\tLoss: 208.779129\n",
      "Train Epoch: 1485 [1800/2589 (70%)]\tLoss: 194.495636\n",
      "Train Epoch: 1485 [2100/2589 (81%)]\tLoss: 217.614487\n",
      "Train Epoch: 1485 [2400/2589 (93%)]\tLoss: 133.131577\n",
      "====> Epoch: 1485 Average train loss: 207.3996\n",
      "====> Epoch: 1485 Average test loss: 917.5065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1486 [0/2589 (0%)]\tLoss: 194.766312\n",
      "Train Epoch: 1486 [300/2589 (12%)]\tLoss: 177.327835\n",
      "Train Epoch: 1486 [600/2589 (23%)]\tLoss: 538.182922\n",
      "Train Epoch: 1486 [900/2589 (35%)]\tLoss: 183.209335\n",
      "Train Epoch: 1486 [1200/2589 (46%)]\tLoss: 164.155090\n",
      "Train Epoch: 1486 [1500/2589 (58%)]\tLoss: 157.693985\n",
      "Train Epoch: 1486 [1800/2589 (70%)]\tLoss: 150.429535\n",
      "Train Epoch: 1486 [2100/2589 (81%)]\tLoss: 181.840607\n",
      "Train Epoch: 1486 [2400/2589 (93%)]\tLoss: 248.587784\n",
      "====> Epoch: 1486 Average train loss: 202.7559\n",
      "====> Epoch: 1486 Average test loss: 904.2228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1487 [0/2589 (0%)]\tLoss: 270.876495\n",
      "Train Epoch: 1487 [300/2589 (12%)]\tLoss: 142.175858\n",
      "Train Epoch: 1487 [600/2589 (23%)]\tLoss: 194.882263\n",
      "Train Epoch: 1487 [900/2589 (35%)]\tLoss: 165.171890\n",
      "Train Epoch: 1487 [1200/2589 (46%)]\tLoss: 172.739807\n",
      "Train Epoch: 1487 [1500/2589 (58%)]\tLoss: 277.641876\n",
      "Train Epoch: 1487 [1800/2589 (70%)]\tLoss: 220.232712\n",
      "Train Epoch: 1487 [2100/2589 (81%)]\tLoss: 203.791245\n",
      "Train Epoch: 1487 [2400/2589 (93%)]\tLoss: 243.519012\n",
      "====> Epoch: 1487 Average train loss: 203.5481\n",
      "====> Epoch: 1487 Average test loss: 912.7736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1488 [0/2589 (0%)]\tLoss: 148.339188\n",
      "Train Epoch: 1488 [300/2589 (12%)]\tLoss: 227.805603\n",
      "Train Epoch: 1488 [600/2589 (23%)]\tLoss: 195.040710\n",
      "Train Epoch: 1488 [900/2589 (35%)]\tLoss: 198.997086\n",
      "Train Epoch: 1488 [1200/2589 (46%)]\tLoss: 156.965378\n",
      "Train Epoch: 1488 [1500/2589 (58%)]\tLoss: 148.883820\n",
      "Train Epoch: 1488 [1800/2589 (70%)]\tLoss: 157.443344\n",
      "Train Epoch: 1488 [2100/2589 (81%)]\tLoss: 205.817001\n",
      "Train Epoch: 1488 [2400/2589 (93%)]\tLoss: 202.291962\n",
      "====> Epoch: 1488 Average train loss: 201.0296\n",
      "====> Epoch: 1488 Average test loss: 903.7809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1489 [0/2589 (0%)]\tLoss: 139.712860\n",
      "Train Epoch: 1489 [300/2589 (12%)]\tLoss: 177.969803\n",
      "Train Epoch: 1489 [600/2589 (23%)]\tLoss: 188.703659\n",
      "Train Epoch: 1489 [900/2589 (35%)]\tLoss: 193.148529\n",
      "Train Epoch: 1489 [1200/2589 (46%)]\tLoss: 258.061646\n",
      "Train Epoch: 1489 [1500/2589 (58%)]\tLoss: 192.000931\n",
      "Train Epoch: 1489 [1800/2589 (70%)]\tLoss: 192.009552\n",
      "Train Epoch: 1489 [2100/2589 (81%)]\tLoss: 177.434250\n",
      "Train Epoch: 1489 [2400/2589 (93%)]\tLoss: 176.778824\n",
      "====> Epoch: 1489 Average train loss: 204.6097\n",
      "====> Epoch: 1489 Average test loss: 922.4877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1490 [0/2589 (0%)]\tLoss: 305.723602\n",
      "Train Epoch: 1490 [300/2589 (12%)]\tLoss: 198.906479\n",
      "Train Epoch: 1490 [600/2589 (23%)]\tLoss: 223.831497\n",
      "Train Epoch: 1490 [900/2589 (35%)]\tLoss: 161.357925\n",
      "Train Epoch: 1490 [1200/2589 (46%)]\tLoss: 347.766174\n",
      "Train Epoch: 1490 [1500/2589 (58%)]\tLoss: 268.543060\n",
      "Train Epoch: 1490 [1800/2589 (70%)]\tLoss: 330.641541\n",
      "Train Epoch: 1490 [2100/2589 (81%)]\tLoss: 234.137009\n",
      "Train Epoch: 1490 [2400/2589 (93%)]\tLoss: 228.329422\n",
      "====> Epoch: 1490 Average train loss: 219.0980\n",
      "====> Epoch: 1490 Average test loss: 915.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1491 [0/2589 (0%)]\tLoss: 135.397568\n",
      "Train Epoch: 1491 [300/2589 (12%)]\tLoss: 219.364059\n",
      "Train Epoch: 1491 [600/2589 (23%)]\tLoss: 411.631287\n",
      "Train Epoch: 1491 [900/2589 (35%)]\tLoss: 189.866760\n",
      "Train Epoch: 1491 [1200/2589 (46%)]\tLoss: 253.635086\n",
      "Train Epoch: 1491 [1500/2589 (58%)]\tLoss: 217.146149\n",
      "Train Epoch: 1491 [1800/2589 (70%)]\tLoss: 198.028259\n",
      "Train Epoch: 1491 [2100/2589 (81%)]\tLoss: 317.349304\n",
      "Train Epoch: 1491 [2400/2589 (93%)]\tLoss: 223.737244\n",
      "====> Epoch: 1491 Average train loss: 212.8538\n",
      "====> Epoch: 1491 Average test loss: 916.6981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1492 [0/2589 (0%)]\tLoss: 175.874863\n",
      "Train Epoch: 1492 [300/2589 (12%)]\tLoss: 205.708832\n",
      "Train Epoch: 1492 [600/2589 (23%)]\tLoss: 190.879639\n",
      "Train Epoch: 1492 [900/2589 (35%)]\tLoss: 203.756058\n",
      "Train Epoch: 1492 [1200/2589 (46%)]\tLoss: 248.789642\n",
      "Train Epoch: 1492 [1500/2589 (58%)]\tLoss: 187.877274\n",
      "Train Epoch: 1492 [1800/2589 (70%)]\tLoss: 198.949844\n",
      "Train Epoch: 1492 [2100/2589 (81%)]\tLoss: 156.566910\n",
      "Train Epoch: 1492 [2400/2589 (93%)]\tLoss: 222.776138\n",
      "====> Epoch: 1492 Average train loss: 200.2287\n",
      "====> Epoch: 1492 Average test loss: 911.8558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1493 [0/2589 (0%)]\tLoss: 158.489746\n",
      "Train Epoch: 1493 [300/2589 (12%)]\tLoss: 251.322830\n",
      "Train Epoch: 1493 [600/2589 (23%)]\tLoss: 175.479080\n",
      "Train Epoch: 1493 [900/2589 (35%)]\tLoss: 210.488251\n",
      "Train Epoch: 1493 [1200/2589 (46%)]\tLoss: 274.123047\n",
      "Train Epoch: 1493 [1500/2589 (58%)]\tLoss: 173.927246\n",
      "Train Epoch: 1493 [1800/2589 (70%)]\tLoss: 250.490204\n",
      "Train Epoch: 1493 [2100/2589 (81%)]\tLoss: 178.635330\n",
      "Train Epoch: 1493 [2400/2589 (93%)]\tLoss: 160.562180\n",
      "====> Epoch: 1493 Average train loss: 209.9827\n",
      "====> Epoch: 1493 Average test loss: 909.6863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1494 [0/2589 (0%)]\tLoss: 137.773346\n",
      "Train Epoch: 1494 [300/2589 (12%)]\tLoss: 196.222366\n",
      "Train Epoch: 1494 [600/2589 (23%)]\tLoss: 173.982925\n",
      "Train Epoch: 1494 [900/2589 (35%)]\tLoss: 168.874054\n",
      "Train Epoch: 1494 [1200/2589 (46%)]\tLoss: 281.617279\n",
      "Train Epoch: 1494 [1500/2589 (58%)]\tLoss: 211.136734\n",
      "Train Epoch: 1494 [1800/2589 (70%)]\tLoss: 139.489029\n",
      "Train Epoch: 1494 [2100/2589 (81%)]\tLoss: 161.559738\n",
      "Train Epoch: 1494 [2400/2589 (93%)]\tLoss: 115.704277\n",
      "====> Epoch: 1494 Average train loss: 202.1095\n",
      "====> Epoch: 1494 Average test loss: 903.3013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1495 [0/2589 (0%)]\tLoss: 252.680634\n",
      "Train Epoch: 1495 [300/2589 (12%)]\tLoss: 182.994659\n",
      "Train Epoch: 1495 [600/2589 (23%)]\tLoss: 151.579117\n",
      "Train Epoch: 1495 [900/2589 (35%)]\tLoss: 158.975662\n",
      "Train Epoch: 1495 [1200/2589 (46%)]\tLoss: 226.957870\n",
      "Train Epoch: 1495 [1500/2589 (58%)]\tLoss: 309.183594\n",
      "Train Epoch: 1495 [1800/2589 (70%)]\tLoss: 154.947662\n",
      "Train Epoch: 1495 [2100/2589 (81%)]\tLoss: 184.550613\n",
      "Train Epoch: 1495 [2400/2589 (93%)]\tLoss: 247.957367\n",
      "====> Epoch: 1495 Average train loss: 222.2645\n",
      "====> Epoch: 1495 Average test loss: 913.1531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1496 [0/2589 (0%)]\tLoss: 183.014267\n",
      "Train Epoch: 1496 [300/2589 (12%)]\tLoss: 219.136093\n",
      "Train Epoch: 1496 [600/2589 (23%)]\tLoss: 168.163574\n",
      "Train Epoch: 1496 [900/2589 (35%)]\tLoss: 148.961197\n",
      "Train Epoch: 1496 [1200/2589 (46%)]\tLoss: 175.521759\n",
      "Train Epoch: 1496 [1500/2589 (58%)]\tLoss: 176.394272\n",
      "Train Epoch: 1496 [1800/2589 (70%)]\tLoss: 284.636536\n",
      "Train Epoch: 1496 [2100/2589 (81%)]\tLoss: 241.777374\n",
      "Train Epoch: 1496 [2400/2589 (93%)]\tLoss: 152.264435\n",
      "====> Epoch: 1496 Average train loss: 226.0839\n",
      "====> Epoch: 1496 Average test loss: 908.4496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1497 [0/2589 (0%)]\tLoss: 167.377548\n",
      "Train Epoch: 1497 [300/2589 (12%)]\tLoss: 146.438431\n",
      "Train Epoch: 1497 [600/2589 (23%)]\tLoss: 160.833801\n",
      "Train Epoch: 1497 [900/2589 (35%)]\tLoss: 152.546860\n",
      "Train Epoch: 1497 [1200/2589 (46%)]\tLoss: 152.947189\n",
      "Train Epoch: 1497 [1500/2589 (58%)]\tLoss: 175.601746\n",
      "Train Epoch: 1497 [1800/2589 (70%)]\tLoss: 163.920441\n",
      "Train Epoch: 1497 [2100/2589 (81%)]\tLoss: 222.257843\n",
      "Train Epoch: 1497 [2400/2589 (93%)]\tLoss: 138.120056\n",
      "====> Epoch: 1497 Average train loss: 216.0336\n",
      "====> Epoch: 1497 Average test loss: 898.7261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1498 [0/2589 (0%)]\tLoss: 245.715607\n",
      "Train Epoch: 1498 [300/2589 (12%)]\tLoss: 210.636658\n",
      "Train Epoch: 1498 [600/2589 (23%)]\tLoss: 249.637268\n",
      "Train Epoch: 1498 [900/2589 (35%)]\tLoss: 225.060974\n",
      "Train Epoch: 1498 [1200/2589 (46%)]\tLoss: 178.046188\n",
      "Train Epoch: 1498 [1500/2589 (58%)]\tLoss: 198.749344\n",
      "Train Epoch: 1498 [1800/2589 (70%)]\tLoss: 310.038574\n",
      "Train Epoch: 1498 [2100/2589 (81%)]\tLoss: 363.197327\n",
      "Train Epoch: 1498 [2400/2589 (93%)]\tLoss: 200.624985\n",
      "====> Epoch: 1498 Average train loss: 217.4845\n",
      "====> Epoch: 1498 Average test loss: 911.8613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1499 [0/2589 (0%)]\tLoss: 201.716492\n",
      "Train Epoch: 1499 [300/2589 (12%)]\tLoss: 157.289413\n",
      "Train Epoch: 1499 [600/2589 (23%)]\tLoss: 206.107620\n",
      "Train Epoch: 1499 [900/2589 (35%)]\tLoss: 229.403168\n",
      "Train Epoch: 1499 [1200/2589 (46%)]\tLoss: 218.128616\n",
      "Train Epoch: 1499 [1500/2589 (58%)]\tLoss: 206.076416\n",
      "Train Epoch: 1499 [1800/2589 (70%)]\tLoss: 213.400360\n",
      "Train Epoch: 1499 [2100/2589 (81%)]\tLoss: 200.170151\n",
      "Train Epoch: 1499 [2400/2589 (93%)]\tLoss: 151.734085\n",
      "====> Epoch: 1499 Average train loss: 194.8324\n",
      "====> Epoch: 1499 Average test loss: 910.7343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1500 [0/2589 (0%)]\tLoss: 142.474380\n",
      "Train Epoch: 1500 [300/2589 (12%)]\tLoss: 296.355865\n",
      "Train Epoch: 1500 [600/2589 (23%)]\tLoss: 246.842133\n",
      "Train Epoch: 1500 [900/2589 (35%)]\tLoss: 199.440750\n",
      "Train Epoch: 1500 [1200/2589 (46%)]\tLoss: 151.390564\n",
      "Train Epoch: 1500 [1500/2589 (58%)]\tLoss: 216.397690\n",
      "Train Epoch: 1500 [1800/2589 (70%)]\tLoss: 140.299667\n",
      "Train Epoch: 1500 [2100/2589 (81%)]\tLoss: 188.922104\n",
      "Train Epoch: 1500 [2400/2589 (93%)]\tLoss: 170.845993\n",
      "====> Epoch: 1500 Average train loss: 204.0083\n",
      "====> Epoch: 1500 Average test loss: 911.3395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1501 [0/2589 (0%)]\tLoss: 179.100250\n",
      "Train Epoch: 1501 [300/2589 (12%)]\tLoss: 157.739700\n",
      "Train Epoch: 1501 [600/2589 (23%)]\tLoss: 195.463608\n",
      "Train Epoch: 1501 [900/2589 (35%)]\tLoss: 252.205994\n",
      "Train Epoch: 1501 [1200/2589 (46%)]\tLoss: 250.258163\n",
      "Train Epoch: 1501 [1500/2589 (58%)]\tLoss: 158.849960\n",
      "Train Epoch: 1501 [1800/2589 (70%)]\tLoss: 197.597366\n",
      "Train Epoch: 1501 [2100/2589 (81%)]\tLoss: 172.647247\n",
      "Train Epoch: 1501 [2400/2589 (93%)]\tLoss: 259.029419\n",
      "====> Epoch: 1501 Average train loss: 212.8944\n",
      "====> Epoch: 1501 Average test loss: 934.6276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1502 [0/2589 (0%)]\tLoss: 178.691833\n",
      "Train Epoch: 1502 [300/2589 (12%)]\tLoss: 282.764771\n",
      "Train Epoch: 1502 [600/2589 (23%)]\tLoss: 296.242645\n",
      "Train Epoch: 1502 [900/2589 (35%)]\tLoss: 207.149551\n",
      "Train Epoch: 1502 [1200/2589 (46%)]\tLoss: 240.598953\n",
      "Train Epoch: 1502 [1500/2589 (58%)]\tLoss: 173.782028\n",
      "Train Epoch: 1502 [1800/2589 (70%)]\tLoss: 188.143463\n",
      "Train Epoch: 1502 [2100/2589 (81%)]\tLoss: 169.109375\n",
      "Train Epoch: 1502 [2400/2589 (93%)]\tLoss: 211.270203\n",
      "====> Epoch: 1502 Average train loss: 212.8457\n",
      "====> Epoch: 1502 Average test loss: 896.4084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1503 [0/2589 (0%)]\tLoss: 182.523682\n",
      "Train Epoch: 1503 [300/2589 (12%)]\tLoss: 158.465363\n",
      "Train Epoch: 1503 [600/2589 (23%)]\tLoss: 191.080231\n",
      "Train Epoch: 1503 [900/2589 (35%)]\tLoss: 153.190445\n",
      "Train Epoch: 1503 [1200/2589 (46%)]\tLoss: 178.356155\n",
      "Train Epoch: 1503 [1500/2589 (58%)]\tLoss: 162.131683\n",
      "Train Epoch: 1503 [1800/2589 (70%)]\tLoss: 254.122711\n",
      "Train Epoch: 1503 [2100/2589 (81%)]\tLoss: 160.990158\n",
      "Train Epoch: 1503 [2400/2589 (93%)]\tLoss: 241.981842\n",
      "====> Epoch: 1503 Average train loss: 207.6262\n",
      "====> Epoch: 1503 Average test loss: 914.0725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1504 [0/2589 (0%)]\tLoss: 199.772308\n",
      "Train Epoch: 1504 [300/2589 (12%)]\tLoss: 204.827957\n",
      "Train Epoch: 1504 [600/2589 (23%)]\tLoss: 160.961761\n",
      "Train Epoch: 1504 [900/2589 (35%)]\tLoss: 255.883499\n",
      "Train Epoch: 1504 [1200/2589 (46%)]\tLoss: 167.051239\n",
      "Train Epoch: 1504 [1500/2589 (58%)]\tLoss: 198.492783\n",
      "Train Epoch: 1504 [1800/2589 (70%)]\tLoss: 199.036942\n",
      "Train Epoch: 1504 [2100/2589 (81%)]\tLoss: 256.499634\n",
      "Train Epoch: 1504 [2400/2589 (93%)]\tLoss: 146.127930\n",
      "====> Epoch: 1504 Average train loss: 212.3974\n",
      "====> Epoch: 1504 Average test loss: 908.7695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1505 [0/2589 (0%)]\tLoss: 304.809570\n",
      "Train Epoch: 1505 [300/2589 (12%)]\tLoss: 172.030991\n",
      "Train Epoch: 1505 [600/2589 (23%)]\tLoss: 182.767914\n",
      "Train Epoch: 1505 [900/2589 (35%)]\tLoss: 188.118393\n",
      "Train Epoch: 1505 [1200/2589 (46%)]\tLoss: 240.838669\n",
      "Train Epoch: 1505 [1500/2589 (58%)]\tLoss: 150.838318\n",
      "Train Epoch: 1505 [1800/2589 (70%)]\tLoss: 188.657150\n",
      "Train Epoch: 1505 [2100/2589 (81%)]\tLoss: 233.394608\n",
      "Train Epoch: 1505 [2400/2589 (93%)]\tLoss: 251.922455\n",
      "====> Epoch: 1505 Average train loss: 207.2557\n",
      "====> Epoch: 1505 Average test loss: 919.8436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1506 [0/2589 (0%)]\tLoss: 269.610077\n",
      "Train Epoch: 1506 [300/2589 (12%)]\tLoss: 237.524765\n",
      "Train Epoch: 1506 [600/2589 (23%)]\tLoss: 204.504425\n",
      "Train Epoch: 1506 [900/2589 (35%)]\tLoss: 216.437836\n",
      "Train Epoch: 1506 [1200/2589 (46%)]\tLoss: 414.549408\n",
      "Train Epoch: 1506 [1500/2589 (58%)]\tLoss: 273.019897\n",
      "Train Epoch: 1506 [1800/2589 (70%)]\tLoss: 113.127289\n",
      "Train Epoch: 1506 [2100/2589 (81%)]\tLoss: 263.670502\n",
      "Train Epoch: 1506 [2400/2589 (93%)]\tLoss: 266.567688\n",
      "====> Epoch: 1506 Average train loss: 210.1222\n",
      "====> Epoch: 1506 Average test loss: 895.5656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1507 [0/2589 (0%)]\tLoss: 154.314743\n",
      "Train Epoch: 1507 [300/2589 (12%)]\tLoss: 228.792755\n",
      "Train Epoch: 1507 [600/2589 (23%)]\tLoss: 252.906677\n",
      "Train Epoch: 1507 [900/2589 (35%)]\tLoss: 367.134583\n",
      "Train Epoch: 1507 [1200/2589 (46%)]\tLoss: 194.916595\n",
      "Train Epoch: 1507 [1500/2589 (58%)]\tLoss: 304.138855\n",
      "Train Epoch: 1507 [1800/2589 (70%)]\tLoss: 202.843353\n",
      "Train Epoch: 1507 [2100/2589 (81%)]\tLoss: 275.251953\n",
      "Train Epoch: 1507 [2400/2589 (93%)]\tLoss: 216.874481\n",
      "====> Epoch: 1507 Average train loss: 207.6696\n",
      "====> Epoch: 1507 Average test loss: 908.9144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1508 [0/2589 (0%)]\tLoss: 214.382339\n",
      "Train Epoch: 1508 [300/2589 (12%)]\tLoss: 186.460129\n",
      "Train Epoch: 1508 [600/2589 (23%)]\tLoss: 165.409668\n",
      "Train Epoch: 1508 [900/2589 (35%)]\tLoss: 219.401627\n",
      "Train Epoch: 1508 [1200/2589 (46%)]\tLoss: 253.618271\n",
      "Train Epoch: 1508 [1500/2589 (58%)]\tLoss: 209.835022\n",
      "Train Epoch: 1508 [1800/2589 (70%)]\tLoss: 219.665192\n",
      "Train Epoch: 1508 [2100/2589 (81%)]\tLoss: 181.816345\n",
      "Train Epoch: 1508 [2400/2589 (93%)]\tLoss: 212.762894\n",
      "====> Epoch: 1508 Average train loss: 210.7898\n",
      "====> Epoch: 1508 Average test loss: 926.4145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1509 [0/2589 (0%)]\tLoss: 187.917007\n",
      "Train Epoch: 1509 [300/2589 (12%)]\tLoss: 273.264435\n",
      "Train Epoch: 1509 [600/2589 (23%)]\tLoss: 180.901291\n",
      "Train Epoch: 1509 [900/2589 (35%)]\tLoss: 176.407028\n",
      "Train Epoch: 1509 [1200/2589 (46%)]\tLoss: 224.732895\n",
      "Train Epoch: 1509 [1500/2589 (58%)]\tLoss: 240.572037\n",
      "Train Epoch: 1509 [1800/2589 (70%)]\tLoss: 171.011703\n",
      "Train Epoch: 1509 [2100/2589 (81%)]\tLoss: 524.258850\n",
      "Train Epoch: 1509 [2400/2589 (93%)]\tLoss: 258.024963\n",
      "====> Epoch: 1509 Average train loss: 227.6224\n",
      "====> Epoch: 1509 Average test loss: 906.3655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1510 [0/2589 (0%)]\tLoss: 169.538971\n",
      "Train Epoch: 1510 [300/2589 (12%)]\tLoss: 299.477356\n",
      "Train Epoch: 1510 [600/2589 (23%)]\tLoss: 135.048965\n",
      "Train Epoch: 1510 [900/2589 (35%)]\tLoss: 409.439545\n",
      "Train Epoch: 1510 [1200/2589 (46%)]\tLoss: 186.296448\n",
      "Train Epoch: 1510 [1500/2589 (58%)]\tLoss: 159.892242\n",
      "Train Epoch: 1510 [1800/2589 (70%)]\tLoss: 248.132889\n",
      "Train Epoch: 1510 [2100/2589 (81%)]\tLoss: 202.994354\n",
      "Train Epoch: 1510 [2400/2589 (93%)]\tLoss: 190.744370\n",
      "====> Epoch: 1510 Average train loss: 218.3246\n",
      "====> Epoch: 1510 Average test loss: 913.1137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1511 [0/2589 (0%)]\tLoss: 244.025818\n",
      "Train Epoch: 1511 [300/2589 (12%)]\tLoss: 239.664032\n",
      "Train Epoch: 1511 [600/2589 (23%)]\tLoss: 161.914505\n",
      "Train Epoch: 1511 [900/2589 (35%)]\tLoss: 198.728973\n",
      "Train Epoch: 1511 [1200/2589 (46%)]\tLoss: 154.622620\n",
      "Train Epoch: 1511 [1500/2589 (58%)]\tLoss: 213.517792\n",
      "Train Epoch: 1511 [1800/2589 (70%)]\tLoss: 216.741867\n",
      "Train Epoch: 1511 [2100/2589 (81%)]\tLoss: 183.176651\n",
      "Train Epoch: 1511 [2400/2589 (93%)]\tLoss: 194.616028\n",
      "====> Epoch: 1511 Average train loss: 204.5475\n",
      "====> Epoch: 1511 Average test loss: 895.4208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1512 [0/2589 (0%)]\tLoss: 268.764984\n",
      "Train Epoch: 1512 [300/2589 (12%)]\tLoss: 142.328125\n",
      "Train Epoch: 1512 [600/2589 (23%)]\tLoss: 148.782135\n",
      "Train Epoch: 1512 [900/2589 (35%)]\tLoss: 143.988861\n",
      "Train Epoch: 1512 [1200/2589 (46%)]\tLoss: 218.513000\n",
      "Train Epoch: 1512 [1500/2589 (58%)]\tLoss: 267.339478\n",
      "Train Epoch: 1512 [1800/2589 (70%)]\tLoss: 240.397278\n",
      "Train Epoch: 1512 [2100/2589 (81%)]\tLoss: 174.299164\n",
      "Train Epoch: 1512 [2400/2589 (93%)]\tLoss: 235.875702\n",
      "====> Epoch: 1512 Average train loss: 207.9837\n",
      "====> Epoch: 1512 Average test loss: 910.1924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1513 [0/2589 (0%)]\tLoss: 150.447617\n",
      "Train Epoch: 1513 [300/2589 (12%)]\tLoss: 217.884995\n",
      "Train Epoch: 1513 [600/2589 (23%)]\tLoss: 173.929474\n",
      "Train Epoch: 1513 [900/2589 (35%)]\tLoss: 114.420738\n",
      "Train Epoch: 1513 [1200/2589 (46%)]\tLoss: 237.618164\n",
      "Train Epoch: 1513 [1500/2589 (58%)]\tLoss: 327.492065\n",
      "Train Epoch: 1513 [1800/2589 (70%)]\tLoss: 221.844925\n",
      "Train Epoch: 1513 [2100/2589 (81%)]\tLoss: 158.125381\n",
      "Train Epoch: 1513 [2400/2589 (93%)]\tLoss: 183.357452\n",
      "====> Epoch: 1513 Average train loss: 205.1879\n",
      "====> Epoch: 1513 Average test loss: 917.3044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1514 [0/2589 (0%)]\tLoss: 142.932220\n",
      "Train Epoch: 1514 [300/2589 (12%)]\tLoss: 189.444962\n",
      "Train Epoch: 1514 [600/2589 (23%)]\tLoss: 146.811630\n",
      "Train Epoch: 1514 [900/2589 (35%)]\tLoss: 504.518402\n",
      "Train Epoch: 1514 [1200/2589 (46%)]\tLoss: 250.999496\n",
      "Train Epoch: 1514 [1500/2589 (58%)]\tLoss: 169.078964\n",
      "Train Epoch: 1514 [1800/2589 (70%)]\tLoss: 183.661072\n",
      "Train Epoch: 1514 [2100/2589 (81%)]\tLoss: 162.181885\n",
      "Train Epoch: 1514 [2400/2589 (93%)]\tLoss: 274.602539\n",
      "====> Epoch: 1514 Average train loss: 213.8992\n",
      "====> Epoch: 1514 Average test loss: 896.4741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1515 [0/2589 (0%)]\tLoss: 152.021103\n",
      "Train Epoch: 1515 [300/2589 (12%)]\tLoss: 213.447205\n",
      "Train Epoch: 1515 [600/2589 (23%)]\tLoss: 322.064148\n",
      "Train Epoch: 1515 [900/2589 (35%)]\tLoss: 160.012436\n",
      "Train Epoch: 1515 [1200/2589 (46%)]\tLoss: 215.308624\n",
      "Train Epoch: 1515 [1500/2589 (58%)]\tLoss: 296.720184\n",
      "Train Epoch: 1515 [1800/2589 (70%)]\tLoss: 160.559525\n",
      "Train Epoch: 1515 [2100/2589 (81%)]\tLoss: 296.044800\n",
      "Train Epoch: 1515 [2400/2589 (93%)]\tLoss: 155.245682\n",
      "====> Epoch: 1515 Average train loss: 212.5843\n",
      "====> Epoch: 1515 Average test loss: 913.9353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1516 [0/2589 (0%)]\tLoss: 162.351974\n",
      "Train Epoch: 1516 [300/2589 (12%)]\tLoss: 236.329529\n",
      "Train Epoch: 1516 [600/2589 (23%)]\tLoss: 164.652863\n",
      "Train Epoch: 1516 [900/2589 (35%)]\tLoss: 267.856476\n",
      "Train Epoch: 1516 [1200/2589 (46%)]\tLoss: 153.113632\n",
      "Train Epoch: 1516 [1500/2589 (58%)]\tLoss: 256.279602\n",
      "Train Epoch: 1516 [1800/2589 (70%)]\tLoss: 282.719025\n",
      "Train Epoch: 1516 [2100/2589 (81%)]\tLoss: 210.772293\n",
      "Train Epoch: 1516 [2400/2589 (93%)]\tLoss: 233.602570\n",
      "====> Epoch: 1516 Average train loss: 230.4444\n",
      "====> Epoch: 1516 Average test loss: 915.4933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1517 [0/2589 (0%)]\tLoss: 190.198425\n",
      "Train Epoch: 1517 [300/2589 (12%)]\tLoss: 251.038651\n",
      "Train Epoch: 1517 [600/2589 (23%)]\tLoss: 222.812927\n",
      "Train Epoch: 1517 [900/2589 (35%)]\tLoss: 297.838867\n",
      "Train Epoch: 1517 [1200/2589 (46%)]\tLoss: 134.182968\n",
      "Train Epoch: 1517 [1500/2589 (58%)]\tLoss: 165.450287\n",
      "Train Epoch: 1517 [1800/2589 (70%)]\tLoss: 189.811722\n",
      "Train Epoch: 1517 [2100/2589 (81%)]\tLoss: 214.360352\n",
      "Train Epoch: 1517 [2400/2589 (93%)]\tLoss: 174.681381\n",
      "====> Epoch: 1517 Average train loss: 213.7748\n",
      "====> Epoch: 1517 Average test loss: 902.9103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1518 [0/2589 (0%)]\tLoss: 166.514206\n",
      "Train Epoch: 1518 [300/2589 (12%)]\tLoss: 332.223328\n",
      "Train Epoch: 1518 [600/2589 (23%)]\tLoss: 179.592072\n",
      "Train Epoch: 1518 [900/2589 (35%)]\tLoss: 235.291473\n",
      "Train Epoch: 1518 [1200/2589 (46%)]\tLoss: 153.617950\n",
      "Train Epoch: 1518 [1500/2589 (58%)]\tLoss: 158.191986\n",
      "Train Epoch: 1518 [1800/2589 (70%)]\tLoss: 217.383850\n",
      "Train Epoch: 1518 [2100/2589 (81%)]\tLoss: 167.453751\n",
      "Train Epoch: 1518 [2400/2589 (93%)]\tLoss: 156.410553\n",
      "====> Epoch: 1518 Average train loss: 222.2733\n",
      "====> Epoch: 1518 Average test loss: 915.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1519 [0/2589 (0%)]\tLoss: 148.218552\n",
      "Train Epoch: 1519 [300/2589 (12%)]\tLoss: 205.993912\n",
      "Train Epoch: 1519 [600/2589 (23%)]\tLoss: 149.618301\n",
      "Train Epoch: 1519 [900/2589 (35%)]\tLoss: 168.014221\n",
      "Train Epoch: 1519 [1200/2589 (46%)]\tLoss: 168.696732\n",
      "Train Epoch: 1519 [1500/2589 (58%)]\tLoss: 187.323135\n",
      "Train Epoch: 1519 [1800/2589 (70%)]\tLoss: 162.633926\n",
      "Train Epoch: 1519 [2100/2589 (81%)]\tLoss: 204.707016\n",
      "Train Epoch: 1519 [2400/2589 (93%)]\tLoss: 271.064087\n",
      "====> Epoch: 1519 Average train loss: 206.6601\n",
      "====> Epoch: 1519 Average test loss: 902.3592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1520 [0/2589 (0%)]\tLoss: 151.020355\n",
      "Train Epoch: 1520 [300/2589 (12%)]\tLoss: 177.677322\n",
      "Train Epoch: 1520 [600/2589 (23%)]\tLoss: 134.892670\n",
      "Train Epoch: 1520 [900/2589 (35%)]\tLoss: 222.588852\n",
      "Train Epoch: 1520 [1200/2589 (46%)]\tLoss: 180.690140\n",
      "Train Epoch: 1520 [1500/2589 (58%)]\tLoss: 182.490952\n",
      "Train Epoch: 1520 [1800/2589 (70%)]\tLoss: 172.066315\n",
      "Train Epoch: 1520 [2100/2589 (81%)]\tLoss: 178.426620\n",
      "Train Epoch: 1520 [2400/2589 (93%)]\tLoss: 256.482971\n",
      "====> Epoch: 1520 Average train loss: 212.5743\n",
      "====> Epoch: 1520 Average test loss: 905.7686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1521 [0/2589 (0%)]\tLoss: 211.443512\n",
      "Train Epoch: 1521 [300/2589 (12%)]\tLoss: 180.711090\n",
      "Train Epoch: 1521 [600/2589 (23%)]\tLoss: 241.973328\n",
      "Train Epoch: 1521 [900/2589 (35%)]\tLoss: 194.804108\n",
      "Train Epoch: 1521 [1200/2589 (46%)]\tLoss: 228.421036\n",
      "Train Epoch: 1521 [1500/2589 (58%)]\tLoss: 176.444336\n",
      "Train Epoch: 1521 [1800/2589 (70%)]\tLoss: 183.561813\n",
      "Train Epoch: 1521 [2100/2589 (81%)]\tLoss: 228.329163\n",
      "Train Epoch: 1521 [2400/2589 (93%)]\tLoss: 318.280853\n",
      "====> Epoch: 1521 Average train loss: 209.1015\n",
      "====> Epoch: 1521 Average test loss: 898.9394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1522 [0/2589 (0%)]\tLoss: 144.264755\n",
      "Train Epoch: 1522 [300/2589 (12%)]\tLoss: 196.703690\n",
      "Train Epoch: 1522 [600/2589 (23%)]\tLoss: 195.826996\n",
      "Train Epoch: 1522 [900/2589 (35%)]\tLoss: 207.205505\n",
      "Train Epoch: 1522 [1200/2589 (46%)]\tLoss: 199.568268\n",
      "Train Epoch: 1522 [1500/2589 (58%)]\tLoss: 229.669815\n",
      "Train Epoch: 1522 [1800/2589 (70%)]\tLoss: 146.439285\n",
      "Train Epoch: 1522 [2100/2589 (81%)]\tLoss: 207.671494\n",
      "Train Epoch: 1522 [2400/2589 (93%)]\tLoss: 271.926849\n",
      "====> Epoch: 1522 Average train loss: 217.6729\n",
      "====> Epoch: 1522 Average test loss: 911.1149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1523 [0/2589 (0%)]\tLoss: 170.668518\n",
      "Train Epoch: 1523 [300/2589 (12%)]\tLoss: 342.258514\n",
      "Train Epoch: 1523 [600/2589 (23%)]\tLoss: 193.013123\n",
      "Train Epoch: 1523 [900/2589 (35%)]\tLoss: 398.200104\n",
      "Train Epoch: 1523 [1200/2589 (46%)]\tLoss: 167.782166\n",
      "Train Epoch: 1523 [1500/2589 (58%)]\tLoss: 246.353088\n",
      "Train Epoch: 1523 [1800/2589 (70%)]\tLoss: 191.173767\n",
      "Train Epoch: 1523 [2100/2589 (81%)]\tLoss: 216.405594\n",
      "Train Epoch: 1523 [2400/2589 (93%)]\tLoss: 164.876083\n",
      "====> Epoch: 1523 Average train loss: 213.6794\n",
      "====> Epoch: 1523 Average test loss: 909.8541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1524 [0/2589 (0%)]\tLoss: 180.191956\n",
      "Train Epoch: 1524 [300/2589 (12%)]\tLoss: 223.746689\n",
      "Train Epoch: 1524 [600/2589 (23%)]\tLoss: 271.258728\n",
      "Train Epoch: 1524 [900/2589 (35%)]\tLoss: 216.753479\n",
      "Train Epoch: 1524 [1200/2589 (46%)]\tLoss: 174.371841\n",
      "Train Epoch: 1524 [1500/2589 (58%)]\tLoss: 306.701813\n",
      "Train Epoch: 1524 [1800/2589 (70%)]\tLoss: 181.105896\n",
      "Train Epoch: 1524 [2100/2589 (81%)]\tLoss: 220.710754\n",
      "Train Epoch: 1524 [2400/2589 (93%)]\tLoss: 191.690948\n",
      "====> Epoch: 1524 Average train loss: 212.8601\n",
      "====> Epoch: 1524 Average test loss: 911.8407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1525 [0/2589 (0%)]\tLoss: 165.795685\n",
      "Train Epoch: 1525 [300/2589 (12%)]\tLoss: 220.137451\n",
      "Train Epoch: 1525 [600/2589 (23%)]\tLoss: 149.444427\n",
      "Train Epoch: 1525 [900/2589 (35%)]\tLoss: 264.745789\n",
      "Train Epoch: 1525 [1200/2589 (46%)]\tLoss: 179.544632\n",
      "Train Epoch: 1525 [1500/2589 (58%)]\tLoss: 162.342621\n",
      "Train Epoch: 1525 [1800/2589 (70%)]\tLoss: 218.731873\n",
      "Train Epoch: 1525 [2100/2589 (81%)]\tLoss: 170.511124\n",
      "Train Epoch: 1525 [2400/2589 (93%)]\tLoss: 173.228851\n",
      "====> Epoch: 1525 Average train loss: 206.7258\n",
      "====> Epoch: 1525 Average test loss: 899.3335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1526 [0/2589 (0%)]\tLoss: 226.349792\n",
      "Train Epoch: 1526 [300/2589 (12%)]\tLoss: 178.189514\n",
      "Train Epoch: 1526 [600/2589 (23%)]\tLoss: 185.038361\n",
      "Train Epoch: 1526 [900/2589 (35%)]\tLoss: 421.359314\n",
      "Train Epoch: 1526 [1200/2589 (46%)]\tLoss: 250.086594\n",
      "Train Epoch: 1526 [1500/2589 (58%)]\tLoss: 126.756828\n",
      "Train Epoch: 1526 [1800/2589 (70%)]\tLoss: 182.261459\n",
      "Train Epoch: 1526 [2100/2589 (81%)]\tLoss: 264.137909\n",
      "Train Epoch: 1526 [2400/2589 (93%)]\tLoss: 223.604462\n",
      "====> Epoch: 1526 Average train loss: 216.1620\n",
      "====> Epoch: 1526 Average test loss: 918.2082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1527 [0/2589 (0%)]\tLoss: 196.208282\n",
      "Train Epoch: 1527 [300/2589 (12%)]\tLoss: 151.319336\n",
      "Train Epoch: 1527 [600/2589 (23%)]\tLoss: 304.670685\n",
      "Train Epoch: 1527 [900/2589 (35%)]\tLoss: 175.029205\n",
      "Train Epoch: 1527 [1200/2589 (46%)]\tLoss: 186.292419\n",
      "Train Epoch: 1527 [1500/2589 (58%)]\tLoss: 149.354431\n",
      "Train Epoch: 1527 [1800/2589 (70%)]\tLoss: 197.749344\n",
      "Train Epoch: 1527 [2100/2589 (81%)]\tLoss: 202.755829\n",
      "Train Epoch: 1527 [2400/2589 (93%)]\tLoss: 241.357422\n",
      "====> Epoch: 1527 Average train loss: 196.9749\n",
      "====> Epoch: 1527 Average test loss: 910.0584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1528 [0/2589 (0%)]\tLoss: 152.017441\n",
      "Train Epoch: 1528 [300/2589 (12%)]\tLoss: 253.293259\n",
      "Train Epoch: 1528 [600/2589 (23%)]\tLoss: 188.602722\n",
      "Train Epoch: 1528 [900/2589 (35%)]\tLoss: 223.685379\n",
      "Train Epoch: 1528 [1200/2589 (46%)]\tLoss: 252.404724\n",
      "Train Epoch: 1528 [1500/2589 (58%)]\tLoss: 253.782822\n",
      "Train Epoch: 1528 [1800/2589 (70%)]\tLoss: 164.421249\n",
      "Train Epoch: 1528 [2100/2589 (81%)]\tLoss: 184.272873\n",
      "Train Epoch: 1528 [2400/2589 (93%)]\tLoss: 172.570572\n",
      "====> Epoch: 1528 Average train loss: 206.4158\n",
      "====> Epoch: 1528 Average test loss: 914.6400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1529 [0/2589 (0%)]\tLoss: 170.965790\n",
      "Train Epoch: 1529 [300/2589 (12%)]\tLoss: 220.613022\n",
      "Train Epoch: 1529 [600/2589 (23%)]\tLoss: 125.935257\n",
      "Train Epoch: 1529 [900/2589 (35%)]\tLoss: 211.466385\n",
      "Train Epoch: 1529 [1200/2589 (46%)]\tLoss: 159.060455\n",
      "Train Epoch: 1529 [1500/2589 (58%)]\tLoss: 201.161133\n",
      "Train Epoch: 1529 [1800/2589 (70%)]\tLoss: 287.901703\n",
      "Train Epoch: 1529 [2100/2589 (81%)]\tLoss: 236.897842\n",
      "Train Epoch: 1529 [2400/2589 (93%)]\tLoss: 227.421707\n",
      "====> Epoch: 1529 Average train loss: 213.7084\n",
      "====> Epoch: 1529 Average test loss: 913.2568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1530 [0/2589 (0%)]\tLoss: 185.330109\n",
      "Train Epoch: 1530 [300/2589 (12%)]\tLoss: 172.126373\n",
      "Train Epoch: 1530 [600/2589 (23%)]\tLoss: 258.599945\n",
      "Train Epoch: 1530 [900/2589 (35%)]\tLoss: 389.573334\n",
      "Train Epoch: 1530 [1200/2589 (46%)]\tLoss: 134.414276\n",
      "Train Epoch: 1530 [1500/2589 (58%)]\tLoss: 163.148773\n",
      "Train Epoch: 1530 [1800/2589 (70%)]\tLoss: 193.840790\n",
      "Train Epoch: 1530 [2100/2589 (81%)]\tLoss: 205.456528\n",
      "Train Epoch: 1530 [2400/2589 (93%)]\tLoss: 163.012222\n",
      "====> Epoch: 1530 Average train loss: 217.1452\n",
      "====> Epoch: 1530 Average test loss: 910.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1531 [0/2589 (0%)]\tLoss: 211.382309\n",
      "Train Epoch: 1531 [300/2589 (12%)]\tLoss: 207.463608\n",
      "Train Epoch: 1531 [600/2589 (23%)]\tLoss: 189.662445\n",
      "Train Epoch: 1531 [900/2589 (35%)]\tLoss: 216.313263\n",
      "Train Epoch: 1531 [1200/2589 (46%)]\tLoss: 167.566498\n",
      "Train Epoch: 1531 [1500/2589 (58%)]\tLoss: 450.266724\n",
      "Train Epoch: 1531 [1800/2589 (70%)]\tLoss: 236.529846\n",
      "Train Epoch: 1531 [2100/2589 (81%)]\tLoss: 377.312927\n",
      "Train Epoch: 1531 [2400/2589 (93%)]\tLoss: 148.184006\n",
      "====> Epoch: 1531 Average train loss: 206.3421\n",
      "====> Epoch: 1531 Average test loss: 895.3046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1532 [0/2589 (0%)]\tLoss: 208.153748\n",
      "Train Epoch: 1532 [300/2589 (12%)]\tLoss: 165.838547\n",
      "Train Epoch: 1532 [600/2589 (23%)]\tLoss: 181.753036\n",
      "Train Epoch: 1532 [900/2589 (35%)]\tLoss: 218.959656\n",
      "Train Epoch: 1532 [1200/2589 (46%)]\tLoss: 199.993073\n",
      "Train Epoch: 1532 [1500/2589 (58%)]\tLoss: 113.746056\n",
      "Train Epoch: 1532 [1800/2589 (70%)]\tLoss: 188.508759\n",
      "Train Epoch: 1532 [2100/2589 (81%)]\tLoss: 241.327362\n",
      "Train Epoch: 1532 [2400/2589 (93%)]\tLoss: 175.436966\n",
      "====> Epoch: 1532 Average train loss: 192.9338\n",
      "====> Epoch: 1532 Average test loss: 931.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1533 [0/2589 (0%)]\tLoss: 192.466507\n",
      "Train Epoch: 1533 [300/2589 (12%)]\tLoss: 195.626907\n",
      "Train Epoch: 1533 [600/2589 (23%)]\tLoss: 198.993271\n",
      "Train Epoch: 1533 [900/2589 (35%)]\tLoss: 151.701187\n",
      "Train Epoch: 1533 [1200/2589 (46%)]\tLoss: 227.411652\n",
      "Train Epoch: 1533 [1500/2589 (58%)]\tLoss: 174.353455\n",
      "Train Epoch: 1533 [1800/2589 (70%)]\tLoss: 180.563095\n",
      "Train Epoch: 1533 [2100/2589 (81%)]\tLoss: 214.947586\n",
      "Train Epoch: 1533 [2400/2589 (93%)]\tLoss: 152.760803\n",
      "====> Epoch: 1533 Average train loss: 215.6225\n",
      "====> Epoch: 1533 Average test loss: 908.3279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1534 [0/2589 (0%)]\tLoss: 224.879730\n",
      "Train Epoch: 1534 [300/2589 (12%)]\tLoss: 211.180252\n",
      "Train Epoch: 1534 [600/2589 (23%)]\tLoss: 192.508972\n",
      "Train Epoch: 1534 [900/2589 (35%)]\tLoss: 214.070572\n",
      "Train Epoch: 1534 [1200/2589 (46%)]\tLoss: 122.243553\n",
      "Train Epoch: 1534 [1500/2589 (58%)]\tLoss: 167.831985\n",
      "Train Epoch: 1534 [1800/2589 (70%)]\tLoss: 256.387299\n",
      "Train Epoch: 1534 [2100/2589 (81%)]\tLoss: 190.045181\n",
      "Train Epoch: 1534 [2400/2589 (93%)]\tLoss: 231.708191\n",
      "====> Epoch: 1534 Average train loss: 206.9294\n",
      "====> Epoch: 1534 Average test loss: 911.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1535 [0/2589 (0%)]\tLoss: 246.700592\n",
      "Train Epoch: 1535 [300/2589 (12%)]\tLoss: 271.493103\n",
      "Train Epoch: 1535 [600/2589 (23%)]\tLoss: 211.075119\n",
      "Train Epoch: 1535 [900/2589 (35%)]\tLoss: 128.467560\n",
      "Train Epoch: 1535 [1200/2589 (46%)]\tLoss: 187.579849\n",
      "Train Epoch: 1535 [1500/2589 (58%)]\tLoss: 210.259583\n",
      "Train Epoch: 1535 [1800/2589 (70%)]\tLoss: 208.862274\n",
      "Train Epoch: 1535 [2100/2589 (81%)]\tLoss: 162.300354\n",
      "Train Epoch: 1535 [2400/2589 (93%)]\tLoss: 194.335663\n",
      "====> Epoch: 1535 Average train loss: 211.9772\n",
      "====> Epoch: 1535 Average test loss: 900.8948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1536 [0/2589 (0%)]\tLoss: 216.588959\n",
      "Train Epoch: 1536 [300/2589 (12%)]\tLoss: 126.140091\n",
      "Train Epoch: 1536 [600/2589 (23%)]\tLoss: 315.297150\n",
      "Train Epoch: 1536 [900/2589 (35%)]\tLoss: 245.837463\n",
      "Train Epoch: 1536 [1200/2589 (46%)]\tLoss: 263.498199\n",
      "Train Epoch: 1536 [1500/2589 (58%)]\tLoss: 193.737854\n",
      "Train Epoch: 1536 [1800/2589 (70%)]\tLoss: 160.076691\n",
      "Train Epoch: 1536 [2100/2589 (81%)]\tLoss: 153.962357\n",
      "Train Epoch: 1536 [2400/2589 (93%)]\tLoss: 273.056183\n",
      "====> Epoch: 1536 Average train loss: 218.2299\n",
      "====> Epoch: 1536 Average test loss: 911.9100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1537 [0/2589 (0%)]\tLoss: 172.123138\n",
      "Train Epoch: 1537 [300/2589 (12%)]\tLoss: 246.584610\n",
      "Train Epoch: 1537 [600/2589 (23%)]\tLoss: 131.074081\n",
      "Train Epoch: 1537 [900/2589 (35%)]\tLoss: 227.692520\n",
      "Train Epoch: 1537 [1200/2589 (46%)]\tLoss: 174.587463\n",
      "Train Epoch: 1537 [1500/2589 (58%)]\tLoss: 226.694489\n",
      "Train Epoch: 1537 [1800/2589 (70%)]\tLoss: 216.929230\n",
      "Train Epoch: 1537 [2100/2589 (81%)]\tLoss: 444.818176\n",
      "Train Epoch: 1537 [2400/2589 (93%)]\tLoss: 253.594650\n",
      "====> Epoch: 1537 Average train loss: 214.7941\n",
      "====> Epoch: 1537 Average test loss: 919.6729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1538 [0/2589 (0%)]\tLoss: 218.810440\n",
      "Train Epoch: 1538 [300/2589 (12%)]\tLoss: 189.424637\n",
      "Train Epoch: 1538 [600/2589 (23%)]\tLoss: 142.419769\n",
      "Train Epoch: 1538 [900/2589 (35%)]\tLoss: 144.270599\n",
      "Train Epoch: 1538 [1200/2589 (46%)]\tLoss: 142.529266\n",
      "Train Epoch: 1538 [1500/2589 (58%)]\tLoss: 196.215744\n",
      "Train Epoch: 1538 [1800/2589 (70%)]\tLoss: 167.637894\n",
      "Train Epoch: 1538 [2100/2589 (81%)]\tLoss: 177.991257\n",
      "Train Epoch: 1538 [2400/2589 (93%)]\tLoss: 233.163651\n",
      "====> Epoch: 1538 Average train loss: 212.5706\n",
      "====> Epoch: 1538 Average test loss: 905.0466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1539 [0/2589 (0%)]\tLoss: 162.234116\n",
      "Train Epoch: 1539 [300/2589 (12%)]\tLoss: 246.216049\n",
      "Train Epoch: 1539 [600/2589 (23%)]\tLoss: 234.191254\n",
      "Train Epoch: 1539 [900/2589 (35%)]\tLoss: 190.864212\n",
      "Train Epoch: 1539 [1200/2589 (46%)]\tLoss: 203.437408\n",
      "Train Epoch: 1539 [1500/2589 (58%)]\tLoss: 152.409988\n",
      "Train Epoch: 1539 [1800/2589 (70%)]\tLoss: 152.034134\n",
      "Train Epoch: 1539 [2100/2589 (81%)]\tLoss: 218.044632\n",
      "Train Epoch: 1539 [2400/2589 (93%)]\tLoss: 249.173584\n",
      "====> Epoch: 1539 Average train loss: 204.6734\n",
      "====> Epoch: 1539 Average test loss: 909.2217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1540 [0/2589 (0%)]\tLoss: 158.410980\n",
      "Train Epoch: 1540 [300/2589 (12%)]\tLoss: 164.548508\n",
      "Train Epoch: 1540 [600/2589 (23%)]\tLoss: 173.689453\n",
      "Train Epoch: 1540 [900/2589 (35%)]\tLoss: 190.941727\n",
      "Train Epoch: 1540 [1200/2589 (46%)]\tLoss: 230.448593\n",
      "Train Epoch: 1540 [1500/2589 (58%)]\tLoss: 210.140030\n",
      "Train Epoch: 1540 [1800/2589 (70%)]\tLoss: 162.529922\n",
      "Train Epoch: 1540 [2100/2589 (81%)]\tLoss: 167.986511\n",
      "Train Epoch: 1540 [2400/2589 (93%)]\tLoss: 159.020767\n",
      "====> Epoch: 1540 Average train loss: 213.3947\n",
      "====> Epoch: 1540 Average test loss: 903.3093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1541 [0/2589 (0%)]\tLoss: 180.364441\n",
      "Train Epoch: 1541 [300/2589 (12%)]\tLoss: 205.113068\n",
      "Train Epoch: 1541 [600/2589 (23%)]\tLoss: 210.995392\n",
      "Train Epoch: 1541 [900/2589 (35%)]\tLoss: 200.997101\n",
      "Train Epoch: 1541 [1200/2589 (46%)]\tLoss: 186.097305\n",
      "Train Epoch: 1541 [1500/2589 (58%)]\tLoss: 191.450912\n",
      "Train Epoch: 1541 [1800/2589 (70%)]\tLoss: 237.126984\n",
      "Train Epoch: 1541 [2100/2589 (81%)]\tLoss: 228.962646\n",
      "Train Epoch: 1541 [2400/2589 (93%)]\tLoss: 216.687561\n",
      "====> Epoch: 1541 Average train loss: 203.6983\n",
      "====> Epoch: 1541 Average test loss: 901.6876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1542 [0/2589 (0%)]\tLoss: 171.176788\n",
      "Train Epoch: 1542 [300/2589 (12%)]\tLoss: 134.307343\n",
      "Train Epoch: 1542 [600/2589 (23%)]\tLoss: 208.312286\n",
      "Train Epoch: 1542 [900/2589 (35%)]\tLoss: 181.446808\n",
      "Train Epoch: 1542 [1200/2589 (46%)]\tLoss: 230.789032\n",
      "Train Epoch: 1542 [1500/2589 (58%)]\tLoss: 142.193924\n",
      "Train Epoch: 1542 [1800/2589 (70%)]\tLoss: 155.842987\n",
      "Train Epoch: 1542 [2100/2589 (81%)]\tLoss: 163.741180\n",
      "Train Epoch: 1542 [2400/2589 (93%)]\tLoss: 161.035477\n",
      "====> Epoch: 1542 Average train loss: 212.1261\n",
      "====> Epoch: 1542 Average test loss: 906.1487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1543 [0/2589 (0%)]\tLoss: 211.059738\n",
      "Train Epoch: 1543 [300/2589 (12%)]\tLoss: 160.136566\n",
      "Train Epoch: 1543 [600/2589 (23%)]\tLoss: 152.495255\n",
      "Train Epoch: 1543 [900/2589 (35%)]\tLoss: 135.781647\n",
      "Train Epoch: 1543 [1200/2589 (46%)]\tLoss: 267.497437\n",
      "Train Epoch: 1543 [1500/2589 (58%)]\tLoss: 176.442169\n",
      "Train Epoch: 1543 [1800/2589 (70%)]\tLoss: 179.971970\n",
      "Train Epoch: 1543 [2100/2589 (81%)]\tLoss: 207.123993\n",
      "Train Epoch: 1543 [2400/2589 (93%)]\tLoss: 160.302643\n",
      "====> Epoch: 1543 Average train loss: 203.8722\n",
      "====> Epoch: 1543 Average test loss: 910.0411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1544 [0/2589 (0%)]\tLoss: 209.747375\n",
      "Train Epoch: 1544 [300/2589 (12%)]\tLoss: 212.045731\n",
      "Train Epoch: 1544 [600/2589 (23%)]\tLoss: 180.568604\n",
      "Train Epoch: 1544 [900/2589 (35%)]\tLoss: 341.677704\n",
      "Train Epoch: 1544 [1200/2589 (46%)]\tLoss: 282.968811\n",
      "Train Epoch: 1544 [1500/2589 (58%)]\tLoss: 271.347565\n",
      "Train Epoch: 1544 [1800/2589 (70%)]\tLoss: 179.972076\n",
      "Train Epoch: 1544 [2100/2589 (81%)]\tLoss: 217.487411\n",
      "Train Epoch: 1544 [2400/2589 (93%)]\tLoss: 207.000580\n",
      "====> Epoch: 1544 Average train loss: 221.4537\n",
      "====> Epoch: 1544 Average test loss: 909.0722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1545 [0/2589 (0%)]\tLoss: 187.417084\n",
      "Train Epoch: 1545 [300/2589 (12%)]\tLoss: 221.838287\n",
      "Train Epoch: 1545 [600/2589 (23%)]\tLoss: 156.312241\n",
      "Train Epoch: 1545 [900/2589 (35%)]\tLoss: 189.338226\n",
      "Train Epoch: 1545 [1200/2589 (46%)]\tLoss: 176.672363\n",
      "Train Epoch: 1545 [1500/2589 (58%)]\tLoss: 227.160156\n",
      "Train Epoch: 1545 [1800/2589 (70%)]\tLoss: 210.222214\n",
      "Train Epoch: 1545 [2100/2589 (81%)]\tLoss: 314.564545\n",
      "Train Epoch: 1545 [2400/2589 (93%)]\tLoss: 319.008392\n",
      "====> Epoch: 1545 Average train loss: 222.9914\n",
      "====> Epoch: 1545 Average test loss: 911.6256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1546 [0/2589 (0%)]\tLoss: 183.688690\n",
      "Train Epoch: 1546 [300/2589 (12%)]\tLoss: 174.292191\n",
      "Train Epoch: 1546 [600/2589 (23%)]\tLoss: 178.128098\n",
      "Train Epoch: 1546 [900/2589 (35%)]\tLoss: 201.766800\n",
      "Train Epoch: 1546 [1200/2589 (46%)]\tLoss: 181.991959\n",
      "Train Epoch: 1546 [1500/2589 (58%)]\tLoss: 147.667084\n",
      "Train Epoch: 1546 [1800/2589 (70%)]\tLoss: 183.866699\n",
      "Train Epoch: 1546 [2100/2589 (81%)]\tLoss: 125.903999\n",
      "Train Epoch: 1546 [2400/2589 (93%)]\tLoss: 151.525177\n",
      "====> Epoch: 1546 Average train loss: 213.9194\n",
      "====> Epoch: 1546 Average test loss: 902.0790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1547 [0/2589 (0%)]\tLoss: 235.380966\n",
      "Train Epoch: 1547 [300/2589 (12%)]\tLoss: 151.162872\n",
      "Train Epoch: 1547 [600/2589 (23%)]\tLoss: 210.269577\n",
      "Train Epoch: 1547 [900/2589 (35%)]\tLoss: 270.395599\n",
      "Train Epoch: 1547 [1200/2589 (46%)]\tLoss: 242.290802\n",
      "Train Epoch: 1547 [1500/2589 (58%)]\tLoss: 185.343842\n",
      "Train Epoch: 1547 [1800/2589 (70%)]\tLoss: 181.690674\n",
      "Train Epoch: 1547 [2100/2589 (81%)]\tLoss: 442.930573\n",
      "Train Epoch: 1547 [2400/2589 (93%)]\tLoss: 113.850212\n",
      "====> Epoch: 1547 Average train loss: 198.7432\n",
      "====> Epoch: 1547 Average test loss: 914.2584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1548 [0/2589 (0%)]\tLoss: 180.934479\n",
      "Train Epoch: 1548 [300/2589 (12%)]\tLoss: 155.413223\n",
      "Train Epoch: 1548 [600/2589 (23%)]\tLoss: 133.818039\n",
      "Train Epoch: 1548 [900/2589 (35%)]\tLoss: 165.930099\n",
      "Train Epoch: 1548 [1200/2589 (46%)]\tLoss: 180.601425\n",
      "Train Epoch: 1548 [1500/2589 (58%)]\tLoss: 139.918472\n",
      "Train Epoch: 1548 [1800/2589 (70%)]\tLoss: 166.873322\n",
      "Train Epoch: 1548 [2100/2589 (81%)]\tLoss: 179.103683\n",
      "Train Epoch: 1548 [2400/2589 (93%)]\tLoss: 260.806671\n",
      "====> Epoch: 1548 Average train loss: 200.2237\n",
      "====> Epoch: 1548 Average test loss: 908.9203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1549 [0/2589 (0%)]\tLoss: 184.382294\n",
      "Train Epoch: 1549 [300/2589 (12%)]\tLoss: 254.729431\n",
      "Train Epoch: 1549 [600/2589 (23%)]\tLoss: 206.239365\n",
      "Train Epoch: 1549 [900/2589 (35%)]\tLoss: 198.697250\n",
      "Train Epoch: 1549 [1200/2589 (46%)]\tLoss: 191.315826\n",
      "Train Epoch: 1549 [1500/2589 (58%)]\tLoss: 173.953583\n",
      "Train Epoch: 1549 [1800/2589 (70%)]\tLoss: 305.289673\n",
      "Train Epoch: 1549 [2100/2589 (81%)]\tLoss: 205.227356\n",
      "Train Epoch: 1549 [2400/2589 (93%)]\tLoss: 271.581360\n",
      "====> Epoch: 1549 Average train loss: 200.5214\n",
      "====> Epoch: 1549 Average test loss: 922.3589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1550 [0/2589 (0%)]\tLoss: 217.589996\n",
      "Train Epoch: 1550 [300/2589 (12%)]\tLoss: 204.919388\n",
      "Train Epoch: 1550 [600/2589 (23%)]\tLoss: 240.828293\n",
      "Train Epoch: 1550 [900/2589 (35%)]\tLoss: 184.476425\n",
      "Train Epoch: 1550 [1200/2589 (46%)]\tLoss: 177.532455\n",
      "Train Epoch: 1550 [1500/2589 (58%)]\tLoss: 202.915497\n",
      "Train Epoch: 1550 [1800/2589 (70%)]\tLoss: 243.372665\n",
      "Train Epoch: 1550 [2100/2589 (81%)]\tLoss: 289.612762\n",
      "Train Epoch: 1550 [2400/2589 (93%)]\tLoss: 159.078262\n",
      "====> Epoch: 1550 Average train loss: 202.7797\n",
      "====> Epoch: 1550 Average test loss: 901.1323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1551 [0/2589 (0%)]\tLoss: 200.724197\n",
      "Train Epoch: 1551 [300/2589 (12%)]\tLoss: 475.136902\n",
      "Train Epoch: 1551 [600/2589 (23%)]\tLoss: 241.796600\n",
      "Train Epoch: 1551 [900/2589 (35%)]\tLoss: 181.520126\n",
      "Train Epoch: 1551 [1200/2589 (46%)]\tLoss: 271.155945\n",
      "Train Epoch: 1551 [1500/2589 (58%)]\tLoss: 265.437042\n",
      "Train Epoch: 1551 [1800/2589 (70%)]\tLoss: 216.080719\n",
      "Train Epoch: 1551 [2100/2589 (81%)]\tLoss: 175.890305\n",
      "Train Epoch: 1551 [2400/2589 (93%)]\tLoss: 221.455185\n",
      "====> Epoch: 1551 Average train loss: 211.8109\n",
      "====> Epoch: 1551 Average test loss: 920.5338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1552 [0/2589 (0%)]\tLoss: 152.793320\n",
      "Train Epoch: 1552 [300/2589 (12%)]\tLoss: 230.282089\n",
      "Train Epoch: 1552 [600/2589 (23%)]\tLoss: 154.944565\n",
      "Train Epoch: 1552 [900/2589 (35%)]\tLoss: 114.458153\n",
      "Train Epoch: 1552 [1200/2589 (46%)]\tLoss: 271.641235\n",
      "Train Epoch: 1552 [1500/2589 (58%)]\tLoss: 431.404572\n",
      "Train Epoch: 1552 [1800/2589 (70%)]\tLoss: 175.323776\n",
      "Train Epoch: 1552 [2100/2589 (81%)]\tLoss: 117.452248\n",
      "Train Epoch: 1552 [2400/2589 (93%)]\tLoss: 147.857666\n",
      "====> Epoch: 1552 Average train loss: 214.5510\n",
      "====> Epoch: 1552 Average test loss: 904.3224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1553 [0/2589 (0%)]\tLoss: 149.148605\n",
      "Train Epoch: 1553 [300/2589 (12%)]\tLoss: 143.644241\n",
      "Train Epoch: 1553 [600/2589 (23%)]\tLoss: 214.688568\n",
      "Train Epoch: 1553 [900/2589 (35%)]\tLoss: 133.346512\n",
      "Train Epoch: 1553 [1200/2589 (46%)]\tLoss: 141.667862\n",
      "Train Epoch: 1553 [1500/2589 (58%)]\tLoss: 152.064102\n",
      "Train Epoch: 1553 [1800/2589 (70%)]\tLoss: 146.364517\n",
      "Train Epoch: 1553 [2100/2589 (81%)]\tLoss: 157.615128\n",
      "Train Epoch: 1553 [2400/2589 (93%)]\tLoss: 208.989090\n",
      "====> Epoch: 1553 Average train loss: 203.0489\n",
      "====> Epoch: 1553 Average test loss: 903.1139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1554 [0/2589 (0%)]\tLoss: 237.237503\n",
      "Train Epoch: 1554 [300/2589 (12%)]\tLoss: 219.009415\n",
      "Train Epoch: 1554 [600/2589 (23%)]\tLoss: 181.460129\n",
      "Train Epoch: 1554 [900/2589 (35%)]\tLoss: 157.143295\n",
      "Train Epoch: 1554 [1200/2589 (46%)]\tLoss: 311.748566\n",
      "Train Epoch: 1554 [1500/2589 (58%)]\tLoss: 174.664566\n",
      "Train Epoch: 1554 [1800/2589 (70%)]\tLoss: 311.048950\n",
      "Train Epoch: 1554 [2100/2589 (81%)]\tLoss: 109.560791\n",
      "Train Epoch: 1554 [2400/2589 (93%)]\tLoss: 216.231125\n",
      "====> Epoch: 1554 Average train loss: 212.9877\n",
      "====> Epoch: 1554 Average test loss: 905.6172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1555 [0/2589 (0%)]\tLoss: 263.085724\n",
      "Train Epoch: 1555 [300/2589 (12%)]\tLoss: 182.830536\n",
      "Train Epoch: 1555 [600/2589 (23%)]\tLoss: 170.581009\n",
      "Train Epoch: 1555 [900/2589 (35%)]\tLoss: 305.431976\n",
      "Train Epoch: 1555 [1200/2589 (46%)]\tLoss: 214.190460\n",
      "Train Epoch: 1555 [1500/2589 (58%)]\tLoss: 145.127640\n",
      "Train Epoch: 1555 [1800/2589 (70%)]\tLoss: 196.832092\n",
      "Train Epoch: 1555 [2100/2589 (81%)]\tLoss: 262.583832\n",
      "Train Epoch: 1555 [2400/2589 (93%)]\tLoss: 148.930664\n",
      "====> Epoch: 1555 Average train loss: 216.8771\n",
      "====> Epoch: 1555 Average test loss: 903.6571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1556 [0/2589 (0%)]\tLoss: 251.604263\n",
      "Train Epoch: 1556 [300/2589 (12%)]\tLoss: 243.338928\n",
      "Train Epoch: 1556 [600/2589 (23%)]\tLoss: 157.129913\n",
      "Train Epoch: 1556 [900/2589 (35%)]\tLoss: 123.190071\n",
      "Train Epoch: 1556 [1200/2589 (46%)]\tLoss: 165.590179\n",
      "Train Epoch: 1556 [1500/2589 (58%)]\tLoss: 198.918259\n",
      "Train Epoch: 1556 [1800/2589 (70%)]\tLoss: 194.014328\n",
      "Train Epoch: 1556 [2100/2589 (81%)]\tLoss: 175.641861\n",
      "Train Epoch: 1556 [2400/2589 (93%)]\tLoss: 221.822113\n",
      "====> Epoch: 1556 Average train loss: 202.1369\n",
      "====> Epoch: 1556 Average test loss: 911.5383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1557 [0/2589 (0%)]\tLoss: 179.941879\n",
      "Train Epoch: 1557 [300/2589 (12%)]\tLoss: 224.741028\n",
      "Train Epoch: 1557 [600/2589 (23%)]\tLoss: 173.656357\n",
      "Train Epoch: 1557 [900/2589 (35%)]\tLoss: 198.976593\n",
      "Train Epoch: 1557 [1200/2589 (46%)]\tLoss: 141.929413\n",
      "Train Epoch: 1557 [1500/2589 (58%)]\tLoss: 254.808258\n",
      "Train Epoch: 1557 [1800/2589 (70%)]\tLoss: 343.772858\n",
      "Train Epoch: 1557 [2100/2589 (81%)]\tLoss: 193.400070\n",
      "Train Epoch: 1557 [2400/2589 (93%)]\tLoss: 176.381683\n",
      "====> Epoch: 1557 Average train loss: 210.3984\n",
      "====> Epoch: 1557 Average test loss: 922.4939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1558 [0/2589 (0%)]\tLoss: 200.730042\n",
      "Train Epoch: 1558 [300/2589 (12%)]\tLoss: 233.564972\n",
      "Train Epoch: 1558 [600/2589 (23%)]\tLoss: 275.013245\n",
      "Train Epoch: 1558 [900/2589 (35%)]\tLoss: 161.998703\n",
      "Train Epoch: 1558 [1200/2589 (46%)]\tLoss: 246.621170\n",
      "Train Epoch: 1558 [1500/2589 (58%)]\tLoss: 145.790359\n",
      "Train Epoch: 1558 [1800/2589 (70%)]\tLoss: 271.113556\n",
      "Train Epoch: 1558 [2100/2589 (81%)]\tLoss: 175.226135\n",
      "Train Epoch: 1558 [2400/2589 (93%)]\tLoss: 178.923477\n",
      "====> Epoch: 1558 Average train loss: 202.1178\n",
      "====> Epoch: 1558 Average test loss: 925.2367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1559 [0/2589 (0%)]\tLoss: 231.212662\n",
      "Train Epoch: 1559 [300/2589 (12%)]\tLoss: 228.458633\n",
      "Train Epoch: 1559 [600/2589 (23%)]\tLoss: 168.114349\n",
      "Train Epoch: 1559 [900/2589 (35%)]\tLoss: 164.401199\n",
      "Train Epoch: 1559 [1200/2589 (46%)]\tLoss: 290.356018\n",
      "Train Epoch: 1559 [1500/2589 (58%)]\tLoss: 242.862701\n",
      "Train Epoch: 1559 [1800/2589 (70%)]\tLoss: 136.666656\n",
      "Train Epoch: 1559 [2100/2589 (81%)]\tLoss: 195.362167\n",
      "Train Epoch: 1559 [2400/2589 (93%)]\tLoss: 278.992828\n",
      "====> Epoch: 1559 Average train loss: 207.4144\n",
      "====> Epoch: 1559 Average test loss: 907.4415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1560 [0/2589 (0%)]\tLoss: 450.481964\n",
      "Train Epoch: 1560 [300/2589 (12%)]\tLoss: 140.521057\n",
      "Train Epoch: 1560 [600/2589 (23%)]\tLoss: 195.978546\n",
      "Train Epoch: 1560 [900/2589 (35%)]\tLoss: 197.139938\n",
      "Train Epoch: 1560 [1200/2589 (46%)]\tLoss: 105.848618\n",
      "Train Epoch: 1560 [1500/2589 (58%)]\tLoss: 236.764130\n",
      "Train Epoch: 1560 [1800/2589 (70%)]\tLoss: 237.915924\n",
      "Train Epoch: 1560 [2100/2589 (81%)]\tLoss: 181.195007\n",
      "Train Epoch: 1560 [2400/2589 (93%)]\tLoss: 239.465958\n",
      "====> Epoch: 1560 Average train loss: 205.6496\n",
      "====> Epoch: 1560 Average test loss: 917.4174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1561 [0/2589 (0%)]\tLoss: 271.408722\n",
      "Train Epoch: 1561 [300/2589 (12%)]\tLoss: 210.552963\n",
      "Train Epoch: 1561 [600/2589 (23%)]\tLoss: 312.636139\n",
      "Train Epoch: 1561 [900/2589 (35%)]\tLoss: 191.812775\n",
      "Train Epoch: 1561 [1200/2589 (46%)]\tLoss: 199.465118\n",
      "Train Epoch: 1561 [1500/2589 (58%)]\tLoss: 219.514389\n",
      "Train Epoch: 1561 [1800/2589 (70%)]\tLoss: 207.702545\n",
      "Train Epoch: 1561 [2100/2589 (81%)]\tLoss: 201.879654\n",
      "Train Epoch: 1561 [2400/2589 (93%)]\tLoss: 315.185608\n",
      "====> Epoch: 1561 Average train loss: 206.8184\n",
      "====> Epoch: 1561 Average test loss: 919.7845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1562 [0/2589 (0%)]\tLoss: 175.167511\n",
      "Train Epoch: 1562 [300/2589 (12%)]\tLoss: 215.725021\n",
      "Train Epoch: 1562 [600/2589 (23%)]\tLoss: 279.426605\n",
      "Train Epoch: 1562 [900/2589 (35%)]\tLoss: 393.630951\n",
      "Train Epoch: 1562 [1200/2589 (46%)]\tLoss: 148.033966\n",
      "Train Epoch: 1562 [1500/2589 (58%)]\tLoss: 181.537689\n",
      "Train Epoch: 1562 [1800/2589 (70%)]\tLoss: 216.456238\n",
      "Train Epoch: 1562 [2100/2589 (81%)]\tLoss: 258.989136\n",
      "Train Epoch: 1562 [2400/2589 (93%)]\tLoss: 188.691940\n",
      "====> Epoch: 1562 Average train loss: 228.1583\n",
      "====> Epoch: 1562 Average test loss: 937.8029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1563 [0/2589 (0%)]\tLoss: 543.273682\n",
      "Train Epoch: 1563 [300/2589 (12%)]\tLoss: 161.423569\n",
      "Train Epoch: 1563 [600/2589 (23%)]\tLoss: 167.174957\n",
      "Train Epoch: 1563 [900/2589 (35%)]\tLoss: 207.835663\n",
      "Train Epoch: 1563 [1200/2589 (46%)]\tLoss: 123.174385\n",
      "Train Epoch: 1563 [1500/2589 (58%)]\tLoss: 171.462845\n",
      "Train Epoch: 1563 [1800/2589 (70%)]\tLoss: 182.942764\n",
      "Train Epoch: 1563 [2100/2589 (81%)]\tLoss: 278.269867\n",
      "Train Epoch: 1563 [2400/2589 (93%)]\tLoss: 240.514053\n",
      "====> Epoch: 1563 Average train loss: 206.9324\n",
      "====> Epoch: 1563 Average test loss: 912.6632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1564 [0/2589 (0%)]\tLoss: 163.485062\n",
      "Train Epoch: 1564 [300/2589 (12%)]\tLoss: 189.161789\n",
      "Train Epoch: 1564 [600/2589 (23%)]\tLoss: 128.603958\n",
      "Train Epoch: 1564 [900/2589 (35%)]\tLoss: 367.288055\n",
      "Train Epoch: 1564 [1200/2589 (46%)]\tLoss: 158.623322\n",
      "Train Epoch: 1564 [1500/2589 (58%)]\tLoss: 149.353027\n",
      "Train Epoch: 1564 [1800/2589 (70%)]\tLoss: 169.805862\n",
      "Train Epoch: 1564 [2100/2589 (81%)]\tLoss: 289.228790\n",
      "Train Epoch: 1564 [2400/2589 (93%)]\tLoss: 232.446930\n",
      "====> Epoch: 1564 Average train loss: 209.9978\n",
      "====> Epoch: 1564 Average test loss: 909.2664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1565 [0/2589 (0%)]\tLoss: 184.572159\n",
      "Train Epoch: 1565 [300/2589 (12%)]\tLoss: 231.473557\n",
      "Train Epoch: 1565 [600/2589 (23%)]\tLoss: 248.159943\n",
      "Train Epoch: 1565 [900/2589 (35%)]\tLoss: 262.708832\n",
      "Train Epoch: 1565 [1200/2589 (46%)]\tLoss: 172.565857\n",
      "Train Epoch: 1565 [1500/2589 (58%)]\tLoss: 146.846481\n",
      "Train Epoch: 1565 [1800/2589 (70%)]\tLoss: 255.370834\n",
      "Train Epoch: 1565 [2100/2589 (81%)]\tLoss: 176.392365\n",
      "Train Epoch: 1565 [2400/2589 (93%)]\tLoss: 197.143097\n",
      "====> Epoch: 1565 Average train loss: 210.3572\n",
      "====> Epoch: 1565 Average test loss: 915.5760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1566 [0/2589 (0%)]\tLoss: 132.191467\n",
      "Train Epoch: 1566 [300/2589 (12%)]\tLoss: 176.383652\n",
      "Train Epoch: 1566 [600/2589 (23%)]\tLoss: 176.218567\n",
      "Train Epoch: 1566 [900/2589 (35%)]\tLoss: 193.699036\n",
      "Train Epoch: 1566 [1200/2589 (46%)]\tLoss: 315.477325\n",
      "Train Epoch: 1566 [1500/2589 (58%)]\tLoss: 412.807404\n",
      "Train Epoch: 1566 [1800/2589 (70%)]\tLoss: 180.232910\n",
      "Train Epoch: 1566 [2100/2589 (81%)]\tLoss: 161.793655\n",
      "Train Epoch: 1566 [2400/2589 (93%)]\tLoss: 334.388794\n",
      "====> Epoch: 1566 Average train loss: 214.2761\n",
      "====> Epoch: 1566 Average test loss: 897.9241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1567 [0/2589 (0%)]\tLoss: 181.664124\n",
      "Train Epoch: 1567 [300/2589 (12%)]\tLoss: 167.952408\n",
      "Train Epoch: 1567 [600/2589 (23%)]\tLoss: 240.320282\n",
      "Train Epoch: 1567 [900/2589 (35%)]\tLoss: 356.297333\n",
      "Train Epoch: 1567 [1200/2589 (46%)]\tLoss: 140.009003\n",
      "Train Epoch: 1567 [1500/2589 (58%)]\tLoss: 226.586411\n",
      "Train Epoch: 1567 [1800/2589 (70%)]\tLoss: 142.663773\n",
      "Train Epoch: 1567 [2100/2589 (81%)]\tLoss: 252.588654\n",
      "Train Epoch: 1567 [2400/2589 (93%)]\tLoss: 110.917221\n",
      "====> Epoch: 1567 Average train loss: 215.3869\n",
      "====> Epoch: 1567 Average test loss: 909.7517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1568 [0/2589 (0%)]\tLoss: 178.591263\n",
      "Train Epoch: 1568 [300/2589 (12%)]\tLoss: 169.678619\n",
      "Train Epoch: 1568 [600/2589 (23%)]\tLoss: 202.997818\n",
      "Train Epoch: 1568 [900/2589 (35%)]\tLoss: 208.833893\n",
      "Train Epoch: 1568 [1200/2589 (46%)]\tLoss: 126.332664\n",
      "Train Epoch: 1568 [1500/2589 (58%)]\tLoss: 199.315765\n",
      "Train Epoch: 1568 [1800/2589 (70%)]\tLoss: 149.071716\n",
      "Train Epoch: 1568 [2100/2589 (81%)]\tLoss: 213.678604\n",
      "Train Epoch: 1568 [2400/2589 (93%)]\tLoss: 175.380173\n",
      "====> Epoch: 1568 Average train loss: 209.0722\n",
      "====> Epoch: 1568 Average test loss: 909.4919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1569 [0/2589 (0%)]\tLoss: 297.905243\n",
      "Train Epoch: 1569 [300/2589 (12%)]\tLoss: 236.462433\n",
      "Train Epoch: 1569 [600/2589 (23%)]\tLoss: 180.397232\n",
      "Train Epoch: 1569 [900/2589 (35%)]\tLoss: 203.840805\n",
      "Train Epoch: 1569 [1200/2589 (46%)]\tLoss: 228.556564\n",
      "Train Epoch: 1569 [1500/2589 (58%)]\tLoss: 143.600021\n",
      "Train Epoch: 1569 [1800/2589 (70%)]\tLoss: 289.545441\n",
      "Train Epoch: 1569 [2100/2589 (81%)]\tLoss: 174.735260\n",
      "Train Epoch: 1569 [2400/2589 (93%)]\tLoss: 144.631744\n",
      "====> Epoch: 1569 Average train loss: 209.0480\n",
      "====> Epoch: 1569 Average test loss: 905.6285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1570 [0/2589 (0%)]\tLoss: 160.561264\n",
      "Train Epoch: 1570 [300/2589 (12%)]\tLoss: 188.223389\n",
      "Train Epoch: 1570 [600/2589 (23%)]\tLoss: 305.677460\n",
      "Train Epoch: 1570 [900/2589 (35%)]\tLoss: 229.387482\n",
      "Train Epoch: 1570 [1200/2589 (46%)]\tLoss: 249.755798\n",
      "Train Epoch: 1570 [1500/2589 (58%)]\tLoss: 218.432449\n",
      "Train Epoch: 1570 [1800/2589 (70%)]\tLoss: 159.528000\n",
      "Train Epoch: 1570 [2100/2589 (81%)]\tLoss: 178.921722\n",
      "Train Epoch: 1570 [2400/2589 (93%)]\tLoss: 181.881638\n",
      "====> Epoch: 1570 Average train loss: 216.1113\n",
      "====> Epoch: 1570 Average test loss: 909.0510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1571 [0/2589 (0%)]\tLoss: 187.378601\n",
      "Train Epoch: 1571 [300/2589 (12%)]\tLoss: 213.578705\n",
      "Train Epoch: 1571 [600/2589 (23%)]\tLoss: 200.947647\n",
      "Train Epoch: 1571 [900/2589 (35%)]\tLoss: 184.530777\n",
      "Train Epoch: 1571 [1200/2589 (46%)]\tLoss: 371.385376\n",
      "Train Epoch: 1571 [1500/2589 (58%)]\tLoss: 198.069275\n",
      "Train Epoch: 1571 [1800/2589 (70%)]\tLoss: 313.635529\n",
      "Train Epoch: 1571 [2100/2589 (81%)]\tLoss: 243.849670\n",
      "Train Epoch: 1571 [2400/2589 (93%)]\tLoss: 242.107224\n",
      "====> Epoch: 1571 Average train loss: 226.5739\n",
      "====> Epoch: 1571 Average test loss: 923.6707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1572 [0/2589 (0%)]\tLoss: 170.570374\n",
      "Train Epoch: 1572 [300/2589 (12%)]\tLoss: 143.909958\n",
      "Train Epoch: 1572 [600/2589 (23%)]\tLoss: 137.081390\n",
      "Train Epoch: 1572 [900/2589 (35%)]\tLoss: 129.335663\n",
      "Train Epoch: 1572 [1200/2589 (46%)]\tLoss: 149.053802\n",
      "Train Epoch: 1572 [1500/2589 (58%)]\tLoss: 245.676117\n",
      "Train Epoch: 1572 [1800/2589 (70%)]\tLoss: 202.822891\n",
      "Train Epoch: 1572 [2100/2589 (81%)]\tLoss: 287.217957\n",
      "Train Epoch: 1572 [2400/2589 (93%)]\tLoss: 190.284912\n",
      "====> Epoch: 1572 Average train loss: 211.0297\n",
      "====> Epoch: 1572 Average test loss: 902.8431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1573 [0/2589 (0%)]\tLoss: 171.400223\n",
      "Train Epoch: 1573 [300/2589 (12%)]\tLoss: 405.431671\n",
      "Train Epoch: 1573 [600/2589 (23%)]\tLoss: 205.502731\n",
      "Train Epoch: 1573 [900/2589 (35%)]\tLoss: 144.047989\n",
      "Train Epoch: 1573 [1200/2589 (46%)]\tLoss: 243.353470\n",
      "Train Epoch: 1573 [1500/2589 (58%)]\tLoss: 146.130157\n",
      "Train Epoch: 1573 [1800/2589 (70%)]\tLoss: 185.165833\n",
      "Train Epoch: 1573 [2100/2589 (81%)]\tLoss: 199.136230\n",
      "Train Epoch: 1573 [2400/2589 (93%)]\tLoss: 150.115372\n",
      "====> Epoch: 1573 Average train loss: 203.1451\n",
      "====> Epoch: 1573 Average test loss: 915.3465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1574 [0/2589 (0%)]\tLoss: 140.306839\n",
      "Train Epoch: 1574 [300/2589 (12%)]\tLoss: 154.392807\n",
      "Train Epoch: 1574 [600/2589 (23%)]\tLoss: 183.447723\n",
      "Train Epoch: 1574 [900/2589 (35%)]\tLoss: 150.501602\n",
      "Train Epoch: 1574 [1200/2589 (46%)]\tLoss: 225.138870\n",
      "Train Epoch: 1574 [1500/2589 (58%)]\tLoss: 243.644394\n",
      "Train Epoch: 1574 [1800/2589 (70%)]\tLoss: 205.352020\n",
      "Train Epoch: 1574 [2100/2589 (81%)]\tLoss: 313.395905\n",
      "Train Epoch: 1574 [2400/2589 (93%)]\tLoss: 154.994858\n",
      "====> Epoch: 1574 Average train loss: 213.1797\n",
      "====> Epoch: 1574 Average test loss: 899.8492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1575 [0/2589 (0%)]\tLoss: 219.001999\n",
      "Train Epoch: 1575 [300/2589 (12%)]\tLoss: 193.181961\n",
      "Train Epoch: 1575 [600/2589 (23%)]\tLoss: 227.969177\n",
      "Train Epoch: 1575 [900/2589 (35%)]\tLoss: 141.742050\n",
      "Train Epoch: 1575 [1200/2589 (46%)]\tLoss: 164.569962\n",
      "Train Epoch: 1575 [1500/2589 (58%)]\tLoss: 238.949921\n",
      "Train Epoch: 1575 [1800/2589 (70%)]\tLoss: 237.532913\n",
      "Train Epoch: 1575 [2100/2589 (81%)]\tLoss: 234.155426\n",
      "Train Epoch: 1575 [2400/2589 (93%)]\tLoss: 310.160797\n",
      "====> Epoch: 1575 Average train loss: 210.5056\n",
      "====> Epoch: 1575 Average test loss: 898.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1576 [0/2589 (0%)]\tLoss: 280.473145\n",
      "Train Epoch: 1576 [300/2589 (12%)]\tLoss: 156.253769\n",
      "Train Epoch: 1576 [600/2589 (23%)]\tLoss: 181.128235\n",
      "Train Epoch: 1576 [900/2589 (35%)]\tLoss: 292.604340\n",
      "Train Epoch: 1576 [1200/2589 (46%)]\tLoss: 201.847748\n",
      "Train Epoch: 1576 [1500/2589 (58%)]\tLoss: 251.196548\n",
      "Train Epoch: 1576 [1800/2589 (70%)]\tLoss: 276.839417\n",
      "Train Epoch: 1576 [2100/2589 (81%)]\tLoss: 215.357513\n",
      "Train Epoch: 1576 [2400/2589 (93%)]\tLoss: 126.037483\n",
      "====> Epoch: 1576 Average train loss: 213.3100\n",
      "====> Epoch: 1576 Average test loss: 911.0580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1577 [0/2589 (0%)]\tLoss: 158.640839\n",
      "Train Epoch: 1577 [300/2589 (12%)]\tLoss: 160.977997\n",
      "Train Epoch: 1577 [600/2589 (23%)]\tLoss: 218.451096\n",
      "Train Epoch: 1577 [900/2589 (35%)]\tLoss: 268.946075\n",
      "Train Epoch: 1577 [1200/2589 (46%)]\tLoss: 203.157913\n",
      "Train Epoch: 1577 [1500/2589 (58%)]\tLoss: 146.679947\n",
      "Train Epoch: 1577 [1800/2589 (70%)]\tLoss: 309.528198\n",
      "Train Epoch: 1577 [2100/2589 (81%)]\tLoss: 154.336563\n",
      "Train Epoch: 1577 [2400/2589 (93%)]\tLoss: 117.370628\n",
      "====> Epoch: 1577 Average train loss: 207.0968\n",
      "====> Epoch: 1577 Average test loss: 915.5550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1578 [0/2589 (0%)]\tLoss: 174.468918\n",
      "Train Epoch: 1578 [300/2589 (12%)]\tLoss: 210.454559\n",
      "Train Epoch: 1578 [600/2589 (23%)]\tLoss: 163.657669\n",
      "Train Epoch: 1578 [900/2589 (35%)]\tLoss: 229.502533\n",
      "Train Epoch: 1578 [1200/2589 (46%)]\tLoss: 231.598846\n",
      "Train Epoch: 1578 [1500/2589 (58%)]\tLoss: 287.020020\n",
      "Train Epoch: 1578 [1800/2589 (70%)]\tLoss: 181.950668\n",
      "Train Epoch: 1578 [2100/2589 (81%)]\tLoss: 468.047821\n",
      "Train Epoch: 1578 [2400/2589 (93%)]\tLoss: 193.007309\n",
      "====> Epoch: 1578 Average train loss: 209.2709\n",
      "====> Epoch: 1578 Average test loss: 897.8401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1579 [0/2589 (0%)]\tLoss: 192.051819\n",
      "Train Epoch: 1579 [300/2589 (12%)]\tLoss: 160.129211\n",
      "Train Epoch: 1579 [600/2589 (23%)]\tLoss: 158.436584\n",
      "Train Epoch: 1579 [900/2589 (35%)]\tLoss: 280.983398\n",
      "Train Epoch: 1579 [1200/2589 (46%)]\tLoss: 270.527618\n",
      "Train Epoch: 1579 [1500/2589 (58%)]\tLoss: 157.195099\n",
      "Train Epoch: 1579 [1800/2589 (70%)]\tLoss: 179.343353\n",
      "Train Epoch: 1579 [2100/2589 (81%)]\tLoss: 109.147018\n",
      "Train Epoch: 1579 [2400/2589 (93%)]\tLoss: 159.956070\n",
      "====> Epoch: 1579 Average train loss: 208.3447\n",
      "====> Epoch: 1579 Average test loss: 909.4438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1580 [0/2589 (0%)]\tLoss: 132.831955\n",
      "Train Epoch: 1580 [300/2589 (12%)]\tLoss: 305.125580\n",
      "Train Epoch: 1580 [600/2589 (23%)]\tLoss: 147.255798\n",
      "Train Epoch: 1580 [900/2589 (35%)]\tLoss: 175.135681\n",
      "Train Epoch: 1580 [1200/2589 (46%)]\tLoss: 173.034180\n",
      "Train Epoch: 1580 [1500/2589 (58%)]\tLoss: 247.973526\n",
      "Train Epoch: 1580 [1800/2589 (70%)]\tLoss: 183.879837\n",
      "Train Epoch: 1580 [2100/2589 (81%)]\tLoss: 277.461029\n",
      "Train Epoch: 1580 [2400/2589 (93%)]\tLoss: 182.009781\n",
      "====> Epoch: 1580 Average train loss: 211.8849\n",
      "====> Epoch: 1580 Average test loss: 913.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1581 [0/2589 (0%)]\tLoss: 166.756058\n",
      "Train Epoch: 1581 [300/2589 (12%)]\tLoss: 300.263489\n",
      "Train Epoch: 1581 [600/2589 (23%)]\tLoss: 199.029617\n",
      "Train Epoch: 1581 [900/2589 (35%)]\tLoss: 161.343292\n",
      "Train Epoch: 1581 [1200/2589 (46%)]\tLoss: 202.681137\n",
      "Train Epoch: 1581 [1500/2589 (58%)]\tLoss: 163.141129\n",
      "Train Epoch: 1581 [1800/2589 (70%)]\tLoss: 198.809784\n",
      "Train Epoch: 1581 [2100/2589 (81%)]\tLoss: 211.393402\n",
      "Train Epoch: 1581 [2400/2589 (93%)]\tLoss: 212.752136\n",
      "====> Epoch: 1581 Average train loss: 209.2276\n",
      "====> Epoch: 1581 Average test loss: 914.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1582 [0/2589 (0%)]\tLoss: 181.448196\n",
      "Train Epoch: 1582 [300/2589 (12%)]\tLoss: 338.623444\n",
      "Train Epoch: 1582 [600/2589 (23%)]\tLoss: 138.509140\n",
      "Train Epoch: 1582 [900/2589 (35%)]\tLoss: 245.891571\n",
      "Train Epoch: 1582 [1200/2589 (46%)]\tLoss: 164.574646\n",
      "Train Epoch: 1582 [1500/2589 (58%)]\tLoss: 277.269897\n",
      "Train Epoch: 1582 [1800/2589 (70%)]\tLoss: 193.658493\n",
      "Train Epoch: 1582 [2100/2589 (81%)]\tLoss: 155.780823\n",
      "Train Epoch: 1582 [2400/2589 (93%)]\tLoss: 133.631393\n",
      "====> Epoch: 1582 Average train loss: 213.1940\n",
      "====> Epoch: 1582 Average test loss: 897.6208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1583 [0/2589 (0%)]\tLoss: 193.533783\n",
      "Train Epoch: 1583 [300/2589 (12%)]\tLoss: 177.663559\n",
      "Train Epoch: 1583 [600/2589 (23%)]\tLoss: 179.159515\n",
      "Train Epoch: 1583 [900/2589 (35%)]\tLoss: 183.820557\n",
      "Train Epoch: 1583 [1200/2589 (46%)]\tLoss: 186.899963\n",
      "Train Epoch: 1583 [1500/2589 (58%)]\tLoss: 231.653381\n",
      "Train Epoch: 1583 [1800/2589 (70%)]\tLoss: 191.165359\n",
      "Train Epoch: 1583 [2100/2589 (81%)]\tLoss: 173.980637\n",
      "Train Epoch: 1583 [2400/2589 (93%)]\tLoss: 217.231445\n",
      "====> Epoch: 1583 Average train loss: 220.0913\n",
      "====> Epoch: 1583 Average test loss: 899.2064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1584 [0/2589 (0%)]\tLoss: 163.181229\n",
      "Train Epoch: 1584 [300/2589 (12%)]\tLoss: 230.502686\n",
      "Train Epoch: 1584 [600/2589 (23%)]\tLoss: 132.072357\n",
      "Train Epoch: 1584 [900/2589 (35%)]\tLoss: 167.379913\n",
      "Train Epoch: 1584 [1200/2589 (46%)]\tLoss: 159.048309\n",
      "Train Epoch: 1584 [1500/2589 (58%)]\tLoss: 344.202026\n",
      "Train Epoch: 1584 [1800/2589 (70%)]\tLoss: 185.730331\n",
      "Train Epoch: 1584 [2100/2589 (81%)]\tLoss: 208.982162\n",
      "Train Epoch: 1584 [2400/2589 (93%)]\tLoss: 195.754852\n",
      "====> Epoch: 1584 Average train loss: 207.6182\n",
      "====> Epoch: 1584 Average test loss: 901.0270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1585 [0/2589 (0%)]\tLoss: 411.957214\n",
      "Train Epoch: 1585 [300/2589 (12%)]\tLoss: 136.906311\n",
      "Train Epoch: 1585 [600/2589 (23%)]\tLoss: 211.142578\n",
      "Train Epoch: 1585 [900/2589 (35%)]\tLoss: 144.756577\n",
      "Train Epoch: 1585 [1200/2589 (46%)]\tLoss: 165.098801\n",
      "Train Epoch: 1585 [1500/2589 (58%)]\tLoss: 367.964844\n",
      "Train Epoch: 1585 [1800/2589 (70%)]\tLoss: 219.204483\n",
      "Train Epoch: 1585 [2100/2589 (81%)]\tLoss: 183.997406\n",
      "Train Epoch: 1585 [2400/2589 (93%)]\tLoss: 143.211029\n",
      "====> Epoch: 1585 Average train loss: 207.6098\n",
      "====> Epoch: 1585 Average test loss: 897.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1586 [0/2589 (0%)]\tLoss: 151.818985\n",
      "Train Epoch: 1586 [300/2589 (12%)]\tLoss: 292.509277\n",
      "Train Epoch: 1586 [600/2589 (23%)]\tLoss: 280.812622\n",
      "Train Epoch: 1586 [900/2589 (35%)]\tLoss: 153.745300\n",
      "Train Epoch: 1586 [1200/2589 (46%)]\tLoss: 165.725540\n",
      "Train Epoch: 1586 [1500/2589 (58%)]\tLoss: 334.875763\n",
      "Train Epoch: 1586 [1800/2589 (70%)]\tLoss: 212.416412\n",
      "Train Epoch: 1586 [2100/2589 (81%)]\tLoss: 162.915283\n",
      "Train Epoch: 1586 [2400/2589 (93%)]\tLoss: 254.368408\n",
      "====> Epoch: 1586 Average train loss: 210.7233\n",
      "====> Epoch: 1586 Average test loss: 912.0167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1587 [0/2589 (0%)]\tLoss: 265.057526\n",
      "Train Epoch: 1587 [300/2589 (12%)]\tLoss: 164.524124\n",
      "Train Epoch: 1587 [600/2589 (23%)]\tLoss: 190.634476\n",
      "Train Epoch: 1587 [900/2589 (35%)]\tLoss: 184.062881\n",
      "Train Epoch: 1587 [1200/2589 (46%)]\tLoss: 219.180069\n",
      "Train Epoch: 1587 [1500/2589 (58%)]\tLoss: 168.852402\n",
      "Train Epoch: 1587 [1800/2589 (70%)]\tLoss: 176.593704\n",
      "Train Epoch: 1587 [2100/2589 (81%)]\tLoss: 205.693604\n",
      "Train Epoch: 1587 [2400/2589 (93%)]\tLoss: 213.009476\n",
      "====> Epoch: 1587 Average train loss: 205.2146\n",
      "====> Epoch: 1587 Average test loss: 922.1567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1588 [0/2589 (0%)]\tLoss: 165.647369\n",
      "Train Epoch: 1588 [300/2589 (12%)]\tLoss: 123.538055\n",
      "Train Epoch: 1588 [600/2589 (23%)]\tLoss: 239.602722\n",
      "Train Epoch: 1588 [900/2589 (35%)]\tLoss: 201.235580\n",
      "Train Epoch: 1588 [1200/2589 (46%)]\tLoss: 156.037735\n",
      "Train Epoch: 1588 [1500/2589 (58%)]\tLoss: 201.953156\n",
      "Train Epoch: 1588 [1800/2589 (70%)]\tLoss: 196.780136\n",
      "Train Epoch: 1588 [2100/2589 (81%)]\tLoss: 122.341805\n",
      "Train Epoch: 1588 [2400/2589 (93%)]\tLoss: 228.169388\n",
      "====> Epoch: 1588 Average train loss: 203.3810\n",
      "====> Epoch: 1588 Average test loss: 901.7042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1589 [0/2589 (0%)]\tLoss: 204.785538\n",
      "Train Epoch: 1589 [300/2589 (12%)]\tLoss: 183.230118\n",
      "Train Epoch: 1589 [600/2589 (23%)]\tLoss: 258.363800\n",
      "Train Epoch: 1589 [900/2589 (35%)]\tLoss: 167.747986\n",
      "Train Epoch: 1589 [1200/2589 (46%)]\tLoss: 134.364319\n",
      "Train Epoch: 1589 [1500/2589 (58%)]\tLoss: 139.724899\n",
      "Train Epoch: 1589 [1800/2589 (70%)]\tLoss: 180.775772\n",
      "Train Epoch: 1589 [2100/2589 (81%)]\tLoss: 169.539734\n",
      "Train Epoch: 1589 [2400/2589 (93%)]\tLoss: 225.301300\n",
      "====> Epoch: 1589 Average train loss: 211.3384\n",
      "====> Epoch: 1589 Average test loss: 909.3651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1590 [0/2589 (0%)]\tLoss: 227.240234\n",
      "Train Epoch: 1590 [300/2589 (12%)]\tLoss: 248.784882\n",
      "Train Epoch: 1590 [600/2589 (23%)]\tLoss: 151.903946\n",
      "Train Epoch: 1590 [900/2589 (35%)]\tLoss: 227.298676\n",
      "Train Epoch: 1590 [1200/2589 (46%)]\tLoss: 197.194778\n",
      "Train Epoch: 1590 [1500/2589 (58%)]\tLoss: 252.713898\n",
      "Train Epoch: 1590 [1800/2589 (70%)]\tLoss: 161.107666\n",
      "Train Epoch: 1590 [2100/2589 (81%)]\tLoss: 164.767441\n",
      "Train Epoch: 1590 [2400/2589 (93%)]\tLoss: 234.934982\n",
      "====> Epoch: 1590 Average train loss: 214.4769\n",
      "====> Epoch: 1590 Average test loss: 893.5874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1591 [0/2589 (0%)]\tLoss: 307.714752\n",
      "Train Epoch: 1591 [300/2589 (12%)]\tLoss: 374.500336\n",
      "Train Epoch: 1591 [600/2589 (23%)]\tLoss: 242.085846\n",
      "Train Epoch: 1591 [900/2589 (35%)]\tLoss: 170.045670\n",
      "Train Epoch: 1591 [1200/2589 (46%)]\tLoss: 190.425262\n",
      "Train Epoch: 1591 [1500/2589 (58%)]\tLoss: 243.231674\n",
      "Train Epoch: 1591 [1800/2589 (70%)]\tLoss: 339.505341\n",
      "Train Epoch: 1591 [2100/2589 (81%)]\tLoss: 176.862747\n",
      "Train Epoch: 1591 [2400/2589 (93%)]\tLoss: 182.506302\n",
      "====> Epoch: 1591 Average train loss: 227.0221\n",
      "====> Epoch: 1591 Average test loss: 902.0096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1592 [0/2589 (0%)]\tLoss: 190.311722\n",
      "Train Epoch: 1592 [300/2589 (12%)]\tLoss: 192.729721\n",
      "Train Epoch: 1592 [600/2589 (23%)]\tLoss: 157.049988\n",
      "Train Epoch: 1592 [900/2589 (35%)]\tLoss: 318.649017\n",
      "Train Epoch: 1592 [1200/2589 (46%)]\tLoss: 224.979782\n",
      "Train Epoch: 1592 [1500/2589 (58%)]\tLoss: 146.888443\n",
      "Train Epoch: 1592 [1800/2589 (70%)]\tLoss: 150.057556\n",
      "Train Epoch: 1592 [2100/2589 (81%)]\tLoss: 124.255959\n",
      "Train Epoch: 1592 [2400/2589 (93%)]\tLoss: 203.029724\n",
      "====> Epoch: 1592 Average train loss: 208.6344\n",
      "====> Epoch: 1592 Average test loss: 911.2468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1593 [0/2589 (0%)]\tLoss: 172.614670\n",
      "Train Epoch: 1593 [300/2589 (12%)]\tLoss: 149.243164\n",
      "Train Epoch: 1593 [600/2589 (23%)]\tLoss: 178.921951\n",
      "Train Epoch: 1593 [900/2589 (35%)]\tLoss: 250.793945\n",
      "Train Epoch: 1593 [1200/2589 (46%)]\tLoss: 334.807892\n",
      "Train Epoch: 1593 [1500/2589 (58%)]\tLoss: 171.368393\n",
      "Train Epoch: 1593 [1800/2589 (70%)]\tLoss: 184.336777\n",
      "Train Epoch: 1593 [2100/2589 (81%)]\tLoss: 340.397064\n",
      "Train Epoch: 1593 [2400/2589 (93%)]\tLoss: 311.823944\n",
      "====> Epoch: 1593 Average train loss: 221.6124\n",
      "====> Epoch: 1593 Average test loss: 919.6202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1594 [0/2589 (0%)]\tLoss: 141.625870\n",
      "Train Epoch: 1594 [300/2589 (12%)]\tLoss: 133.659637\n",
      "Train Epoch: 1594 [600/2589 (23%)]\tLoss: 211.605927\n",
      "Train Epoch: 1594 [900/2589 (35%)]\tLoss: 269.361206\n",
      "Train Epoch: 1594 [1200/2589 (46%)]\tLoss: 240.464890\n",
      "Train Epoch: 1594 [1500/2589 (58%)]\tLoss: 265.231354\n",
      "Train Epoch: 1594 [1800/2589 (70%)]\tLoss: 241.032013\n",
      "Train Epoch: 1594 [2100/2589 (81%)]\tLoss: 285.684692\n",
      "Train Epoch: 1594 [2400/2589 (93%)]\tLoss: 195.256516\n",
      "====> Epoch: 1594 Average train loss: 199.9736\n",
      "====> Epoch: 1594 Average test loss: 901.4712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1595 [0/2589 (0%)]\tLoss: 210.460724\n",
      "Train Epoch: 1595 [300/2589 (12%)]\tLoss: 287.506622\n",
      "Train Epoch: 1595 [600/2589 (23%)]\tLoss: 316.127228\n",
      "Train Epoch: 1595 [900/2589 (35%)]\tLoss: 158.289200\n",
      "Train Epoch: 1595 [1200/2589 (46%)]\tLoss: 129.721741\n",
      "Train Epoch: 1595 [1500/2589 (58%)]\tLoss: 174.835602\n",
      "Train Epoch: 1595 [1800/2589 (70%)]\tLoss: 234.077637\n",
      "Train Epoch: 1595 [2100/2589 (81%)]\tLoss: 231.608749\n",
      "Train Epoch: 1595 [2400/2589 (93%)]\tLoss: 283.637573\n",
      "====> Epoch: 1595 Average train loss: 206.9162\n",
      "====> Epoch: 1595 Average test loss: 896.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1596 [0/2589 (0%)]\tLoss: 157.003281\n",
      "Train Epoch: 1596 [300/2589 (12%)]\tLoss: 311.533966\n",
      "Train Epoch: 1596 [600/2589 (23%)]\tLoss: 372.669312\n",
      "Train Epoch: 1596 [900/2589 (35%)]\tLoss: 163.805847\n",
      "Train Epoch: 1596 [1200/2589 (46%)]\tLoss: 234.466370\n",
      "Train Epoch: 1596 [1500/2589 (58%)]\tLoss: 168.110947\n",
      "Train Epoch: 1596 [1800/2589 (70%)]\tLoss: 362.052521\n",
      "Train Epoch: 1596 [2100/2589 (81%)]\tLoss: 230.343979\n",
      "Train Epoch: 1596 [2400/2589 (93%)]\tLoss: 220.137115\n",
      "====> Epoch: 1596 Average train loss: 201.4448\n",
      "====> Epoch: 1596 Average test loss: 909.6170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1597 [0/2589 (0%)]\tLoss: 185.871719\n",
      "Train Epoch: 1597 [300/2589 (12%)]\tLoss: 156.141144\n",
      "Train Epoch: 1597 [600/2589 (23%)]\tLoss: 201.694397\n",
      "Train Epoch: 1597 [900/2589 (35%)]\tLoss: 132.342987\n",
      "Train Epoch: 1597 [1200/2589 (46%)]\tLoss: 217.660446\n",
      "Train Epoch: 1597 [1500/2589 (58%)]\tLoss: 291.412689\n",
      "Train Epoch: 1597 [1800/2589 (70%)]\tLoss: 138.870270\n",
      "Train Epoch: 1597 [2100/2589 (81%)]\tLoss: 179.551727\n",
      "Train Epoch: 1597 [2400/2589 (93%)]\tLoss: 230.887924\n",
      "====> Epoch: 1597 Average train loss: 207.2571\n",
      "====> Epoch: 1597 Average test loss: 922.0829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1598 [0/2589 (0%)]\tLoss: 189.185547\n",
      "Train Epoch: 1598 [300/2589 (12%)]\tLoss: 146.434113\n",
      "Train Epoch: 1598 [600/2589 (23%)]\tLoss: 227.776718\n",
      "Train Epoch: 1598 [900/2589 (35%)]\tLoss: 247.251602\n",
      "Train Epoch: 1598 [1200/2589 (46%)]\tLoss: 154.905334\n",
      "Train Epoch: 1598 [1500/2589 (58%)]\tLoss: 275.823212\n",
      "Train Epoch: 1598 [1800/2589 (70%)]\tLoss: 186.906464\n",
      "Train Epoch: 1598 [2100/2589 (81%)]\tLoss: 252.794983\n",
      "Train Epoch: 1598 [2400/2589 (93%)]\tLoss: 301.680450\n",
      "====> Epoch: 1598 Average train loss: 208.8221\n",
      "====> Epoch: 1598 Average test loss: 891.4083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1599 [0/2589 (0%)]\tLoss: 253.831741\n",
      "Train Epoch: 1599 [300/2589 (12%)]\tLoss: 261.174194\n",
      "Train Epoch: 1599 [600/2589 (23%)]\tLoss: 224.681503\n",
      "Train Epoch: 1599 [900/2589 (35%)]\tLoss: 191.530914\n",
      "Train Epoch: 1599 [1200/2589 (46%)]\tLoss: 171.579132\n",
      "Train Epoch: 1599 [1500/2589 (58%)]\tLoss: 185.598282\n",
      "Train Epoch: 1599 [1800/2589 (70%)]\tLoss: 156.593033\n",
      "Train Epoch: 1599 [2100/2589 (81%)]\tLoss: 164.601761\n",
      "Train Epoch: 1599 [2400/2589 (93%)]\tLoss: 127.504875\n",
      "====> Epoch: 1599 Average train loss: 201.0880\n",
      "====> Epoch: 1599 Average test loss: 901.7316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1600 [0/2589 (0%)]\tLoss: 211.821640\n",
      "Train Epoch: 1600 [300/2589 (12%)]\tLoss: 193.035492\n",
      "Train Epoch: 1600 [600/2589 (23%)]\tLoss: 226.915741\n",
      "Train Epoch: 1600 [900/2589 (35%)]\tLoss: 154.100143\n",
      "Train Epoch: 1600 [1200/2589 (46%)]\tLoss: 272.314484\n",
      "Train Epoch: 1600 [1500/2589 (58%)]\tLoss: 240.949966\n",
      "Train Epoch: 1600 [1800/2589 (70%)]\tLoss: 194.748138\n",
      "Train Epoch: 1600 [2100/2589 (81%)]\tLoss: 215.403717\n",
      "Train Epoch: 1600 [2400/2589 (93%)]\tLoss: 201.598007\n",
      "====> Epoch: 1600 Average train loss: 216.7967\n",
      "====> Epoch: 1600 Average test loss: 909.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1601 [0/2589 (0%)]\tLoss: 125.119972\n",
      "Train Epoch: 1601 [300/2589 (12%)]\tLoss: 276.650452\n",
      "Train Epoch: 1601 [600/2589 (23%)]\tLoss: 418.918152\n",
      "Train Epoch: 1601 [900/2589 (35%)]\tLoss: 166.532486\n",
      "Train Epoch: 1601 [1200/2589 (46%)]\tLoss: 318.599640\n",
      "Train Epoch: 1601 [1500/2589 (58%)]\tLoss: 249.915695\n",
      "Train Epoch: 1601 [1800/2589 (70%)]\tLoss: 186.454315\n",
      "Train Epoch: 1601 [2100/2589 (81%)]\tLoss: 199.351105\n",
      "Train Epoch: 1601 [2400/2589 (93%)]\tLoss: 249.207367\n",
      "====> Epoch: 1601 Average train loss: 218.3236\n",
      "====> Epoch: 1601 Average test loss: 919.3714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1602 [0/2589 (0%)]\tLoss: 223.928680\n",
      "Train Epoch: 1602 [300/2589 (12%)]\tLoss: 211.451309\n",
      "Train Epoch: 1602 [600/2589 (23%)]\tLoss: 154.515686\n",
      "Train Epoch: 1602 [900/2589 (35%)]\tLoss: 184.498520\n",
      "Train Epoch: 1602 [1200/2589 (46%)]\tLoss: 251.262558\n",
      "Train Epoch: 1602 [1500/2589 (58%)]\tLoss: 236.042435\n",
      "Train Epoch: 1602 [1800/2589 (70%)]\tLoss: 300.524750\n",
      "Train Epoch: 1602 [2100/2589 (81%)]\tLoss: 142.853867\n",
      "Train Epoch: 1602 [2400/2589 (93%)]\tLoss: 304.043091\n",
      "====> Epoch: 1602 Average train loss: 204.1474\n",
      "====> Epoch: 1602 Average test loss: 921.2428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1603 [0/2589 (0%)]\tLoss: 222.342270\n",
      "Train Epoch: 1603 [300/2589 (12%)]\tLoss: 168.566559\n",
      "Train Epoch: 1603 [600/2589 (23%)]\tLoss: 157.876068\n",
      "Train Epoch: 1603 [900/2589 (35%)]\tLoss: 249.786591\n",
      "Train Epoch: 1603 [1200/2589 (46%)]\tLoss: 149.310226\n",
      "Train Epoch: 1603 [1500/2589 (58%)]\tLoss: 289.755066\n",
      "Train Epoch: 1603 [1800/2589 (70%)]\tLoss: 220.559906\n",
      "Train Epoch: 1603 [2100/2589 (81%)]\tLoss: 216.341217\n",
      "Train Epoch: 1603 [2400/2589 (93%)]\tLoss: 296.146393\n",
      "====> Epoch: 1603 Average train loss: 204.8014\n",
      "====> Epoch: 1603 Average test loss: 901.7214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1604 [0/2589 (0%)]\tLoss: 264.286743\n",
      "Train Epoch: 1604 [300/2589 (12%)]\tLoss: 137.317871\n",
      "Train Epoch: 1604 [600/2589 (23%)]\tLoss: 172.404434\n",
      "Train Epoch: 1604 [900/2589 (35%)]\tLoss: 166.532623\n",
      "Train Epoch: 1604 [1200/2589 (46%)]\tLoss: 201.566422\n",
      "Train Epoch: 1604 [1500/2589 (58%)]\tLoss: 213.309860\n",
      "Train Epoch: 1604 [1800/2589 (70%)]\tLoss: 157.105515\n",
      "Train Epoch: 1604 [2100/2589 (81%)]\tLoss: 156.488876\n",
      "Train Epoch: 1604 [2400/2589 (93%)]\tLoss: 237.657654\n",
      "====> Epoch: 1604 Average train loss: 212.1076\n",
      "====> Epoch: 1604 Average test loss: 906.2700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1605 [0/2589 (0%)]\tLoss: 224.024475\n",
      "Train Epoch: 1605 [300/2589 (12%)]\tLoss: 166.658951\n",
      "Train Epoch: 1605 [600/2589 (23%)]\tLoss: 149.109726\n",
      "Train Epoch: 1605 [900/2589 (35%)]\tLoss: 284.858429\n",
      "Train Epoch: 1605 [1200/2589 (46%)]\tLoss: 174.284027\n",
      "Train Epoch: 1605 [1500/2589 (58%)]\tLoss: 154.909164\n",
      "Train Epoch: 1605 [1800/2589 (70%)]\tLoss: 220.870300\n",
      "Train Epoch: 1605 [2100/2589 (81%)]\tLoss: 249.418503\n",
      "Train Epoch: 1605 [2400/2589 (93%)]\tLoss: 131.613937\n",
      "====> Epoch: 1605 Average train loss: 199.5943\n",
      "====> Epoch: 1605 Average test loss: 908.1088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1606 [0/2589 (0%)]\tLoss: 177.963593\n",
      "Train Epoch: 1606 [300/2589 (12%)]\tLoss: 213.286774\n",
      "Train Epoch: 1606 [600/2589 (23%)]\tLoss: 295.520050\n",
      "Train Epoch: 1606 [900/2589 (35%)]\tLoss: 191.254883\n",
      "Train Epoch: 1606 [1200/2589 (46%)]\tLoss: 206.580612\n",
      "Train Epoch: 1606 [1500/2589 (58%)]\tLoss: 214.138763\n",
      "Train Epoch: 1606 [1800/2589 (70%)]\tLoss: 190.157745\n",
      "Train Epoch: 1606 [2100/2589 (81%)]\tLoss: 197.625549\n",
      "Train Epoch: 1606 [2400/2589 (93%)]\tLoss: 273.368347\n",
      "====> Epoch: 1606 Average train loss: 216.0998\n",
      "====> Epoch: 1606 Average test loss: 895.5424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1607 [0/2589 (0%)]\tLoss: 132.955856\n",
      "Train Epoch: 1607 [300/2589 (12%)]\tLoss: 150.966599\n",
      "Train Epoch: 1607 [600/2589 (23%)]\tLoss: 187.868973\n",
      "Train Epoch: 1607 [900/2589 (35%)]\tLoss: 240.276611\n",
      "Train Epoch: 1607 [1200/2589 (46%)]\tLoss: 227.692291\n",
      "Train Epoch: 1607 [1500/2589 (58%)]\tLoss: 183.439804\n",
      "Train Epoch: 1607 [1800/2589 (70%)]\tLoss: 121.859444\n",
      "Train Epoch: 1607 [2100/2589 (81%)]\tLoss: 136.258865\n",
      "Train Epoch: 1607 [2400/2589 (93%)]\tLoss: 140.218536\n",
      "====> Epoch: 1607 Average train loss: 204.1413\n",
      "====> Epoch: 1607 Average test loss: 908.9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1608 [0/2589 (0%)]\tLoss: 124.375328\n",
      "Train Epoch: 1608 [300/2589 (12%)]\tLoss: 125.943336\n",
      "Train Epoch: 1608 [600/2589 (23%)]\tLoss: 295.272461\n",
      "Train Epoch: 1608 [900/2589 (35%)]\tLoss: 211.159836\n",
      "Train Epoch: 1608 [1200/2589 (46%)]\tLoss: 151.636490\n",
      "Train Epoch: 1608 [1500/2589 (58%)]\tLoss: 321.533569\n",
      "Train Epoch: 1608 [1800/2589 (70%)]\tLoss: 197.338348\n",
      "Train Epoch: 1608 [2100/2589 (81%)]\tLoss: 200.919342\n",
      "Train Epoch: 1608 [2400/2589 (93%)]\tLoss: 185.451462\n",
      "====> Epoch: 1608 Average train loss: 203.7867\n",
      "====> Epoch: 1608 Average test loss: 917.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1609 [0/2589 (0%)]\tLoss: 167.694855\n",
      "Train Epoch: 1609 [300/2589 (12%)]\tLoss: 300.012817\n",
      "Train Epoch: 1609 [600/2589 (23%)]\tLoss: 202.482529\n",
      "Train Epoch: 1609 [900/2589 (35%)]\tLoss: 224.501678\n",
      "Train Epoch: 1609 [1200/2589 (46%)]\tLoss: 277.305328\n",
      "Train Epoch: 1609 [1500/2589 (58%)]\tLoss: 373.365021\n",
      "Train Epoch: 1609 [1800/2589 (70%)]\tLoss: 118.850227\n",
      "Train Epoch: 1609 [2100/2589 (81%)]\tLoss: 377.739716\n",
      "Train Epoch: 1609 [2400/2589 (93%)]\tLoss: 176.491608\n",
      "====> Epoch: 1609 Average train loss: 214.0285\n",
      "====> Epoch: 1609 Average test loss: 906.3138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1610 [0/2589 (0%)]\tLoss: 147.011414\n",
      "Train Epoch: 1610 [300/2589 (12%)]\tLoss: 133.340256\n",
      "Train Epoch: 1610 [600/2589 (23%)]\tLoss: 236.203049\n",
      "Train Epoch: 1610 [900/2589 (35%)]\tLoss: 261.326080\n",
      "Train Epoch: 1610 [1200/2589 (46%)]\tLoss: 171.451141\n",
      "Train Epoch: 1610 [1500/2589 (58%)]\tLoss: 169.201141\n",
      "Train Epoch: 1610 [1800/2589 (70%)]\tLoss: 297.450073\n",
      "Train Epoch: 1610 [2100/2589 (81%)]\tLoss: 222.931320\n",
      "Train Epoch: 1610 [2400/2589 (93%)]\tLoss: 207.453995\n",
      "====> Epoch: 1610 Average train loss: 205.4424\n",
      "====> Epoch: 1610 Average test loss: 904.4896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1611 [0/2589 (0%)]\tLoss: 150.993118\n",
      "Train Epoch: 1611 [300/2589 (12%)]\tLoss: 312.088043\n",
      "Train Epoch: 1611 [600/2589 (23%)]\tLoss: 159.462067\n",
      "Train Epoch: 1611 [900/2589 (35%)]\tLoss: 213.064972\n",
      "Train Epoch: 1611 [1200/2589 (46%)]\tLoss: 200.005539\n",
      "Train Epoch: 1611 [1500/2589 (58%)]\tLoss: 183.368591\n",
      "Train Epoch: 1611 [1800/2589 (70%)]\tLoss: 239.635513\n",
      "Train Epoch: 1611 [2100/2589 (81%)]\tLoss: 155.975143\n",
      "Train Epoch: 1611 [2400/2589 (93%)]\tLoss: 219.056183\n",
      "====> Epoch: 1611 Average train loss: 205.2923\n",
      "====> Epoch: 1611 Average test loss: 923.6313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1612 [0/2589 (0%)]\tLoss: 183.243378\n",
      "Train Epoch: 1612 [300/2589 (12%)]\tLoss: 224.683334\n",
      "Train Epoch: 1612 [600/2589 (23%)]\tLoss: 294.307617\n",
      "Train Epoch: 1612 [900/2589 (35%)]\tLoss: 301.520844\n",
      "Train Epoch: 1612 [1200/2589 (46%)]\tLoss: 435.377991\n",
      "Train Epoch: 1612 [1500/2589 (58%)]\tLoss: 184.539001\n",
      "Train Epoch: 1612 [1800/2589 (70%)]\tLoss: 241.832367\n",
      "Train Epoch: 1612 [2100/2589 (81%)]\tLoss: 244.491394\n",
      "Train Epoch: 1612 [2400/2589 (93%)]\tLoss: 199.233139\n",
      "====> Epoch: 1612 Average train loss: 216.9324\n",
      "====> Epoch: 1612 Average test loss: 910.2920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1613 [0/2589 (0%)]\tLoss: 203.553009\n",
      "Train Epoch: 1613 [300/2589 (12%)]\tLoss: 161.307098\n",
      "Train Epoch: 1613 [600/2589 (23%)]\tLoss: 155.591980\n",
      "Train Epoch: 1613 [900/2589 (35%)]\tLoss: 382.397186\n",
      "Train Epoch: 1613 [1200/2589 (46%)]\tLoss: 199.303696\n",
      "Train Epoch: 1613 [1500/2589 (58%)]\tLoss: 249.842239\n",
      "Train Epoch: 1613 [1800/2589 (70%)]\tLoss: 217.494644\n",
      "Train Epoch: 1613 [2100/2589 (81%)]\tLoss: 246.126740\n",
      "Train Epoch: 1613 [2400/2589 (93%)]\tLoss: 253.906952\n",
      "====> Epoch: 1613 Average train loss: 217.8426\n",
      "====> Epoch: 1613 Average test loss: 896.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1614 [0/2589 (0%)]\tLoss: 365.002045\n",
      "Train Epoch: 1614 [300/2589 (12%)]\tLoss: 210.101593\n",
      "Train Epoch: 1614 [600/2589 (23%)]\tLoss: 188.788223\n",
      "Train Epoch: 1614 [900/2589 (35%)]\tLoss: 334.672852\n",
      "Train Epoch: 1614 [1200/2589 (46%)]\tLoss: 195.580780\n",
      "Train Epoch: 1614 [1500/2589 (58%)]\tLoss: 175.312836\n",
      "Train Epoch: 1614 [1800/2589 (70%)]\tLoss: 257.537201\n",
      "Train Epoch: 1614 [2100/2589 (81%)]\tLoss: 153.045807\n",
      "Train Epoch: 1614 [2400/2589 (93%)]\tLoss: 198.337006\n",
      "====> Epoch: 1614 Average train loss: 208.5128\n",
      "====> Epoch: 1614 Average test loss: 908.9291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1615 [0/2589 (0%)]\tLoss: 317.916901\n",
      "Train Epoch: 1615 [300/2589 (12%)]\tLoss: 157.144867\n",
      "Train Epoch: 1615 [600/2589 (23%)]\tLoss: 230.749008\n",
      "Train Epoch: 1615 [900/2589 (35%)]\tLoss: 294.317505\n",
      "Train Epoch: 1615 [1200/2589 (46%)]\tLoss: 168.853867\n",
      "Train Epoch: 1615 [1500/2589 (58%)]\tLoss: 240.772156\n",
      "Train Epoch: 1615 [1800/2589 (70%)]\tLoss: 220.452850\n",
      "Train Epoch: 1615 [2100/2589 (81%)]\tLoss: 211.283920\n",
      "Train Epoch: 1615 [2400/2589 (93%)]\tLoss: 313.135742\n",
      "====> Epoch: 1615 Average train loss: 222.3842\n",
      "====> Epoch: 1615 Average test loss: 910.6146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1616 [0/2589 (0%)]\tLoss: 250.673080\n",
      "Train Epoch: 1616 [300/2589 (12%)]\tLoss: 215.769775\n",
      "Train Epoch: 1616 [600/2589 (23%)]\tLoss: 236.855759\n",
      "Train Epoch: 1616 [900/2589 (35%)]\tLoss: 201.838638\n",
      "Train Epoch: 1616 [1200/2589 (46%)]\tLoss: 158.356308\n",
      "Train Epoch: 1616 [1500/2589 (58%)]\tLoss: 248.098816\n",
      "Train Epoch: 1616 [1800/2589 (70%)]\tLoss: 232.838181\n",
      "Train Epoch: 1616 [2100/2589 (81%)]\tLoss: 194.801270\n",
      "Train Epoch: 1616 [2400/2589 (93%)]\tLoss: 258.583466\n",
      "====> Epoch: 1616 Average train loss: 215.0479\n",
      "====> Epoch: 1616 Average test loss: 905.7253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1617 [0/2589 (0%)]\tLoss: 241.530029\n",
      "Train Epoch: 1617 [300/2589 (12%)]\tLoss: 148.180984\n",
      "Train Epoch: 1617 [600/2589 (23%)]\tLoss: 242.699905\n",
      "Train Epoch: 1617 [900/2589 (35%)]\tLoss: 165.459427\n",
      "Train Epoch: 1617 [1200/2589 (46%)]\tLoss: 167.436676\n",
      "Train Epoch: 1617 [1500/2589 (58%)]\tLoss: 177.472946\n",
      "Train Epoch: 1617 [1800/2589 (70%)]\tLoss: 355.007324\n",
      "Train Epoch: 1617 [2100/2589 (81%)]\tLoss: 140.472107\n",
      "Train Epoch: 1617 [2400/2589 (93%)]\tLoss: 156.118790\n",
      "====> Epoch: 1617 Average train loss: 216.9463\n",
      "====> Epoch: 1617 Average test loss: 921.3990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1618 [0/2589 (0%)]\tLoss: 240.117615\n",
      "Train Epoch: 1618 [300/2589 (12%)]\tLoss: 246.865128\n",
      "Train Epoch: 1618 [600/2589 (23%)]\tLoss: 190.749191\n",
      "Train Epoch: 1618 [900/2589 (35%)]\tLoss: 166.950394\n",
      "Train Epoch: 1618 [1200/2589 (46%)]\tLoss: 415.516296\n",
      "Train Epoch: 1618 [1500/2589 (58%)]\tLoss: 212.235657\n",
      "Train Epoch: 1618 [1800/2589 (70%)]\tLoss: 165.813202\n",
      "Train Epoch: 1618 [2100/2589 (81%)]\tLoss: 189.182617\n",
      "Train Epoch: 1618 [2400/2589 (93%)]\tLoss: 118.153709\n",
      "====> Epoch: 1618 Average train loss: 206.1362\n",
      "====> Epoch: 1618 Average test loss: 921.1590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1619 [0/2589 (0%)]\tLoss: 202.477081\n",
      "Train Epoch: 1619 [300/2589 (12%)]\tLoss: 174.535080\n",
      "Train Epoch: 1619 [600/2589 (23%)]\tLoss: 198.414001\n",
      "Train Epoch: 1619 [900/2589 (35%)]\tLoss: 188.190628\n",
      "Train Epoch: 1619 [1200/2589 (46%)]\tLoss: 194.022949\n",
      "Train Epoch: 1619 [1500/2589 (58%)]\tLoss: 205.037933\n",
      "Train Epoch: 1619 [1800/2589 (70%)]\tLoss: 146.001495\n",
      "Train Epoch: 1619 [2100/2589 (81%)]\tLoss: 158.048508\n",
      "Train Epoch: 1619 [2400/2589 (93%)]\tLoss: 192.446121\n",
      "====> Epoch: 1619 Average train loss: 210.5356\n",
      "====> Epoch: 1619 Average test loss: 931.3240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1620 [0/2589 (0%)]\tLoss: 190.242188\n",
      "Train Epoch: 1620 [300/2589 (12%)]\tLoss: 167.853302\n",
      "Train Epoch: 1620 [600/2589 (23%)]\tLoss: 195.499649\n",
      "Train Epoch: 1620 [900/2589 (35%)]\tLoss: 105.610497\n",
      "Train Epoch: 1620 [1200/2589 (46%)]\tLoss: 167.601761\n",
      "Train Epoch: 1620 [1500/2589 (58%)]\tLoss: 235.247360\n",
      "Train Epoch: 1620 [1800/2589 (70%)]\tLoss: 179.821594\n",
      "Train Epoch: 1620 [2100/2589 (81%)]\tLoss: 140.266998\n",
      "Train Epoch: 1620 [2400/2589 (93%)]\tLoss: 207.308167\n",
      "====> Epoch: 1620 Average train loss: 203.5414\n",
      "====> Epoch: 1620 Average test loss: 885.3853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1621 [0/2589 (0%)]\tLoss: 144.454041\n",
      "Train Epoch: 1621 [300/2589 (12%)]\tLoss: 177.562820\n",
      "Train Epoch: 1621 [600/2589 (23%)]\tLoss: 198.722977\n",
      "Train Epoch: 1621 [900/2589 (35%)]\tLoss: 172.584473\n",
      "Train Epoch: 1621 [1200/2589 (46%)]\tLoss: 141.523300\n",
      "Train Epoch: 1621 [1500/2589 (58%)]\tLoss: 177.426758\n",
      "Train Epoch: 1621 [1800/2589 (70%)]\tLoss: 198.275696\n",
      "Train Epoch: 1621 [2100/2589 (81%)]\tLoss: 132.569092\n",
      "Train Epoch: 1621 [2400/2589 (93%)]\tLoss: 217.176590\n",
      "====> Epoch: 1621 Average train loss: 210.6199\n",
      "====> Epoch: 1621 Average test loss: 916.9249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1622 [0/2589 (0%)]\tLoss: 207.063522\n",
      "Train Epoch: 1622 [300/2589 (12%)]\tLoss: 217.632492\n",
      "Train Epoch: 1622 [600/2589 (23%)]\tLoss: 195.336151\n",
      "Train Epoch: 1622 [900/2589 (35%)]\tLoss: 178.878387\n",
      "Train Epoch: 1622 [1200/2589 (46%)]\tLoss: 181.765671\n",
      "Train Epoch: 1622 [1500/2589 (58%)]\tLoss: 336.468231\n",
      "Train Epoch: 1622 [1800/2589 (70%)]\tLoss: 189.022385\n",
      "Train Epoch: 1622 [2100/2589 (81%)]\tLoss: 268.183807\n",
      "Train Epoch: 1622 [2400/2589 (93%)]\tLoss: 180.934280\n",
      "====> Epoch: 1622 Average train loss: 208.6478\n",
      "====> Epoch: 1622 Average test loss: 899.8084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1623 [0/2589 (0%)]\tLoss: 156.801682\n",
      "Train Epoch: 1623 [300/2589 (12%)]\tLoss: 205.517197\n",
      "Train Epoch: 1623 [600/2589 (23%)]\tLoss: 194.936371\n",
      "Train Epoch: 1623 [900/2589 (35%)]\tLoss: 184.033051\n",
      "Train Epoch: 1623 [1200/2589 (46%)]\tLoss: 227.050186\n",
      "Train Epoch: 1623 [1500/2589 (58%)]\tLoss: 203.143860\n",
      "Train Epoch: 1623 [1800/2589 (70%)]\tLoss: 169.418564\n",
      "Train Epoch: 1623 [2100/2589 (81%)]\tLoss: 185.332657\n",
      "Train Epoch: 1623 [2400/2589 (93%)]\tLoss: 185.770157\n",
      "====> Epoch: 1623 Average train loss: 220.3839\n",
      "====> Epoch: 1623 Average test loss: 903.5936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1624 [0/2589 (0%)]\tLoss: 151.720398\n",
      "Train Epoch: 1624 [300/2589 (12%)]\tLoss: 161.954269\n",
      "Train Epoch: 1624 [600/2589 (23%)]\tLoss: 189.451172\n",
      "Train Epoch: 1624 [900/2589 (35%)]\tLoss: 180.297119\n",
      "Train Epoch: 1624 [1200/2589 (46%)]\tLoss: 235.160583\n",
      "Train Epoch: 1624 [1500/2589 (58%)]\tLoss: 152.035126\n",
      "Train Epoch: 1624 [1800/2589 (70%)]\tLoss: 248.414246\n",
      "Train Epoch: 1624 [2100/2589 (81%)]\tLoss: 224.011581\n",
      "Train Epoch: 1624 [2400/2589 (93%)]\tLoss: 174.658585\n",
      "====> Epoch: 1624 Average train loss: 216.4221\n",
      "====> Epoch: 1624 Average test loss: 923.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1625 [0/2589 (0%)]\tLoss: 164.696777\n",
      "Train Epoch: 1625 [300/2589 (12%)]\tLoss: 185.714645\n",
      "Train Epoch: 1625 [600/2589 (23%)]\tLoss: 146.190613\n",
      "Train Epoch: 1625 [900/2589 (35%)]\tLoss: 156.318542\n",
      "Train Epoch: 1625 [1200/2589 (46%)]\tLoss: 229.516861\n",
      "Train Epoch: 1625 [1500/2589 (58%)]\tLoss: 163.580429\n",
      "Train Epoch: 1625 [1800/2589 (70%)]\tLoss: 240.170303\n",
      "Train Epoch: 1625 [2100/2589 (81%)]\tLoss: 204.127609\n",
      "Train Epoch: 1625 [2400/2589 (93%)]\tLoss: 145.096893\n",
      "====> Epoch: 1625 Average train loss: 215.5421\n",
      "====> Epoch: 1625 Average test loss: 904.1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1626 [0/2589 (0%)]\tLoss: 192.084244\n",
      "Train Epoch: 1626 [300/2589 (12%)]\tLoss: 268.884277\n",
      "Train Epoch: 1626 [600/2589 (23%)]\tLoss: 144.621246\n",
      "Train Epoch: 1626 [900/2589 (35%)]\tLoss: 257.381531\n",
      "Train Epoch: 1626 [1200/2589 (46%)]\tLoss: 271.197845\n",
      "Train Epoch: 1626 [1500/2589 (58%)]\tLoss: 185.172745\n",
      "Train Epoch: 1626 [1800/2589 (70%)]\tLoss: 172.276031\n",
      "Train Epoch: 1626 [2100/2589 (81%)]\tLoss: 203.887955\n",
      "Train Epoch: 1626 [2400/2589 (93%)]\tLoss: 227.589630\n",
      "====> Epoch: 1626 Average train loss: 216.5068\n",
      "====> Epoch: 1626 Average test loss: 899.1156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1627 [0/2589 (0%)]\tLoss: 237.535355\n",
      "Train Epoch: 1627 [300/2589 (12%)]\tLoss: 225.533203\n",
      "Train Epoch: 1627 [600/2589 (23%)]\tLoss: 426.000519\n",
      "Train Epoch: 1627 [900/2589 (35%)]\tLoss: 189.856445\n",
      "Train Epoch: 1627 [1200/2589 (46%)]\tLoss: 285.541687\n",
      "Train Epoch: 1627 [1500/2589 (58%)]\tLoss: 256.037140\n",
      "Train Epoch: 1627 [1800/2589 (70%)]\tLoss: 212.906479\n",
      "Train Epoch: 1627 [2100/2589 (81%)]\tLoss: 174.207596\n",
      "Train Epoch: 1627 [2400/2589 (93%)]\tLoss: 226.504898\n",
      "====> Epoch: 1627 Average train loss: 221.1335\n",
      "====> Epoch: 1627 Average test loss: 904.0729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1628 [0/2589 (0%)]\tLoss: 146.915924\n",
      "Train Epoch: 1628 [300/2589 (12%)]\tLoss: 151.614410\n",
      "Train Epoch: 1628 [600/2589 (23%)]\tLoss: 249.471298\n",
      "Train Epoch: 1628 [900/2589 (35%)]\tLoss: 173.273941\n",
      "Train Epoch: 1628 [1200/2589 (46%)]\tLoss: 196.029190\n",
      "Train Epoch: 1628 [1500/2589 (58%)]\tLoss: 286.520508\n",
      "Train Epoch: 1628 [1800/2589 (70%)]\tLoss: 152.806976\n",
      "Train Epoch: 1628 [2100/2589 (81%)]\tLoss: 212.321579\n",
      "Train Epoch: 1628 [2400/2589 (93%)]\tLoss: 170.382004\n",
      "====> Epoch: 1628 Average train loss: 202.9661\n",
      "====> Epoch: 1628 Average test loss: 902.4988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1629 [0/2589 (0%)]\tLoss: 367.673431\n",
      "Train Epoch: 1629 [300/2589 (12%)]\tLoss: 183.125290\n",
      "Train Epoch: 1629 [600/2589 (23%)]\tLoss: 206.261948\n",
      "Train Epoch: 1629 [900/2589 (35%)]\tLoss: 202.875809\n",
      "Train Epoch: 1629 [1200/2589 (46%)]\tLoss: 166.047531\n",
      "Train Epoch: 1629 [1500/2589 (58%)]\tLoss: 261.533661\n",
      "Train Epoch: 1629 [1800/2589 (70%)]\tLoss: 201.408096\n",
      "Train Epoch: 1629 [2100/2589 (81%)]\tLoss: 268.713104\n",
      "Train Epoch: 1629 [2400/2589 (93%)]\tLoss: 201.800522\n",
      "====> Epoch: 1629 Average train loss: 215.0126\n",
      "====> Epoch: 1629 Average test loss: 897.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1630 [0/2589 (0%)]\tLoss: 160.895187\n",
      "Train Epoch: 1630 [300/2589 (12%)]\tLoss: 455.156860\n",
      "Train Epoch: 1630 [600/2589 (23%)]\tLoss: 182.593170\n",
      "Train Epoch: 1630 [900/2589 (35%)]\tLoss: 205.164581\n",
      "Train Epoch: 1630 [1200/2589 (46%)]\tLoss: 310.572113\n",
      "Train Epoch: 1630 [1500/2589 (58%)]\tLoss: 254.347916\n",
      "Train Epoch: 1630 [1800/2589 (70%)]\tLoss: 173.439667\n",
      "Train Epoch: 1630 [2100/2589 (81%)]\tLoss: 152.908508\n",
      "Train Epoch: 1630 [2400/2589 (93%)]\tLoss: 229.451080\n",
      "====> Epoch: 1630 Average train loss: 201.3256\n",
      "====> Epoch: 1630 Average test loss: 905.7972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1631 [0/2589 (0%)]\tLoss: 182.590591\n",
      "Train Epoch: 1631 [300/2589 (12%)]\tLoss: 169.452194\n",
      "Train Epoch: 1631 [600/2589 (23%)]\tLoss: 157.856491\n",
      "Train Epoch: 1631 [900/2589 (35%)]\tLoss: 294.260895\n",
      "Train Epoch: 1631 [1200/2589 (46%)]\tLoss: 157.126190\n",
      "Train Epoch: 1631 [1500/2589 (58%)]\tLoss: 195.412247\n",
      "Train Epoch: 1631 [1800/2589 (70%)]\tLoss: 190.866547\n",
      "Train Epoch: 1631 [2100/2589 (81%)]\tLoss: 229.245651\n",
      "Train Epoch: 1631 [2400/2589 (93%)]\tLoss: 245.028671\n",
      "====> Epoch: 1631 Average train loss: 220.0324\n",
      "====> Epoch: 1631 Average test loss: 893.6404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1632 [0/2589 (0%)]\tLoss: 217.917725\n",
      "Train Epoch: 1632 [300/2589 (12%)]\tLoss: 215.757706\n",
      "Train Epoch: 1632 [600/2589 (23%)]\tLoss: 252.224884\n",
      "Train Epoch: 1632 [900/2589 (35%)]\tLoss: 224.192764\n",
      "Train Epoch: 1632 [1200/2589 (46%)]\tLoss: 160.854980\n",
      "Train Epoch: 1632 [1500/2589 (58%)]\tLoss: 195.785217\n",
      "Train Epoch: 1632 [1800/2589 (70%)]\tLoss: 168.144836\n",
      "Train Epoch: 1632 [2100/2589 (81%)]\tLoss: 167.431213\n",
      "Train Epoch: 1632 [2400/2589 (93%)]\tLoss: 174.249084\n",
      "====> Epoch: 1632 Average train loss: 208.6599\n",
      "====> Epoch: 1632 Average test loss: 920.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1633 [0/2589 (0%)]\tLoss: 211.198334\n",
      "Train Epoch: 1633 [300/2589 (12%)]\tLoss: 205.046432\n",
      "Train Epoch: 1633 [600/2589 (23%)]\tLoss: 195.194595\n",
      "Train Epoch: 1633 [900/2589 (35%)]\tLoss: 141.044922\n",
      "Train Epoch: 1633 [1200/2589 (46%)]\tLoss: 405.328949\n",
      "Train Epoch: 1633 [1500/2589 (58%)]\tLoss: 213.421951\n",
      "Train Epoch: 1633 [1800/2589 (70%)]\tLoss: 282.538910\n",
      "Train Epoch: 1633 [2100/2589 (81%)]\tLoss: 369.767181\n",
      "Train Epoch: 1633 [2400/2589 (93%)]\tLoss: 209.229111\n",
      "====> Epoch: 1633 Average train loss: 213.3676\n",
      "====> Epoch: 1633 Average test loss: 908.5638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1634 [0/2589 (0%)]\tLoss: 203.010803\n",
      "Train Epoch: 1634 [300/2589 (12%)]\tLoss: 172.313431\n",
      "Train Epoch: 1634 [600/2589 (23%)]\tLoss: 184.226028\n",
      "Train Epoch: 1634 [900/2589 (35%)]\tLoss: 220.731476\n",
      "Train Epoch: 1634 [1200/2589 (46%)]\tLoss: 204.362900\n",
      "Train Epoch: 1634 [1500/2589 (58%)]\tLoss: 129.494949\n",
      "Train Epoch: 1634 [1800/2589 (70%)]\tLoss: 240.790710\n",
      "Train Epoch: 1634 [2100/2589 (81%)]\tLoss: 214.521210\n",
      "Train Epoch: 1634 [2400/2589 (93%)]\tLoss: 263.231049\n",
      "====> Epoch: 1634 Average train loss: 210.1801\n",
      "====> Epoch: 1634 Average test loss: 950.2816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1635 [0/2589 (0%)]\tLoss: 167.910416\n",
      "Train Epoch: 1635 [300/2589 (12%)]\tLoss: 206.424759\n",
      "Train Epoch: 1635 [600/2589 (23%)]\tLoss: 227.776657\n",
      "Train Epoch: 1635 [900/2589 (35%)]\tLoss: 241.578476\n",
      "Train Epoch: 1635 [1200/2589 (46%)]\tLoss: 165.476135\n",
      "Train Epoch: 1635 [1500/2589 (58%)]\tLoss: 160.938416\n",
      "Train Epoch: 1635 [1800/2589 (70%)]\tLoss: 168.573288\n",
      "Train Epoch: 1635 [2100/2589 (81%)]\tLoss: 171.782379\n",
      "Train Epoch: 1635 [2400/2589 (93%)]\tLoss: 168.580673\n",
      "====> Epoch: 1635 Average train loss: 222.6703\n",
      "====> Epoch: 1635 Average test loss: 905.6262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1636 [0/2589 (0%)]\tLoss: 180.475250\n",
      "Train Epoch: 1636 [300/2589 (12%)]\tLoss: 208.633942\n",
      "Train Epoch: 1636 [600/2589 (23%)]\tLoss: 217.201279\n",
      "Train Epoch: 1636 [900/2589 (35%)]\tLoss: 108.366402\n",
      "Train Epoch: 1636 [1200/2589 (46%)]\tLoss: 240.761948\n",
      "Train Epoch: 1636 [1500/2589 (58%)]\tLoss: 204.663681\n",
      "Train Epoch: 1636 [1800/2589 (70%)]\tLoss: 195.410553\n",
      "Train Epoch: 1636 [2100/2589 (81%)]\tLoss: 173.902039\n",
      "Train Epoch: 1636 [2400/2589 (93%)]\tLoss: 205.887238\n",
      "====> Epoch: 1636 Average train loss: 210.5461\n",
      "====> Epoch: 1636 Average test loss: 893.1529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1637 [0/2589 (0%)]\tLoss: 253.877014\n",
      "Train Epoch: 1637 [300/2589 (12%)]\tLoss: 247.043533\n",
      "Train Epoch: 1637 [600/2589 (23%)]\tLoss: 228.664551\n",
      "Train Epoch: 1637 [900/2589 (35%)]\tLoss: 188.195816\n",
      "Train Epoch: 1637 [1200/2589 (46%)]\tLoss: 239.541580\n",
      "Train Epoch: 1637 [1500/2589 (58%)]\tLoss: 233.659698\n",
      "Train Epoch: 1637 [1800/2589 (70%)]\tLoss: 233.203613\n",
      "Train Epoch: 1637 [2100/2589 (81%)]\tLoss: 247.249847\n",
      "Train Epoch: 1637 [2400/2589 (93%)]\tLoss: 145.941742\n",
      "====> Epoch: 1637 Average train loss: 207.1763\n",
      "====> Epoch: 1637 Average test loss: 907.2520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1638 [0/2589 (0%)]\tLoss: 237.316498\n",
      "Train Epoch: 1638 [300/2589 (12%)]\tLoss: 149.354431\n",
      "Train Epoch: 1638 [600/2589 (23%)]\tLoss: 160.377136\n",
      "Train Epoch: 1638 [900/2589 (35%)]\tLoss: 149.975479\n",
      "Train Epoch: 1638 [1200/2589 (46%)]\tLoss: 296.016266\n",
      "Train Epoch: 1638 [1500/2589 (58%)]\tLoss: 211.957260\n",
      "Train Epoch: 1638 [1800/2589 (70%)]\tLoss: 236.039246\n",
      "Train Epoch: 1638 [2100/2589 (81%)]\tLoss: 225.029922\n",
      "Train Epoch: 1638 [2400/2589 (93%)]\tLoss: 311.425781\n",
      "====> Epoch: 1638 Average train loss: 214.5811\n",
      "====> Epoch: 1638 Average test loss: 903.3235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1639 [0/2589 (0%)]\tLoss: 148.809265\n",
      "Train Epoch: 1639 [300/2589 (12%)]\tLoss: 199.717102\n",
      "Train Epoch: 1639 [600/2589 (23%)]\tLoss: 269.278137\n",
      "Train Epoch: 1639 [900/2589 (35%)]\tLoss: 188.153702\n",
      "Train Epoch: 1639 [1200/2589 (46%)]\tLoss: 196.400131\n",
      "Train Epoch: 1639 [1500/2589 (58%)]\tLoss: 181.424072\n",
      "Train Epoch: 1639 [1800/2589 (70%)]\tLoss: 212.837494\n",
      "Train Epoch: 1639 [2100/2589 (81%)]\tLoss: 213.677185\n",
      "Train Epoch: 1639 [2400/2589 (93%)]\tLoss: 198.939697\n",
      "====> Epoch: 1639 Average train loss: 209.8787\n",
      "====> Epoch: 1639 Average test loss: 900.6516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1640 [0/2589 (0%)]\tLoss: 226.521027\n",
      "Train Epoch: 1640 [300/2589 (12%)]\tLoss: 222.906479\n",
      "Train Epoch: 1640 [600/2589 (23%)]\tLoss: 137.153610\n",
      "Train Epoch: 1640 [900/2589 (35%)]\tLoss: 174.340393\n",
      "Train Epoch: 1640 [1200/2589 (46%)]\tLoss: 204.360153\n",
      "Train Epoch: 1640 [1500/2589 (58%)]\tLoss: 164.181702\n",
      "Train Epoch: 1640 [1800/2589 (70%)]\tLoss: 225.242676\n",
      "Train Epoch: 1640 [2100/2589 (81%)]\tLoss: 167.488724\n",
      "Train Epoch: 1640 [2400/2589 (93%)]\tLoss: 198.521896\n",
      "====> Epoch: 1640 Average train loss: 216.4384\n",
      "====> Epoch: 1640 Average test loss: 905.5114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1641 [0/2589 (0%)]\tLoss: 192.552353\n",
      "Train Epoch: 1641 [300/2589 (12%)]\tLoss: 130.335800\n",
      "Train Epoch: 1641 [600/2589 (23%)]\tLoss: 148.679962\n",
      "Train Epoch: 1641 [900/2589 (35%)]\tLoss: 156.807510\n",
      "Train Epoch: 1641 [1200/2589 (46%)]\tLoss: 138.723633\n",
      "Train Epoch: 1641 [1500/2589 (58%)]\tLoss: 152.758621\n",
      "Train Epoch: 1641 [1800/2589 (70%)]\tLoss: 254.229446\n",
      "Train Epoch: 1641 [2100/2589 (81%)]\tLoss: 207.578644\n",
      "Train Epoch: 1641 [2400/2589 (93%)]\tLoss: 271.088654\n",
      "====> Epoch: 1641 Average train loss: 204.7896\n",
      "====> Epoch: 1641 Average test loss: 894.7285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1642 [0/2589 (0%)]\tLoss: 162.638870\n",
      "Train Epoch: 1642 [300/2589 (12%)]\tLoss: 265.767548\n",
      "Train Epoch: 1642 [600/2589 (23%)]\tLoss: 221.117584\n",
      "Train Epoch: 1642 [900/2589 (35%)]\tLoss: 217.902344\n",
      "Train Epoch: 1642 [1200/2589 (46%)]\tLoss: 249.463348\n",
      "Train Epoch: 1642 [1500/2589 (58%)]\tLoss: 146.752274\n",
      "Train Epoch: 1642 [1800/2589 (70%)]\tLoss: 153.729523\n",
      "Train Epoch: 1642 [2100/2589 (81%)]\tLoss: 403.410034\n",
      "Train Epoch: 1642 [2400/2589 (93%)]\tLoss: 183.310684\n",
      "====> Epoch: 1642 Average train loss: 204.9808\n",
      "====> Epoch: 1642 Average test loss: 909.9226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1643 [0/2589 (0%)]\tLoss: 252.685944\n",
      "Train Epoch: 1643 [300/2589 (12%)]\tLoss: 158.634521\n",
      "Train Epoch: 1643 [600/2589 (23%)]\tLoss: 172.864059\n",
      "Train Epoch: 1643 [900/2589 (35%)]\tLoss: 147.591736\n",
      "Train Epoch: 1643 [1200/2589 (46%)]\tLoss: 216.413574\n",
      "Train Epoch: 1643 [1500/2589 (58%)]\tLoss: 118.581818\n",
      "Train Epoch: 1643 [1800/2589 (70%)]\tLoss: 171.812149\n",
      "Train Epoch: 1643 [2100/2589 (81%)]\tLoss: 201.144012\n",
      "Train Epoch: 1643 [2400/2589 (93%)]\tLoss: 234.946426\n",
      "====> Epoch: 1643 Average train loss: 211.4610\n",
      "====> Epoch: 1643 Average test loss: 907.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1644 [0/2589 (0%)]\tLoss: 128.877701\n",
      "Train Epoch: 1644 [300/2589 (12%)]\tLoss: 143.254440\n",
      "Train Epoch: 1644 [600/2589 (23%)]\tLoss: 132.658905\n",
      "Train Epoch: 1644 [900/2589 (35%)]\tLoss: 144.968445\n",
      "Train Epoch: 1644 [1200/2589 (46%)]\tLoss: 226.830017\n",
      "Train Epoch: 1644 [1500/2589 (58%)]\tLoss: 255.911636\n",
      "Train Epoch: 1644 [1800/2589 (70%)]\tLoss: 160.080826\n",
      "Train Epoch: 1644 [2100/2589 (81%)]\tLoss: 170.582748\n",
      "Train Epoch: 1644 [2400/2589 (93%)]\tLoss: 377.439545\n",
      "====> Epoch: 1644 Average train loss: 207.6805\n",
      "====> Epoch: 1644 Average test loss: 874.7739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1645 [0/2589 (0%)]\tLoss: 145.044098\n",
      "Train Epoch: 1645 [300/2589 (12%)]\tLoss: 133.690323\n",
      "Train Epoch: 1645 [600/2589 (23%)]\tLoss: 143.707138\n",
      "Train Epoch: 1645 [900/2589 (35%)]\tLoss: 176.505722\n",
      "Train Epoch: 1645 [1200/2589 (46%)]\tLoss: 223.821396\n",
      "Train Epoch: 1645 [1500/2589 (58%)]\tLoss: 184.235321\n",
      "Train Epoch: 1645 [1800/2589 (70%)]\tLoss: 310.306061\n",
      "Train Epoch: 1645 [2100/2589 (81%)]\tLoss: 441.133728\n",
      "Train Epoch: 1645 [2400/2589 (93%)]\tLoss: 167.210159\n",
      "====> Epoch: 1645 Average train loss: 208.2151\n",
      "====> Epoch: 1645 Average test loss: 896.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1646 [0/2589 (0%)]\tLoss: 190.303558\n",
      "Train Epoch: 1646 [300/2589 (12%)]\tLoss: 142.438293\n",
      "Train Epoch: 1646 [600/2589 (23%)]\tLoss: 173.110519\n",
      "Train Epoch: 1646 [900/2589 (35%)]\tLoss: 182.430817\n",
      "Train Epoch: 1646 [1200/2589 (46%)]\tLoss: 228.165192\n",
      "Train Epoch: 1646 [1500/2589 (58%)]\tLoss: 174.497482\n",
      "Train Epoch: 1646 [1800/2589 (70%)]\tLoss: 229.590195\n",
      "Train Epoch: 1646 [2100/2589 (81%)]\tLoss: 317.270355\n",
      "Train Epoch: 1646 [2400/2589 (93%)]\tLoss: 134.769760\n",
      "====> Epoch: 1646 Average train loss: 207.6605\n",
      "====> Epoch: 1646 Average test loss: 909.0881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1647 [0/2589 (0%)]\tLoss: 234.760223\n",
      "Train Epoch: 1647 [300/2589 (12%)]\tLoss: 173.035477\n",
      "Train Epoch: 1647 [600/2589 (23%)]\tLoss: 374.253967\n",
      "Train Epoch: 1647 [900/2589 (35%)]\tLoss: 208.737823\n",
      "Train Epoch: 1647 [1200/2589 (46%)]\tLoss: 237.776199\n",
      "Train Epoch: 1647 [1500/2589 (58%)]\tLoss: 205.625397\n",
      "Train Epoch: 1647 [1800/2589 (70%)]\tLoss: 143.632339\n",
      "Train Epoch: 1647 [2100/2589 (81%)]\tLoss: 226.731033\n",
      "Train Epoch: 1647 [2400/2589 (93%)]\tLoss: 268.923798\n",
      "====> Epoch: 1647 Average train loss: 204.7937\n",
      "====> Epoch: 1647 Average test loss: 912.0939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1648 [0/2589 (0%)]\tLoss: 165.960770\n",
      "Train Epoch: 1648 [300/2589 (12%)]\tLoss: 154.100052\n",
      "Train Epoch: 1648 [600/2589 (23%)]\tLoss: 222.696259\n",
      "Train Epoch: 1648 [900/2589 (35%)]\tLoss: 209.762665\n",
      "Train Epoch: 1648 [1200/2589 (46%)]\tLoss: 175.908707\n",
      "Train Epoch: 1648 [1500/2589 (58%)]\tLoss: 238.807510\n",
      "Train Epoch: 1648 [1800/2589 (70%)]\tLoss: 221.498917\n",
      "Train Epoch: 1648 [2100/2589 (81%)]\tLoss: 168.165527\n",
      "Train Epoch: 1648 [2400/2589 (93%)]\tLoss: 212.372513\n",
      "====> Epoch: 1648 Average train loss: 206.0654\n",
      "====> Epoch: 1648 Average test loss: 905.3160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1649 [0/2589 (0%)]\tLoss: 324.362823\n",
      "Train Epoch: 1649 [300/2589 (12%)]\tLoss: 225.250275\n",
      "Train Epoch: 1649 [600/2589 (23%)]\tLoss: 183.129486\n",
      "Train Epoch: 1649 [900/2589 (35%)]\tLoss: 150.386093\n",
      "Train Epoch: 1649 [1200/2589 (46%)]\tLoss: 151.583145\n",
      "Train Epoch: 1649 [1500/2589 (58%)]\tLoss: 261.457367\n",
      "Train Epoch: 1649 [1800/2589 (70%)]\tLoss: 208.676498\n",
      "Train Epoch: 1649 [2100/2589 (81%)]\tLoss: 219.770554\n",
      "Train Epoch: 1649 [2400/2589 (93%)]\tLoss: 445.621948\n",
      "====> Epoch: 1649 Average train loss: 210.6857\n",
      "====> Epoch: 1649 Average test loss: 905.5820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1650 [0/2589 (0%)]\tLoss: 260.470306\n",
      "Train Epoch: 1650 [300/2589 (12%)]\tLoss: 179.497650\n",
      "Train Epoch: 1650 [600/2589 (23%)]\tLoss: 156.910309\n",
      "Train Epoch: 1650 [900/2589 (35%)]\tLoss: 165.426086\n",
      "Train Epoch: 1650 [1200/2589 (46%)]\tLoss: 201.913116\n",
      "Train Epoch: 1650 [1500/2589 (58%)]\tLoss: 211.898926\n",
      "Train Epoch: 1650 [1800/2589 (70%)]\tLoss: 157.596344\n",
      "Train Epoch: 1650 [2100/2589 (81%)]\tLoss: 167.752350\n",
      "Train Epoch: 1650 [2400/2589 (93%)]\tLoss: 256.428467\n",
      "====> Epoch: 1650 Average train loss: 204.2078\n",
      "====> Epoch: 1650 Average test loss: 901.8455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1651 [0/2589 (0%)]\tLoss: 127.430206\n",
      "Train Epoch: 1651 [300/2589 (12%)]\tLoss: 128.985001\n",
      "Train Epoch: 1651 [600/2589 (23%)]\tLoss: 148.472458\n",
      "Train Epoch: 1651 [900/2589 (35%)]\tLoss: 207.975723\n",
      "Train Epoch: 1651 [1200/2589 (46%)]\tLoss: 329.462982\n",
      "Train Epoch: 1651 [1500/2589 (58%)]\tLoss: 163.912308\n",
      "Train Epoch: 1651 [1800/2589 (70%)]\tLoss: 154.107346\n",
      "Train Epoch: 1651 [2100/2589 (81%)]\tLoss: 199.376465\n",
      "Train Epoch: 1651 [2400/2589 (93%)]\tLoss: 157.919525\n",
      "====> Epoch: 1651 Average train loss: 207.6810\n",
      "====> Epoch: 1651 Average test loss: 905.6392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1652 [0/2589 (0%)]\tLoss: 180.693573\n",
      "Train Epoch: 1652 [300/2589 (12%)]\tLoss: 156.056778\n",
      "Train Epoch: 1652 [600/2589 (23%)]\tLoss: 159.774445\n",
      "Train Epoch: 1652 [900/2589 (35%)]\tLoss: 137.717590\n",
      "Train Epoch: 1652 [1200/2589 (46%)]\tLoss: 182.601456\n",
      "Train Epoch: 1652 [1500/2589 (58%)]\tLoss: 232.078140\n",
      "Train Epoch: 1652 [1800/2589 (70%)]\tLoss: 174.614532\n",
      "Train Epoch: 1652 [2100/2589 (81%)]\tLoss: 185.213272\n",
      "Train Epoch: 1652 [2400/2589 (93%)]\tLoss: 159.805099\n",
      "====> Epoch: 1652 Average train loss: 212.8455\n",
      "====> Epoch: 1652 Average test loss: 894.4321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1653 [0/2589 (0%)]\tLoss: 234.886169\n",
      "Train Epoch: 1653 [300/2589 (12%)]\tLoss: 195.912216\n",
      "Train Epoch: 1653 [600/2589 (23%)]\tLoss: 190.885605\n",
      "Train Epoch: 1653 [900/2589 (35%)]\tLoss: 250.193390\n",
      "Train Epoch: 1653 [1200/2589 (46%)]\tLoss: 221.006897\n",
      "Train Epoch: 1653 [1500/2589 (58%)]\tLoss: 216.416183\n",
      "Train Epoch: 1653 [1800/2589 (70%)]\tLoss: 144.824615\n",
      "Train Epoch: 1653 [2100/2589 (81%)]\tLoss: 170.478745\n",
      "Train Epoch: 1653 [2400/2589 (93%)]\tLoss: 195.450974\n",
      "====> Epoch: 1653 Average train loss: 212.3621\n",
      "====> Epoch: 1653 Average test loss: 903.3048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1654 [0/2589 (0%)]\tLoss: 162.689713\n",
      "Train Epoch: 1654 [300/2589 (12%)]\tLoss: 145.109283\n",
      "Train Epoch: 1654 [600/2589 (23%)]\tLoss: 296.762482\n",
      "Train Epoch: 1654 [900/2589 (35%)]\tLoss: 293.429047\n",
      "Train Epoch: 1654 [1200/2589 (46%)]\tLoss: 218.409958\n",
      "Train Epoch: 1654 [1500/2589 (58%)]\tLoss: 186.952332\n",
      "Train Epoch: 1654 [1800/2589 (70%)]\tLoss: 154.767136\n",
      "Train Epoch: 1654 [2100/2589 (81%)]\tLoss: 172.816101\n",
      "Train Epoch: 1654 [2400/2589 (93%)]\tLoss: 200.143784\n",
      "====> Epoch: 1654 Average train loss: 213.0102\n",
      "====> Epoch: 1654 Average test loss: 910.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1655 [0/2589 (0%)]\tLoss: 145.188156\n",
      "Train Epoch: 1655 [300/2589 (12%)]\tLoss: 183.513641\n",
      "Train Epoch: 1655 [600/2589 (23%)]\tLoss: 241.177002\n",
      "Train Epoch: 1655 [900/2589 (35%)]\tLoss: 185.366379\n",
      "Train Epoch: 1655 [1200/2589 (46%)]\tLoss: 221.094254\n",
      "Train Epoch: 1655 [1500/2589 (58%)]\tLoss: 179.551102\n",
      "Train Epoch: 1655 [1800/2589 (70%)]\tLoss: 388.983856\n",
      "Train Epoch: 1655 [2100/2589 (81%)]\tLoss: 130.988403\n",
      "Train Epoch: 1655 [2400/2589 (93%)]\tLoss: 216.814240\n",
      "====> Epoch: 1655 Average train loss: 222.9677\n",
      "====> Epoch: 1655 Average test loss: 923.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1656 [0/2589 (0%)]\tLoss: 199.786880\n",
      "Train Epoch: 1656 [300/2589 (12%)]\tLoss: 126.689957\n",
      "Train Epoch: 1656 [600/2589 (23%)]\tLoss: 199.375412\n",
      "Train Epoch: 1656 [900/2589 (35%)]\tLoss: 158.215271\n",
      "Train Epoch: 1656 [1200/2589 (46%)]\tLoss: 224.137543\n",
      "Train Epoch: 1656 [1500/2589 (58%)]\tLoss: 202.228683\n",
      "Train Epoch: 1656 [1800/2589 (70%)]\tLoss: 182.373627\n",
      "Train Epoch: 1656 [2100/2589 (81%)]\tLoss: 185.023148\n",
      "Train Epoch: 1656 [2400/2589 (93%)]\tLoss: 217.645981\n",
      "====> Epoch: 1656 Average train loss: 212.0179\n",
      "====> Epoch: 1656 Average test loss: 915.5346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1657 [0/2589 (0%)]\tLoss: 184.836517\n",
      "Train Epoch: 1657 [300/2589 (12%)]\tLoss: 205.810226\n",
      "Train Epoch: 1657 [600/2589 (23%)]\tLoss: 173.139175\n",
      "Train Epoch: 1657 [900/2589 (35%)]\tLoss: 208.541458\n",
      "Train Epoch: 1657 [1200/2589 (46%)]\tLoss: 136.638519\n",
      "Train Epoch: 1657 [1500/2589 (58%)]\tLoss: 193.165695\n",
      "Train Epoch: 1657 [1800/2589 (70%)]\tLoss: 159.723770\n",
      "Train Epoch: 1657 [2100/2589 (81%)]\tLoss: 200.581802\n",
      "Train Epoch: 1657 [2400/2589 (93%)]\tLoss: 172.761978\n",
      "====> Epoch: 1657 Average train loss: 204.5161\n",
      "====> Epoch: 1657 Average test loss: 904.6332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1658 [0/2589 (0%)]\tLoss: 167.947830\n",
      "Train Epoch: 1658 [300/2589 (12%)]\tLoss: 178.999817\n",
      "Train Epoch: 1658 [600/2589 (23%)]\tLoss: 275.511261\n",
      "Train Epoch: 1658 [900/2589 (35%)]\tLoss: 144.775772\n",
      "Train Epoch: 1658 [1200/2589 (46%)]\tLoss: 182.385590\n",
      "Train Epoch: 1658 [1500/2589 (58%)]\tLoss: 198.171066\n",
      "Train Epoch: 1658 [1800/2589 (70%)]\tLoss: 162.435028\n",
      "Train Epoch: 1658 [2100/2589 (81%)]\tLoss: 220.755890\n",
      "Train Epoch: 1658 [2400/2589 (93%)]\tLoss: 223.427490\n",
      "====> Epoch: 1658 Average train loss: 209.3924\n",
      "====> Epoch: 1658 Average test loss: 898.7040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1659 [0/2589 (0%)]\tLoss: 179.647812\n",
      "Train Epoch: 1659 [300/2589 (12%)]\tLoss: 241.975128\n",
      "Train Epoch: 1659 [600/2589 (23%)]\tLoss: 211.111053\n",
      "Train Epoch: 1659 [900/2589 (35%)]\tLoss: 202.492813\n",
      "Train Epoch: 1659 [1200/2589 (46%)]\tLoss: 259.540527\n",
      "Train Epoch: 1659 [1500/2589 (58%)]\tLoss: 180.328201\n",
      "Train Epoch: 1659 [1800/2589 (70%)]\tLoss: 202.495392\n",
      "Train Epoch: 1659 [2100/2589 (81%)]\tLoss: 155.037170\n",
      "Train Epoch: 1659 [2400/2589 (93%)]\tLoss: 162.132812\n",
      "====> Epoch: 1659 Average train loss: 208.6543\n",
      "====> Epoch: 1659 Average test loss: 908.8776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1660 [0/2589 (0%)]\tLoss: 258.488190\n",
      "Train Epoch: 1660 [300/2589 (12%)]\tLoss: 154.238342\n",
      "Train Epoch: 1660 [600/2589 (23%)]\tLoss: 167.019318\n",
      "Train Epoch: 1660 [900/2589 (35%)]\tLoss: 191.615433\n",
      "Train Epoch: 1660 [1200/2589 (46%)]\tLoss: 169.012466\n",
      "Train Epoch: 1660 [1500/2589 (58%)]\tLoss: 214.604767\n",
      "Train Epoch: 1660 [1800/2589 (70%)]\tLoss: 265.874969\n",
      "Train Epoch: 1660 [2100/2589 (81%)]\tLoss: 192.750809\n",
      "Train Epoch: 1660 [2400/2589 (93%)]\tLoss: 267.493347\n",
      "====> Epoch: 1660 Average train loss: 216.0502\n",
      "====> Epoch: 1660 Average test loss: 912.5017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1661 [0/2589 (0%)]\tLoss: 307.052612\n",
      "Train Epoch: 1661 [300/2589 (12%)]\tLoss: 155.441605\n",
      "Train Epoch: 1661 [600/2589 (23%)]\tLoss: 135.557938\n",
      "Train Epoch: 1661 [900/2589 (35%)]\tLoss: 166.318344\n",
      "Train Epoch: 1661 [1200/2589 (46%)]\tLoss: 192.957108\n",
      "Train Epoch: 1661 [1500/2589 (58%)]\tLoss: 165.169113\n",
      "Train Epoch: 1661 [1800/2589 (70%)]\tLoss: 325.035065\n",
      "Train Epoch: 1661 [2100/2589 (81%)]\tLoss: 203.827652\n",
      "Train Epoch: 1661 [2400/2589 (93%)]\tLoss: 171.099442\n",
      "====> Epoch: 1661 Average train loss: 207.4413\n",
      "====> Epoch: 1661 Average test loss: 906.6038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1662 [0/2589 (0%)]\tLoss: 191.810867\n",
      "Train Epoch: 1662 [300/2589 (12%)]\tLoss: 116.665817\n",
      "Train Epoch: 1662 [600/2589 (23%)]\tLoss: 184.777344\n",
      "Train Epoch: 1662 [900/2589 (35%)]\tLoss: 115.333885\n",
      "Train Epoch: 1662 [1200/2589 (46%)]\tLoss: 255.805618\n",
      "Train Epoch: 1662 [1500/2589 (58%)]\tLoss: 212.775116\n",
      "Train Epoch: 1662 [1800/2589 (70%)]\tLoss: 159.516251\n",
      "Train Epoch: 1662 [2100/2589 (81%)]\tLoss: 200.967285\n",
      "Train Epoch: 1662 [2400/2589 (93%)]\tLoss: 234.657043\n",
      "====> Epoch: 1662 Average train loss: 207.6910\n",
      "====> Epoch: 1662 Average test loss: 904.4990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1663 [0/2589 (0%)]\tLoss: 204.296219\n",
      "Train Epoch: 1663 [300/2589 (12%)]\tLoss: 176.767746\n",
      "Train Epoch: 1663 [600/2589 (23%)]\tLoss: 340.320312\n",
      "Train Epoch: 1663 [900/2589 (35%)]\tLoss: 186.018234\n",
      "Train Epoch: 1663 [1200/2589 (46%)]\tLoss: 203.853363\n",
      "Train Epoch: 1663 [1500/2589 (58%)]\tLoss: 189.160614\n",
      "Train Epoch: 1663 [1800/2589 (70%)]\tLoss: 184.142471\n",
      "Train Epoch: 1663 [2100/2589 (81%)]\tLoss: 216.228500\n",
      "Train Epoch: 1663 [2400/2589 (93%)]\tLoss: 150.567917\n",
      "====> Epoch: 1663 Average train loss: 214.9003\n",
      "====> Epoch: 1663 Average test loss: 900.3182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1664 [0/2589 (0%)]\tLoss: 170.041977\n",
      "Train Epoch: 1664 [300/2589 (12%)]\tLoss: 144.173233\n",
      "Train Epoch: 1664 [600/2589 (23%)]\tLoss: 234.961121\n",
      "Train Epoch: 1664 [900/2589 (35%)]\tLoss: 213.887405\n",
      "Train Epoch: 1664 [1200/2589 (46%)]\tLoss: 177.608810\n",
      "Train Epoch: 1664 [1500/2589 (58%)]\tLoss: 232.003738\n",
      "Train Epoch: 1664 [1800/2589 (70%)]\tLoss: 243.151184\n",
      "Train Epoch: 1664 [2100/2589 (81%)]\tLoss: 216.052750\n",
      "Train Epoch: 1664 [2400/2589 (93%)]\tLoss: 171.737274\n",
      "====> Epoch: 1664 Average train loss: 220.2893\n",
      "====> Epoch: 1664 Average test loss: 886.5090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1665 [0/2589 (0%)]\tLoss: 191.567856\n",
      "Train Epoch: 1665 [300/2589 (12%)]\tLoss: 141.598434\n",
      "Train Epoch: 1665 [600/2589 (23%)]\tLoss: 225.238739\n",
      "Train Epoch: 1665 [900/2589 (35%)]\tLoss: 142.264252\n",
      "Train Epoch: 1665 [1200/2589 (46%)]\tLoss: 157.311356\n",
      "Train Epoch: 1665 [1500/2589 (58%)]\tLoss: 205.030624\n",
      "Train Epoch: 1665 [1800/2589 (70%)]\tLoss: 187.408463\n",
      "Train Epoch: 1665 [2100/2589 (81%)]\tLoss: 220.733002\n",
      "Train Epoch: 1665 [2400/2589 (93%)]\tLoss: 140.287827\n",
      "====> Epoch: 1665 Average train loss: 201.5162\n",
      "====> Epoch: 1665 Average test loss: 907.7036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1666 [0/2589 (0%)]\tLoss: 160.205627\n",
      "Train Epoch: 1666 [300/2589 (12%)]\tLoss: 219.145340\n",
      "Train Epoch: 1666 [600/2589 (23%)]\tLoss: 248.570114\n",
      "Train Epoch: 1666 [900/2589 (35%)]\tLoss: 280.572449\n",
      "Train Epoch: 1666 [1200/2589 (46%)]\tLoss: 167.734161\n",
      "Train Epoch: 1666 [1500/2589 (58%)]\tLoss: 205.627899\n",
      "Train Epoch: 1666 [1800/2589 (70%)]\tLoss: 156.051041\n",
      "Train Epoch: 1666 [2100/2589 (81%)]\tLoss: 179.700623\n",
      "Train Epoch: 1666 [2400/2589 (93%)]\tLoss: 218.686386\n",
      "====> Epoch: 1666 Average train loss: 209.1982\n",
      "====> Epoch: 1666 Average test loss: 917.4211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1667 [0/2589 (0%)]\tLoss: 207.462341\n",
      "Train Epoch: 1667 [300/2589 (12%)]\tLoss: 162.193893\n",
      "Train Epoch: 1667 [600/2589 (23%)]\tLoss: 169.531189\n",
      "Train Epoch: 1667 [900/2589 (35%)]\tLoss: 187.500839\n",
      "Train Epoch: 1667 [1200/2589 (46%)]\tLoss: 235.015732\n",
      "Train Epoch: 1667 [1500/2589 (58%)]\tLoss: 213.664154\n",
      "Train Epoch: 1667 [1800/2589 (70%)]\tLoss: 168.051865\n",
      "Train Epoch: 1667 [2100/2589 (81%)]\tLoss: 180.144974\n",
      "Train Epoch: 1667 [2400/2589 (93%)]\tLoss: 207.023148\n",
      "====> Epoch: 1667 Average train loss: 202.2676\n",
      "====> Epoch: 1667 Average test loss: 901.8837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1668 [0/2589 (0%)]\tLoss: 212.165955\n",
      "Train Epoch: 1668 [300/2589 (12%)]\tLoss: 104.507111\n",
      "Train Epoch: 1668 [600/2589 (23%)]\tLoss: 297.292450\n",
      "Train Epoch: 1668 [900/2589 (35%)]\tLoss: 142.296570\n",
      "Train Epoch: 1668 [1200/2589 (46%)]\tLoss: 234.593246\n",
      "Train Epoch: 1668 [1500/2589 (58%)]\tLoss: 157.175812\n",
      "Train Epoch: 1668 [1800/2589 (70%)]\tLoss: 145.048630\n",
      "Train Epoch: 1668 [2100/2589 (81%)]\tLoss: 210.441864\n",
      "Train Epoch: 1668 [2400/2589 (93%)]\tLoss: 198.893829\n",
      "====> Epoch: 1668 Average train loss: 204.3360\n",
      "====> Epoch: 1668 Average test loss: 908.8462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1669 [0/2589 (0%)]\tLoss: 291.892609\n",
      "Train Epoch: 1669 [300/2589 (12%)]\tLoss: 204.526199\n",
      "Train Epoch: 1669 [600/2589 (23%)]\tLoss: 232.923843\n",
      "Train Epoch: 1669 [900/2589 (35%)]\tLoss: 158.586380\n",
      "Train Epoch: 1669 [1200/2589 (46%)]\tLoss: 212.748428\n",
      "Train Epoch: 1669 [1500/2589 (58%)]\tLoss: 210.199539\n",
      "Train Epoch: 1669 [1800/2589 (70%)]\tLoss: 261.602478\n",
      "Train Epoch: 1669 [2100/2589 (81%)]\tLoss: 148.478058\n",
      "Train Epoch: 1669 [2400/2589 (93%)]\tLoss: 180.101105\n",
      "====> Epoch: 1669 Average train loss: 208.6111\n",
      "====> Epoch: 1669 Average test loss: 911.6766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1670 [0/2589 (0%)]\tLoss: 188.637756\n",
      "Train Epoch: 1670 [300/2589 (12%)]\tLoss: 171.203995\n",
      "Train Epoch: 1670 [600/2589 (23%)]\tLoss: 143.736053\n",
      "Train Epoch: 1670 [900/2589 (35%)]\tLoss: 226.964752\n",
      "Train Epoch: 1670 [1200/2589 (46%)]\tLoss: 223.143616\n",
      "Train Epoch: 1670 [1500/2589 (58%)]\tLoss: 162.395691\n",
      "Train Epoch: 1670 [1800/2589 (70%)]\tLoss: 306.662109\n",
      "Train Epoch: 1670 [2100/2589 (81%)]\tLoss: 159.860458\n",
      "Train Epoch: 1670 [2400/2589 (93%)]\tLoss: 134.943558\n",
      "====> Epoch: 1670 Average train loss: 219.4968\n",
      "====> Epoch: 1670 Average test loss: 919.0411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1671 [0/2589 (0%)]\tLoss: 144.637436\n",
      "Train Epoch: 1671 [300/2589 (12%)]\tLoss: 258.618591\n",
      "Train Epoch: 1671 [600/2589 (23%)]\tLoss: 225.096664\n",
      "Train Epoch: 1671 [900/2589 (35%)]\tLoss: 217.886002\n",
      "Train Epoch: 1671 [1200/2589 (46%)]\tLoss: 121.824791\n",
      "Train Epoch: 1671 [1500/2589 (58%)]\tLoss: 174.150192\n",
      "Train Epoch: 1671 [1800/2589 (70%)]\tLoss: 220.530746\n",
      "Train Epoch: 1671 [2100/2589 (81%)]\tLoss: 208.158966\n",
      "Train Epoch: 1671 [2400/2589 (93%)]\tLoss: 364.711334\n",
      "====> Epoch: 1671 Average train loss: 196.6309\n",
      "====> Epoch: 1671 Average test loss: 902.7066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1672 [0/2589 (0%)]\tLoss: 162.860306\n",
      "Train Epoch: 1672 [300/2589 (12%)]\tLoss: 193.055527\n",
      "Train Epoch: 1672 [600/2589 (23%)]\tLoss: 162.013565\n",
      "Train Epoch: 1672 [900/2589 (35%)]\tLoss: 253.805634\n",
      "Train Epoch: 1672 [1200/2589 (46%)]\tLoss: 176.245987\n",
      "Train Epoch: 1672 [1500/2589 (58%)]\tLoss: 160.999191\n",
      "Train Epoch: 1672 [1800/2589 (70%)]\tLoss: 205.121353\n",
      "Train Epoch: 1672 [2100/2589 (81%)]\tLoss: 244.384735\n",
      "Train Epoch: 1672 [2400/2589 (93%)]\tLoss: 150.426758\n",
      "====> Epoch: 1672 Average train loss: 194.6470\n",
      "====> Epoch: 1672 Average test loss: 920.6179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1673 [0/2589 (0%)]\tLoss: 159.528168\n",
      "Train Epoch: 1673 [300/2589 (12%)]\tLoss: 232.810333\n",
      "Train Epoch: 1673 [600/2589 (23%)]\tLoss: 206.304489\n",
      "Train Epoch: 1673 [900/2589 (35%)]\tLoss: 177.000549\n",
      "Train Epoch: 1673 [1200/2589 (46%)]\tLoss: 155.483261\n",
      "Train Epoch: 1673 [1500/2589 (58%)]\tLoss: 185.253571\n",
      "Train Epoch: 1673 [1800/2589 (70%)]\tLoss: 208.866272\n",
      "Train Epoch: 1673 [2100/2589 (81%)]\tLoss: 346.329041\n",
      "Train Epoch: 1673 [2400/2589 (93%)]\tLoss: 659.873596\n",
      "====> Epoch: 1673 Average train loss: 206.5842\n",
      "====> Epoch: 1673 Average test loss: 909.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1674 [0/2589 (0%)]\tLoss: 190.637726\n",
      "Train Epoch: 1674 [300/2589 (12%)]\tLoss: 355.202179\n",
      "Train Epoch: 1674 [600/2589 (23%)]\tLoss: 229.642014\n",
      "Train Epoch: 1674 [900/2589 (35%)]\tLoss: 202.515686\n",
      "Train Epoch: 1674 [1200/2589 (46%)]\tLoss: 151.550201\n",
      "Train Epoch: 1674 [1500/2589 (58%)]\tLoss: 151.222748\n",
      "Train Epoch: 1674 [1800/2589 (70%)]\tLoss: 156.618652\n",
      "Train Epoch: 1674 [2100/2589 (81%)]\tLoss: 204.904068\n",
      "Train Epoch: 1674 [2400/2589 (93%)]\tLoss: 145.091644\n",
      "====> Epoch: 1674 Average train loss: 217.1879\n",
      "====> Epoch: 1674 Average test loss: 908.0760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1675 [0/2589 (0%)]\tLoss: 199.923447\n",
      "Train Epoch: 1675 [300/2589 (12%)]\tLoss: 205.147217\n",
      "Train Epoch: 1675 [600/2589 (23%)]\tLoss: 153.208710\n",
      "Train Epoch: 1675 [900/2589 (35%)]\tLoss: 213.800873\n",
      "Train Epoch: 1675 [1200/2589 (46%)]\tLoss: 168.306915\n",
      "Train Epoch: 1675 [1500/2589 (58%)]\tLoss: 196.598175\n",
      "Train Epoch: 1675 [1800/2589 (70%)]\tLoss: 138.295013\n",
      "Train Epoch: 1675 [2100/2589 (81%)]\tLoss: 236.071472\n",
      "Train Epoch: 1675 [2400/2589 (93%)]\tLoss: 214.066864\n",
      "====> Epoch: 1675 Average train loss: 212.4728\n",
      "====> Epoch: 1675 Average test loss: 907.2915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1676 [0/2589 (0%)]\tLoss: 132.242737\n",
      "Train Epoch: 1676 [300/2589 (12%)]\tLoss: 182.454987\n",
      "Train Epoch: 1676 [600/2589 (23%)]\tLoss: 223.733200\n",
      "Train Epoch: 1676 [900/2589 (35%)]\tLoss: 182.687698\n",
      "Train Epoch: 1676 [1200/2589 (46%)]\tLoss: 302.733856\n",
      "Train Epoch: 1676 [1500/2589 (58%)]\tLoss: 202.675568\n",
      "Train Epoch: 1676 [1800/2589 (70%)]\tLoss: 165.992050\n",
      "Train Epoch: 1676 [2100/2589 (81%)]\tLoss: 219.887314\n",
      "Train Epoch: 1676 [2400/2589 (93%)]\tLoss: 185.279449\n",
      "====> Epoch: 1676 Average train loss: 212.6219\n",
      "====> Epoch: 1676 Average test loss: 906.3355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1677 [0/2589 (0%)]\tLoss: 182.322845\n",
      "Train Epoch: 1677 [300/2589 (12%)]\tLoss: 194.496338\n",
      "Train Epoch: 1677 [600/2589 (23%)]\tLoss: 166.072342\n",
      "Train Epoch: 1677 [900/2589 (35%)]\tLoss: 195.532028\n",
      "Train Epoch: 1677 [1200/2589 (46%)]\tLoss: 174.954361\n",
      "Train Epoch: 1677 [1500/2589 (58%)]\tLoss: 191.263687\n",
      "Train Epoch: 1677 [1800/2589 (70%)]\tLoss: 245.938095\n",
      "Train Epoch: 1677 [2100/2589 (81%)]\tLoss: 261.155518\n",
      "Train Epoch: 1677 [2400/2589 (93%)]\tLoss: 213.360931\n",
      "====> Epoch: 1677 Average train loss: 204.8572\n",
      "====> Epoch: 1677 Average test loss: 908.2230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1678 [0/2589 (0%)]\tLoss: 256.155151\n",
      "Train Epoch: 1678 [300/2589 (12%)]\tLoss: 214.985153\n",
      "Train Epoch: 1678 [600/2589 (23%)]\tLoss: 163.515869\n",
      "Train Epoch: 1678 [900/2589 (35%)]\tLoss: 286.313629\n",
      "Train Epoch: 1678 [1200/2589 (46%)]\tLoss: 268.712036\n",
      "Train Epoch: 1678 [1500/2589 (58%)]\tLoss: 174.738419\n",
      "Train Epoch: 1678 [1800/2589 (70%)]\tLoss: 172.615143\n",
      "Train Epoch: 1678 [2100/2589 (81%)]\tLoss: 220.732422\n",
      "Train Epoch: 1678 [2400/2589 (93%)]\tLoss: 120.794563\n",
      "====> Epoch: 1678 Average train loss: 204.4460\n",
      "====> Epoch: 1678 Average test loss: 919.1569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1679 [0/2589 (0%)]\tLoss: 253.192871\n",
      "Train Epoch: 1679 [300/2589 (12%)]\tLoss: 145.212982\n",
      "Train Epoch: 1679 [600/2589 (23%)]\tLoss: 148.779205\n",
      "Train Epoch: 1679 [900/2589 (35%)]\tLoss: 137.119629\n",
      "Train Epoch: 1679 [1200/2589 (46%)]\tLoss: 203.835693\n",
      "Train Epoch: 1679 [1500/2589 (58%)]\tLoss: 173.573715\n",
      "Train Epoch: 1679 [1800/2589 (70%)]\tLoss: 177.723770\n",
      "Train Epoch: 1679 [2100/2589 (81%)]\tLoss: 165.447784\n",
      "Train Epoch: 1679 [2400/2589 (93%)]\tLoss: 159.581848\n",
      "====> Epoch: 1679 Average train loss: 212.7009\n",
      "====> Epoch: 1679 Average test loss: 905.6882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1680 [0/2589 (0%)]\tLoss: 199.498444\n",
      "Train Epoch: 1680 [300/2589 (12%)]\tLoss: 193.093094\n",
      "Train Epoch: 1680 [600/2589 (23%)]\tLoss: 207.425949\n",
      "Train Epoch: 1680 [900/2589 (35%)]\tLoss: 228.648895\n",
      "Train Epoch: 1680 [1200/2589 (46%)]\tLoss: 211.595993\n",
      "Train Epoch: 1680 [1500/2589 (58%)]\tLoss: 262.991486\n",
      "Train Epoch: 1680 [1800/2589 (70%)]\tLoss: 168.731293\n",
      "Train Epoch: 1680 [2100/2589 (81%)]\tLoss: 343.759155\n",
      "Train Epoch: 1680 [2400/2589 (93%)]\tLoss: 198.464951\n",
      "====> Epoch: 1680 Average train loss: 214.6089\n",
      "====> Epoch: 1680 Average test loss: 895.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1681 [0/2589 (0%)]\tLoss: 138.791321\n",
      "Train Epoch: 1681 [300/2589 (12%)]\tLoss: 156.398849\n",
      "Train Epoch: 1681 [600/2589 (23%)]\tLoss: 192.529495\n",
      "Train Epoch: 1681 [900/2589 (35%)]\tLoss: 142.185135\n",
      "Train Epoch: 1681 [1200/2589 (46%)]\tLoss: 137.790390\n",
      "Train Epoch: 1681 [1500/2589 (58%)]\tLoss: 170.768951\n",
      "Train Epoch: 1681 [1800/2589 (70%)]\tLoss: 262.272583\n",
      "Train Epoch: 1681 [2100/2589 (81%)]\tLoss: 191.656662\n",
      "Train Epoch: 1681 [2400/2589 (93%)]\tLoss: 169.274963\n",
      "====> Epoch: 1681 Average train loss: 196.7665\n",
      "====> Epoch: 1681 Average test loss: 902.2128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1682 [0/2589 (0%)]\tLoss: 153.031830\n",
      "Train Epoch: 1682 [300/2589 (12%)]\tLoss: 185.178360\n",
      "Train Epoch: 1682 [600/2589 (23%)]\tLoss: 169.385544\n",
      "Train Epoch: 1682 [900/2589 (35%)]\tLoss: 166.701950\n",
      "Train Epoch: 1682 [1200/2589 (46%)]\tLoss: 210.705276\n",
      "Train Epoch: 1682 [1500/2589 (58%)]\tLoss: 338.706940\n",
      "Train Epoch: 1682 [1800/2589 (70%)]\tLoss: 169.042038\n",
      "Train Epoch: 1682 [2100/2589 (81%)]\tLoss: 179.410736\n",
      "Train Epoch: 1682 [2400/2589 (93%)]\tLoss: 187.017502\n",
      "====> Epoch: 1682 Average train loss: 203.9335\n",
      "====> Epoch: 1682 Average test loss: 895.6849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1683 [0/2589 (0%)]\tLoss: 377.213074\n",
      "Train Epoch: 1683 [300/2589 (12%)]\tLoss: 172.535248\n",
      "Train Epoch: 1683 [600/2589 (23%)]\tLoss: 211.706284\n",
      "Train Epoch: 1683 [900/2589 (35%)]\tLoss: 186.448318\n",
      "Train Epoch: 1683 [1200/2589 (46%)]\tLoss: 403.051300\n",
      "Train Epoch: 1683 [1500/2589 (58%)]\tLoss: 206.838333\n",
      "Train Epoch: 1683 [1800/2589 (70%)]\tLoss: 158.297333\n",
      "Train Epoch: 1683 [2100/2589 (81%)]\tLoss: 200.641342\n",
      "Train Epoch: 1683 [2400/2589 (93%)]\tLoss: 379.172058\n",
      "====> Epoch: 1683 Average train loss: 214.6670\n",
      "====> Epoch: 1683 Average test loss: 903.4738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1684 [0/2589 (0%)]\tLoss: 234.954636\n",
      "Train Epoch: 1684 [300/2589 (12%)]\tLoss: 226.760025\n",
      "Train Epoch: 1684 [600/2589 (23%)]\tLoss: 251.302032\n",
      "Train Epoch: 1684 [900/2589 (35%)]\tLoss: 139.242966\n",
      "Train Epoch: 1684 [1200/2589 (46%)]\tLoss: 192.710159\n",
      "Train Epoch: 1684 [1500/2589 (58%)]\tLoss: 211.251221\n",
      "Train Epoch: 1684 [1800/2589 (70%)]\tLoss: 192.859680\n",
      "Train Epoch: 1684 [2100/2589 (81%)]\tLoss: 188.743744\n",
      "Train Epoch: 1684 [2400/2589 (93%)]\tLoss: 165.087753\n",
      "====> Epoch: 1684 Average train loss: 222.0859\n",
      "====> Epoch: 1684 Average test loss: 907.8014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1685 [0/2589 (0%)]\tLoss: 166.460983\n",
      "Train Epoch: 1685 [300/2589 (12%)]\tLoss: 151.922913\n",
      "Train Epoch: 1685 [600/2589 (23%)]\tLoss: 195.688400\n",
      "Train Epoch: 1685 [900/2589 (35%)]\tLoss: 308.795807\n",
      "Train Epoch: 1685 [1200/2589 (46%)]\tLoss: 312.561310\n",
      "Train Epoch: 1685 [1500/2589 (58%)]\tLoss: 215.425873\n",
      "Train Epoch: 1685 [1800/2589 (70%)]\tLoss: 197.698441\n",
      "Train Epoch: 1685 [2100/2589 (81%)]\tLoss: 213.864899\n",
      "Train Epoch: 1685 [2400/2589 (93%)]\tLoss: 159.861252\n",
      "====> Epoch: 1685 Average train loss: 204.6783\n",
      "====> Epoch: 1685 Average test loss: 896.2613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1686 [0/2589 (0%)]\tLoss: 205.911758\n",
      "Train Epoch: 1686 [300/2589 (12%)]\tLoss: 175.802933\n",
      "Train Epoch: 1686 [600/2589 (23%)]\tLoss: 144.641571\n",
      "Train Epoch: 1686 [900/2589 (35%)]\tLoss: 162.470886\n",
      "Train Epoch: 1686 [1200/2589 (46%)]\tLoss: 180.190948\n",
      "Train Epoch: 1686 [1500/2589 (58%)]\tLoss: 390.254211\n",
      "Train Epoch: 1686 [1800/2589 (70%)]\tLoss: 212.485275\n",
      "Train Epoch: 1686 [2100/2589 (81%)]\tLoss: 204.584152\n",
      "Train Epoch: 1686 [2400/2589 (93%)]\tLoss: 323.254395\n",
      "====> Epoch: 1686 Average train loss: 219.1765\n",
      "====> Epoch: 1686 Average test loss: 917.5883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1687 [0/2589 (0%)]\tLoss: 261.121887\n",
      "Train Epoch: 1687 [300/2589 (12%)]\tLoss: 261.816223\n",
      "Train Epoch: 1687 [600/2589 (23%)]\tLoss: 128.799591\n",
      "Train Epoch: 1687 [900/2589 (35%)]\tLoss: 189.094788\n",
      "Train Epoch: 1687 [1200/2589 (46%)]\tLoss: 269.004944\n",
      "Train Epoch: 1687 [1500/2589 (58%)]\tLoss: 179.579315\n",
      "Train Epoch: 1687 [1800/2589 (70%)]\tLoss: 234.663818\n",
      "Train Epoch: 1687 [2100/2589 (81%)]\tLoss: 158.264435\n",
      "Train Epoch: 1687 [2400/2589 (93%)]\tLoss: 253.785889\n",
      "====> Epoch: 1687 Average train loss: 204.3121\n",
      "====> Epoch: 1687 Average test loss: 901.2122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1688 [0/2589 (0%)]\tLoss: 227.328186\n",
      "Train Epoch: 1688 [300/2589 (12%)]\tLoss: 454.025391\n",
      "Train Epoch: 1688 [600/2589 (23%)]\tLoss: 219.075775\n",
      "Train Epoch: 1688 [900/2589 (35%)]\tLoss: 370.338593\n",
      "Train Epoch: 1688 [1200/2589 (46%)]\tLoss: 262.490021\n",
      "Train Epoch: 1688 [1500/2589 (58%)]\tLoss: 184.357147\n",
      "Train Epoch: 1688 [1800/2589 (70%)]\tLoss: 210.787521\n",
      "Train Epoch: 1688 [2100/2589 (81%)]\tLoss: 232.197906\n",
      "Train Epoch: 1688 [2400/2589 (93%)]\tLoss: 199.332687\n",
      "====> Epoch: 1688 Average train loss: 215.3428\n",
      "====> Epoch: 1688 Average test loss: 908.6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1689 [0/2589 (0%)]\tLoss: 144.070801\n",
      "Train Epoch: 1689 [300/2589 (12%)]\tLoss: 192.727142\n",
      "Train Epoch: 1689 [600/2589 (23%)]\tLoss: 156.998077\n",
      "Train Epoch: 1689 [900/2589 (35%)]\tLoss: 181.920013\n",
      "Train Epoch: 1689 [1200/2589 (46%)]\tLoss: 158.192078\n",
      "Train Epoch: 1689 [1500/2589 (58%)]\tLoss: 181.217697\n",
      "Train Epoch: 1689 [1800/2589 (70%)]\tLoss: 180.939713\n",
      "Train Epoch: 1689 [2100/2589 (81%)]\tLoss: 222.696487\n",
      "Train Epoch: 1689 [2400/2589 (93%)]\tLoss: 143.672089\n",
      "====> Epoch: 1689 Average train loss: 211.2540\n",
      "====> Epoch: 1689 Average test loss: 905.7233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1690 [0/2589 (0%)]\tLoss: 224.763641\n",
      "Train Epoch: 1690 [300/2589 (12%)]\tLoss: 279.903839\n",
      "Train Epoch: 1690 [600/2589 (23%)]\tLoss: 223.809052\n",
      "Train Epoch: 1690 [900/2589 (35%)]\tLoss: 235.541489\n",
      "Train Epoch: 1690 [1200/2589 (46%)]\tLoss: 202.582581\n",
      "Train Epoch: 1690 [1500/2589 (58%)]\tLoss: 196.584335\n",
      "Train Epoch: 1690 [1800/2589 (70%)]\tLoss: 117.739876\n",
      "Train Epoch: 1690 [2100/2589 (81%)]\tLoss: 230.519424\n",
      "Train Epoch: 1690 [2400/2589 (93%)]\tLoss: 142.841263\n",
      "====> Epoch: 1690 Average train loss: 208.4885\n",
      "====> Epoch: 1690 Average test loss: 903.6619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1691 [0/2589 (0%)]\tLoss: 329.909668\n",
      "Train Epoch: 1691 [300/2589 (12%)]\tLoss: 174.603424\n",
      "Train Epoch: 1691 [600/2589 (23%)]\tLoss: 152.877289\n",
      "Train Epoch: 1691 [900/2589 (35%)]\tLoss: 284.685730\n",
      "Train Epoch: 1691 [1200/2589 (46%)]\tLoss: 194.449036\n",
      "Train Epoch: 1691 [1500/2589 (58%)]\tLoss: 182.384460\n",
      "Train Epoch: 1691 [1800/2589 (70%)]\tLoss: 266.438293\n",
      "Train Epoch: 1691 [2100/2589 (81%)]\tLoss: 144.706161\n",
      "Train Epoch: 1691 [2400/2589 (93%)]\tLoss: 172.816406\n",
      "====> Epoch: 1691 Average train loss: 205.2534\n",
      "====> Epoch: 1691 Average test loss: 913.5003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1692 [0/2589 (0%)]\tLoss: 141.528290\n",
      "Train Epoch: 1692 [300/2589 (12%)]\tLoss: 161.667999\n",
      "Train Epoch: 1692 [600/2589 (23%)]\tLoss: 195.966156\n",
      "Train Epoch: 1692 [900/2589 (35%)]\tLoss: 182.692780\n",
      "Train Epoch: 1692 [1200/2589 (46%)]\tLoss: 232.524155\n",
      "Train Epoch: 1692 [1500/2589 (58%)]\tLoss: 203.126038\n",
      "Train Epoch: 1692 [1800/2589 (70%)]\tLoss: 165.044998\n",
      "Train Epoch: 1692 [2100/2589 (81%)]\tLoss: 199.862946\n",
      "Train Epoch: 1692 [2400/2589 (93%)]\tLoss: 199.128967\n",
      "====> Epoch: 1692 Average train loss: 195.2964\n",
      "====> Epoch: 1692 Average test loss: 908.0624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1693 [0/2589 (0%)]\tLoss: 194.977783\n",
      "Train Epoch: 1693 [300/2589 (12%)]\tLoss: 131.496246\n",
      "Train Epoch: 1693 [600/2589 (23%)]\tLoss: 336.812317\n",
      "Train Epoch: 1693 [900/2589 (35%)]\tLoss: 171.022614\n",
      "Train Epoch: 1693 [1200/2589 (46%)]\tLoss: 295.151672\n",
      "Train Epoch: 1693 [1500/2589 (58%)]\tLoss: 214.534424\n",
      "Train Epoch: 1693 [1800/2589 (70%)]\tLoss: 169.307327\n",
      "Train Epoch: 1693 [2100/2589 (81%)]\tLoss: 299.338287\n",
      "Train Epoch: 1693 [2400/2589 (93%)]\tLoss: 292.358429\n",
      "====> Epoch: 1693 Average train loss: 202.3589\n",
      "====> Epoch: 1693 Average test loss: 908.0358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1694 [0/2589 (0%)]\tLoss: 218.631653\n",
      "Train Epoch: 1694 [300/2589 (12%)]\tLoss: 192.555283\n",
      "Train Epoch: 1694 [600/2589 (23%)]\tLoss: 198.621597\n",
      "Train Epoch: 1694 [900/2589 (35%)]\tLoss: 223.789719\n",
      "Train Epoch: 1694 [1200/2589 (46%)]\tLoss: 168.834793\n",
      "Train Epoch: 1694 [1500/2589 (58%)]\tLoss: 233.631866\n",
      "Train Epoch: 1694 [1800/2589 (70%)]\tLoss: 226.498550\n",
      "Train Epoch: 1694 [2100/2589 (81%)]\tLoss: 189.143982\n",
      "Train Epoch: 1694 [2400/2589 (93%)]\tLoss: 274.074310\n",
      "====> Epoch: 1694 Average train loss: 216.0432\n",
      "====> Epoch: 1694 Average test loss: 912.7809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1695 [0/2589 (0%)]\tLoss: 159.820969\n",
      "Train Epoch: 1695 [300/2589 (12%)]\tLoss: 277.901184\n",
      "Train Epoch: 1695 [600/2589 (23%)]\tLoss: 222.491852\n",
      "Train Epoch: 1695 [900/2589 (35%)]\tLoss: 215.913605\n",
      "Train Epoch: 1695 [1200/2589 (46%)]\tLoss: 145.660538\n",
      "Train Epoch: 1695 [1500/2589 (58%)]\tLoss: 192.925690\n",
      "Train Epoch: 1695 [1800/2589 (70%)]\tLoss: 352.599762\n",
      "Train Epoch: 1695 [2100/2589 (81%)]\tLoss: 127.109306\n",
      "Train Epoch: 1695 [2400/2589 (93%)]\tLoss: 287.477966\n",
      "====> Epoch: 1695 Average train loss: 210.9397\n",
      "====> Epoch: 1695 Average test loss: 901.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1696 [0/2589 (0%)]\tLoss: 214.645813\n",
      "Train Epoch: 1696 [300/2589 (12%)]\tLoss: 200.134689\n",
      "Train Epoch: 1696 [600/2589 (23%)]\tLoss: 184.156219\n",
      "Train Epoch: 1696 [900/2589 (35%)]\tLoss: 234.847336\n",
      "Train Epoch: 1696 [1200/2589 (46%)]\tLoss: 139.295547\n",
      "Train Epoch: 1696 [1500/2589 (58%)]\tLoss: 244.466003\n",
      "Train Epoch: 1696 [1800/2589 (70%)]\tLoss: 306.380402\n",
      "Train Epoch: 1696 [2100/2589 (81%)]\tLoss: 183.400543\n",
      "Train Epoch: 1696 [2400/2589 (93%)]\tLoss: 210.336105\n",
      "====> Epoch: 1696 Average train loss: 213.6086\n",
      "====> Epoch: 1696 Average test loss: 902.9183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1697 [0/2589 (0%)]\tLoss: 191.486023\n",
      "Train Epoch: 1697 [300/2589 (12%)]\tLoss: 226.834732\n",
      "Train Epoch: 1697 [600/2589 (23%)]\tLoss: 235.007767\n",
      "Train Epoch: 1697 [900/2589 (35%)]\tLoss: 246.410583\n",
      "Train Epoch: 1697 [1200/2589 (46%)]\tLoss: 220.809784\n",
      "Train Epoch: 1697 [1500/2589 (58%)]\tLoss: 191.444916\n",
      "Train Epoch: 1697 [1800/2589 (70%)]\tLoss: 179.899597\n",
      "Train Epoch: 1697 [2100/2589 (81%)]\tLoss: 178.856842\n",
      "Train Epoch: 1697 [2400/2589 (93%)]\tLoss: 196.387299\n",
      "====> Epoch: 1697 Average train loss: 211.8932\n",
      "====> Epoch: 1697 Average test loss: 924.0943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1698 [0/2589 (0%)]\tLoss: 219.282990\n",
      "Train Epoch: 1698 [300/2589 (12%)]\tLoss: 209.442398\n",
      "Train Epoch: 1698 [600/2589 (23%)]\tLoss: 164.837433\n",
      "Train Epoch: 1698 [900/2589 (35%)]\tLoss: 175.970398\n",
      "Train Epoch: 1698 [1200/2589 (46%)]\tLoss: 216.814453\n",
      "Train Epoch: 1698 [1500/2589 (58%)]\tLoss: 245.633408\n",
      "Train Epoch: 1698 [1800/2589 (70%)]\tLoss: 205.791641\n",
      "Train Epoch: 1698 [2100/2589 (81%)]\tLoss: 149.338181\n",
      "Train Epoch: 1698 [2400/2589 (93%)]\tLoss: 304.305023\n",
      "====> Epoch: 1698 Average train loss: 207.7517\n",
      "====> Epoch: 1698 Average test loss: 904.2348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1699 [0/2589 (0%)]\tLoss: 132.148621\n",
      "Train Epoch: 1699 [300/2589 (12%)]\tLoss: 224.452850\n",
      "Train Epoch: 1699 [600/2589 (23%)]\tLoss: 170.187302\n",
      "Train Epoch: 1699 [900/2589 (35%)]\tLoss: 117.586006\n",
      "Train Epoch: 1699 [1200/2589 (46%)]\tLoss: 259.021088\n",
      "Train Epoch: 1699 [1500/2589 (58%)]\tLoss: 197.748352\n",
      "Train Epoch: 1699 [1800/2589 (70%)]\tLoss: 146.516769\n",
      "Train Epoch: 1699 [2100/2589 (81%)]\tLoss: 242.968414\n",
      "Train Epoch: 1699 [2400/2589 (93%)]\tLoss: 190.730453\n",
      "====> Epoch: 1699 Average train loss: 214.5863\n",
      "====> Epoch: 1699 Average test loss: 904.4537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1700 [0/2589 (0%)]\tLoss: 179.874313\n",
      "Train Epoch: 1700 [300/2589 (12%)]\tLoss: 189.289612\n",
      "Train Epoch: 1700 [600/2589 (23%)]\tLoss: 185.373764\n",
      "Train Epoch: 1700 [900/2589 (35%)]\tLoss: 180.546478\n",
      "Train Epoch: 1700 [1200/2589 (46%)]\tLoss: 174.112045\n",
      "Train Epoch: 1700 [1500/2589 (58%)]\tLoss: 193.731354\n",
      "Train Epoch: 1700 [1800/2589 (70%)]\tLoss: 310.646057\n",
      "Train Epoch: 1700 [2100/2589 (81%)]\tLoss: 223.094666\n",
      "Train Epoch: 1700 [2400/2589 (93%)]\tLoss: 167.770355\n",
      "====> Epoch: 1700 Average train loss: 209.4503\n",
      "====> Epoch: 1700 Average test loss: 915.2733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1701 [0/2589 (0%)]\tLoss: 211.758240\n",
      "Train Epoch: 1701 [300/2589 (12%)]\tLoss: 192.700256\n",
      "Train Epoch: 1701 [600/2589 (23%)]\tLoss: 247.982346\n",
      "Train Epoch: 1701 [900/2589 (35%)]\tLoss: 290.236389\n",
      "Train Epoch: 1701 [1200/2589 (46%)]\tLoss: 302.366394\n",
      "Train Epoch: 1701 [1500/2589 (58%)]\tLoss: 168.537979\n",
      "Train Epoch: 1701 [1800/2589 (70%)]\tLoss: 151.564255\n",
      "Train Epoch: 1701 [2100/2589 (81%)]\tLoss: 278.674988\n",
      "Train Epoch: 1701 [2400/2589 (93%)]\tLoss: 190.807297\n",
      "====> Epoch: 1701 Average train loss: 203.5896\n",
      "====> Epoch: 1701 Average test loss: 908.5891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1702 [0/2589 (0%)]\tLoss: 164.199158\n",
      "Train Epoch: 1702 [300/2589 (12%)]\tLoss: 148.133133\n",
      "Train Epoch: 1702 [600/2589 (23%)]\tLoss: 184.674408\n",
      "Train Epoch: 1702 [900/2589 (35%)]\tLoss: 180.245850\n",
      "Train Epoch: 1702 [1200/2589 (46%)]\tLoss: 142.395355\n",
      "Train Epoch: 1702 [1500/2589 (58%)]\tLoss: 194.566055\n",
      "Train Epoch: 1702 [1800/2589 (70%)]\tLoss: 337.398438\n",
      "Train Epoch: 1702 [2100/2589 (81%)]\tLoss: 231.620667\n",
      "Train Epoch: 1702 [2400/2589 (93%)]\tLoss: 145.841766\n",
      "====> Epoch: 1702 Average train loss: 199.0305\n",
      "====> Epoch: 1702 Average test loss: 902.4095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1703 [0/2589 (0%)]\tLoss: 163.179703\n",
      "Train Epoch: 1703 [300/2589 (12%)]\tLoss: 335.933777\n",
      "Train Epoch: 1703 [600/2589 (23%)]\tLoss: 188.261215\n",
      "Train Epoch: 1703 [900/2589 (35%)]\tLoss: 133.819641\n",
      "Train Epoch: 1703 [1200/2589 (46%)]\tLoss: 158.169098\n",
      "Train Epoch: 1703 [1500/2589 (58%)]\tLoss: 312.881714\n",
      "Train Epoch: 1703 [1800/2589 (70%)]\tLoss: 208.276794\n",
      "Train Epoch: 1703 [2100/2589 (81%)]\tLoss: 145.357040\n",
      "Train Epoch: 1703 [2400/2589 (93%)]\tLoss: 168.550644\n",
      "====> Epoch: 1703 Average train loss: 203.9000\n",
      "====> Epoch: 1703 Average test loss: 916.8196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1704 [0/2589 (0%)]\tLoss: 154.015305\n",
      "Train Epoch: 1704 [300/2589 (12%)]\tLoss: 197.660568\n",
      "Train Epoch: 1704 [600/2589 (23%)]\tLoss: 136.542786\n",
      "Train Epoch: 1704 [900/2589 (35%)]\tLoss: 178.377609\n",
      "Train Epoch: 1704 [1200/2589 (46%)]\tLoss: 126.977776\n",
      "Train Epoch: 1704 [1500/2589 (58%)]\tLoss: 142.343597\n",
      "Train Epoch: 1704 [1800/2589 (70%)]\tLoss: 200.888458\n",
      "Train Epoch: 1704 [2100/2589 (81%)]\tLoss: 144.940201\n",
      "Train Epoch: 1704 [2400/2589 (93%)]\tLoss: 289.948242\n",
      "====> Epoch: 1704 Average train loss: 204.2192\n",
      "====> Epoch: 1704 Average test loss: 907.0289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1705 [0/2589 (0%)]\tLoss: 133.467453\n",
      "Train Epoch: 1705 [300/2589 (12%)]\tLoss: 128.158798\n",
      "Train Epoch: 1705 [600/2589 (23%)]\tLoss: 163.363281\n",
      "Train Epoch: 1705 [900/2589 (35%)]\tLoss: 220.502884\n",
      "Train Epoch: 1705 [1200/2589 (46%)]\tLoss: 181.008377\n",
      "Train Epoch: 1705 [1500/2589 (58%)]\tLoss: 154.325363\n",
      "Train Epoch: 1705 [1800/2589 (70%)]\tLoss: 189.770691\n",
      "Train Epoch: 1705 [2100/2589 (81%)]\tLoss: 168.453064\n",
      "Train Epoch: 1705 [2400/2589 (93%)]\tLoss: 150.009232\n",
      "====> Epoch: 1705 Average train loss: 205.6777\n",
      "====> Epoch: 1705 Average test loss: 921.6648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1706 [0/2589 (0%)]\tLoss: 182.621155\n",
      "Train Epoch: 1706 [300/2589 (12%)]\tLoss: 176.024460\n",
      "Train Epoch: 1706 [600/2589 (23%)]\tLoss: 158.622391\n",
      "Train Epoch: 1706 [900/2589 (35%)]\tLoss: 321.896851\n",
      "Train Epoch: 1706 [1200/2589 (46%)]\tLoss: 136.544861\n",
      "Train Epoch: 1706 [1500/2589 (58%)]\tLoss: 239.221252\n",
      "Train Epoch: 1706 [1800/2589 (70%)]\tLoss: 172.317780\n",
      "Train Epoch: 1706 [2100/2589 (81%)]\tLoss: 286.801270\n",
      "Train Epoch: 1706 [2400/2589 (93%)]\tLoss: 389.685455\n",
      "====> Epoch: 1706 Average train loss: 220.3101\n",
      "====> Epoch: 1706 Average test loss: 896.6077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1707 [0/2589 (0%)]\tLoss: 172.317032\n",
      "Train Epoch: 1707 [300/2589 (12%)]\tLoss: 193.222580\n",
      "Train Epoch: 1707 [600/2589 (23%)]\tLoss: 202.103607\n",
      "Train Epoch: 1707 [900/2589 (35%)]\tLoss: 198.290985\n",
      "Train Epoch: 1707 [1200/2589 (46%)]\tLoss: 167.477921\n",
      "Train Epoch: 1707 [1500/2589 (58%)]\tLoss: 164.363052\n",
      "Train Epoch: 1707 [1800/2589 (70%)]\tLoss: 128.687164\n",
      "Train Epoch: 1707 [2100/2589 (81%)]\tLoss: 138.906769\n",
      "Train Epoch: 1707 [2400/2589 (93%)]\tLoss: 179.863220\n",
      "====> Epoch: 1707 Average train loss: 195.7334\n",
      "====> Epoch: 1707 Average test loss: 895.1233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1708 [0/2589 (0%)]\tLoss: 301.257812\n",
      "Train Epoch: 1708 [300/2589 (12%)]\tLoss: 177.987442\n",
      "Train Epoch: 1708 [600/2589 (23%)]\tLoss: 261.822906\n",
      "Train Epoch: 1708 [900/2589 (35%)]\tLoss: 177.933914\n",
      "Train Epoch: 1708 [1200/2589 (46%)]\tLoss: 149.283691\n",
      "Train Epoch: 1708 [1500/2589 (58%)]\tLoss: 195.629105\n",
      "Train Epoch: 1708 [1800/2589 (70%)]\tLoss: 358.814056\n",
      "Train Epoch: 1708 [2100/2589 (81%)]\tLoss: 175.893616\n",
      "Train Epoch: 1708 [2400/2589 (93%)]\tLoss: 177.280365\n",
      "====> Epoch: 1708 Average train loss: 217.8477\n",
      "====> Epoch: 1708 Average test loss: 905.1898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1709 [0/2589 (0%)]\tLoss: 170.598618\n",
      "Train Epoch: 1709 [300/2589 (12%)]\tLoss: 187.284256\n",
      "Train Epoch: 1709 [600/2589 (23%)]\tLoss: 212.364227\n",
      "Train Epoch: 1709 [900/2589 (35%)]\tLoss: 245.286896\n",
      "Train Epoch: 1709 [1200/2589 (46%)]\tLoss: 251.021591\n",
      "Train Epoch: 1709 [1500/2589 (58%)]\tLoss: 180.524368\n",
      "Train Epoch: 1709 [1800/2589 (70%)]\tLoss: 192.041809\n",
      "Train Epoch: 1709 [2100/2589 (81%)]\tLoss: 264.608093\n",
      "Train Epoch: 1709 [2400/2589 (93%)]\tLoss: 194.534012\n",
      "====> Epoch: 1709 Average train loss: 207.7004\n",
      "====> Epoch: 1709 Average test loss: 908.6794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1710 [0/2589 (0%)]\tLoss: 226.174423\n",
      "Train Epoch: 1710 [300/2589 (12%)]\tLoss: 246.641861\n",
      "Train Epoch: 1710 [600/2589 (23%)]\tLoss: 207.189789\n",
      "Train Epoch: 1710 [900/2589 (35%)]\tLoss: 201.871582\n",
      "Train Epoch: 1710 [1200/2589 (46%)]\tLoss: 135.489761\n",
      "Train Epoch: 1710 [1500/2589 (58%)]\tLoss: 151.846130\n",
      "Train Epoch: 1710 [1800/2589 (70%)]\tLoss: 269.844727\n",
      "Train Epoch: 1710 [2100/2589 (81%)]\tLoss: 199.425201\n",
      "Train Epoch: 1710 [2400/2589 (93%)]\tLoss: 208.178452\n",
      "====> Epoch: 1710 Average train loss: 214.9773\n",
      "====> Epoch: 1710 Average test loss: 918.5651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1711 [0/2589 (0%)]\tLoss: 227.704239\n",
      "Train Epoch: 1711 [300/2589 (12%)]\tLoss: 144.586380\n",
      "Train Epoch: 1711 [600/2589 (23%)]\tLoss: 219.693054\n",
      "Train Epoch: 1711 [900/2589 (35%)]\tLoss: 276.392731\n",
      "Train Epoch: 1711 [1200/2589 (46%)]\tLoss: 239.750397\n",
      "Train Epoch: 1711 [1500/2589 (58%)]\tLoss: 158.893326\n",
      "Train Epoch: 1711 [1800/2589 (70%)]\tLoss: 165.997284\n",
      "Train Epoch: 1711 [2100/2589 (81%)]\tLoss: 200.028259\n",
      "Train Epoch: 1711 [2400/2589 (93%)]\tLoss: 211.765793\n",
      "====> Epoch: 1711 Average train loss: 212.7912\n",
      "====> Epoch: 1711 Average test loss: 900.3420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1712 [0/2589 (0%)]\tLoss: 239.175095\n",
      "Train Epoch: 1712 [300/2589 (12%)]\tLoss: 213.786850\n",
      "Train Epoch: 1712 [600/2589 (23%)]\tLoss: 158.872086\n",
      "Train Epoch: 1712 [900/2589 (35%)]\tLoss: 269.979889\n",
      "Train Epoch: 1712 [1200/2589 (46%)]\tLoss: 193.743347\n",
      "Train Epoch: 1712 [1500/2589 (58%)]\tLoss: 186.852249\n",
      "Train Epoch: 1712 [1800/2589 (70%)]\tLoss: 234.577957\n",
      "Train Epoch: 1712 [2100/2589 (81%)]\tLoss: 173.653580\n",
      "Train Epoch: 1712 [2400/2589 (93%)]\tLoss: 177.986389\n",
      "====> Epoch: 1712 Average train loss: 207.1067\n",
      "====> Epoch: 1712 Average test loss: 904.7763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1713 [0/2589 (0%)]\tLoss: 202.069672\n",
      "Train Epoch: 1713 [300/2589 (12%)]\tLoss: 179.142746\n",
      "Train Epoch: 1713 [600/2589 (23%)]\tLoss: 179.296631\n",
      "Train Epoch: 1713 [900/2589 (35%)]\tLoss: 217.657776\n",
      "Train Epoch: 1713 [1200/2589 (46%)]\tLoss: 153.183868\n",
      "Train Epoch: 1713 [1500/2589 (58%)]\tLoss: 221.664352\n",
      "Train Epoch: 1713 [1800/2589 (70%)]\tLoss: 171.487625\n",
      "Train Epoch: 1713 [2100/2589 (81%)]\tLoss: 153.339401\n",
      "Train Epoch: 1713 [2400/2589 (93%)]\tLoss: 191.135483\n",
      "====> Epoch: 1713 Average train loss: 191.7900\n",
      "====> Epoch: 1713 Average test loss: 916.7828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1714 [0/2589 (0%)]\tLoss: 161.870224\n",
      "Train Epoch: 1714 [300/2589 (12%)]\tLoss: 478.614197\n",
      "Train Epoch: 1714 [600/2589 (23%)]\tLoss: 274.859406\n",
      "Train Epoch: 1714 [900/2589 (35%)]\tLoss: 288.822083\n",
      "Train Epoch: 1714 [1200/2589 (46%)]\tLoss: 136.281311\n",
      "Train Epoch: 1714 [1500/2589 (58%)]\tLoss: 205.758896\n",
      "Train Epoch: 1714 [1800/2589 (70%)]\tLoss: 160.031235\n",
      "Train Epoch: 1714 [2100/2589 (81%)]\tLoss: 190.357117\n",
      "Train Epoch: 1714 [2400/2589 (93%)]\tLoss: 128.689331\n",
      "====> Epoch: 1714 Average train loss: 213.1840\n",
      "====> Epoch: 1714 Average test loss: 910.2736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1715 [0/2589 (0%)]\tLoss: 230.573471\n",
      "Train Epoch: 1715 [300/2589 (12%)]\tLoss: 132.861893\n",
      "Train Epoch: 1715 [600/2589 (23%)]\tLoss: 165.008347\n",
      "Train Epoch: 1715 [900/2589 (35%)]\tLoss: 204.863525\n",
      "Train Epoch: 1715 [1200/2589 (46%)]\tLoss: 212.361359\n",
      "Train Epoch: 1715 [1500/2589 (58%)]\tLoss: 188.946091\n",
      "Train Epoch: 1715 [1800/2589 (70%)]\tLoss: 226.517487\n",
      "Train Epoch: 1715 [2100/2589 (81%)]\tLoss: 191.460709\n",
      "Train Epoch: 1715 [2400/2589 (93%)]\tLoss: 198.518890\n",
      "====> Epoch: 1715 Average train loss: 203.2440\n",
      "====> Epoch: 1715 Average test loss: 907.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1716 [0/2589 (0%)]\tLoss: 193.192154\n",
      "Train Epoch: 1716 [300/2589 (12%)]\tLoss: 158.678787\n",
      "Train Epoch: 1716 [600/2589 (23%)]\tLoss: 177.097427\n",
      "Train Epoch: 1716 [900/2589 (35%)]\tLoss: 207.085159\n",
      "Train Epoch: 1716 [1200/2589 (46%)]\tLoss: 229.816925\n",
      "Train Epoch: 1716 [1500/2589 (58%)]\tLoss: 251.696915\n",
      "Train Epoch: 1716 [1800/2589 (70%)]\tLoss: 172.810196\n",
      "Train Epoch: 1716 [2100/2589 (81%)]\tLoss: 235.466095\n",
      "Train Epoch: 1716 [2400/2589 (93%)]\tLoss: 286.489349\n",
      "====> Epoch: 1716 Average train loss: 205.6414\n",
      "====> Epoch: 1716 Average test loss: 905.2238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1717 [0/2589 (0%)]\tLoss: 149.782806\n",
      "Train Epoch: 1717 [300/2589 (12%)]\tLoss: 133.271957\n",
      "Train Epoch: 1717 [600/2589 (23%)]\tLoss: 205.575409\n",
      "Train Epoch: 1717 [900/2589 (35%)]\tLoss: 132.611877\n",
      "Train Epoch: 1717 [1200/2589 (46%)]\tLoss: 158.718231\n",
      "Train Epoch: 1717 [1500/2589 (58%)]\tLoss: 205.648376\n",
      "Train Epoch: 1717 [1800/2589 (70%)]\tLoss: 209.304001\n",
      "Train Epoch: 1717 [2100/2589 (81%)]\tLoss: 165.447235\n",
      "Train Epoch: 1717 [2400/2589 (93%)]\tLoss: 220.212814\n",
      "====> Epoch: 1717 Average train loss: 202.0493\n",
      "====> Epoch: 1717 Average test loss: 908.1368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1718 [0/2589 (0%)]\tLoss: 167.985321\n",
      "Train Epoch: 1718 [300/2589 (12%)]\tLoss: 159.750031\n",
      "Train Epoch: 1718 [600/2589 (23%)]\tLoss: 240.514984\n",
      "Train Epoch: 1718 [900/2589 (35%)]\tLoss: 188.040421\n",
      "Train Epoch: 1718 [1200/2589 (46%)]\tLoss: 154.570511\n",
      "Train Epoch: 1718 [1500/2589 (58%)]\tLoss: 203.449188\n",
      "Train Epoch: 1718 [1800/2589 (70%)]\tLoss: 257.641418\n",
      "Train Epoch: 1718 [2100/2589 (81%)]\tLoss: 279.349152\n",
      "Train Epoch: 1718 [2400/2589 (93%)]\tLoss: 125.894180\n",
      "====> Epoch: 1718 Average train loss: 210.7882\n",
      "====> Epoch: 1718 Average test loss: 923.9316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1719 [0/2589 (0%)]\tLoss: 187.595612\n",
      "Train Epoch: 1719 [300/2589 (12%)]\tLoss: 166.988037\n",
      "Train Epoch: 1719 [600/2589 (23%)]\tLoss: 159.516342\n",
      "Train Epoch: 1719 [900/2589 (35%)]\tLoss: 146.247467\n",
      "Train Epoch: 1719 [1200/2589 (46%)]\tLoss: 118.905609\n",
      "Train Epoch: 1719 [1500/2589 (58%)]\tLoss: 144.999115\n",
      "Train Epoch: 1719 [1800/2589 (70%)]\tLoss: 203.878418\n",
      "Train Epoch: 1719 [2100/2589 (81%)]\tLoss: 341.146942\n",
      "Train Epoch: 1719 [2400/2589 (93%)]\tLoss: 304.461914\n",
      "====> Epoch: 1719 Average train loss: 213.8688\n",
      "====> Epoch: 1719 Average test loss: 898.3596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1720 [0/2589 (0%)]\tLoss: 303.565643\n",
      "Train Epoch: 1720 [300/2589 (12%)]\tLoss: 153.044952\n",
      "Train Epoch: 1720 [600/2589 (23%)]\tLoss: 152.503067\n",
      "Train Epoch: 1720 [900/2589 (35%)]\tLoss: 192.940750\n",
      "Train Epoch: 1720 [1200/2589 (46%)]\tLoss: 179.117340\n",
      "Train Epoch: 1720 [1500/2589 (58%)]\tLoss: 188.243362\n",
      "Train Epoch: 1720 [1800/2589 (70%)]\tLoss: 187.243469\n",
      "Train Epoch: 1720 [2100/2589 (81%)]\tLoss: 265.583923\n",
      "Train Epoch: 1720 [2400/2589 (93%)]\tLoss: 172.623398\n",
      "====> Epoch: 1720 Average train loss: 196.8533\n",
      "====> Epoch: 1720 Average test loss: 900.3900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1721 [0/2589 (0%)]\tLoss: 223.390335\n",
      "Train Epoch: 1721 [300/2589 (12%)]\tLoss: 162.670639\n",
      "Train Epoch: 1721 [600/2589 (23%)]\tLoss: 206.718246\n",
      "Train Epoch: 1721 [900/2589 (35%)]\tLoss: 168.745941\n",
      "Train Epoch: 1721 [1200/2589 (46%)]\tLoss: 174.710648\n",
      "Train Epoch: 1721 [1500/2589 (58%)]\tLoss: 529.996948\n",
      "Train Epoch: 1721 [1800/2589 (70%)]\tLoss: 194.996872\n",
      "Train Epoch: 1721 [2100/2589 (81%)]\tLoss: 246.414230\n",
      "Train Epoch: 1721 [2400/2589 (93%)]\tLoss: 193.859650\n",
      "====> Epoch: 1721 Average train loss: 203.5793\n",
      "====> Epoch: 1721 Average test loss: 901.2606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1722 [0/2589 (0%)]\tLoss: 153.676270\n",
      "Train Epoch: 1722 [300/2589 (12%)]\tLoss: 197.797150\n",
      "Train Epoch: 1722 [600/2589 (23%)]\tLoss: 172.300339\n",
      "Train Epoch: 1722 [900/2589 (35%)]\tLoss: 133.003693\n",
      "Train Epoch: 1722 [1200/2589 (46%)]\tLoss: 175.855515\n",
      "Train Epoch: 1722 [1500/2589 (58%)]\tLoss: 183.050003\n",
      "Train Epoch: 1722 [1800/2589 (70%)]\tLoss: 241.119431\n",
      "Train Epoch: 1722 [2100/2589 (81%)]\tLoss: 240.213440\n",
      "Train Epoch: 1722 [2400/2589 (93%)]\tLoss: 169.185257\n",
      "====> Epoch: 1722 Average train loss: 210.2448\n",
      "====> Epoch: 1722 Average test loss: 917.8277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1723 [0/2589 (0%)]\tLoss: 216.610153\n",
      "Train Epoch: 1723 [300/2589 (12%)]\tLoss: 124.766396\n",
      "Train Epoch: 1723 [600/2589 (23%)]\tLoss: 224.646088\n",
      "Train Epoch: 1723 [900/2589 (35%)]\tLoss: 225.045563\n",
      "Train Epoch: 1723 [1200/2589 (46%)]\tLoss: 194.164627\n",
      "Train Epoch: 1723 [1500/2589 (58%)]\tLoss: 193.788528\n",
      "Train Epoch: 1723 [1800/2589 (70%)]\tLoss: 273.031952\n",
      "Train Epoch: 1723 [2100/2589 (81%)]\tLoss: 164.549088\n",
      "Train Epoch: 1723 [2400/2589 (93%)]\tLoss: 222.194504\n",
      "====> Epoch: 1723 Average train loss: 216.1579\n",
      "====> Epoch: 1723 Average test loss: 904.1768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1724 [0/2589 (0%)]\tLoss: 320.396393\n",
      "Train Epoch: 1724 [300/2589 (12%)]\tLoss: 158.057419\n",
      "Train Epoch: 1724 [600/2589 (23%)]\tLoss: 162.062225\n",
      "Train Epoch: 1724 [900/2589 (35%)]\tLoss: 186.832047\n",
      "Train Epoch: 1724 [1200/2589 (46%)]\tLoss: 189.321793\n",
      "Train Epoch: 1724 [1500/2589 (58%)]\tLoss: 166.579605\n",
      "Train Epoch: 1724 [1800/2589 (70%)]\tLoss: 193.261703\n",
      "Train Epoch: 1724 [2100/2589 (81%)]\tLoss: 149.733353\n",
      "Train Epoch: 1724 [2400/2589 (93%)]\tLoss: 298.490601\n",
      "====> Epoch: 1724 Average train loss: 203.5080\n",
      "====> Epoch: 1724 Average test loss: 905.6512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1725 [0/2589 (0%)]\tLoss: 187.462952\n",
      "Train Epoch: 1725 [300/2589 (12%)]\tLoss: 263.688782\n",
      "Train Epoch: 1725 [600/2589 (23%)]\tLoss: 260.999237\n",
      "Train Epoch: 1725 [900/2589 (35%)]\tLoss: 194.128479\n",
      "Train Epoch: 1725 [1200/2589 (46%)]\tLoss: 245.165665\n",
      "Train Epoch: 1725 [1500/2589 (58%)]\tLoss: 282.161346\n",
      "Train Epoch: 1725 [1800/2589 (70%)]\tLoss: 171.871811\n",
      "Train Epoch: 1725 [2100/2589 (81%)]\tLoss: 225.315414\n",
      "Train Epoch: 1725 [2400/2589 (93%)]\tLoss: 223.306900\n",
      "====> Epoch: 1725 Average train loss: 213.2376\n",
      "====> Epoch: 1725 Average test loss: 908.5316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1726 [0/2589 (0%)]\tLoss: 152.161072\n",
      "Train Epoch: 1726 [300/2589 (12%)]\tLoss: 162.398605\n",
      "Train Epoch: 1726 [600/2589 (23%)]\tLoss: 123.381348\n",
      "Train Epoch: 1726 [900/2589 (35%)]\tLoss: 213.663162\n",
      "Train Epoch: 1726 [1200/2589 (46%)]\tLoss: 218.031967\n",
      "Train Epoch: 1726 [1500/2589 (58%)]\tLoss: 206.654358\n",
      "Train Epoch: 1726 [1800/2589 (70%)]\tLoss: 199.508987\n",
      "Train Epoch: 1726 [2100/2589 (81%)]\tLoss: 168.012421\n",
      "Train Epoch: 1726 [2400/2589 (93%)]\tLoss: 192.560364\n",
      "====> Epoch: 1726 Average train loss: 210.9536\n",
      "====> Epoch: 1726 Average test loss: 899.6308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1727 [0/2589 (0%)]\tLoss: 131.541519\n",
      "Train Epoch: 1727 [300/2589 (12%)]\tLoss: 111.650146\n",
      "Train Epoch: 1727 [600/2589 (23%)]\tLoss: 290.425903\n",
      "Train Epoch: 1727 [900/2589 (35%)]\tLoss: 260.176331\n",
      "Train Epoch: 1727 [1200/2589 (46%)]\tLoss: 166.670959\n",
      "Train Epoch: 1727 [1500/2589 (58%)]\tLoss: 294.030792\n",
      "Train Epoch: 1727 [1800/2589 (70%)]\tLoss: 158.682159\n",
      "Train Epoch: 1727 [2100/2589 (81%)]\tLoss: 281.129883\n",
      "Train Epoch: 1727 [2400/2589 (93%)]\tLoss: 159.549774\n",
      "====> Epoch: 1727 Average train loss: 210.1145\n",
      "====> Epoch: 1727 Average test loss: 905.0306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1728 [0/2589 (0%)]\tLoss: 217.489304\n",
      "Train Epoch: 1728 [300/2589 (12%)]\tLoss: 191.452209\n",
      "Train Epoch: 1728 [600/2589 (23%)]\tLoss: 236.704590\n",
      "Train Epoch: 1728 [900/2589 (35%)]\tLoss: 191.961746\n",
      "Train Epoch: 1728 [1200/2589 (46%)]\tLoss: 203.138351\n",
      "Train Epoch: 1728 [1500/2589 (58%)]\tLoss: 137.481491\n",
      "Train Epoch: 1728 [1800/2589 (70%)]\tLoss: 171.915588\n",
      "Train Epoch: 1728 [2100/2589 (81%)]\tLoss: 235.622086\n",
      "Train Epoch: 1728 [2400/2589 (93%)]\tLoss: 144.567947\n",
      "====> Epoch: 1728 Average train loss: 208.2952\n",
      "====> Epoch: 1728 Average test loss: 903.0741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1729 [0/2589 (0%)]\tLoss: 137.001984\n",
      "Train Epoch: 1729 [300/2589 (12%)]\tLoss: 198.909256\n",
      "Train Epoch: 1729 [600/2589 (23%)]\tLoss: 340.075256\n",
      "Train Epoch: 1729 [900/2589 (35%)]\tLoss: 162.839142\n",
      "Train Epoch: 1729 [1200/2589 (46%)]\tLoss: 159.003952\n",
      "Train Epoch: 1729 [1500/2589 (58%)]\tLoss: 240.449539\n",
      "Train Epoch: 1729 [1800/2589 (70%)]\tLoss: 214.308121\n",
      "Train Epoch: 1729 [2100/2589 (81%)]\tLoss: 180.326950\n",
      "Train Epoch: 1729 [2400/2589 (93%)]\tLoss: 142.446228\n",
      "====> Epoch: 1729 Average train loss: 211.3607\n",
      "====> Epoch: 1729 Average test loss: 913.4113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1730 [0/2589 (0%)]\tLoss: 291.351257\n",
      "Train Epoch: 1730 [300/2589 (12%)]\tLoss: 167.041595\n",
      "Train Epoch: 1730 [600/2589 (23%)]\tLoss: 144.021896\n",
      "Train Epoch: 1730 [900/2589 (35%)]\tLoss: 191.945602\n",
      "Train Epoch: 1730 [1200/2589 (46%)]\tLoss: 229.424805\n",
      "Train Epoch: 1730 [1500/2589 (58%)]\tLoss: 189.433182\n",
      "Train Epoch: 1730 [1800/2589 (70%)]\tLoss: 195.622986\n",
      "Train Epoch: 1730 [2100/2589 (81%)]\tLoss: 183.877838\n",
      "Train Epoch: 1730 [2400/2589 (93%)]\tLoss: 131.101913\n",
      "====> Epoch: 1730 Average train loss: 205.4293\n",
      "====> Epoch: 1730 Average test loss: 893.1630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1731 [0/2589 (0%)]\tLoss: 196.596176\n",
      "Train Epoch: 1731 [300/2589 (12%)]\tLoss: 251.301605\n",
      "Train Epoch: 1731 [600/2589 (23%)]\tLoss: 240.088577\n",
      "Train Epoch: 1731 [900/2589 (35%)]\tLoss: 177.722137\n",
      "Train Epoch: 1731 [1200/2589 (46%)]\tLoss: 160.636200\n",
      "Train Epoch: 1731 [1500/2589 (58%)]\tLoss: 243.228500\n",
      "Train Epoch: 1731 [1800/2589 (70%)]\tLoss: 183.081543\n",
      "Train Epoch: 1731 [2100/2589 (81%)]\tLoss: 193.752304\n",
      "Train Epoch: 1731 [2400/2589 (93%)]\tLoss: 171.743607\n",
      "====> Epoch: 1731 Average train loss: 199.8691\n",
      "====> Epoch: 1731 Average test loss: 911.7784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1732 [0/2589 (0%)]\tLoss: 220.214157\n",
      "Train Epoch: 1732 [300/2589 (12%)]\tLoss: 241.504196\n",
      "Train Epoch: 1732 [600/2589 (23%)]\tLoss: 270.426636\n",
      "Train Epoch: 1732 [900/2589 (35%)]\tLoss: 237.935074\n",
      "Train Epoch: 1732 [1200/2589 (46%)]\tLoss: 167.932419\n",
      "Train Epoch: 1732 [1500/2589 (58%)]\tLoss: 208.622482\n",
      "Train Epoch: 1732 [1800/2589 (70%)]\tLoss: 218.725845\n",
      "Train Epoch: 1732 [2100/2589 (81%)]\tLoss: 174.376740\n",
      "Train Epoch: 1732 [2400/2589 (93%)]\tLoss: 172.123276\n",
      "====> Epoch: 1732 Average train loss: 209.0339\n",
      "====> Epoch: 1732 Average test loss: 908.2513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1733 [0/2589 (0%)]\tLoss: 165.038742\n",
      "Train Epoch: 1733 [300/2589 (12%)]\tLoss: 344.481262\n",
      "Train Epoch: 1733 [600/2589 (23%)]\tLoss: 175.124573\n",
      "Train Epoch: 1733 [900/2589 (35%)]\tLoss: 252.983200\n",
      "Train Epoch: 1733 [1200/2589 (46%)]\tLoss: 203.507538\n",
      "Train Epoch: 1733 [1500/2589 (58%)]\tLoss: 190.089081\n",
      "Train Epoch: 1733 [1800/2589 (70%)]\tLoss: 256.487152\n",
      "Train Epoch: 1733 [2100/2589 (81%)]\tLoss: 192.148895\n",
      "Train Epoch: 1733 [2400/2589 (93%)]\tLoss: 201.429428\n",
      "====> Epoch: 1733 Average train loss: 200.3170\n",
      "====> Epoch: 1733 Average test loss: 915.2012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1734 [0/2589 (0%)]\tLoss: 222.768036\n",
      "Train Epoch: 1734 [300/2589 (12%)]\tLoss: 230.997345\n",
      "Train Epoch: 1734 [600/2589 (23%)]\tLoss: 201.744095\n",
      "Train Epoch: 1734 [900/2589 (35%)]\tLoss: 246.083450\n",
      "Train Epoch: 1734 [1200/2589 (46%)]\tLoss: 178.043137\n",
      "Train Epoch: 1734 [1500/2589 (58%)]\tLoss: 161.293350\n",
      "Train Epoch: 1734 [1800/2589 (70%)]\tLoss: 160.683762\n",
      "Train Epoch: 1734 [2100/2589 (81%)]\tLoss: 188.277267\n",
      "Train Epoch: 1734 [2400/2589 (93%)]\tLoss: 247.904327\n",
      "====> Epoch: 1734 Average train loss: 212.0893\n",
      "====> Epoch: 1734 Average test loss: 899.0471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1735 [0/2589 (0%)]\tLoss: 193.745834\n",
      "Train Epoch: 1735 [300/2589 (12%)]\tLoss: 148.206696\n",
      "Train Epoch: 1735 [600/2589 (23%)]\tLoss: 274.449738\n",
      "Train Epoch: 1735 [900/2589 (35%)]\tLoss: 152.603485\n",
      "Train Epoch: 1735 [1200/2589 (46%)]\tLoss: 132.336380\n",
      "Train Epoch: 1735 [1500/2589 (58%)]\tLoss: 319.135193\n",
      "Train Epoch: 1735 [1800/2589 (70%)]\tLoss: 196.856186\n",
      "Train Epoch: 1735 [2100/2589 (81%)]\tLoss: 249.490631\n",
      "Train Epoch: 1735 [2400/2589 (93%)]\tLoss: 182.071152\n",
      "====> Epoch: 1735 Average train loss: 207.5990\n",
      "====> Epoch: 1735 Average test loss: 900.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1736 [0/2589 (0%)]\tLoss: 158.047226\n",
      "Train Epoch: 1736 [300/2589 (12%)]\tLoss: 189.456375\n",
      "Train Epoch: 1736 [600/2589 (23%)]\tLoss: 199.227280\n",
      "Train Epoch: 1736 [900/2589 (35%)]\tLoss: 203.975647\n",
      "Train Epoch: 1736 [1200/2589 (46%)]\tLoss: 203.703262\n",
      "Train Epoch: 1736 [1500/2589 (58%)]\tLoss: 352.028870\n",
      "Train Epoch: 1736 [1800/2589 (70%)]\tLoss: 145.427444\n",
      "Train Epoch: 1736 [2100/2589 (81%)]\tLoss: 247.769043\n",
      "Train Epoch: 1736 [2400/2589 (93%)]\tLoss: 299.440491\n",
      "====> Epoch: 1736 Average train loss: 218.3104\n",
      "====> Epoch: 1736 Average test loss: 906.5446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1737 [0/2589 (0%)]\tLoss: 185.816223\n",
      "Train Epoch: 1737 [300/2589 (12%)]\tLoss: 145.776260\n",
      "Train Epoch: 1737 [600/2589 (23%)]\tLoss: 198.292191\n",
      "Train Epoch: 1737 [900/2589 (35%)]\tLoss: 136.384293\n",
      "Train Epoch: 1737 [1200/2589 (46%)]\tLoss: 219.982117\n",
      "Train Epoch: 1737 [1500/2589 (58%)]\tLoss: 145.136978\n",
      "Train Epoch: 1737 [1800/2589 (70%)]\tLoss: 192.361130\n",
      "Train Epoch: 1737 [2100/2589 (81%)]\tLoss: 134.119492\n",
      "Train Epoch: 1737 [2400/2589 (93%)]\tLoss: 274.977051\n",
      "====> Epoch: 1737 Average train loss: 211.5712\n",
      "====> Epoch: 1737 Average test loss: 905.2820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1738 [0/2589 (0%)]\tLoss: 193.310165\n",
      "Train Epoch: 1738 [300/2589 (12%)]\tLoss: 171.190750\n",
      "Train Epoch: 1738 [600/2589 (23%)]\tLoss: 165.034256\n",
      "Train Epoch: 1738 [900/2589 (35%)]\tLoss: 180.636536\n",
      "Train Epoch: 1738 [1200/2589 (46%)]\tLoss: 147.386322\n",
      "Train Epoch: 1738 [1500/2589 (58%)]\tLoss: 138.512985\n",
      "Train Epoch: 1738 [1800/2589 (70%)]\tLoss: 213.822052\n",
      "Train Epoch: 1738 [2100/2589 (81%)]\tLoss: 180.076248\n",
      "Train Epoch: 1738 [2400/2589 (93%)]\tLoss: 427.180664\n",
      "====> Epoch: 1738 Average train loss: 201.5976\n",
      "====> Epoch: 1738 Average test loss: 891.5276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1739 [0/2589 (0%)]\tLoss: 221.308899\n",
      "Train Epoch: 1739 [300/2589 (12%)]\tLoss: 172.841949\n",
      "Train Epoch: 1739 [600/2589 (23%)]\tLoss: 168.532532\n",
      "Train Epoch: 1739 [900/2589 (35%)]\tLoss: 183.455811\n",
      "Train Epoch: 1739 [1200/2589 (46%)]\tLoss: 159.089676\n",
      "Train Epoch: 1739 [1500/2589 (58%)]\tLoss: 204.833115\n",
      "Train Epoch: 1739 [1800/2589 (70%)]\tLoss: 194.467194\n",
      "Train Epoch: 1739 [2100/2589 (81%)]\tLoss: 151.620422\n",
      "Train Epoch: 1739 [2400/2589 (93%)]\tLoss: 257.391937\n",
      "====> Epoch: 1739 Average train loss: 208.4431\n",
      "====> Epoch: 1739 Average test loss: 899.2979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1740 [0/2589 (0%)]\tLoss: 193.321152\n",
      "Train Epoch: 1740 [300/2589 (12%)]\tLoss: 189.801224\n",
      "Train Epoch: 1740 [600/2589 (23%)]\tLoss: 210.023773\n",
      "Train Epoch: 1740 [900/2589 (35%)]\tLoss: 236.558945\n",
      "Train Epoch: 1740 [1200/2589 (46%)]\tLoss: 212.086105\n",
      "Train Epoch: 1740 [1500/2589 (58%)]\tLoss: 144.850571\n",
      "Train Epoch: 1740 [1800/2589 (70%)]\tLoss: 218.875107\n",
      "Train Epoch: 1740 [2100/2589 (81%)]\tLoss: 166.779526\n",
      "Train Epoch: 1740 [2400/2589 (93%)]\tLoss: 273.602722\n",
      "====> Epoch: 1740 Average train loss: 211.5499\n",
      "====> Epoch: 1740 Average test loss: 927.0262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1741 [0/2589 (0%)]\tLoss: 166.872330\n",
      "Train Epoch: 1741 [300/2589 (12%)]\tLoss: 232.607437\n",
      "Train Epoch: 1741 [600/2589 (23%)]\tLoss: 170.139542\n",
      "Train Epoch: 1741 [900/2589 (35%)]\tLoss: 247.948730\n",
      "Train Epoch: 1741 [1200/2589 (46%)]\tLoss: 178.722565\n",
      "Train Epoch: 1741 [1500/2589 (58%)]\tLoss: 211.021194\n",
      "Train Epoch: 1741 [1800/2589 (70%)]\tLoss: 136.686523\n",
      "Train Epoch: 1741 [2100/2589 (81%)]\tLoss: 178.540848\n",
      "Train Epoch: 1741 [2400/2589 (93%)]\tLoss: 160.077545\n",
      "====> Epoch: 1741 Average train loss: 201.1925\n",
      "====> Epoch: 1741 Average test loss: 914.9241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1742 [0/2589 (0%)]\tLoss: 178.068802\n",
      "Train Epoch: 1742 [300/2589 (12%)]\tLoss: 210.440430\n",
      "Train Epoch: 1742 [600/2589 (23%)]\tLoss: 180.495285\n",
      "Train Epoch: 1742 [900/2589 (35%)]\tLoss: 270.535828\n",
      "Train Epoch: 1742 [1200/2589 (46%)]\tLoss: 152.376862\n",
      "Train Epoch: 1742 [1500/2589 (58%)]\tLoss: 189.521057\n",
      "Train Epoch: 1742 [1800/2589 (70%)]\tLoss: 192.441742\n",
      "Train Epoch: 1742 [2100/2589 (81%)]\tLoss: 223.148346\n",
      "Train Epoch: 1742 [2400/2589 (93%)]\tLoss: 229.546616\n",
      "====> Epoch: 1742 Average train loss: 212.9339\n",
      "====> Epoch: 1742 Average test loss: 912.4767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1743 [0/2589 (0%)]\tLoss: 269.760834\n",
      "Train Epoch: 1743 [300/2589 (12%)]\tLoss: 196.975525\n",
      "Train Epoch: 1743 [600/2589 (23%)]\tLoss: 233.727859\n",
      "Train Epoch: 1743 [900/2589 (35%)]\tLoss: 245.102310\n",
      "Train Epoch: 1743 [1200/2589 (46%)]\tLoss: 221.484940\n",
      "Train Epoch: 1743 [1500/2589 (58%)]\tLoss: 222.841934\n",
      "Train Epoch: 1743 [1800/2589 (70%)]\tLoss: 161.256027\n",
      "Train Epoch: 1743 [2100/2589 (81%)]\tLoss: 226.065918\n",
      "Train Epoch: 1743 [2400/2589 (93%)]\tLoss: 163.654144\n",
      "====> Epoch: 1743 Average train loss: 203.8825\n",
      "====> Epoch: 1743 Average test loss: 916.3754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1744 [0/2589 (0%)]\tLoss: 174.761749\n",
      "Train Epoch: 1744 [300/2589 (12%)]\tLoss: 197.407898\n",
      "Train Epoch: 1744 [600/2589 (23%)]\tLoss: 157.899200\n",
      "Train Epoch: 1744 [900/2589 (35%)]\tLoss: 308.461548\n",
      "Train Epoch: 1744 [1200/2589 (46%)]\tLoss: 195.917984\n",
      "Train Epoch: 1744 [1500/2589 (58%)]\tLoss: 307.103149\n",
      "Train Epoch: 1744 [1800/2589 (70%)]\tLoss: 184.220718\n",
      "Train Epoch: 1744 [2100/2589 (81%)]\tLoss: 169.529434\n",
      "Train Epoch: 1744 [2400/2589 (93%)]\tLoss: 186.265167\n",
      "====> Epoch: 1744 Average train loss: 208.0864\n",
      "====> Epoch: 1744 Average test loss: 910.7869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1745 [0/2589 (0%)]\tLoss: 210.707535\n",
      "Train Epoch: 1745 [300/2589 (12%)]\tLoss: 201.021301\n",
      "Train Epoch: 1745 [600/2589 (23%)]\tLoss: 203.030945\n",
      "Train Epoch: 1745 [900/2589 (35%)]\tLoss: 98.514481\n",
      "Train Epoch: 1745 [1200/2589 (46%)]\tLoss: 235.058578\n",
      "Train Epoch: 1745 [1500/2589 (58%)]\tLoss: 212.614777\n",
      "Train Epoch: 1745 [1800/2589 (70%)]\tLoss: 231.016647\n",
      "Train Epoch: 1745 [2100/2589 (81%)]\tLoss: 157.867477\n",
      "Train Epoch: 1745 [2400/2589 (93%)]\tLoss: 125.958374\n",
      "====> Epoch: 1745 Average train loss: 212.6174\n",
      "====> Epoch: 1745 Average test loss: 903.4056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1746 [0/2589 (0%)]\tLoss: 290.540375\n",
      "Train Epoch: 1746 [300/2589 (12%)]\tLoss: 185.566895\n",
      "Train Epoch: 1746 [600/2589 (23%)]\tLoss: 197.489059\n",
      "Train Epoch: 1746 [900/2589 (35%)]\tLoss: 214.041412\n",
      "Train Epoch: 1746 [1200/2589 (46%)]\tLoss: 220.630402\n",
      "Train Epoch: 1746 [1500/2589 (58%)]\tLoss: 235.897507\n",
      "Train Epoch: 1746 [1800/2589 (70%)]\tLoss: 181.561188\n",
      "Train Epoch: 1746 [2100/2589 (81%)]\tLoss: 282.122681\n",
      "Train Epoch: 1746 [2400/2589 (93%)]\tLoss: 247.133530\n",
      "====> Epoch: 1746 Average train loss: 207.6809\n",
      "====> Epoch: 1746 Average test loss: 903.8187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1747 [0/2589 (0%)]\tLoss: 422.068481\n",
      "Train Epoch: 1747 [300/2589 (12%)]\tLoss: 147.845459\n",
      "Train Epoch: 1747 [600/2589 (23%)]\tLoss: 235.297821\n",
      "Train Epoch: 1747 [900/2589 (35%)]\tLoss: 167.242813\n",
      "Train Epoch: 1747 [1200/2589 (46%)]\tLoss: 184.300980\n",
      "Train Epoch: 1747 [1500/2589 (58%)]\tLoss: 152.152328\n",
      "Train Epoch: 1747 [1800/2589 (70%)]\tLoss: 129.611160\n",
      "Train Epoch: 1747 [2100/2589 (81%)]\tLoss: 231.747833\n",
      "Train Epoch: 1747 [2400/2589 (93%)]\tLoss: 185.714294\n",
      "====> Epoch: 1747 Average train loss: 202.8393\n",
      "====> Epoch: 1747 Average test loss: 909.0262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1748 [0/2589 (0%)]\tLoss: 205.099960\n",
      "Train Epoch: 1748 [300/2589 (12%)]\tLoss: 136.469666\n",
      "Train Epoch: 1748 [600/2589 (23%)]\tLoss: 180.635834\n",
      "Train Epoch: 1748 [900/2589 (35%)]\tLoss: 188.983917\n",
      "Train Epoch: 1748 [1200/2589 (46%)]\tLoss: 220.661179\n",
      "Train Epoch: 1748 [1500/2589 (58%)]\tLoss: 171.727249\n",
      "Train Epoch: 1748 [1800/2589 (70%)]\tLoss: 168.749649\n",
      "Train Epoch: 1748 [2100/2589 (81%)]\tLoss: 184.131744\n",
      "Train Epoch: 1748 [2400/2589 (93%)]\tLoss: 189.757462\n",
      "====> Epoch: 1748 Average train loss: 196.9044\n",
      "====> Epoch: 1748 Average test loss: 898.4041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1749 [0/2589 (0%)]\tLoss: 180.490891\n",
      "Train Epoch: 1749 [300/2589 (12%)]\tLoss: 267.911774\n",
      "Train Epoch: 1749 [600/2589 (23%)]\tLoss: 143.960403\n",
      "Train Epoch: 1749 [900/2589 (35%)]\tLoss: 269.473633\n",
      "Train Epoch: 1749 [1200/2589 (46%)]\tLoss: 228.340561\n",
      "Train Epoch: 1749 [1500/2589 (58%)]\tLoss: 221.481125\n",
      "Train Epoch: 1749 [1800/2589 (70%)]\tLoss: 126.005569\n",
      "Train Epoch: 1749 [2100/2589 (81%)]\tLoss: 186.233109\n",
      "Train Epoch: 1749 [2400/2589 (93%)]\tLoss: 229.491119\n",
      "====> Epoch: 1749 Average train loss: 197.7253\n",
      "====> Epoch: 1749 Average test loss: 913.4178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1750 [0/2589 (0%)]\tLoss: 149.854950\n",
      "Train Epoch: 1750 [300/2589 (12%)]\tLoss: 214.442322\n",
      "Train Epoch: 1750 [600/2589 (23%)]\tLoss: 244.854004\n",
      "Train Epoch: 1750 [900/2589 (35%)]\tLoss: 156.257034\n",
      "Train Epoch: 1750 [1200/2589 (46%)]\tLoss: 256.922180\n",
      "Train Epoch: 1750 [1500/2589 (58%)]\tLoss: 223.290268\n",
      "Train Epoch: 1750 [1800/2589 (70%)]\tLoss: 174.972626\n",
      "Train Epoch: 1750 [2100/2589 (81%)]\tLoss: 203.068909\n",
      "Train Epoch: 1750 [2400/2589 (93%)]\tLoss: 261.895935\n",
      "====> Epoch: 1750 Average train loss: 217.3933\n",
      "====> Epoch: 1750 Average test loss: 908.6152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1751 [0/2589 (0%)]\tLoss: 121.765503\n",
      "Train Epoch: 1751 [300/2589 (12%)]\tLoss: 185.570099\n",
      "Train Epoch: 1751 [600/2589 (23%)]\tLoss: 190.611038\n",
      "Train Epoch: 1751 [900/2589 (35%)]\tLoss: 188.303665\n",
      "Train Epoch: 1751 [1200/2589 (46%)]\tLoss: 171.644821\n",
      "Train Epoch: 1751 [1500/2589 (58%)]\tLoss: 222.826920\n",
      "Train Epoch: 1751 [1800/2589 (70%)]\tLoss: 211.974319\n",
      "Train Epoch: 1751 [2100/2589 (81%)]\tLoss: 136.850082\n",
      "Train Epoch: 1751 [2400/2589 (93%)]\tLoss: 214.210922\n",
      "====> Epoch: 1751 Average train loss: 196.6665\n",
      "====> Epoch: 1751 Average test loss: 904.6111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1752 [0/2589 (0%)]\tLoss: 217.002823\n",
      "Train Epoch: 1752 [300/2589 (12%)]\tLoss: 143.965103\n",
      "Train Epoch: 1752 [600/2589 (23%)]\tLoss: 226.233994\n",
      "Train Epoch: 1752 [900/2589 (35%)]\tLoss: 191.701935\n",
      "Train Epoch: 1752 [1200/2589 (46%)]\tLoss: 133.037292\n",
      "Train Epoch: 1752 [1500/2589 (58%)]\tLoss: 186.329971\n",
      "Train Epoch: 1752 [1800/2589 (70%)]\tLoss: 203.511902\n",
      "Train Epoch: 1752 [2100/2589 (81%)]\tLoss: 236.216888\n",
      "Train Epoch: 1752 [2400/2589 (93%)]\tLoss: 206.383942\n",
      "====> Epoch: 1752 Average train loss: 205.9337\n",
      "====> Epoch: 1752 Average test loss: 899.7193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1753 [0/2589 (0%)]\tLoss: 196.437271\n",
      "Train Epoch: 1753 [300/2589 (12%)]\tLoss: 177.048050\n",
      "Train Epoch: 1753 [600/2589 (23%)]\tLoss: 325.465668\n",
      "Train Epoch: 1753 [900/2589 (35%)]\tLoss: 209.187668\n",
      "Train Epoch: 1753 [1200/2589 (46%)]\tLoss: 150.194763\n",
      "Train Epoch: 1753 [1500/2589 (58%)]\tLoss: 210.388763\n",
      "Train Epoch: 1753 [1800/2589 (70%)]\tLoss: 192.742737\n",
      "Train Epoch: 1753 [2100/2589 (81%)]\tLoss: 133.391861\n",
      "Train Epoch: 1753 [2400/2589 (93%)]\tLoss: 221.673203\n",
      "====> Epoch: 1753 Average train loss: 200.9830\n",
      "====> Epoch: 1753 Average test loss: 915.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1754 [0/2589 (0%)]\tLoss: 246.883972\n",
      "Train Epoch: 1754 [300/2589 (12%)]\tLoss: 323.679504\n",
      "Train Epoch: 1754 [600/2589 (23%)]\tLoss: 235.314682\n",
      "Train Epoch: 1754 [900/2589 (35%)]\tLoss: 134.878616\n",
      "Train Epoch: 1754 [1200/2589 (46%)]\tLoss: 336.371307\n",
      "Train Epoch: 1754 [1500/2589 (58%)]\tLoss: 175.092667\n",
      "Train Epoch: 1754 [1800/2589 (70%)]\tLoss: 200.034531\n",
      "Train Epoch: 1754 [2100/2589 (81%)]\tLoss: 266.369232\n",
      "Train Epoch: 1754 [2400/2589 (93%)]\tLoss: 151.139481\n",
      "====> Epoch: 1754 Average train loss: 212.2220\n",
      "====> Epoch: 1754 Average test loss: 900.2099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1755 [0/2589 (0%)]\tLoss: 141.995544\n",
      "Train Epoch: 1755 [300/2589 (12%)]\tLoss: 140.762100\n",
      "Train Epoch: 1755 [600/2589 (23%)]\tLoss: 146.258133\n",
      "Train Epoch: 1755 [900/2589 (35%)]\tLoss: 371.909515\n",
      "Train Epoch: 1755 [1200/2589 (46%)]\tLoss: 345.387543\n",
      "Train Epoch: 1755 [1500/2589 (58%)]\tLoss: 223.283691\n",
      "Train Epoch: 1755 [1800/2589 (70%)]\tLoss: 237.177582\n",
      "Train Epoch: 1755 [2100/2589 (81%)]\tLoss: 172.943222\n",
      "Train Epoch: 1755 [2400/2589 (93%)]\tLoss: 152.169189\n",
      "====> Epoch: 1755 Average train loss: 199.7422\n",
      "====> Epoch: 1755 Average test loss: 921.0311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1756 [0/2589 (0%)]\tLoss: 174.627899\n",
      "Train Epoch: 1756 [300/2589 (12%)]\tLoss: 189.623535\n",
      "Train Epoch: 1756 [600/2589 (23%)]\tLoss: 119.397270\n",
      "Train Epoch: 1756 [900/2589 (35%)]\tLoss: 180.510223\n",
      "Train Epoch: 1756 [1200/2589 (46%)]\tLoss: 228.263702\n",
      "Train Epoch: 1756 [1500/2589 (58%)]\tLoss: 165.316864\n",
      "Train Epoch: 1756 [1800/2589 (70%)]\tLoss: 178.282852\n",
      "Train Epoch: 1756 [2100/2589 (81%)]\tLoss: 167.297394\n",
      "Train Epoch: 1756 [2400/2589 (93%)]\tLoss: 330.639709\n",
      "====> Epoch: 1756 Average train loss: 206.0228\n",
      "====> Epoch: 1756 Average test loss: 907.1583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1757 [0/2589 (0%)]\tLoss: 178.618668\n",
      "Train Epoch: 1757 [300/2589 (12%)]\tLoss: 211.253281\n",
      "Train Epoch: 1757 [600/2589 (23%)]\tLoss: 181.628189\n",
      "Train Epoch: 1757 [900/2589 (35%)]\tLoss: 177.763824\n",
      "Train Epoch: 1757 [1200/2589 (46%)]\tLoss: 205.839401\n",
      "Train Epoch: 1757 [1500/2589 (58%)]\tLoss: 210.487061\n",
      "Train Epoch: 1757 [1800/2589 (70%)]\tLoss: 258.880798\n",
      "Train Epoch: 1757 [2100/2589 (81%)]\tLoss: 155.258072\n",
      "Train Epoch: 1757 [2400/2589 (93%)]\tLoss: 231.723251\n",
      "====> Epoch: 1757 Average train loss: 200.1277\n",
      "====> Epoch: 1757 Average test loss: 907.2674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1758 [0/2589 (0%)]\tLoss: 252.098969\n",
      "Train Epoch: 1758 [300/2589 (12%)]\tLoss: 166.226425\n",
      "Train Epoch: 1758 [600/2589 (23%)]\tLoss: 209.937820\n",
      "Train Epoch: 1758 [900/2589 (35%)]\tLoss: 199.290970\n",
      "Train Epoch: 1758 [1200/2589 (46%)]\tLoss: 357.819305\n",
      "Train Epoch: 1758 [1500/2589 (58%)]\tLoss: 269.000214\n",
      "Train Epoch: 1758 [1800/2589 (70%)]\tLoss: 196.579758\n",
      "Train Epoch: 1758 [2100/2589 (81%)]\tLoss: 527.821228\n",
      "Train Epoch: 1758 [2400/2589 (93%)]\tLoss: 165.237167\n",
      "====> Epoch: 1758 Average train loss: 214.7438\n",
      "====> Epoch: 1758 Average test loss: 911.6895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1759 [0/2589 (0%)]\tLoss: 198.036133\n",
      "Train Epoch: 1759 [300/2589 (12%)]\tLoss: 183.334915\n",
      "Train Epoch: 1759 [600/2589 (23%)]\tLoss: 230.687241\n",
      "Train Epoch: 1759 [900/2589 (35%)]\tLoss: 280.644470\n",
      "Train Epoch: 1759 [1200/2589 (46%)]\tLoss: 135.564102\n",
      "Train Epoch: 1759 [1500/2589 (58%)]\tLoss: 236.513947\n",
      "Train Epoch: 1759 [1800/2589 (70%)]\tLoss: 276.974915\n",
      "Train Epoch: 1759 [2100/2589 (81%)]\tLoss: 136.323105\n",
      "Train Epoch: 1759 [2400/2589 (93%)]\tLoss: 212.192291\n",
      "====> Epoch: 1759 Average train loss: 205.0695\n",
      "====> Epoch: 1759 Average test loss: 907.3621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1760 [0/2589 (0%)]\tLoss: 137.912857\n",
      "Train Epoch: 1760 [300/2589 (12%)]\tLoss: 261.363525\n",
      "Train Epoch: 1760 [600/2589 (23%)]\tLoss: 199.560287\n",
      "Train Epoch: 1760 [900/2589 (35%)]\tLoss: 185.946793\n",
      "Train Epoch: 1760 [1200/2589 (46%)]\tLoss: 225.030899\n",
      "Train Epoch: 1760 [1500/2589 (58%)]\tLoss: 185.392029\n",
      "Train Epoch: 1760 [1800/2589 (70%)]\tLoss: 150.713455\n",
      "Train Epoch: 1760 [2100/2589 (81%)]\tLoss: 193.836075\n",
      "Train Epoch: 1760 [2400/2589 (93%)]\tLoss: 198.961716\n",
      "====> Epoch: 1760 Average train loss: 193.7022\n",
      "====> Epoch: 1760 Average test loss: 915.9146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1761 [0/2589 (0%)]\tLoss: 167.407730\n",
      "Train Epoch: 1761 [300/2589 (12%)]\tLoss: 187.638702\n",
      "Train Epoch: 1761 [600/2589 (23%)]\tLoss: 437.038940\n",
      "Train Epoch: 1761 [900/2589 (35%)]\tLoss: 231.459885\n",
      "Train Epoch: 1761 [1200/2589 (46%)]\tLoss: 182.173203\n",
      "Train Epoch: 1761 [1500/2589 (58%)]\tLoss: 173.700287\n",
      "Train Epoch: 1761 [1800/2589 (70%)]\tLoss: 281.411346\n",
      "Train Epoch: 1761 [2100/2589 (81%)]\tLoss: 207.009125\n",
      "Train Epoch: 1761 [2400/2589 (93%)]\tLoss: 352.150330\n",
      "====> Epoch: 1761 Average train loss: 211.4265\n",
      "====> Epoch: 1761 Average test loss: 909.8811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1762 [0/2589 (0%)]\tLoss: 268.035736\n",
      "Train Epoch: 1762 [300/2589 (12%)]\tLoss: 194.874680\n",
      "Train Epoch: 1762 [600/2589 (23%)]\tLoss: 169.897171\n",
      "Train Epoch: 1762 [900/2589 (35%)]\tLoss: 289.944153\n",
      "Train Epoch: 1762 [1200/2589 (46%)]\tLoss: 167.228790\n",
      "Train Epoch: 1762 [1500/2589 (58%)]\tLoss: 177.313553\n",
      "Train Epoch: 1762 [1800/2589 (70%)]\tLoss: 181.376755\n",
      "Train Epoch: 1762 [2100/2589 (81%)]\tLoss: 174.715637\n",
      "Train Epoch: 1762 [2400/2589 (93%)]\tLoss: 218.859665\n",
      "====> Epoch: 1762 Average train loss: 205.1275\n",
      "====> Epoch: 1762 Average test loss: 918.4864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1763 [0/2589 (0%)]\tLoss: 196.067932\n",
      "Train Epoch: 1763 [300/2589 (12%)]\tLoss: 198.510086\n",
      "Train Epoch: 1763 [600/2589 (23%)]\tLoss: 237.119812\n",
      "Train Epoch: 1763 [900/2589 (35%)]\tLoss: 186.962326\n",
      "Train Epoch: 1763 [1200/2589 (46%)]\tLoss: 182.168625\n",
      "Train Epoch: 1763 [1500/2589 (58%)]\tLoss: 123.151001\n",
      "Train Epoch: 1763 [1800/2589 (70%)]\tLoss: 211.562958\n",
      "Train Epoch: 1763 [2100/2589 (81%)]\tLoss: 219.369675\n",
      "Train Epoch: 1763 [2400/2589 (93%)]\tLoss: 225.146164\n",
      "====> Epoch: 1763 Average train loss: 203.5250\n",
      "====> Epoch: 1763 Average test loss: 891.3377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1764 [0/2589 (0%)]\tLoss: 217.139694\n",
      "Train Epoch: 1764 [300/2589 (12%)]\tLoss: 246.415543\n",
      "Train Epoch: 1764 [600/2589 (23%)]\tLoss: 200.697296\n",
      "Train Epoch: 1764 [900/2589 (35%)]\tLoss: 381.124786\n",
      "Train Epoch: 1764 [1200/2589 (46%)]\tLoss: 137.569046\n",
      "Train Epoch: 1764 [1500/2589 (58%)]\tLoss: 171.000839\n",
      "Train Epoch: 1764 [1800/2589 (70%)]\tLoss: 148.153351\n",
      "Train Epoch: 1764 [2100/2589 (81%)]\tLoss: 194.963287\n",
      "Train Epoch: 1764 [2400/2589 (93%)]\tLoss: 194.474792\n",
      "====> Epoch: 1764 Average train loss: 205.3135\n",
      "====> Epoch: 1764 Average test loss: 911.7290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1765 [0/2589 (0%)]\tLoss: 154.318619\n",
      "Train Epoch: 1765 [300/2589 (12%)]\tLoss: 148.205032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-21da891e3d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#print(target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_mining/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "tr_x = '../data/rnn_train_x.npy'\n",
    "tr_y = '../data/rnn_train_y.npy'\n",
    "tet_x = '../data/rnn_test_x.npy'\n",
    "tet_y = '../data/rnn_test_y.npy'\n",
    "num_epochs = 2000\n",
    "batch_size = 30\n",
    "verbose = True\n",
    "# set models and loss\n",
    "#model = TS_rnn(num_inp = 1, num_hidden = 32, num_layers = 2, dropout = 0, num_dim_mlp = 16) # (self, num_inp = 13, num_hidden = 64, num_layers = 2, dropout = 0.5, num_dim_mlp = 16)\n",
    "model = MLP(num_inp = 44, num_hidden = 256, num_hidden2 = 64) # (self, num_inp = 1, num_hidden = 64, num_hidden2 = 16)\n",
    "#model = TS_rnn()\n",
    "#loss = PDLoss()\n",
    "loss = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)\n",
    "# set the scheduler\n",
    "lamb1 = lambda x: .1**(x//30)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda = lamb1)\n",
    "# loda data\n",
    "train = Data(tr_x, tr_y)\n",
    "test = Data(tet_x, tet_y)\n",
    "dl_train = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "dl_test = DataLoader(test, batch_size = batch_size, shuffle = True)\n",
    "#train the model\n",
    "for epoch in range(num_epochs):\n",
    "    #scheduler.step()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    counter = 0\n",
    "    for batch_idx, dat in enumerate(dl_train):\n",
    "        counter += 1\n",
    "        # train the model\n",
    "        optimizer.zero_grad()\n",
    "        inp, target = dat\n",
    "        #print('----------------')\n",
    "        out = model(inp)\n",
    "        #print(out.squeeze())\n",
    "        #print(target)\n",
    "        lo = loss(out.squeeze(), target)\n",
    "        lo.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += lo.data\n",
    "        if verbose:\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch,\n",
    "                    batch_idx * batch_size,\n",
    "                    len(train),\n",
    "                    100.*batch_idx*batch_size/len(train),\n",
    "                    lo.data\n",
    "                    ))\n",
    "    test_lo = test_model(dl_test, model, loss)\n",
    "    #hit_rate = significant_test(dl_test, model, loss)\n",
    "    if verbose:\n",
    "        # train loss\n",
    "        print('====> Epoch: {} Average train loss: {:.4f}'.format(\n",
    "            epoch,\n",
    "            train_loss/counter\n",
    "            ))\n",
    "        # test loss\n",
    "        print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
    "            epoch,\n",
    "            test_lo\n",
    "            ))\n",
    "        # significant test\n",
    "        #print('====> Epoch: {} Average hit rate in 10 candidate: {: .4f}'.format(\n",
    "        #    epoch,\n",
    "        #    hit_rate\n",
    "        #))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.from_numpy(test_x).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = out[:, -1]\n",
    "#out1 = test_y[:, -1, 0]\n",
    "out1= test_y[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2f107e80>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2f0fc9b0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out.data[100:200].numpy())\n",
    "plt.plot(out1[100:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a29260e10>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_y[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a29f0f828>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_x[:100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2589, 5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor()\n",
    "mlp = mlp.fit(train_x, train_y)\n",
    "out = mlp.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2900c710>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a28ffb668>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out[:100])\n",
    "plt.plot(test_y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
